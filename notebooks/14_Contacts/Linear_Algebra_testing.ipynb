{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EASY WAY OF FINDING PROJECTSION\n",
    "import numpy as np\n",
    "\n",
    "beta = np.linalg.inv(X.T.dot(X)).dot(X.T.dot(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calc_plane(x, y, z):\n",
    "    a = np.column_stack((x, y, np.ones_like(x)))\n",
    "    return np.linalg.lstsq(a, z)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function lstsq in module numpy.linalg:\n",
      "\n",
      "lstsq(a, b, rcond='warn')\n",
      "    Return the least-squares solution to a linear matrix equation.\n",
      "    \n",
      "    Solves the equation `a x = b` by computing a vector `x` that\n",
      "    minimizes the Euclidean 2-norm `|| b - a x ||^2`.  The equation may\n",
      "    be under-, well-, or over- determined (i.e., the number of\n",
      "    linearly independent rows of `a` can be less than, equal to, or\n",
      "    greater than its number of linearly independent columns).  If `a`\n",
      "    is square and of full rank, then `x` (but for round-off error) is\n",
      "    the \"exact\" solution of the equation.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : (M, N) array_like\n",
      "        \"Coefficient\" matrix.\n",
      "    b : {(M,), (M, K)} array_like\n",
      "        Ordinate or \"dependent variable\" values. If `b` is two-dimensional,\n",
      "        the least-squares solution is calculated for each of the `K` columns\n",
      "        of `b`.\n",
      "    rcond : float, optional\n",
      "        Cut-off ratio for small singular values of `a`.\n",
      "        For the purposes of rank determination, singular values are treated\n",
      "        as zero if they are smaller than `rcond` times the largest singular\n",
      "        value of `a`.\n",
      "    \n",
      "        .. versionchanged:: 1.14.0\n",
      "           If not set, a FutureWarning is given. The previous default\n",
      "           of ``-1`` will use the machine precision as `rcond` parameter,\n",
      "           the new default will use the machine precision times `max(M, N)`.\n",
      "           To silence the warning and use the new default, use ``rcond=None``,\n",
      "           to keep using the old behavior, use ``rcond=-1``.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    x : {(N,), (N, K)} ndarray\n",
      "        Least-squares solution. If `b` is two-dimensional,\n",
      "        the solutions are in the `K` columns of `x`.\n",
      "    residuals : {(1,), (K,), (0,)} ndarray\n",
      "        Sums of residuals; squared Euclidean 2-norm for each column in\n",
      "        ``b - a*x``.\n",
      "        If the rank of `a` is < N or M <= N, this is an empty array.\n",
      "        If `b` is 1-dimensional, this is a (1,) shape array.\n",
      "        Otherwise the shape is (K,).\n",
      "    rank : int\n",
      "        Rank of matrix `a`.\n",
      "    s : (min(M, N),) ndarray\n",
      "        Singular values of `a`.\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    LinAlgError\n",
      "        If computation does not converge.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    If `b` is a matrix, then all array results are returned as matrices.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Fit a line, ``y = mx + c``, through some noisy data-points:\n",
      "    \n",
      "    >>> x = np.array([0, 1, 2, 3])\n",
      "    >>> y = np.array([-1, 0.2, 0.9, 2.1])\n",
      "    \n",
      "    By examining the coefficients, we see that the line should have a\n",
      "    gradient of roughly 1 and cut the y-axis at, more or less, -1.\n",
      "    \n",
      "    We can rewrite the line equation as ``y = Ap``, where ``A = [[x 1]]``\n",
      "    and ``p = [[m], [c]]``.  Now use `lstsq` to solve for `p`:\n",
      "    \n",
      "    >>> A = np.vstack([x, np.ones(len(x))]).T\n",
      "    >>> A\n",
      "    array([[ 0.,  1.],\n",
      "           [ 1.,  1.],\n",
      "           [ 2.,  1.],\n",
      "           [ 3.,  1.]])\n",
      "    \n",
      "    >>> m, c = np.linalg.lstsq(A, y, rcond=None)[0]\n",
      "    >>> print(m, c)\n",
      "    1.0 -0.95\n",
      "    \n",
      "    Plot the data along with the fitted line:\n",
      "    \n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> plt.plot(x, y, 'o', label='Original data', markersize=10)\n",
      "    >>> plt.plot(x, m*x + c, 'r', label='Fitted line')\n",
      "    >>> plt.legend()\n",
      "    >>> plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Research on functions\n",
    "#help(np.column_stack) #takes 1D arrays and stacks them as columns into a 2D array\n",
    "#help(np.ones_like) #returns an array of ones with same shape as given array\n",
    "help(np.linalg.lstsq) #returns least-squared solution to linear matrix equation of the form Ax + b\n",
    "a = np.ndarray([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
