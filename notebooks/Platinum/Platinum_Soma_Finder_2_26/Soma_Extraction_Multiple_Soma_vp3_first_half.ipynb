{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTesting out the full soma extraction\\n\\nPseudocode for Algorithm: \\nLoad in mesh\\nSplit mesh into largest pieces: \\n    Iterate through all mesh pieces of a certain threshold\\n    Do the Poisson surface reconstruction:\\n    Find all the mesh pieces of a certain threshold:\\n        (Optional step) Run the screened poisson surface reconstruction\\n        Run the segmentation algorithm\\n        Identify all somas\\n        Save of the soma meshes\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing out the full soma extraction\n",
    "\n",
    "Pseudocode for Algorithm: \n",
    "Load in mesh\n",
    "Split mesh into largest pieces: \n",
    "    Iterate through all mesh pieces of a certain threshold\n",
    "    Do the Poisson surface reconstruction:\n",
    "    Find all the mesh pieces of a certain threshold:\n",
    "        (Optional step) Run the screened poisson surface reconstruction\n",
    "        Run the segmentation algorithm\n",
    "        Identify all somas\n",
    "        Save of the soma meshes\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cgal_Segmentation_Module as csm\n",
    "from whole_neuron_classifier_datajoint_adapted import extract_branches_whole_neuron\n",
    "import whole_neuron_classifier_datajoint_adapted as wcda \n",
    "import time\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_meshlab_script(mlx_script,input_mesh_file,output_mesh_file):\n",
    "    script_command = (\" -i \" + str(input_mesh_file) + \" -o \" + \n",
    "                                    str(output_mesh_file) + \" -s \" + str(mlx_script))\n",
    "    #return script_command\n",
    "    command_to_run = 'xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@ ' + script_command\n",
    "    #command_to_run = 'meshlabserver ' + script_command\n",
    "    \n",
    "    print(command_to_run)\n",
    "    subprocess_result = subprocess.run(command_to_run,shell=True)\n",
    "    \n",
    "    return subprocess_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, contextlib\n",
    "import pathlib\n",
    "import subprocess\n",
    "def meshlab_fix_manifold_path_specific_mls(input_path_and_filename,\n",
    "                                           output_path_and_filename=\"\",\n",
    "                                           segment_id=-1,meshlab_script=\"\"):\n",
    "    #fix the path if it comes with the extension\n",
    "    if input_path_and_filename[-4:] == \".off\":\n",
    "        path_and_filename = input_path_and_filename[:-4]\n",
    "        input_mesh = input_path_and_filename\n",
    "    else:\n",
    "        raise Exception(\"Not passed off file\")\n",
    "    \n",
    "    \n",
    "    if output_path_and_filename == \"\":\n",
    "        output_mesh = path_and_filename+\"_mls.off\"\n",
    "    else:\n",
    "        output_mesh = output_path_and_filename\n",
    "    \n",
    "    if meshlab_script == \"\":\n",
    "        meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"remeshing_remove_non_man_edges.mls\"\n",
    "    \n",
    "    #print(\"meshlab_script = \" + str(meshlab_script))\n",
    "    #print(\"starting meshlabserver fixing non-manifolds\")\n",
    "    subprocess_result_1 = run_meshlab_script(meshlab_script,\n",
    "                      input_mesh,\n",
    "                      output_mesh)\n",
    "    #print(\"Poisson subprocess_result= \"+ str(subprocess_result_1))\n",
    "    \n",
    "    if str(subprocess_result_1)[-13:] != \"returncode=0)\":\n",
    "        raise Exception('neuron' + str(segment_id) + \n",
    "                         ' did not fix the manifold edges')\n",
    "    \n",
    "    return output_mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "def run_poisson_surface_reconstruction(pre_largest_mesh_path,\n",
    "                                       segment_id = \"None\",\n",
    "                                      script_name = \"poisson_working_meshlab.mls\"):\n",
    "\n",
    "    \"\"\"\n",
    "    Will run the poisson surface reconstruction\n",
    "    \n",
    "    \"\"\"\n",
    "    # run the meshlab server script\n",
    "\n",
    "    meshlab_script_path_and_name = str(pathlib.Path.cwd()) + \"/\" + script_name\n",
    "    input_path =str(pathlib.Path.cwd()) + \"/\" +  pre_largest_mesh_path\n",
    "\n",
    "    indices = [i for i, a in enumerate(input_path) if a == \"_\"]\n",
    "    stripped_ending = input_path[:-4]\n",
    "\n",
    "    output_path = stripped_ending + \"_mls.off\"\n",
    "    # print(meshlab_script_path_and_name)\n",
    "    # print(input_path)\n",
    "    # print(output_path)\n",
    "    print(\"Running the mls function\")\n",
    "    meshlab_fix_manifold_path_specific_mls(input_path_and_filename=input_path,\n",
    "                                               output_path_and_filename=output_path,\n",
    "                                               segment_id=segment_id,\n",
    "                                               meshlab_script=meshlab_script_path_and_name)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decimation Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decimate_mesh_from_verts_faces(vertices,faces,segment_id,current_folder):\n",
    "    #write the file to the temp folder\n",
    "    input_file_base = write_Whole_Neuron_Off_file(vertices,faces,segment_id,folder=current_folder)\n",
    "    output_file = input_file_base + \"_decimated\"\n",
    "    \n",
    "    script_name = \"decimation_meshlab.mls\"\n",
    "    meshlab_script_path_and_name = str(pathlib.Path.cwd()) + \"/\" + script_name\n",
    "\n",
    "\n",
    "    meshlab_fix_manifold_path_specific_mls(input_path_and_filename=input_file_base + \".off\",\n",
    "                                                       output_path_and_filename=output_file + \".off\",\n",
    "                                                       meshlab_script=meshlab_script_path_and_name)\n",
    "    \n",
    "    #read in the output mesh and return the vertices and faces\n",
    "    current_mesh = trimesh.load_mesh(output_file + '.off')\n",
    "    \n",
    "    #check if file exists and then delete the temporary decimated mesh filess\n",
    "    if os.path.exists(input_file_base + \".off\"):\n",
    "        os.remove(input_file_base + \".off\")\n",
    "    if os.path.exists(output_file + \".off\"):\n",
    "        os.remove(output_file + \".off\")\n",
    " \n",
    "    return current_mesh.vertices,current_mesh.faces\n",
    "\n",
    "def decimate_mesh_from_path(arg_path):\n",
    "    #write the file to the temp folder\n",
    "    input_file_base = arg_path[:-4]\n",
    "    output_file = input_file_base + \"_decimated\"\n",
    "    \n",
    "    script_name = \"decimation_meshlab.mls\"\n",
    "    meshlab_script_path_and_name = str(pathlib.Path.cwd()) + \"/\" + script_name\n",
    "\n",
    "\n",
    "    meshlab_fix_manifold_path_specific_mls(input_path_and_filename=input_file_base + \".off\",\n",
    "                                                       output_path_and_filename=output_file + \".off\",\n",
    "                                                       meshlab_script=meshlab_script_path_and_name)\n",
    "    \n",
    "    #read in the output mesh and return the vertices and faces\n",
    "    current_mesh = trimesh.load_mesh(output_file + '.off')\n",
    "    \n",
    "#     #check if file exists and then delete the temporary decimated mesh filess\n",
    "#     if os.path.exists(input_file_base + \".off\"):\n",
    "#         os.remove(input_file_base + \".off\")\n",
    "#     if os.path.exists(output_file + \".off\"):\n",
    "#         os.remove(output_file + \".off\")\n",
    " \n",
    "    return current_mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1) Import mesh and find all the significant pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 110778132960975016_stitched.off\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Setting up the mesh file and the output files\n",
    "\"\"\"\n",
    "\n",
    "total_test_meshes = [\n",
    "'110778132960975016_stitched.off']\n",
    "\n",
    "output_file = total_test_meshes[0]\n",
    "folder_name = \"soma_extraction_tests_vp1/\" \n",
    "\n",
    "output_mesh_name = folder_name + output_file\n",
    "print(f\"Working on {output_file}\")\n",
    "\n",
    "indices = [i for i, a in enumerate(output_file) if a == \"_\"]\n",
    "indices\n",
    "seg_id_stripped = output_file[:indices[0]]\n",
    "n = dict(segment_id=int(seg_id_stripped))\n",
    "segment_id = int(seg_id_stripped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pseudocode: \n",
    "1) Split the mesh into significant pieces\n",
    "2) For each significant piece:\n",
    "    1) Run the poisson surface reconstruction\n",
    "    2) Split the poisson surface reconstruction into significant pieces\n",
    "    3) For these signficant inner pieces:\n",
    "        a. Run the cgal segmentation on it\n",
    "        b. Try to identify a soma\n",
    "        c. Break out of inner loop if went\n",
    "        through 2 significant poisson splits in a row and not found soma\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2) Run the loop that does soma identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 60000.0 \n",
      "large_mesh_threshold_inner = 4000.0 \n",
      "soma_size_threshold = 1000.0\n",
      "decimation_ratio = 0.05\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(852479, 3), faces.shape=(1715638, 3))>, <trimesh.Trimesh(vertices.shape=(430196, 3), faces.shape=(858554, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(852479, 3), faces.shape=(1715638, 3))>\n",
      "done exporting\n",
      "Running the mls function\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/soma_extraction_tests_vp1/110778132960975016_stitched_0_largest_piece.off -o /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/soma_extraction_tests_vp1/110778132960975016_stitched_0_largest_piece_mls.off -s /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/poisson_working_meshlab.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh lengths of inner after split: [39190, 26384, 23124, 12948, 3634, 2224, 1870, 1534, 1360, 1302, 1294, 1272, 1260, 1234, 1134, 1064, 1026, 1014, 1002, 998, 980, 976, 976, 846, 826, 746, 742, 736, 736, 726, 722, 716, 716, 708, 702, 698, 696, 648, 646, 632, 612, 610, 588, 584, 556, 544, 544, 544, 540, 538, 536, 528, 524, 524, 522, 518, 518, 512, 506, 502, 500, 492, 490, 472, 470, 466, 464, 460, 458, 458, 456, 456, 456, 454, 448, 444, 440, 440, 440, 438, 436, 428, 426, 424, 424, 424, 424, 420, 418, 410, 404, 396, 396, 396, 394, 394, 388, 386, 386, 386, 384, 382, 380, 380, 380, 378, 378, 374, 372, 370, 370, 368, 368, 368, 366, 366, 360, 360, 358, 358, 356, 354, 354, 352, 352, 352, 350, 350, 348, 348, 344, 344, 344, 340, 340, 338, 338, 338, 338, 338, 336, 332, 332, 332, 330, 330, 328, 328, 328, 328, 326, 326, 324, 322, 322, 322, 320, 320, 318, 316, 316, 314, 312, 312, 312, 310, 310, 310, 308, 308, 308, 308, 308, 308, 308, 306, 304, 302, 302, 300, 300, 300, 298, 296, 296, 296, 296, 294, 294, 292, 292, 290, 288, 288, 288, 288, 288, 286, 284, 284, 284, 284, 282, 280, 280, 280, 280, 278, 278, 276, 276, 274, 274, 274, 274, 270, 270, 270, 270, 270, 270, 268, 266, 264, 264, 264, 264, 262, 262, 260, 260, 260, 260, 260, 260, 260, 258, 258, 256, 256, 256, 254, 254, 254, 254, 252, 252, 252, 252, 252, 252, 252, 250, 250, 250, 250, 250, 250, 248, 248, 248, 248, 248, 248, 248, 246, 246, 244, 244, 244, 244, 244, 244, 244, 244, 242, 242, 242, 242, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 238, 238, 238, 238, 238, 236, 236, 236, 236, 236, 236, 236, 236, 236, 234, 234, 232, 232, 232, 232, 232, 232, 232, 230, 230, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 226, 226, 226, 226, 224, 224, 224, 224, 224, 224, 224, 224, 222, 220, 220, 220, 220, 220, 220, 220, 218, 218, 218, 218, 218, 216, 216, 216, 216, 216, 216, 216, 214, 214, 212, 212, 212, 212, 212, 212, 212, 212, 212, 210, 210, 210, 210, 210, 208, 208, 208, 208, 208, 208, 206, 206, 206, 206, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 202, 202, 202, 202, 202, 202, 202, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 198, 198, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 194, 194, 194, 194, 194, 194, 194, 194, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 190, 190, 190, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 186, 186, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 184, 182, 182, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 178, 178, 178, 178, 178, 178, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 174, 174, 174, 174, 174, 174, 174, 174, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 170, 170, 170, 170, 170, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 166, 166, 166, 166, 166, 166, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 162, 162, 162, 162, 162, 162, 162, 162, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 158, 158, 158, 158, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 154, 154, 154, 154, 154, 154, 154, 154, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 150, 150, 150, 150, 150, 150, 150, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 146, 146, 146, 146, 146, 146, 146, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 142, 142, 142, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 138, 138, 138, 138, 138, 138, 138, 138, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 134, 134, 134, 134, 134, 134, 134, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 130, 130, 130, 130, 130, 130, 130, 130, 130, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 126, 126, 126, 126, 126, 126, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 110, 110, 110, 110, 110, 110, 110, 110, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 98, 98, 98, 98, 98, 98, 98, 98, 98, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 94, 94, 94, 94, 94, 94, 94, 94, 94, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 90, 90, 90, 90, 90, 90, 90, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 82, 82, 82, 82, 82, 82, 82, 82, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 78, 78, 78, 78, 78, 78, 78, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 74, 74, 74, 74, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 66, 66, 66, 66, 66, 66, 66, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 58, 58, 58, 58, 58, 58, 58, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 54, 54, 54, 54, 54, 54, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 46, 46, 46, 46, 46, 46, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 42, 42, 42, 42, 42, 42, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 34, 34, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 30, 30, 30, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 26, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 14, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(19585, 3), faces.shape=(39190, 3))>, <trimesh.Trimesh(vertices.shape=(13194, 3), faces.shape=(26384, 3))>, <trimesh.Trimesh(vertices.shape=(11564, 3), faces.shape=(23124, 3))>, <trimesh.Trimesh(vertices.shape=(6476, 3), faces.shape=(12948, 3))>]\n",
      "stripped_ending 2 = /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/soma_extraction_tests_vp1/110778132960975016_stitched_0_largest_piece_mls\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(19585, 3), faces.shape=(39190, 3))>\n",
      "done exporting /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/soma_extraction_tests_vp1/110778132960975016_stitched_0_largest_piece_mls_0_largest_inner.off\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/soma_extraction_tests_vp1/110778132960975016_stitched_0_largest_piece_mls_0_largest_inner.off -o /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/soma_extraction_tests_vp1/110778132960975016_stitched_0_largest_piece_mls_0_largest_inner_decimated.off -s /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/decimation_meshlab.mls\n",
      "done exporting decimated mesh: /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/soma_extraction_tests_vp1/110778132960975016_stitched_0_largest_piece_mls_0_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0007216930389404297\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/temp/11077813296097501600_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 1.1032485961914062\n",
      "2) Finished: Generating CGAL segmentation for neuron: 1.43086838722229\n",
      "3) Staring: Generating Graph Structure and Identifying Soma\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.005533695220947266\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'soma', 'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00010132789611816406\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.011409282684326172\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.07337737083435059\n",
      "Returning the soma_sdf value AND the classifier\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 5,  0,  2,  6,  1,  9, 10,  8,  4, 11,  3,  7]), array([0.343535  , 0.175936  , 0.169778  , 0.1623595 , 0.1623    ,\n",
      "       0.140884  , 0.1348825 , 0.1171785 , 0.110782  , 0.083365  ,\n",
      "       0.0470147 , 0.03997585]))\n",
      "      ------ Found 1 viable somas: [5]\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(13194, 3), faces.shape=(26384, 3))>\n",
      "done exporting /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/soma_extraction_tests_vp1/110778132960975016_stitched_0_largest_piece_mls_1_largest_inner.off\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/soma_extraction_tests_vp1/110778132960975016_stitched_0_largest_piece_mls_1_largest_inner.off -o /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/soma_extraction_tests_vp1/110778132960975016_stitched_0_largest_piece_mls_1_largest_inner_decimated.off -s /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/decimation_meshlab.mls\n",
      "done exporting decimated mesh: /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/soma_extraction_tests_vp1/110778132960975016_stitched_0_largest_piece_mls_1_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0004572868347167969\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/temp/11077813296097501601_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.6325869560241699\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.8124470710754395\n",
      "3) Staring: Generating Graph Structure and Identifying Soma\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0028564929962158203\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 7.915496826171875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.008424043655395508\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.036644697189331055\n",
      "Returning the soma_sdf value AND the classifier\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 2, 7, 4, 1, 6, 8, 3, 5]), array([0.802637  , 0.246069  , 0.159051  , 0.066702  , 0.06413135,\n",
      "       0.0640791 , 0.06074605, 0.0450605 , 0.0378221 ]))\n",
      "      ------ Found 1 viable somas: [0]\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(11564, 3), faces.shape=(23124, 3))>\n",
      "done exporting /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/soma_extraction_tests_vp1/110778132960975016_stitched_0_largest_piece_mls_2_largest_inner.off\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/soma_extraction_tests_vp1/110778132960975016_stitched_0_largest_piece_mls_2_largest_inner.off -o /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/soma_extraction_tests_vp1/110778132960975016_stitched_0_largest_piece_mls_2_largest_inner_decimated.off -s /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/decimation_meshlab.mls\n",
      "done exporting decimated mesh: /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/soma_extraction_tests_vp1/110778132960975016_stitched_0_largest_piece_mls_2_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008573532104492188\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/temp/11077813296097501602_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.6801073551177979\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.8526298999786377\n",
      "3) Staring: Generating Graph Structure and Identifying Soma\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.002410888671875\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0017104148864746094\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.006489992141723633\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.03184628486633301\n",
      "Returning the soma_sdf value AND the classifier\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 4, 2, 3, 6, 5, 1, 7]), array([0.8871595, 0.0699139, 0.068266 , 0.0524131, 0.0491677, 0.0473692,\n",
      "       0.0426555, 0.0188257]))\n",
      "      ------ Found 1 viable somas: [0]\n",
      "----- working on mesh after poisson #3: <trimesh.Trimesh(vertices.shape=(6476, 3), faces.shape=(12948, 3))>\n",
      "done exporting /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/soma_extraction_tests_vp1/110778132960975016_stitched_0_largest_piece_mls_3_largest_inner.off\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/soma_extraction_tests_vp1/110778132960975016_stitched_0_largest_piece_mls_3_largest_inner.off -o /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/soma_extraction_tests_vp1/110778132960975016_stitched_0_largest_piece_mls_3_largest_inner_decimated.off -s /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/decimation_meshlab.mls\n",
      "done exporting decimated mesh: /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/soma_extraction_tests_vp1/110778132960975016_stitched_0_largest_piece_mls_3_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0005030632019042969\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Soma_Finder_2_26/temp/11077813296097501603_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.34743452072143555\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.44011735916137695\n",
      "3) Staring: Generating Graph Structure and Identifying Soma\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0014350414276123047\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0011320114135742188\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0033674240112304688\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.02042412757873535\n",
      "Returning the soma_sdf value AND the classifier\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 5, 2, 4, 3, 6]), array([0.8466065, 0.0944426, 0.0844768, 0.0467399, 0.043021 , 0.0290599,\n",
      "       0.026304 ]))\n",
      "      ------ Found 1 viable somas: [0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loop that will compute the soma meshes and locations\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ------------parameters------------------\n",
    "decimation_ratio = 0.1\n",
    "large_mesh_threshold = 600000\n",
    "large_mesh_threshold_inner = 40000\n",
    "soma_width_threshold = 0.32\n",
    "soma_size_threshold = 10000\n",
    "\n",
    "large_mesh_threshold = large_mesh_threshold*decimation_ratio\n",
    "large_mesh_threshold_inner = large_mesh_threshold_inner*decimation_ratio\n",
    "soma_size_threshold = soma_size_threshold*decimation_ratio\n",
    "\n",
    "decimation_ratio = 0.05\n",
    "print(f\"Current Arguments Using (adjusted for decimation):\\n large_mesh_threshold= {large_mesh_threshold}\"\n",
    "             f\" \\nlarge_mesh_threshold_inner = {large_mesh_threshold_inner} \\nsoma_size_threshold = {soma_size_threshold}\"\n",
    "             f\"\\ndecimation_ratio = {decimation_ratio}\")\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "\n",
    "\n",
    "\"\"\" New step: add decimation: \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "new_mesh = trimesh.load_mesh(output_mesh_name)\n",
    "mesh_splits = new_mesh.split(only_watertight=False)\n",
    "\n",
    "#len(\"Total mesh splits = \" + str(mesh_splits))\n",
    "#get the largest mesh\n",
    "mesh_lengths = np.array([len(split.faces) for split in mesh_splits])\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.set()\n",
    "# sns.distplot(mesh_lengths)\n",
    "\n",
    "largest_index = np.where(mesh_lengths == np.max(mesh_lengths))\n",
    "largest_mesh = mesh_splits[largest_index][0]\n",
    "\n",
    "\"\"\" -- temporarily changing to the second largest mesh\"\"\"\n",
    "total_mesh_split_lengths = [len(k.faces) for k in mesh_splits]\n",
    "ordered_mesh_splits = mesh_splits[np.flip(np.argsort(total_mesh_split_lengths))]\n",
    "list_of_largest_mesh = [k for k in ordered_mesh_splits if len(k.faces) > large_mesh_threshold]\n",
    "\n",
    "print(f\"Total found significant pieces before Poisson = {list_of_largest_mesh}\")\n",
    "\n",
    "# total_soma_mesh = trimesh.Trimesh(vertices=np.array([]),\n",
    "#                                  triangles = np.array([]))\n",
    "\n",
    "total_soma_list = []\n",
    "total_classifier_list = []\n",
    "total_poisson_list = []\n",
    "\n",
    "#start iterating through \n",
    "no_somas_found_in_big_loop = 0\n",
    "for i,largest_mesh in enumerate(list_of_largest_mesh):\n",
    "    if i == 1:\n",
    "        continue\n",
    "    print(f\"----- working on large mesh #{i}: {largest_mesh}\")\n",
    "    \n",
    "    somas_found_in_big_loop = False\n",
    "\n",
    "    stripped_ending = output_mesh_name[:-4]\n",
    "    pre_largest_mesh_path = stripped_ending + \"_\" + str(i) + \"_largest_piece.off\"\n",
    "\n",
    "    largest_mesh.export(pre_largest_mesh_path)\n",
    "    print(\"done exporting\")\n",
    "    \n",
    "    output_path = run_poisson_surface_reconstruction(pre_largest_mesh_path)\n",
    "    \n",
    "    #---------------- Will carry out the cgal segmentation -------- #\n",
    "    #import the mesh\n",
    "    new_mesh_inner = trimesh.load_mesh(output_path)\n",
    "    \n",
    "    mesh_splits_inner = new_mesh_inner.split(only_watertight=False)\n",
    "    total_mesh_split_lengths_inner = [len(k.faces) for k in mesh_splits_inner]\n",
    "    ordered_mesh_splits_inner = mesh_splits_inner[np.flip(np.argsort(total_mesh_split_lengths_inner))]\n",
    "    print(f\"Mesh lengths of inner after split: {[len(k.faces) for k in ordered_mesh_splits_inner]}\")\n",
    "\n",
    "    list_of_largest_mesh_inner = [k for k in ordered_mesh_splits_inner if len(k.faces) > large_mesh_threshold_inner]\n",
    "    print(f\"Total found significant pieces AFTER Poisson = {list_of_largest_mesh_inner}\")\n",
    "    \n",
    "    stripped_ending = output_path[:-4]\n",
    "    print(f\"stripped_ending 2 = {stripped_ending}\")\n",
    "    n_failed_inner_soma_loops = 0\n",
    "    for j, largest_mesh_inner in enumerate(list_of_largest_mesh_inner):\n",
    "\n",
    "        print(f\"----- working on mesh after poisson #{j}: {largest_mesh_inner}\")\n",
    "        \n",
    "        largest_mesh_path_inner = stripped_ending +\"_\" + str(j) + \"_largest_inner.off\"\n",
    "\n",
    "        #DON'T NEED THIS WRITE NOW BECAUSE IT ALREADY OUTPUTS THE MESH\n",
    "        largest_mesh_inner.export(largest_mesh_path_inner)\n",
    "        print(f\"done exporting {largest_mesh_path_inner}\")\n",
    "        \n",
    "        largest_mesh_path_inner_decimated = decimate_mesh_from_path(largest_mesh_path_inner)\n",
    "        largest_mesh_path_inner_decimated.export(largest_mesh_path_inner[:-4] + \"_decimated.off\")\n",
    "        print(f\"done exporting decimated mesh: {largest_mesh_path_inner}\")\n",
    "        # Starts the actual cgal segmentation:\n",
    "        \n",
    "        faces = np.array(largest_mesh_path_inner_decimated.faces)\n",
    "        verts = np.array(largest_mesh_path_inner_decimated.vertices)\n",
    "        #run the whole algorithm on the neuron to test\n",
    "        segment_id_new = int(str(segment_id) + f\"{i}{j}\")\n",
    "        verts_labels, faces_labels, soma_value,classifier = wcda.extract_branches_whole_neuron(\n",
    "                            import_Off_Flag=False,\n",
    "                            segment_id=segment_id_new,\n",
    "                            vertices=verts,\n",
    "                             triangles=faces,\n",
    "                            pymeshfix_Flag=False,\n",
    "                             import_CGAL_Flag=False,\n",
    "                             return_Only_Labels=True,\n",
    "                             clusters=3,\n",
    "                             smoothness=0.2,\n",
    "                            soma_only=True,\n",
    "                            return_classifier = True\n",
    "                            )\n",
    "        \n",
    "        total_classifier_list.append(classifier)\n",
    "        #total_poisson_list.append(largest_mesh_path_inner_decimated)\n",
    "\n",
    "        # Save all of the portions that resemble a soma\n",
    "        median_values = np.array([v[\"median\"] for k,v in classifier.sdf_final_dict.items()])\n",
    "        segmentation = np.array([k for k,v in classifier.sdf_final_dict.items()])\n",
    "\n",
    "        #order the compartments by greatest to smallest\n",
    "        sorted_medians = np.flip(np.argsort(median_values))\n",
    "        print(f\"segmentation[sorted_medians],median_values[sorted_medians] = {(segmentation[sorted_medians],median_values[sorted_medians])}\")\n",
    "        valid_soma_segments_width = [g for g,h in zip(segmentation[sorted_medians],median_values[sorted_medians]) if ((h > soma_width_threshold)\n",
    "                                                            and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold))]\n",
    "        \n",
    "        \n",
    "        to_add_list = []\n",
    "        if len(valid_soma_segments_width) > 0:\n",
    "            print(f\"      ------ Found {len(valid_soma_segments_width)} viable somas: {valid_soma_segments_width}\")\n",
    "            somas_found_in_big_loop = True\n",
    "            #get the meshes only if signfiicant length\n",
    "            labels_list = classifier.labels_list\n",
    "            \n",
    "            for v in valid_soma_segments_width:\n",
    "                submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "                soma_mesh = largest_mesh_path_inner_decimated.submesh([submesh_face_list],append=True)\n",
    "                to_add_list.append(soma_mesh)\n",
    "\n",
    "\n",
    "            n_failed_inner_soma_loops = 0\n",
    "            \n",
    "        else:\n",
    "            n_failed_inner_soma_loops += 1\n",
    "        \n",
    "        total_soma_list.append(to_add_list)\n",
    "        \n",
    "        # --------------- KEEP TRACK IF FAILED TO FIND SOMA (IF TOO MANY FAILS THEN BREAK)\n",
    "        if n_failed_inner_soma_loops >= 2:\n",
    "            print(\"breaking inner loop because 2 soma fails in a row\")\n",
    "            break\n",
    "        \n",
    "    \n",
    "    # --------------- KEEP TRACK IF FAILED TO FIND SOMA (IF TOO MANY FAILS THEN BREAK)\n",
    "    if somas_found_in_big_loop == False:\n",
    "        no_somas_found_in_big_loop += 1\n",
    "        if no_somas_found_in_big_loop >= 2:\n",
    "            print(\"breaking because 2 fails in a row in big loop\")\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        no_somas_found_in_big_loop = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.savez(\"saved_4_neuron_mesh.npz\",total_soma_list = total_soma_list,total_classifier_list = total_classifier_list, total_poisson_list = total_poisson_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<trimesh.Trimesh(vertices.shape=(1330, 3), faces.shape=(2649, 3))>],\n",
       " [<trimesh.Trimesh(vertices.shape=(1067, 3), faces.shape=(2097, 3))>],\n",
       " [<trimesh.Trimesh(vertices.shape=(1302, 3), faces.shape=(2576, 3))>],\n",
       " [<trimesh.Trimesh(vertices.shape=(887, 3), faces.shape=(1758, 3))>]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_soma_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,s in enumerate(total_soma_list):\n",
    "    s[0].export(f\"mesh_soma_{i}.off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
