{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "#for supressing the output\n",
    "import os, contextlib\n",
    "import pathlib\n",
    "import subprocess\n",
    "\n",
    "#for error counting\n",
    "from collections import Counter\n",
    "\n",
    "#for reading in the new raw_skeleton files\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "#for filtering\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@10.28.0.34:3306\n"
     ]
    }
   ],
   "source": [
    "#setting the address and the username\n",
    "dj.config['database.host'] = '10.28.0.34'\n",
    "dj.config['database.user'] = 'celiib'\n",
    "dj.config['database.password'] = 'newceliipass'\n",
    "dj.config['safemode']=True\n",
    "dj.config[\"display.limit\"] = 20\n",
    "\n",
    "schema = dj.schema('microns_pinky')\n",
    "schema_fc = dj.schema('microns_pinky_fc')\n",
    "pinky = dj.create_virtual_module('pinky', 'microns_pinky')\n",
    "pinky_nda = dj.create_virtual_module('pinky_nda', 'microns_pinky_nda')\n",
    "pinky_radtune = dj.create_virtual_module('pinky_radtune', 'microns_pinky_radtune')\n",
    "pinky_spattune = dj.create_virtual_module('pinky_spattune', 'microns_pinky_spattune')\n",
    "pinky_fc = dj.create_virtual_module('pinky_fc', 'microns_pinky_fc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates the pearson correlation and cosine similarity while accounting for the corner cases\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "\n",
    "def check_nan(v1,v2):\n",
    "    if np.isscalar(v1):\n",
    "        if np.isnan(v1) or v1 == None:\n",
    "            return True\n",
    "    else:\n",
    "        if True in np.isnan(v1) or len(v1) <= 0:\n",
    "            return True\n",
    "        \n",
    "    if np.isscalar(v2):\n",
    "        if np.isnan(v2) or v2 == None:\n",
    "            return True\n",
    "    else:\n",
    "        if True in np.isnan(v2) or len(v2) <= 0:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def find_pearson_old(v1,v2):\n",
    "    v1 = v1.astype(\"float\")\n",
    "    v2 = v2.astype(\"float\")\n",
    "    print(\"v1 = \" + str(v1))\n",
    "    print(\"v2 = \" + str(v2))\n",
    "    if check_nan(v1,v2):\n",
    "        return np.NaN\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        if np.array_equal(v1,v2):\n",
    "            return 1\n",
    "        elif abs(sum(v1 - v2)) >= v1.size:\n",
    "            return -1\n",
    "        else:\n",
    "            #perform the pearson correlation\n",
    "            corr_conversion, p_value_conversion = pearsonr(v1, v2)\n",
    "            return corr_conversion\n",
    "\n",
    "def find_cosine_old(v1,v2):\n",
    "    v1 = v1.astype(\"float\")\n",
    "    v2 = v2.astype(\"float\")\n",
    "    if check_nan(v1,v2):\n",
    "        return np.NaN\n",
    "    if np.array_equal(v1,v2):\n",
    "        return 1\n",
    "    elif abs(sum(v1 - v2)) == v1.size:\n",
    "        return 0\n",
    "    else:\n",
    "        v1 = v1.reshape(1,len(v1))\n",
    "        v2 = v2.reshape(1,len(v2))\n",
    "        return cosine_similarity(v1, v2)[0][0]\n",
    "\n",
    "\n",
    "\n",
    "def find_pearson(v1,v2):\n",
    "    v1 = v1.astype(\"float\")\n",
    "    v2 = v2.astype(\"float\")\n",
    "#     print(\"v1 = \" + str(v1))\n",
    "#     print(\"v2 = \" + str(v2))\n",
    "    if check_nan(v1,v2):\n",
    "        return np.NaN\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        #perform the pearson correlation\n",
    "        if v1.size <= 1 or v2.size <= 1:\n",
    "            return np.NaN\n",
    "        if np.array_equal(v1,v2):\n",
    "            return 1\n",
    "        elif abs(sum(v1 - v2)) >= v1.size:\n",
    "            return -1\n",
    "        else:\n",
    "            corr_conversion, p_value_conversion = pearsonr(v1, v2)\n",
    "            return corr_conversion\n",
    "\n",
    "def find_cosine(v1,v2):\n",
    "    v1 = v1.astype(\"float\")\n",
    "    v2 = v2.astype(\"float\")\n",
    "    if check_nan(v1,v2):\n",
    "        return np.NaN\n",
    "    if v1.size <= 1 or v2.size <= 1:\n",
    "            return np.NaN\n",
    "    if np.array_equal(v1,v2):\n",
    "        return 1\n",
    "    elif abs(sum(v1 - v2)) == v1.size:\n",
    "        return 0\n",
    "    else:\n",
    "        v1 = v1.reshape(1,len(v1))\n",
    "        v2 = v2.reshape(1,len(v2))\n",
    "        return cosine_similarity(v1, v2)[0][0]\n",
    "\n",
    "def find_binary_sim(v1,v2):\n",
    "    v1 = v1.astype(\"float\")\n",
    "    v2 = v2.astype(\"float\")\n",
    "    if check_nan(v1,v2):\n",
    "            return np.NaN\n",
    "    a = np.dot(v1,v2)\n",
    "    b = np.dot(1-v1,v2)\n",
    "    c = np.dot(v1,1-v2)\n",
    "    d = np.dot(1-v1,1-v2)\n",
    "    \n",
    "    return (a)/(a + b + c + d),(a + d)/(a + b + c + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema_fc\n",
    "class ContactCorrelation(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> pinky.Segment\n",
    "    segment_b :bigint unsigned #id of the postsynaptic neuron\n",
    "    ---\n",
    "    n_seg_a              :bigint unsigned #n_presyns contacting onto segment_id\n",
    "    n_seg_b              :bigint unsigned #n_presyns contacting onto segment_b\n",
    "    n_seg_shared           :bigint unsigned #n_presyns contacting onto both segment_id and segment_b\n",
    "    n_seg_union            :bigint unsigned #n_presyns contacting either segment_id or segment_b\n",
    "    n_seg_shared_converted :bigint unsigned #n_presyns contacting onto both and converting on at least 1 postsyn\n",
    "    n_seg_a_converted      :bigint unsigned #n_presyns contacting onto both and converting on postsyna a\n",
    "    n_seg_a_converted_prop=null :float           #proportion of n_presyns contacting onto both which convert at least onto postsyna a\n",
    "    n_seg_b_converted      :bigint unsigned #n_presyns contacting onto both and converting on postsyna b\n",
    "    n_seg_b_converted_prop=null :float           #proportion of n_presyns contacting onto both which convert at least onto postsyna b\n",
    "    binary_conversion_pearson=null :float   #pearson correlation for binary n_synapse/n_contact rate\n",
    "    binary_conversion_cosine=null :float    #cosine similarity correlation for binary n_synapse/n_contact rate\n",
    "    binary_conv_jaccard_ones_ratio=null :float   #a / (a + b + c  + d) for jaccard similarity of binary conversion rate\n",
    "    binary_conv_jaccard_matching_ratio=null :float  # ( a + d )/ (a + b + c  + d) for jaccard similarity of binary conversion rate\n",
    "    conversion_pearson=null :float          #Pearson correlation for n_synapse/n_contact rate\n",
    "    conversion_cosine=null :float           #cosine similarity for n_synapse/n_contact rate\n",
    "    density_pearson=null :float             #Pearson correlation for n_synapse/postsyn_length rate\n",
    "    density_cosine=null :float              #cosine similarity for n_synapse/postsyn_length rate\n",
    "    synapse_volume_mean_pearson=null :float     #Pearson correlation for mean of synaptic volume\n",
    "    synapse_volume_mean_cosine=null :float      #cosine similarity for mean of synaptic volume\n",
    "    synapse_vol_density_pearson=null :float         #Pearson correlation for n_synapses*synapse_sizes_mean/postsyn_length rate\n",
    "    synapse_vol_density_cosine=null :float          #cosine similarity for n_synapses*synapse_sizes_mean/postsyn_length rate\n",
    "    binary_conversion_pearson_converted=null :float   #pearson correlation for binary n_synapse/n_contact rate for axon group with at least 1 conversion\n",
    "    binary_conversion_cosine_converted=null :float    #cosine similarity correlation for binary n_synapse/n_contact rate for axon group with at least 1 conversion\n",
    "    binary_conv_jaccard_ones_ratio_converted=null :float   #a / (a + b + c  + d) for jaccard similarity of binary conversion rate with at least 1 conversion\n",
    "    binary_conv_jaccard_matching_ratio_converted=null :float  # ( a + d )/ (a + b + c  + d) for jaccard similarity of binary conversion rate with at least 1 conversion\n",
    "    conversion_pearson_converted=null :float          #Pearson correlation for n_synapse/n_contact rate for axon group with at least 1 conversion\n",
    "    conversion_cosine_converted=null :float           #cosine similarity for n_synapse/n_contact rate for axon group with at least 1 conversion\n",
    "    density_pearson_converted=null :float             #Pearson correlation for n_synapse/postsyn_length rate for axon group with at least 1 conversion\n",
    "    density_cosine_converted=null :float              #cosine similarity for n_synapse/postsyn_length rate for axon group with at least 1 conversion\n",
    "    synapse_volume_mean_pearson_converted=null :float     #Pearson correlation for mean of synaptic volume for axon group with at least 1 conversion\n",
    "    synapse_volume_mean_cosine_converted=null :float      #cosine similarity for mean of synaptic volume for axon group with at least 1 conversion\n",
    "    synapse_vol_density_pearson_converted=null :float         #Pearson correlation for n_synapses*synapse_sizes_mean/postsyn_length rate for axon group with at least 1 conversion\n",
    "    synapse_vol_density_cosine_converted=null :float          #cosine similarity for n_synapses*synapse_sizes_mean/postsyn_length rate for axon group with at least 1 conversion\n",
    "    \"\"\"\n",
    "\n",
    "    key_source = pinky.Segmentation & pinky.CurrentSegmentation\n",
    "    \n",
    "    def make(self,key):\n",
    "        #Retrieves the PrePost table that will be using in an all in one insertion (MAY HAVE TO ADJUST FOR BIGGER DATA SETS IN FUTURE)\n",
    "        prepost_data = pinky_fc.ContactPrePost.proj(\"postsyn\",\"total_contact_conversion\",\n",
    "                \"total_contact_density\",\"total_synapse_sizes_mean\",\n",
    "                syn_density=\"if(total_postsyn_length=0,null,(total_n_synapses*total_synapse_sizes_mean)/total_postsyn_length)\",\n",
    "                presyn=\"segment_id\").fetch()\n",
    "        df = pd.DataFrame(prepost_data)\n",
    "\n",
    "        #gets all the combinations of postsyn-postsyn without any repeats\n",
    "        targets = (dj.U(\"postsyn\") & pinky.SkeletonContact).proj(segment_id=\"postsyn\") - pinky.SegmentExclude\n",
    "        info = targets * targets.proj(segment_b='segment_id') & 'segment_id < segment_b'\n",
    "        segment_pairs = info.fetch()\n",
    "        \n",
    "        total_correlations = []\n",
    "        print(\"About to start postsyn1,postsyn2\")\n",
    "        \n",
    "        \n",
    "        for i,posts in tqdm(enumerate(segment_pairs)):\n",
    "            index = 4\n",
    "            multiple = 24231\n",
    "            if i < index*multiple:\n",
    "                continue\n",
    "            if i > (index+1)*multiple:\n",
    "                break\n",
    "            \n",
    "            postsyn1,postsyn2 = posts\n",
    "            \n",
    "            start_time = time.time()\n",
    "\n",
    "            #print(\"postsyn1 = \" + str(postsyn1))\n",
    "            #print(\"postsyn2 = \" + str(postsyn2))\n",
    "\n",
    "            #get all of the rows with postsyn 1 and 2 AKA find the number of presyns for each\n",
    "            df_1 = df[df[\"postsyn\"].to_numpy()==postsyn1]\n",
    "            df_2 = df[df[\"postsyn\"].to_numpy()==postsyn2]\n",
    "\n",
    "            #reduce both tables down to common presyns\n",
    "            df_1_common = df_1[df_1[\"presyn\"].isin(df_2[\"presyn\"].to_numpy())].sort_values(by=['presyn'])\n",
    "            df_2_common = df_2[df_2[\"presyn\"].isin(df_1[\"presyn\"].to_numpy())].sort_values(by=['presyn'])\n",
    "\n",
    "\n",
    "            ###########------------------------------------------------------###########\n",
    "            #need to get the common axons that have at least one converted contact on one of the postsyns\n",
    "            \"\"\"pseudocode\n",
    "            #get the conversion rates for both tables\n",
    "            #add them up\n",
    "            #get the indices that are greater than 0\n",
    "            #get the presyn ids that match those rows\n",
    "            #further restrict both groups by those ids\n",
    "            \"\"\"\n",
    "\n",
    "            #get both of their conversion rates\n",
    "            test_1_conv = df_1_common[\"total_contact_conversion\"].to_numpy()\n",
    "            test_2_conv = df_2_common[\"total_contact_conversion\"].to_numpy()\n",
    "\n",
    "            test_1_presyn = df_1_common[\"presyn\"].to_numpy()\n",
    "            new_presyns = test_1_presyn[(test_1_conv + test_2_conv) > 0]\n",
    "\n",
    "            df_1_common_converted = df_1_common[df_1_common[\"presyn\"].isin(new_presyns)]\n",
    "            df_2_common_converted = df_2_common[df_2_common[\"presyn\"].isin(new_presyns)]\n",
    "            ###########------------------------------------------------------###########\n",
    "\n",
    "\n",
    "            #finds the number of segments, shared_segments and union segments\n",
    "            n_seg_a = df_1.shape[0]\n",
    "            n_seg_b = df_2.shape[0]\n",
    "            n_seg_shared = df_1_common.shape[0]\n",
    "            n_seg_shared_converted = df_1_common_converted.shape[0]\n",
    "            n_seg_union = n_seg_a + n_seg_b - n_seg_shared\n",
    "            \n",
    "            \n",
    "            #get the number and proportion on presyns that convert onto each segment inside the converted axon group\n",
    "            if n_seg_shared_converted > 0:\n",
    "                test_1_conv[test_1_conv>1] = 1\n",
    "                n_seg_a_converted = sum(np.ceil(test_1_conv))\n",
    "                test_2_conv[test_2_conv>1] = 1\n",
    "                n_seg_b_converted = sum(np.ceil(test_2_conv))\n",
    "\n",
    "                n_seg_a_converted_prop = n_seg_a_converted/n_seg_shared_converted\n",
    "                n_seg_b_converted_prop = n_seg_b_converted/n_seg_shared_converted\n",
    "            else:\n",
    "                n_seg_a_converted = 0\n",
    "                n_seg_b_converted = 0\n",
    "                n_seg_a_converted_prop = np.NaN\n",
    "                n_seg_b_converted_prop = np.NaN\n",
    "     \n",
    "            dict_segmenation=2\n",
    "            dict_segment_id=postsyn1\n",
    "            dict_segment_b=postsyn2\n",
    "            #initialize the dictionary that will be saved:\n",
    "            corr_dict = dict(segmentation=3,segment_id=postsyn1,\n",
    "                                          segment_b=postsyn2,\n",
    "                                          n_seg_a=n_seg_a,\n",
    "                                            n_seg_b=n_seg_b,\n",
    "                                            n_seg_shared=n_seg_shared,\n",
    "                                            n_seg_shared_converted=n_seg_shared_converted,\n",
    "                                            n_seg_union=n_seg_union,\n",
    "                                            n_seg_a_converted=n_seg_a_converted,\n",
    "                                            n_seg_b_converted=n_seg_b_converted,\n",
    "                                            n_seg_a_converted_prop=n_seg_a_converted_prop,\n",
    "                                            n_seg_b_converted_prop=n_seg_b_converted_prop)\n",
    "\n",
    "            #initialize the variables that need to be set in the dictionary\n",
    "\n",
    "            #ones that are set by 1st group\n",
    "            binary_conversion_pearson = np.NaN\n",
    "            binary_conversion_cosine = np.NaN\n",
    "            binary_conv_jaccard_ones_ratio = np.NaN\n",
    "            binary_conv_jaccard_matching_ratio = np.NaN\n",
    "            conversion_pearson = np.NaN\n",
    "            conversion_cosine = np.NaN\n",
    "            density_pearson = np.NaN\n",
    "            density_cosine = np.NaN\n",
    "            synapse_volume_mean_pearson = np.NaN\n",
    "            synapse_volume_mean_cosine = np.NaN\n",
    "            synapse_vol_density_pearson = np.NaN\n",
    "            synapse_vol_density_cosine = np.NaN\n",
    "\n",
    "            #ones that are set by 2nd group\n",
    "            binary_conversion_pearson_converted = np.NaN\n",
    "            binary_conversion_cosine_converted = np.NaN\n",
    "            binary_conv_jaccard_ones_ratio_converted = np.NaN\n",
    "            binary_conv_jaccard_matching_ratio_converted = np.NaN\n",
    "            conversion_pearson_converted = np.NaN\n",
    "            conversion_cosine_converted = np.NaN\n",
    "            density_pearson_converted = np.NaN\n",
    "            density_cosine_converted = np.NaN\n",
    "            synapse_volume_mean_pearson_converted = np.NaN\n",
    "            synapse_volume_mean_cosine_converted = np.NaN\n",
    "            synapse_vol_density_pearson_converted = np.NaN\n",
    "            synapse_vol_density_cosine_converted = np.NaN\n",
    "\n",
    "\n",
    "            if (not df_1_common.to_numpy().any()) or (not df_2_common.to_numpy().any()):\n",
    "                #total_correlations.append(corr_dict)\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                #retrieve the conversion rates\n",
    "                df_1_common_conversion = df_1_common[\"total_contact_conversion\"].to_numpy()\n",
    "                df_2_common_conversion = df_2_common[\"total_contact_conversion\"].to_numpy()\n",
    "                \n",
    "                #calculate the binary conversion rates\n",
    "                df_1_common_binary_conversion = np.copy(df_1_common_conversion)\n",
    "                df_2_common_binary_conversion = np.copy(df_2_common_conversion)\n",
    "\n",
    "                df_1_common_binary_conversion[df_1_common_binary_conversion>0] = 1.0\n",
    "                df_2_common_binary_conversion[df_2_common_binary_conversion>0] = 1.0\n",
    "                \n",
    "                #retrieve the synapse/postsyn_len\n",
    "                df_1_common_density = df_1_common[\"total_contact_density\"].to_numpy()\n",
    "                df_2_common_density = df_2_common[\"total_contact_density\"].to_numpy()\n",
    "\n",
    "                #retrieve mean of synapse_size\n",
    "                df_1_common_synaptic_size = df_1_common[\"total_synapse_sizes_mean\"].to_numpy()\n",
    "                df_2_common_synaptic_size = df_2_common[\"total_synapse_sizes_mean\"].to_numpy()\n",
    "\n",
    "                #retrieve (total_n_synapses*total_synapse_sizes_mean)/total_postsyn_length\n",
    "                df_1_common_syn_density = df_1_common[\"syn_density\"].to_numpy()\n",
    "                df_2_common_syn_density = df_2_common[\"syn_density\"].to_numpy()\n",
    "\n",
    "                binary_conversion_pearson = find_pearson(df_1_common_binary_conversion, df_2_common_binary_conversion)\n",
    "                binary_conversion_cosine = find_cosine(df_1_common_binary_conversion, df_2_common_binary_conversion)\n",
    "                \n",
    "                #new added metric for the binary calculations based on jacard_similarity\n",
    "                binary_conv_jaccard_ones_ratio,binary_conv_jaccard_matching_ratio = find_binary_sim(df_1_common_binary_conversion,df_2_common_binary_conversion)\n",
    "                \n",
    "                conversion_pearson = find_pearson(df_1_common_conversion, df_2_common_conversion)\n",
    "                conversion_cosine = find_cosine(df_1_common_conversion, df_2_common_conversion)\n",
    "                density_pearson = find_pearson(df_1_common_density, df_2_common_density)\n",
    "                density_cosine = find_cosine(df_1_common_density, df_2_common_density)\n",
    "                synapse_volume_mean_pearson = find_pearson(df_1_common_synaptic_size, df_2_common_synaptic_size)\n",
    "                synapse_volume_mean_cosine = find_cosine(df_1_common_synaptic_size, df_2_common_synaptic_size)\n",
    "                synapse_vol_density_pearson = find_pearson(df_1_common_syn_density, df_2_common_syn_density)\n",
    "                synapse_vol_density_cosine = find_cosine(df_1_common_syn_density, df_2_common_syn_density)\n",
    "\n",
    "                ####reset the df_1_common and df_1_common to reuse code\n",
    "                df_1_common = df_1_common_converted\n",
    "                df_2_common = df_2_common_converted\n",
    "\n",
    "\n",
    "                if (not df_1_common.to_numpy().any()) or (not df_2_common.to_numpy().any()):\n",
    "                    #print(\"none_in_converted\")\n",
    "                    pass\n",
    "                else:\n",
    "                    df_1_common_conversion = df_1_common[\"total_contact_conversion\"].to_numpy()\n",
    "                    df_2_common_conversion = df_2_common[\"total_contact_conversion\"].to_numpy()\n",
    "\n",
    "                    df_1_common_binary_conversion = np.copy(df_1_common_conversion)\n",
    "                    df_2_common_binary_conversion = np.copy(df_2_common_conversion)\n",
    "\n",
    "\n",
    "                    df_1_common_binary_conversion[df_1_common_binary_conversion>0] = 1.0\n",
    "                    df_2_common_binary_conversion[df_2_common_binary_conversion>0] = 1.0\n",
    "\n",
    "                    df_1_common_density = df_1_common[\"total_contact_density\"].to_numpy()\n",
    "                    df_2_common_density = df_2_common[\"total_contact_density\"].to_numpy()\n",
    "\n",
    "\n",
    "                    df_1_common_synaptic_size = df_1_common[\"total_synapse_sizes_mean\"].to_numpy()\n",
    "                    df_2_common_synaptic_size = df_2_common[\"total_synapse_sizes_mean\"].to_numpy()\n",
    "\n",
    "                    df_1_common_syn_density = df_1_common[\"syn_density\"].to_numpy()\n",
    "                    df_2_common_syn_density = df_2_common[\"syn_density\"].to_numpy()\n",
    "\n",
    "                    binary_conversion_pearson_converted = find_pearson(df_1_common_binary_conversion, df_2_common_binary_conversion)\n",
    "                    binary_conversion_cosine_converted = find_cosine(df_1_common_binary_conversion, df_2_common_binary_conversion)\n",
    "                    \n",
    "                    #new added metric for the binary calculations based on jacard_similarity\n",
    "                    binary_conv_jaccard_ones_ratio_converted,binary_conv_jaccard_matching_ratio_converted = find_binary_sim(df_1_common_binary_conversion,df_2_common_binary_conversion)\n",
    "                \n",
    "                    conversion_pearson_converted = find_pearson(df_1_common_conversion, df_2_common_conversion)\n",
    "                    conversion_cosine_converted = find_cosine(df_1_common_conversion, df_2_common_conversion)\n",
    "                    density_pearson_converted = find_pearson(df_1_common_density, df_2_common_density)\n",
    "                    density_cosine_converted = find_cosine(df_1_common_density, df_2_common_density)\n",
    "                    synapse_volume_mean_pearson_converted = find_pearson(df_1_common_synaptic_size, df_2_common_synaptic_size)\n",
    "                    synapse_volume_mean_cosine_converted = find_cosine(df_1_common_synaptic_size, df_2_common_synaptic_size)\n",
    "                    synapse_vol_density_pearson_converted = find_pearson(df_1_common_syn_density, df_2_common_syn_density)\n",
    "                    synapse_vol_density_cosine_converted = find_cosine(df_1_common_syn_density, df_2_common_syn_density)\n",
    "\n",
    "\n",
    "            corr_dict[\"binary_conversion_pearson\"] = binary_conversion_pearson\n",
    "            corr_dict[\"binary_conversion_cosine\"] = binary_conversion_cosine\n",
    "            corr_dict[\"binary_conv_jaccard_ones_ratio\"] = binary_conv_jaccard_ones_ratio\n",
    "            corr_dict[\"binary_conv_jaccard_matching_ratio\"] = binary_conv_jaccard_matching_ratio\n",
    "            corr_dict[\"conversion_pearson\"] = conversion_pearson\n",
    "            corr_dict[\"conversion_cosine\"] = conversion_cosine\n",
    "            corr_dict[\"density_pearson\"] = density_pearson\n",
    "            corr_dict[\"density_cosine\"] = density_cosine\n",
    "            corr_dict[\"synapse_volume_mean_pearson\"] = synapse_volume_mean_pearson\n",
    "            corr_dict[\"synapse_volume_mean_cosine\"] = synapse_volume_mean_cosine\n",
    "            corr_dict[\"synapse_vol_density_pearson\"] = synapse_vol_density_pearson\n",
    "            corr_dict[\"synapse_vol_density_cosine\"] = synapse_vol_density_cosine\n",
    "\n",
    "            corr_dict[\"binary_conversion_pearson_converted\"] = binary_conversion_pearson_converted\n",
    "            corr_dict[\"binary_conversion_cosine_converted\"] = binary_conversion_cosine_converted\n",
    "            corr_dict[\"binary_conv_jaccard_ones_ratio_converted\"] = binary_conv_jaccard_ones_ratio_converted\n",
    "            corr_dict[\"binary_conv_jaccard_matching_ratio_converted\"] = binary_conv_jaccard_matching_ratio_converted\n",
    "            corr_dict[\"conversion_pearson_converted\"] = conversion_pearson_converted\n",
    "            corr_dict[\"conversion_cosine_converted\"] = conversion_cosine_converted\n",
    "            corr_dict[\"density_pearson_converted\"] = density_pearson_converted\n",
    "            corr_dict[\"density_cosine_converted\"] = density_cosine_converted\n",
    "            corr_dict[\"synapse_volume_mean_pearson_converted\"] = synapse_volume_mean_pearson_converted\n",
    "            corr_dict[\"synapse_volume_mean_cosine_converted\"] = synapse_volume_mean_cosine_converted\n",
    "            corr_dict[\"synapse_vol_density_pearson_converted\"] = synapse_vol_density_pearson_converted\n",
    "            corr_dict[\"synapse_vol_density_cosine_converted\"] = synapse_vol_density_cosine_converted\n",
    "\n",
    "            total_correlations.append(corr_dict)\n",
    "\n",
    "        #write all of the dictionaries to the database\n",
    "        self.insert(total_correlations,skip_duplicates=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to start postsyn1,postsyn2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121153it [48:22, 42.69it/s]   c:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\datajoint\\connection.py:150: UserWarning: Mysql server has gone away. Reconnecting to the server.\n",
      "  warnings.warn(\"Mysql server has gone away. Reconnecting to the server.\")\n",
      "c:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\datajoint\\connection.py:150: UserWarning: Mysql server has gone away. Reconnecting to the server.\n",
      "  warnings.warn(\"Mysql server has gone away. Reconnecting to the server.\")\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "(2003, \"Can't connect to MySQL server on '10.28.0.34' ([WinError 10013] An attempt was made to access a socket in a way forbidden by its access permissions)\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36m_read_bytes\u001b[1;34m(self, num_bytes)\u001b[0m\n\u001b[0;32m    690\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    575\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\datajoint\\connection.py\u001b[0m in \u001b[0;36mquery\u001b[1;34m(self, query, args, as_dict, suppress_warnings, reconnect)\u001b[0m\n\u001b[0;32m    146\u001b[0m                     \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m                 \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInterfaceError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperationalError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pymysql\\cursors.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_executed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pymysql\\cursors.py\u001b[0m in \u001b[0;36m_query\u001b[1;34m(self, q)\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m         \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36mquery\u001b[1;34m(self, sql, unbuffered)\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCOMMAND\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOM_QUERY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msql\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_affected_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_query_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_affected_rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36m_read_query_result\u001b[1;34m(self, unbuffered)\u001b[0m\n\u001b[0;32m    731\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMySQLResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 732\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    733\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1075\u001b[1;33m             \u001b[0mfirst_packet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_packet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1076\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36m_read_packet\u001b[1;34m(self, packet_type)\u001b[0m\n\u001b[0;32m    656\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 657\u001b[1;33m             \u001b[0mpacket_header\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m             \u001b[1;31m#if DEBUG: dump_packet(packet_header)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36m_read_bytes\u001b[1;34m(self, num_bytes)\u001b[0m\n\u001b[0;32m    698\u001b[0m                     \u001b[0mCR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCR_SERVER_LOST\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \"Lost connection to MySQL server during query (%s)\" % (e,))\n\u001b[0m\u001b[0;32m    700\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: (2013, 'Lost connection to MySQL server during query ([WinError 10054] An existing connection was forcibly closed by the remote host)')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self, sock)\u001b[0m\n\u001b[0;32m    582\u001b[0m                                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m                                 **kwargs)\n\u001b[0m\u001b[0;32m    584\u001b[0m                             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 712\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    713\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    702\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 10013] An attempt was made to access a socket in a way forbidden by its access permissions",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6950a8d71c65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mContactCorrelation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Total time = \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\datajoint\\autopopulate.py\u001b[0m in \u001b[0;36mpopulate\u001b[1;34m(self, suppress_errors, return_exception_objects, reserve_jobs, order, limit, max_calls, display_progress, *restrictions)\u001b[0m\n\u001b[0;32m    152\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_allow_insert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m                         \u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m                         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-e2d4e058a5ee>\u001b[0m in \u001b[0;36mmake\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;31m#write all of the dictionaries to the database\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_correlations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mskip_duplicates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\datajoint\\table.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, rows, replace, skip_duplicates, ignore_extra_fields, allow_direct_insert)\u001b[0m\n\u001b[0;32m    295\u001b[0m                                if skip_duplicates else ''))\n\u001b[0;32m    296\u001b[0m                 self.connection.query(query, args=list(\n\u001b[1;32m--> 297\u001b[1;33m                     itertools.chain.from_iterable((v for v in r['values'] if v is not None) for r in rows)))\n\u001b[0m\u001b[0;32m    298\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOperationalError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInternalError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIntegrityError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mserver_error_codes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'command denied'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\datajoint\\connection.py\u001b[0m in \u001b[0;36mquery\u001b[1;34m(self, query, args, as_dict, suppress_warnings, reconnect)\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_connection_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mreconnect\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mysql server has gone away. Reconnecting to the server.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_transaction\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcancel_transaction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\datajoint\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     98\u001b[0m                          \u001b[1;34m\"STRICT_ALL_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                 \u001b[0mcharset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'connection.charset'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m                 **self.conn_info)\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pymysql\\__init__.py\u001b[0m in \u001b[0;36mConnect\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \"\"\"\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mconnections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mConnection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconnections\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_orig_conn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, host, user, password, database, port, unix_socket, charset, sql_mode, read_default_file, conv, use_unicode, client_flag, cursorclass, init_command, connect_timeout, ssl, read_default_group, compress, named_pipe, autocommit, db, passwd, local_infile, max_allowed_packet, defer_connect, auth_plugin_map, read_timeout, write_timeout, bind_address, binary_prefix, program_name, server_public_key)\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_create_ssl_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msslp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\celii\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self, sock)\u001b[0m\n\u001b[0;32m    628\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_exc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[1;31m# If e is neither DatabaseError or IOError, It's a bug.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: (2003, \"Can't connect to MySQL server on '10.28.0.34' ([WinError 10013] An attempt was made to access a socket in a way forbidden by its access permissions)\")"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "ContactCorrelation.populate()\n",
    "print(\"Total time = \" + str(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "484620/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What this table measures: \n",
    "For each axon and postsyn pairing:\n",
    "1) Number of contacts\n",
    "2) postsyn_length\n",
    "3) contact conversion rate\n",
    "4) contact densirty\n",
    "5) total number of synapses\n",
    "6) synapse sizes mean\n",
    "-- repeats them for all the categories\n",
    "\"\"\"\n",
    "\n",
    "pinky_fc.ContactPrePost() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
