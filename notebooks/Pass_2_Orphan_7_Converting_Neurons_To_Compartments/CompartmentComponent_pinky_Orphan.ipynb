{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@10.28.0.34:3306\n"
     ]
    }
   ],
   "source": [
    "#setting the address and the username\n",
    "dj.config['database.host'] = '10.28.0.34'\n",
    "dj.config['database.user'] = 'celiib'\n",
    "dj.config['database.password'] = 'newceliipass'\n",
    "dj.config['safemode']=True\n",
    "dj.config[\"display.limit\"] = 20\n",
    "\n",
    "schema = dj.schema('microns_pinky')\n",
    "pinky = dj.create_virtual_module('pinky', 'microns_pinky')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#schema.jobs     & 'table_name = \"__compartment_final\"'      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinky.Decimation35OrphanStitched & pinky.CurrentSegmentation & 'decimation_ratio=0.35' & pinky.CoarseLabelOrphan.proj()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "\n",
    "def generate_neighborhood(triangles, num_vertices):\n",
    "    neighborhood = dict()\n",
    "    for i in range(num_vertices):\n",
    "        neighborhood[i] = set()\n",
    "    for node1, node2, node3 in triangles:\n",
    "        neighborhood[node1].update([node2, node3])\n",
    "        neighborhood[node2].update([node1, node3])\n",
    "        neighborhood[node3].update([node1, node2])\n",
    "    return neighborhood\n",
    "\n",
    "def compress_compartments(neighborhood, vertex_labels):\n",
    "    boundary_clusters = dict()\n",
    "    for unique_label in np.unique(vertex_labels):\n",
    "        boundary_clusters[unique_label] = dict()#list()\n",
    "\n",
    "    starting_node = 0 # This assumes that there are no disconnected portions... I should actually figure out exactly what's going on here.\n",
    "    visited_nodes = set()\n",
    "    temp_stack = set()\n",
    "    temp_stack.add(starting_node)    \n",
    "    while len(temp_stack) > 0:\n",
    "        starting_node = temp_stack.pop()\n",
    "        if starting_node not in visited_nodes:\n",
    "            same_label_neighbors = set()\n",
    "            node_label = vertex_labels[starting_node]\n",
    "            is_on_boundary = False\n",
    "            for neighboring_node in neighborhood[starting_node]: # Think about if I truly need the same labeled neighbors...\n",
    "                                                                 # Only way for it to be truly self contained right?\n",
    "                if node_label == vertex_labels[neighboring_node]:\n",
    "                    same_label_neighbors.add(neighboring_node)\n",
    "                else:\n",
    "                    is_on_boundary = True\n",
    "            if is_on_boundary:\n",
    "#                 boundary_clusters[node_label].append((starting_node, same_label_neighbors))\n",
    "                boundary_clusters[node_label][starting_node] = same_label_neighbors\n",
    "                \n",
    "            visited_nodes.add(starting_node)\n",
    "            temp_stack.update(neighborhood[starting_node])\n",
    "    return boundary_clusters\n",
    "\n",
    "def _separate_compartment(neighborhood, cluster, boundary_points):\n",
    "    components = dict()\n",
    "    compartment_index = 0\n",
    "    while len(cluster) > 0:\n",
    "        visited_nodes = set()\n",
    "        temp_stack = set()\n",
    "        temp_stack.add(next(iter(cluster)))\n",
    "        boundaries_hit = set()\n",
    "        while len(temp_stack) > 0:\n",
    "            starting_node = temp_stack.pop()\n",
    "            if starting_node not in visited_nodes:\n",
    "                visited_nodes.add(starting_node)\n",
    "                if starting_node in boundary_points:\n",
    "                    boundaries_hit.add(starting_node)\n",
    "                    temp_stack.update(cluster[starting_node])\n",
    "                else:\n",
    "                    temp_stack.update(neighborhood[starting_node])\n",
    "        [cluster.pop(boundary_hit) for boundary_hit in boundaries_hit]        \n",
    "        components[compartment_index] = visited_nodes\n",
    "        compartment_index += 1\n",
    "    return components\n",
    "\n",
    "def separate_compartments(neighborhood, boundary_clusters):\n",
    "    compartment_components = dict()\n",
    "    boundary_clusters_copy = boundary_clusters.copy()\n",
    "    for label, boundary_cluster in boundary_clusters_copy.items():\n",
    "        cluster = dict()\n",
    "        boundary_points = set()\n",
    "        for node, neighbors in boundary_cluster.items():\n",
    "            boundary_points.add(node)\n",
    "            cluster[node] = neighbors\n",
    "        components = _separate_compartment(neighborhood, cluster, boundary_points)\n",
    "        compartment_components[label] = components\n",
    "    return compartment_components\n",
    "        \n",
    "############################################################################################################# For Below\n",
    "\n",
    "@schema\n",
    "class CompartmentOrphan(dj.Computed):\n",
    "    definition = \"\"\"\n",
    "    -> pinky.Decimation35OrphanStitched\n",
    "    ---\n",
    "    \"\"\"\n",
    "\n",
    "    class ComponentOrphan(dj.Part):\n",
    "        definition = \"\"\"\n",
    "        -> CompartmentOrphan\n",
    "        compartment_type   : varchar(16)        # Basal, Apical, spine head, etc.\n",
    "        component_index    : smallint unsigned  # Which sub-compartment of a certain label this is.\n",
    "        ---\n",
    "        n_vertex_indices   : bigint\n",
    "        n_triangle_indices : bigint\n",
    "        vertex_indices     : longblob           # preserved indices of each vertex of this sub-compartment\n",
    "        triangle_indices   : longblob           # preserved indices of each triangle of this sub-compartment\n",
    "        \"\"\"\n",
    "    \n",
    "    key_source = pinky.Decimation35OrphanStitched & pinky.CurrentSegmentation & 'decimation_ratio=0.35' & pinky.CoarseLabelOrphan.proj()\n",
    "    \n",
    "    def make(self, key):\n",
    "        def generate_triangle_neighborhood(triangles):\n",
    "            \"\"\"\n",
    "            Maps each vertex node to every triangle they appear in.\n",
    "            \"\"\"\n",
    "            triangle_neighborhood = dict()\n",
    "            for i in range(len(triangles)):\n",
    "                triangle_neighborhood[i] = set()\n",
    "            for i, (node1, node2, node3) in enumerate(triangles):\n",
    "                triangle_neighborhood[node1].add(i)\n",
    "                triangle_neighborhood[node2].add(i)\n",
    "                triangle_neighborhood[node3].add(i)\n",
    "            return triangle_neighborhood\n",
    "        \n",
    "        def generate_component_keys(key, components, triangles, triangle_neighborhood, labeled_triangles):\n",
    "            for label_key, compartment in components.items():\n",
    "                for component_index, component in compartment.items():\n",
    "                    try:\n",
    "                        label_name = (pinky.LabelKey & dict(numeric=label_key)).fetch1('description')\n",
    "                    except:\n",
    "                        label_name = str(label_key)\n",
    "                        \n",
    "                    vertex_indices = np.array(list(component))\n",
    "                    triangle_indices = np.unique([triangle_index for node in component\n",
    "                                                  for triangle_index in triangle_neighborhood[node]\n",
    "                                                  if labeled_triangles[triangle_index] == label_key])\n",
    "                    set_vertex_indices = set(vertex_indices)\n",
    "                    true_triangle_indices = []\n",
    "                    for triangle_index in triangle_indices:\n",
    "                        node1, node2, node3 = triangles[triangle_index]\n",
    "                        if node1 in set_vertex_indices:\n",
    "                            if node2 in set_vertex_indices:\n",
    "                                if node3 in set_vertex_indices:\n",
    "                                    true_triangle_indices.append(triangle_index)                        \n",
    "                    triangle_indices = np.array(true_triangle_indices)\n",
    "                    yield dict(key,\n",
    "                               compartment_type=label_name,\n",
    "                               component_index=component_index,\n",
    "                               n_vertex_indices=len(vertex_indices),\n",
    "                               n_triangle_indices=len(triangle_indices),\n",
    "                               vertex_indices=vertex_indices,\n",
    "                               triangle_indices=triangle_indices)\n",
    "        \n",
    "        start = time.time()\n",
    "        #print(\"hello\")\n",
    "        mesh = (pinky.Decimation35OrphanStitched & key).fetch1()\n",
    "        labels = (pinky.CoarseLabelOrphan & key).fetch1()\n",
    "        #print(\"something\")\n",
    "        if len(np.unique(labels['triangles'])) == 1:\n",
    "            #print(\"heyo\")\n",
    "            self.insert1(key)\n",
    "            label_name = (pinky.LabelKey & dict(numeric=np.unique(labels['triangles'])[0])).fetch1('description')\n",
    "            vertex_indices = np.arange(len(labels['vertices']), dtype=np.uint32)\n",
    "            triangle_indices = np.arange(len(labels['triangles']), dtype=np.uint32)\n",
    "            new_dict= dict(key,\n",
    "                                                compartment_type=label_name,\n",
    "                                                component_index=0,\n",
    "                                                n_vertex_indices=len(vertex_indices),\n",
    "                                                n_triangle_indices=len(triangle_indices),\n",
    "                                                vertex_indices=vertex_indices,\n",
    "                                                triangle_indices=triangle_indices)\n",
    "            \n",
    "            CompartmentOrphan.ComponentOrphan().insert1(dict(key,\n",
    "                                                compartment_type=label_name,\n",
    "                                                component_index=0,\n",
    "                                                n_vertex_indices=len(vertex_indices),\n",
    "                                                n_triangle_indices=len(triangle_indices),\n",
    "                                                vertex_indices=vertex_indices,\n",
    "                                                triangle_indices=triangle_indices))\n",
    "            return\n",
    "        \n",
    "        neighborhood = generate_neighborhood(mesh['triangles'], len(mesh['vertices']))\n",
    "        boundary_clusters = compress_compartments(neighborhood, labels['vertices'])\n",
    "        components = separate_compartments(neighborhood, boundary_clusters)\n",
    "        triangle_neighborhood = generate_triangle_neighborhood(mesh['triangles'])\n",
    "\n",
    "        self.insert1(key)\n",
    "        CompartmentOrphan.ComponentOrphan().insert(generate_component_keys(key, components, mesh['triangles'],\n",
    "                                                               triangle_neighborhood, labels['triangles']))\n",
    "\n",
    "        print(key['segment_id'], \"finished separating components:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(schema.jobs & \"table_name='__compartment_orphan'\").delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "CompartmentOrphan.populate(reserve_jobs=True)\n",
    "print(f\"Total time = {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check that all neurons have components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(schema.jobs & \"table_name='__compartment_final'\").delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that there are all components in there\n",
    "segment_id = pinky.CompartmentOrphan.ComponentOrphan.fetch(\"segment_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(segment_id))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Conclusion: Script ran successfully and processed all\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
