{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import time\n",
    "import pymeshfix\n",
    "import os\n",
    "import datetime\n",
    "import calcification_Module as cm\n",
    "from meshparty import trimesh_io\n",
    "\n",
    "#for supressing the output\n",
    "import os, contextlib\n",
    "import pathlib\n",
    "import subprocess\n",
    "\n",
    "#for error counting\n",
    "from collections import Counter\n",
    "\n",
    "#for reading in the new raw_skeleton files\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@10.28.0.34:3306\n"
     ]
    }
   ],
   "source": [
    "#setting the address and the username\n",
    "dj.config['database.host'] = '10.28.0.34'\n",
    "dj.config['database.user'] = 'celiib'\n",
    "dj.config['database.password'] = 'newceliipass'\n",
    "dj.config['safemode']=True\n",
    "dj.config[\"display.limit\"] = 20\n",
    "\n",
    "schema = dj.schema('microns_ta3p100')\n",
    "ta3p100 = dj.create_virtual_module('ta3p100', 'microns_ta3p100')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOMATICALLY GENERATING CODE FOR CONTACT CORRELATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all of the possible \n",
    "\n",
    "targets = (dj.U(\"postsyn\") & ta3p100.ContactTestSharedContact).proj(segment_id=\"postsyn\") - ta3p100.SegmentExclude\n",
    "info = targets * targets.proj(segment_b='segment_id') & 'segment_id < segment_b'\n",
    "info\n",
    "\n",
    "segment_pairs = info.fetch()\n",
    "segment_pairs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8660254037844388\n",
      "-0.029219759796989472\n",
      "-0.6026168953755794\n",
      "Total time for correlation = 0.010935783386230469\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#pull down the PrePost\n",
    "# prepost_data = ta3p100.ContactPrePostTestReal.proj(\"presyn\",\n",
    "#         \"postsyn\",\"total_contact_conversion\",\"total_contact_density\",\"total_synapse_sizes_mean\").fetch()\n",
    "\n",
    "prepost_data = ta3p100.ContactPrePostTestReal.proj(\"presyn\",\n",
    "        \"postsyn\",\"total_contact_conversion\",\"total_contact_density\").fetch()\n",
    "\n",
    "\n",
    "#put data in Dataframe\n",
    "df = pd.DataFrame(prepost_data)\n",
    "\n",
    "start_time = time.time()\n",
    "#get one of the possible combinations from segment pairs\n",
    "postsyn1 = 648518346341353019\n",
    "postsyn2 = 648518346341352223\n",
    "\n",
    "#get all of the rows with postsyn 1 and 2\n",
    "df_1 = df[df[\"postsyn\"]==postsyn1][:5]\n",
    "df_2 = df[df[\"postsyn\"]==postsyn2][1:]\n",
    "#how you restrict a table by the values in the other table\n",
    "df_1_common = df_1[df_1[\"presyn\"].isin(df_2[\"presyn\"])].sort_values(by=['presyn'])\n",
    "df_2_common = df_2[df_2[\"presyn\"].isin(df_1[\"presyn\"])].sort_values(by=['presyn'])\n",
    "#how to extract the data\n",
    "#postsyns = restr_df[\"presyn\"].to_numpy()\n",
    "# df_1_common_conversion = df_1[df_1[\"presyn\"].isin(df_2[\"presyn\"])].sort_values(by=['presyn'])[\"total_contact_conversion\"].to_numpy()\n",
    "# df_2_common_conversion = df_2[df_2[\"presyn\"].isin(df_1[\"presyn\"])].sort_values(by=['presyn'])[\"total_contact_conversion\"].to_numpy()\n",
    "df_1_common_conversion = df_1_common[\"total_contact_conversion\"].to_numpy()\n",
    "df_2_common_conversion = df_2_common[\"total_contact_conversion\"].to_numpy()\n",
    "\n",
    "df_1_common_binary_conversion = np.copy(df_1_common_conversion)\n",
    "df_2_common_binary_conversion = np.copy(df_2_common_conversion)\n",
    "\n",
    "\n",
    "df_1_common_binary_conversion[df_1_common_binary_conversion>0] = 1.0\n",
    "df_2_common_binary_conversion[df_2_common_binary_conversion>0] = 1.0\n",
    "\n",
    "# print(df_1_common_binary_conversion)\n",
    "# print(df_2_common_binary_conversion)\n",
    "\n",
    "#postsyns = restr_df[\"presyn\"].to_numpy()\n",
    "#df_1_common_density = df_1[df_1[\"presyn\"].isin(df_2[\"presyn\"])].sort_values(by=['presyn'])[\"total_contact_density\"].to_numpy()\n",
    "#df_2_common_density = df_2[df_2[\"presyn\"].isin(df_1[\"presyn\"])].sort_values(by=['presyn'])[\"total_contact_density\"].to_numpy()\n",
    "df_1_common_density = df_1_common[\"total_contact_density\"].to_numpy()\n",
    "df_2_common_density = df_2_common[\"total_contact_density\"].to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "#get the synaptic volume density\n",
    "# df_1_common_synaptic_size = df_1[df_1[\"presyn\"].isin(df_2[\"presyn\"])].sort_values(by=['presyn'])[\"total_synapse_sizes_mean\"].to_numpy()\n",
    "# df_2_common_synaptic_size = df_2[df_2[\"presyn\"].isin(df_1[\"presyn\"])].sort_values(by=['presyn'])[\"total_synapse_sizes_mean\"].to_numpy()\n",
    "# df_1_common_synaptic_size_2 = df_1_common[\"total_synapse_sizes_mean\"].to_numpy()\n",
    "# df_1_common_synaptic_size_2 = df_2_common[\"total_synapse_sizes_mean\"].to_numpy()\n",
    "\n",
    "#calculate the coefficient\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#start_time = time.time()\n",
    "\n",
    "corr_conversion, p_value_conversion = pearsonr(df_1_common_conversion, df_2_common_conversion)\n",
    "df_1_common_binary_conversion = df_1_common_binary_conversion.reshape(1,len(df_1_common_binary_conversion))\n",
    "df_2_common_binary_conversion = df_2_common_binary_conversion.reshape(1,len(df_2_common_binary_conversion))\n",
    "corr_density, p_value_density = pearsonr(df_1_common_density, df_2_common_density)\n",
    "cos_lib = cosine_similarity(df_1_common_binary_conversion, df_2_common_binary_conversion)\n",
    "\n",
    "# corr_synaptic_size, p_value_synaptic = pearsonr(df_1_common_synaptic_size, df_2_common_synaptic_size)\n",
    "print(cos_lib[0][0])\n",
    "print(corr_conversion)\n",
    "print(corr_density)\n",
    "\n",
    "\n",
    "# print(corr_synaptic_size)\n",
    "print(f\"Total time for correlation = {time.time()-start_time}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr([1., 1., 1., 1.],[1., 1., 1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.corrcoef([1., 1., 1., 1.],[1., 1., 1., 1.])[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the binary conversion rate\n",
    "df_1_common_conversion[df_1_common_conversion>0] = 1\n",
    "df_1_common_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0, 0.234, 0.99, 2.33, 2.5, 0, 0])\n",
    "x[x>0] = 1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.copy(df_1_common_conversion)\n",
    "y[y>0] = 1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_common_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1.0,1.0,1.0,1.0])\n",
    "y = np.array([1.0,1.0,0.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try out the new correlation technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "scipy.stats.cov(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// from http://skipperkongen.dk/2018/09/19/cosine-similarity-in-python/\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "start_time = time.time()\n",
    "# vectors\n",
    "a = np.array([1.0,1.0,1.0,1.0])\n",
    "b = np.array([1.0,1.0,0.0,1.0])\n",
    "\n",
    "a = np.array([1.0,1.0,0.0,1.0])\n",
    "b = np.array([1.0,1.0,0.0,1.0])\n",
    " \n",
    "# # manually compute cosine similarity\n",
    "# dot = np.dot(a, b)\n",
    "# norma = np.linalg.norm(a)\n",
    "# normb = np.linalg.norm(b)\n",
    "# cos = dot / (norma * normb)\n",
    "\n",
    "\n",
    "# # use library, operates on sets of vectors\n",
    "# aa = a.reshape(1,4)\n",
    "# ba = b.reshape(1,4)\n",
    "# cos_lib = cosine_similarity(aa, ba)\n",
    "cos_lib = cosine_similarity(a, b)\n",
    "cos_lib\n",
    "print(f\"Took total sec: {time.time()-start_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
