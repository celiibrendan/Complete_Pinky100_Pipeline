{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: Would extract the spines from a mesh and test\n",
    "that you can make it completely manifold\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import time\n",
    "import pymeshfix\n",
    "import os\n",
    "import datetime\n",
    "import calcification_Module as cm\n",
    "from meshparty import trimesh_io\n",
    "\n",
    "#for supressing the output\n",
    "import os, contextlib\n",
    "import pathlib\n",
    "import subprocess\n",
    "\n",
    "#for error counting\n",
    "from collections import Counter\n",
    "\n",
    "#for reading in the new raw_skeleton files\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "from Skeleton_Stitcher import stitch_skeleton_with_degree_check, find_skeleton_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@10.28.0.34:3306\n"
     ]
    }
   ],
   "source": [
    "#setting the address and the username\n",
    "dj.config['database.host'] = '10.28.0.34'\n",
    "dj.config['database.user'] = 'celiib'\n",
    "dj.config['database.password'] = 'newceliipass'\n",
    "dj.config['safemode']=True\n",
    "dj.config[\"display.limit\"] = 20\n",
    "\n",
    "schema = dj.schema('microns_pinky')\n",
    "pinky = dj.create_virtual_module('pinky', 'microns_pinky')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.ERD(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output for the skeleton edges to be stored by datajoint\n",
    "\"\"\" OLD WAY THAT DATAJOINT WAS GETTING MAD AT \n",
    "def read_skeleton(file_path):\n",
    "    with open(file_path) as f:\n",
    "        bones = list()\n",
    "        for line in f.readlines():\n",
    "            bones.append(np.array(line.split()[1:], float).reshape(-1, 3))\n",
    "    return np.array(bones)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" NEW FLAT LIST WAY, this is outdated for one below\"\"\"\n",
    "#\n",
    "def read_skeleton_flat(file_path):\n",
    "    with open(file_path) as f:\n",
    "        bones = list()\n",
    "        for line in f.readlines():\n",
    "            for r in (np.array(line.split()[1:], float).reshape(-1, 3)):\n",
    "                bones.append(r)\n",
    "            bones.append([np.nan,np.nan,np.nan])\n",
    "    return np.array(bones).astype(float)\n",
    "\n",
    "\n",
    "\"\"\" New read function: for adjusted 2 vert skeleton output\"\"\"\n",
    "# def read_raw_skeleton(file_path):\n",
    "#     edges = list()\n",
    "#     with open(file_path) as f:\n",
    "#         reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONE)\n",
    "#         for i,row in enumerate(reader):\n",
    "#             v1 = (float(row[1]),float(row[2]),float(row[3]))\n",
    "#             v2 = (float(row[4]),float(row[5]),float(row[6]))\n",
    "#             edges.append((v1,v2))\n",
    "#     return np.array(edges).astype(float)\n",
    "\n",
    "\n",
    "def read_skeleton_revised(file_path):\n",
    "    with open(file_path) as f:\n",
    "        bones = np.array([])\n",
    "        for line in f.readlines():\n",
    "            #print(line)\n",
    "            line = (np.array(line.split()[1:], float).reshape(-1, 3))\n",
    "            #print(line[:-1])\n",
    "            #print(line[1:])\n",
    "\n",
    "            #print(bones.size)\n",
    "            if bones.size <= 0:\n",
    "                bones = np.stack((line[:-1],line[1:]),axis=1)\n",
    "            else:\n",
    "                bones = np.vstack((bones,(np.stack((line[:-1],line[1:]),axis=1))))\n",
    "            #print(bones)\n",
    "\n",
    "\n",
    "    return np.array(bones).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure there is a temp file in the directory, if not then make one\n",
    "#if temp folder doesn't exist then create it\n",
    "if (os.path.isdir(os.getcwd() + \"/pymesh_neurons\")) == False:\n",
    "    os.mkdir(\"pymesh_neurons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the output file\n",
    "##write the OFF file for the neuron\n",
    "import pathlib\n",
    "def write_Whole_Neuron_Off_file(neuron_ID,\n",
    "                                vertices=[], \n",
    "                                triangles=[],\n",
    "                                folder=\"pymesh_neurons\"):\n",
    "    #primary_key = dict(segmentation=1, segment_id=segment_id, decimation_ratio=0.35)\n",
    "    #vertices, triangles = (mesh_Table_35 & primary_key).fetch1('vertices', 'triangles')\n",
    "    \n",
    "    num_vertices = (len(vertices))\n",
    "    num_faces = len(triangles)\n",
    "    \n",
    "    #get the current file location\n",
    "    file_loc = pathlib.Path.cwd() / folder\n",
    "    filename = \"neuron_\" + str(neuron_ID)\n",
    "    path_and_filename = file_loc / filename\n",
    "    \n",
    "    #print(file_loc)\n",
    "    #print(path_and_filename)\n",
    "    \n",
    "    #open the file and start writing to it    \n",
    "    f = open(str(path_and_filename) + \".off\", \"w\")\n",
    "    f.write(\"OFF\\n\")\n",
    "    f.write(str(num_vertices) + \" \" + str(num_faces) + \" 0\\n\" )\n",
    "    \n",
    "    \n",
    "    #iterate through and write all of the vertices in the file\n",
    "    for verts in vertices:\n",
    "        f.write(str(verts[0]) + \" \" + str(verts[1]) + \" \" + str(verts[2])+\"\\n\")\n",
    "    \n",
    "    #print(\"Done writing verts\")\n",
    "        \n",
    "    for faces in triangles:\n",
    "        f.write(\"3 \" + str(faces[0]) + \" \" + str(faces[1]) + \" \" + str(faces[2])+\"\\n\")\n",
    "    \n",
    "    print(\"Done writing OFF file\")\n",
    "    #f.write(\"end\")\n",
    "    \n",
    "    return str(path_and_filename),str(filename),str(file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meshlab_fix_manifold(key,folder=\"pymesh_NEURITES\"):\n",
    "    \n",
    "    file_loc = pathlib.Path.cwd() / folder\n",
    "    filename = \"neuron_\" + str(key[\"segment_id\"])\n",
    "    path_and_filename = str(file_loc / filename)\n",
    "    \n",
    "    \n",
    "    input_mesh = path_and_filename + \".off\"\n",
    "    output_mesh = path_and_filename+\"_mls.off\"\n",
    "    \n",
    "    \n",
    "    meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"remeshing_remove_non_man_edges.mls\"\n",
    "    \n",
    "    print(\"starting meshlabserver fixing non-manifolds\")\n",
    "    subprocess_result_1 = run_meshlab_script(meshlab_script,\n",
    "                      input_mesh,\n",
    "                      output_mesh)\n",
    "    #print(\"Poisson subprocess_result= \"+ str(subprocess_result_1))\n",
    "    \n",
    "    if str(subprocess_result_1)[-13:] != \"returncode=0)\":\n",
    "        raise Exception('neuron' + str(key[\"segment_id\"]) + \n",
    "                         ' did not fix the manifold edges')\n",
    "    \n",
    "    return output_mesh\n",
    "\n",
    "def meshlab_fix_manifold_path(path_and_filename,segment_id=-1):\n",
    "    #fix the path if it comes with the extension\n",
    "    if path_and_filename[-4:] == \".off\":\n",
    "        path_and_filename = path_and_filename[-4:]\n",
    "    \n",
    "    input_mesh = path_and_filename + \".off\"\n",
    "    output_mesh = path_and_filename+\"_mls.off\"\n",
    "    \n",
    "    #print(\"input_mesh = \" + str(input_mesh))\n",
    "    #print(\"output_mesh = \" + str(output_mesh))\n",
    "    \n",
    "    meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"remeshing_remove_non_man_edges.mls\"\n",
    "    \n",
    "    print(\"starting meshlabserver fixing non-manifolds\")\n",
    "    subprocess_result_1 = run_meshlab_script(meshlab_script,\n",
    "                      input_mesh,\n",
    "                      output_mesh)\n",
    "    #print(\"Poisson subprocess_result= \"+ str(subprocess_result_1))\n",
    "    \n",
    "    if str(subprocess_result_1)[-13:] != \"returncode=0)\":\n",
    "        raise Exception('neuron' + str(segment_id) + \n",
    "                         ' did not fix the manifold edges')\n",
    "    \n",
    "    return output_mesh\n",
    "\n",
    "def meshlab_fix_manifold_path_specific_mls(path_and_filename,segment_id=-1,meshlab_script=\"\"):\n",
    "    #fix the path if it comes with the extension\n",
    "    if path_and_filename[-4:] == \".off\":\n",
    "        path_and_filename = path_and_filename[-4:]\n",
    "    \n",
    "    input_mesh = path_and_filename + \".off\"\n",
    "    output_mesh = path_and_filename+\"_mls.off\"\n",
    "    \n",
    "    #print(\"input_mesh = \" + str(input_mesh))\n",
    "    #print(\"output_mesh = \" + str(output_mesh))\n",
    "    if meshlab_script == \"\":\n",
    "        meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"remeshing_remove_non_man_edges.mls\"\n",
    "    \n",
    "    print(\"meshlab_script = \" + str(meshlab_script))\n",
    "    #print(\"starting meshlabserver fixing non-manifolds\")\n",
    "    subprocess_result_1 = run_meshlab_script(meshlab_script,\n",
    "                      input_mesh,\n",
    "                      output_mesh)\n",
    "    #print(\"Poisson subprocess_result= \"+ str(subprocess_result_1))\n",
    "    \n",
    "    if str(subprocess_result_1)[-13:] != \"returncode=0)\":\n",
    "        raise Exception('neuron' + str(segment_id) + \n",
    "                         ' did not fix the manifold edges')\n",
    "    \n",
    "    return output_mesh\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_meshlab_script(mlx_script,input_mesh_file,output_mesh_file):\n",
    "    \n",
    "    \n",
    "    script_command = (\" -i \" + str(input_mesh_file) + \" -o \" + \n",
    "                                    str(output_mesh_file) + \" -s \" + str(mlx_script))\n",
    "    #return script_command\n",
    "    subprocess_result = subprocess.run('xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@ ' + \n",
    "                   script_command,shell=True)\n",
    "    \n",
    "    return subprocess_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_source = ((dj.U(\"segmentation\",\"segment_id\") & pinky.CoarseLabelFinal.proj()) \n",
    "+ (dj.U(\"segmentation\",\"segment_id\") & pinky.CoarseLabelOrphan.proj()))\n",
    "\n",
    "key_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = dict(segmentation=3,segment_id=648518346341371119)\n",
    "# split_significance_threshold = 100\n",
    "\n",
    "# global_time = time.time()\n",
    "# #get the mesh with the error segments filtered away\n",
    "# start_time = time.time()\n",
    "# new_key = remove_error_segments(key)\n",
    "# print(f\"Step 1: Retrieving Mesh and removing error segments: {time.time() - start_time}\")\n",
    "\n",
    "# #where i deal with the error segments\n",
    "# if new_key[\"vertices\"].size<2:\n",
    "#     start_time = time.time()\n",
    "#     print(\"All faces were error segments, inserting dummy entry\")\n",
    "#     #create the key with None\n",
    "#     new_key[\"n_vertices\"] = 0\n",
    "#     new_key[\"n_triangles\"] = 0\n",
    "#     new_key[\"vertices\"] = np.array([]).astype(float)\n",
    "#     new_key[\"triangles\"] = np.array([]).astype(float)\n",
    "#     new_key[\"n_edges\"] = 0\n",
    "#     new_key[\"edges\"] = np.array([]).astype(float)\n",
    "#     new_key[\"n_bodies\"] = 0\n",
    "#     new_key[\"n_bodies_stitched\"] = 0\n",
    "#     new_key[\"largest_mesh_perc\"] = 0\n",
    "#     new_key[\"largest_mesh_distance_perc\"] = 0\n",
    "#     self.insert1(new_key,skip_duplicates=True)\n",
    "\n",
    "#     #insert dummy dictionary into correspondence table\n",
    "# #             new_correspondence_dict = dict(segmentation=key[\"segmentation\"],\n",
    "# #                                            segment_id=key[\"segment_id\"],\n",
    "# #                                            time_updated=str(datetime.datetime.now()),\n",
    "# #                                            n_correspondence = 0,\n",
    "# #                                            correspondence=np.array([]).astype(float))\n",
    "\n",
    "# #             #if all goes well then write to correspondence database\n",
    "# #             ta3p100.NeuronRawSkeletonCorrespondence.insert1(new_correspondence_dict,skip_duplicates=True)\n",
    "\n",
    "\n",
    "#     print(f\"Step 2: Inserting dummy dictionary: {time.time() - start_time}\")\n",
    "#     print(f\"Total time: {time.time() - global_time}\")\n",
    "#     print(\"\\n\\n\")\n",
    "\n",
    "# else:\n",
    "#     mesh = trimesh_io.Mesh(vertices=new_key[\"vertices\"], faces=new_key[\"triangles\"])\n",
    "#     total_splits = mesh.split(only_watertight=False)\n",
    "#     print(f\"There were {len(total_splits)} after split and significance threshold\")\n",
    "#     mesh_pieces = [k for k in total_splits if len(k.faces) > split_significance_threshold]\n",
    "#     print(f\"There were {len(mesh_pieces)} after split and significance threshold\")\n",
    "#     for g,mh in enumerate(mesh_pieces):\n",
    "#         print(f\"Mesh piece {g} with number of faces {len(mh.faces)}\")\n",
    "\n",
    "#     print(f\"Step 2a: Getting the number of splits: {time.time() - start_time}\")\n",
    "\n",
    "#     #get the largest mesh piece\n",
    "#     largest_mesh_index = -1\n",
    "#     largest_mesh_size = 0\n",
    "\n",
    "#     for t,msh in enumerate(mesh_pieces):\n",
    "#         if len(msh.faces) > largest_mesh_size:\n",
    "#             largest_mesh_index = t\n",
    "#             largest_mesh_size = len(msh.faces) \n",
    "\n",
    "#     #largest mesh piece\n",
    "#     largest_mesh_perc = largest_mesh_size/len(mesh.faces)\n",
    "#     new_key[\"largest_mesh_perc\"] = largest_mesh_perc\n",
    "#     print(\"largest mesh perc = \" + str(largest_mesh_perc))\n",
    "\n",
    "#     largest_mesh_skeleton_distance = -1\n",
    "\n",
    "#     paths_used = []\n",
    "#     total_edges = np.array([])\n",
    "\n",
    "#     for h,m in enumerate(mesh_pieces): \n",
    "#         print(f\"Working on split {h} with face total = {len(m.faces)}\")\n",
    "\n",
    "\n",
    "\n",
    "#         #print(\"Step 2: Remove all error semgents\")\n",
    "#         start_time = time.time()\n",
    "#         #pass the vertices and faces to pymeshfix to become watertight\n",
    "#         #meshfix = pymeshfix.MeshFix(new_key[\"vertices\"],new_key[\"triangles\"])\n",
    "#         meshfix = pymeshfix.MeshFix(m.vertices,m.faces)\n",
    "#         meshfix.repair(verbose=False,joincomp=True,remove_smallest_components=False)\n",
    "#         print(f\"Step 2: Pymesh shrinkwrapping: {time.time() - start_time}\")\n",
    "\n",
    "#         #print(\"Step 2: Writing Off File\")\n",
    "#         start_time = time.time()\n",
    "#         #write the new mesh to off file\n",
    "#         path_and_filename,filename,file_loc = write_Whole_Neuron_Off_file(str(new_key[\"segment_id\"]),meshfix.v,meshfix.f)\n",
    "#         print(f\"Step 3: Writing shrinkwrap off file: {time.time() - start_time}\")\n",
    "#         paths_used.append(path_and_filename)\n",
    "\n",
    "#         #Run the meshlabserver scripts\n",
    "#         start_time = time.time()\n",
    "#         #output_mesh = meshlab_fix_manifold(key) old way without path\n",
    "#         output_mesh = meshlab_fix_manifold_path(path_and_filename,key[\"segment_id\"])\n",
    "#         print(f\"Step 4: Meshlab fixing non-manifolds: {time.time() - start_time}\")\n",
    "\n",
    "#         print(output_mesh[:-4])\n",
    "\n",
    "#         #send to be skeletonized\n",
    "#         start_time = time.time()\n",
    "#         return_value = cm.calcification(output_mesh[:-4])\n",
    "#         if return_value > 0:\n",
    "#             raise Exception('skeletonization for neuron ' + str(new_key[\"segment_id\"]) + \n",
    "#                             ' did not finish... exited with error code: ' + str(return_value))\n",
    "#         #print(f\"Step 5: Generating Skeleton: {time.time() - start_time}\")\n",
    "\n",
    "\n",
    "\n",
    "#         #read in the skeleton files into an array\n",
    "#         #start_time = time.time()\n",
    "\n",
    "#         ##****** this needs to be changed for reading them in******\n",
    "#         bone_array = read_skeleton_revised(output_mesh[:-4]+\"_skeleton.cgal\")\n",
    "#         #correspondence_array = read_skeleton_revised(output_mesh[:-4]+\"_correspondance.cgal\")\n",
    "#         #print(bone_array)\n",
    "#         if len(bone_array) <= 0:\n",
    "#             raise Exception('No skeleton generated for ' + str(new_key[\"segment_id\"]))\n",
    "\n",
    "# #             if len(correspondence_array) <= 0:\n",
    "# #                 raise Exception('No CORRESPONDENCE generated for ' + str(new_key[\"segment_id\"]))\n",
    "\n",
    "#         print(f\"Step 5: Generating and reading Skeleton: {time.time() - start_time}\")\n",
    "\n",
    "#         #get the largest mesh skeleton distance\n",
    "#         if h == largest_mesh_index:\n",
    "#             largest_mesh_skeleton_distance = find_skeleton_distance(bone_array)\n",
    "\n",
    "#             #add the skeleton edges to the total edges\n",
    "#         if not total_edges.any():\n",
    "#             total_edges = bone_array\n",
    "#         else:\n",
    "#             total_edges = np.vstack([total_edges,bone_array])\n",
    "\n",
    "#     total_edges_stitched = stitch_skeleton_with_degree_check(total_edges)\n",
    "#     #get the total skeleton distance for the stitched skeleton\n",
    "#     total_skeleton_distance = find_skeleton_distance(total_edges_stitched)\n",
    "#     largest_mesh_distance_perc = largest_mesh_skeleton_distance/total_skeleton_distance\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     new_key[\"n_edges\"] = len(total_edges_stitched)\n",
    "#     new_key[\"edges\"] = total_edges_stitched\n",
    "#     new_key[\"n_bodies\"] = len(total_splits)\n",
    "#     new_key[\"n_bodies_stitched\"] = len(mesh_pieces)\n",
    "#     new_key[\"largest_mesh_perc\"] = largest_mesh_perc\n",
    "#     new_key[\"largest_mesh_distance_perc\"] = largest_mesh_distance_perc\n",
    "\n",
    "#     #self.insert1(new_key,skip_duplicates=True)\n",
    "#     print(f\"Step 6: Inserting dictionary: {time.time() - start_time}\")\n",
    "#     #raise Exception(\"done with one neuron\")\n",
    "#     for path_and_filename in paths_used:\n",
    "#         os.system(\"rm \"+str(path_and_filename)+\"*\")\n",
    "\n",
    "#     print(f\"Total time: {time.time() - global_time}\")\n",
    "#     print(\"\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pseudocode code:\n",
    "1) Get the labels\n",
    "2) Get the decimated mesh\n",
    "3) Get the undecimated mesh\n",
    "4) Do a KD tree to map the decimated vertices to the undecimated and give it the labels\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_key = dict(segment_id=648518346341371119,segmentation=3,decimation_ratio=0.35)\n",
    "new_key = dict(segment_id = search_key[\"segment_id\"],segmentation=search_key[\"segmentation\"])\n",
    "dec_vert_labels = (pinky.OverlayedSpineLabel & search_key).fetch1(\"vertices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_key = dict(segment_id = search_key[\"segment_id\"],segmentation=search_key[\"segmentation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the decimated mesh\n",
    "dec_mesh_table = pinky.PymeshfixDecimatedExcitatoryStitchedMesh & search_key\n",
    "dec_vertices, dec_triangles = dec_mesh_table.fetch1(\"vertices\",\"triangles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the undecimated mesh\n",
    "undec_mesh_table = pinky.ExcitatoryStitchedMeshVp2 & new_key\n",
    "undec_vertices, undec_triangles = undec_mesh_table.fetch1(\"vertices\",\"triangles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "dec_KDTree = KDTree(dec_vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "distances, nearest_nodes = dec_KDTree.query(undec_vertices)\n",
    "print(f\"Total time = {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the labels for the undecimated mesh\n",
    "undecimated_vert_labels = dec_vert_labels[nearest_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undec_triangles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map the labels to the triangles as well\n",
    "len(undec_triangles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traingles_first_verts = undecimated_vert_labels[undec_triangles[:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traingle_labels = undecimated_vert_labels[traingles_first_verts]\n",
    "\n",
    "len(traingle_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traingle_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.ERD(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to do it for excitatory meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pinky.ExcitatoryLeftoverMeshes() & \"n_triangles>40000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(331460, 331460)\n",
      "2119970\n",
      "Total time = 0.1271350383758545\n",
      "(34684, 34684)\n",
      "Total time = 0.16122746467590332\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'triangle_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7eef339f2acf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;31m#save the follow lables to make sure that the migration went correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"undecimated_labels_overlay.npz\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mundecimated_vert_labels_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtriangles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtriangle_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"undecimated_labels_coarse.npz\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_undec_coarse_verts_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtriangles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtriangle_overlay_labels_coarse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'triangle_labels' is not defined"
     ]
    }
   ],
   "source": [
    "segment_id = 648518346349478348\n",
    "\n",
    "full_time = time.time()\n",
    "search_key = dict(segment_id=segment_id,segmentation=3,decimation_ratio=0.35)\n",
    "new_key = dict(segment_id = search_key[\"segment_id\"],segmentation=search_key[\"segmentation\"])\n",
    "dec_vert_labels,dec_tri_labels = (pinky.OverlayedSpineLabel & search_key).fetch1(\"vertices\",\"triangles\")\n",
    "\n",
    "#get the decimated mesh\n",
    "dec_mesh_table = pinky.PymeshfixDecimatedExcitatoryStitchedMesh & search_key\n",
    "dec_vertices, dec_triangles = dec_mesh_table.fetch1(\"vertices\",\"triangles\")\n",
    "\n",
    "\n",
    "#make sure that the labels match up:\n",
    "print((len(dec_vert_labels),len(dec_vertices)))\n",
    "#len(dec_tri_labels),len(dec_triangles)\n",
    "\n",
    "#get the undecimated mesh\n",
    "undec_mesh_table = pinky.Mesh & new_key\n",
    "undec_vertices, undec_triangles = undec_mesh_table.fetch1(\"vertices\",\"triangles\")\n",
    "print(len(undec_triangles))\n",
    "\n",
    "from pykdtree.kdtree import KDTree\n",
    "dec_KDTree = KDTree(dec_vertices)\n",
    "\n",
    "start_time = time.time()\n",
    "distances, nearest_nodes = dec_KDTree.query(undec_vertices)\n",
    "print(f\"Total time = {time.time() - start_time}\")\n",
    "\n",
    "#get the labels for the undecimated mesh\n",
    "undecimated_vert_labels = dec_vert_labels[nearest_nodes]\n",
    "\n",
    "distance_threshold = 200\n",
    "undecimated_vert_labels_new = undecimated_vert_labels.copy()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Start the leftover mesh pieces\n",
    "\"\"\"\n",
    "#get the decimated mesh\n",
    "dec_vert_labels_leftover,dec_tri_labels_leftover = (pinky.LeftoverOverlayedSpineLabel & search_key).fetch1(\"vertices\",\"triangles\")\n",
    "\n",
    "#get the decimated mesh\n",
    "dec_mesh_table_leftover = pinky.ExcitatoryLeftoverMeshes & search_key\n",
    "dec_vertices_leftover, dec_triangles_leftover = dec_mesh_table_leftover.fetch1(\"vertices\",\"triangles\")\n",
    "\n",
    "\n",
    "#make sure that the labels match up:\n",
    "print((len(dec_vert_labels_leftover),len(dec_vertices_leftover)))\n",
    "#len(dec_tri_labels),len(dec_triangles)\n",
    "\n",
    "from pykdtree.kdtree import KDTree\n",
    "dec_KDTree_leftover = KDTree(dec_vertices_leftover)\n",
    "\n",
    "start_time = time.time()\n",
    "distances_leftover, nearest_nodes_leftover = dec_KDTree_leftover.query(undec_vertices)\n",
    "print(f\"Total time = {time.time() - start_time}\")\n",
    "\n",
    "#get the labels for the undecimated mesh\n",
    "undecimated_vert_labels_leftover = dec_vert_labels_leftover[nearest_nodes_leftover]\n",
    "\n",
    "#get the final labels by combining leftover with regular\n",
    "final_undec_overlay_verts_labels = np.zeros(len(undec_vertices))\n",
    "\n",
    "error_distance_threshold = 200\n",
    "\n",
    "for i in range(0,len(final_undec_overlay_verts_labels)):\n",
    "    if distances_leftover[i]>error_distance_threshold and distances[i] > error_distance_threshold:\n",
    "        final_undec_overlay_verts_labels[i] = 10\n",
    "    else:\n",
    "        if distances[i] < distances_leftover[i]:\n",
    "            final_undec_overlay_verts_labels[i] = undecimated_vert_labels[i]\n",
    "        else:\n",
    "            final_undec_overlay_verts_labels[i] = undecimated_vert_labels_leftover[i]\n",
    "            \n",
    "\n",
    "triangle_overlay_labels = final_undec_overlay_verts_labels[undec_triangles[:,0]]\n",
    "Counter(triangle_overlay_labels)\n",
    "\n",
    "#---------------- Done with getting the overalyed vertices ---------------- ##\n",
    "\n",
    "#---------------- Started getting just the coarse labels ---------------- ##\n",
    "\n",
    "#get the labels for the undecimated mesh\n",
    "#get the decimated mesh\n",
    "dec_vert_labels_coarse,dec_tri_labels_coarse= (pinky.CoarseLabelFinal & search_key).fetch1(\"vertices\",\"triangles\")\n",
    "undecimated_vert_labels_coarse = dec_vert_labels_coarse[nearest_nodes]\n",
    "\n",
    "\n",
    "dec_vert_labels_leftover_coarse,dec_tri_labels_leftover_coarse_coarse = (pinky.LeftoverCoarseLabelFinal & search_key).fetch1(\"vertices\",\"triangles\")\n",
    "undecimated_vert_labels_leftover_coarse = dec_vert_labels_leftover_coarse[nearest_nodes_leftover]\n",
    "\n",
    "\n",
    "#get the final labels by combining leftover with regular\n",
    "final_undec_coarse_verts_labels = np.zeros(len(undec_vertices))\n",
    "\n",
    "error_distance_threshold = 200\n",
    "\n",
    "for i in range(0,len(final_undec_coarse_verts_labels)):\n",
    "    if distances_leftover[i]>error_distance_threshold and distances[i] > error_distance_threshold:\n",
    "        final_undec_coarse_verts_labels[i] = 10\n",
    "    else:\n",
    "        if distances[i] < distances_leftover[i]:\n",
    "            final_undec_coarse_verts_labels[i] = undecimated_vert_labels_coarse[i]\n",
    "        else:\n",
    "            final_undec_coarse_verts_labels[i] = undecimated_vert_labels_leftover_coarse[i]\n",
    "            \n",
    "\n",
    "triangle_overlay_labels_coarse = final_undec_coarse_verts_labels[undec_triangles[:,0]]\n",
    "Counter(triangle_overlay_labels_coarse)\n",
    "\n",
    "\n",
    "#now have both the undecimated vertices and the undecimated triangle labels\n",
    "\n",
    "#save the follow lables to make sure that the migration went correctly\n",
    "np.savez(\"undecimated_labels_overlay.npz\",vertices=undecimated_vert_labels_new,triangles=triangle_labels)\n",
    "np.savez(\"undecimated_labels_coarse.npz\",vertices=final_undec_coarse_verts_labels,triangles=triangle_overlay_labels_coarse)\n",
    "\n",
    "\n",
    "#np.savez(\"decimated_labels.npz\",vertices=dec_vert_labels,triangles=dec_tri_labels)\n",
    "print(f\"Total_time = {time.time() - full_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
