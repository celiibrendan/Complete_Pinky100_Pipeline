{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import trimesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking that decimated then screened poisson can be skeletonized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = \"./temp\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "\n",
    "input_mesh = \"96631955273149705_decimated_poisson.off\"\n",
    "output_mesh = \"temp/96631955273149705_decimated_poisson_largest_piece.off\"\n",
    "\n",
    "new_mesh = trimesh.load_mesh(input_mesh)\n",
    "mesh_splits = new_mesh.split(only_watertight=True)\n",
    "mesh_lengths = np.array([len(split.faces) for split in mesh_splits])\n",
    "largest_index = np.where(mesh_lengths == np.max(mesh_lengths))\n",
    "largest_mesh = mesh_splits[largest_index][0]\n",
    "\n",
    "\n",
    "largest_mesh.export(output_mesh)\n",
    "print(\"done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the output file\n",
    "##write the OFF file for the neuron\n",
    "import pathlib\n",
    "def write_Whole_Neuron_Off_file(neuron_ID,\n",
    "                                vertices=[], \n",
    "                                triangles=[],\n",
    "                                folder=\"pymesh_NEURONS\"):\n",
    "    #primary_key = dict(segmentation=1, segment_id=segment_id, decimation_ratio=0.35)\n",
    "    #vertices, triangles = (mesh_Table_35 & primary_key).fetch1('vertices', 'triangles')\n",
    "    \n",
    "    num_vertices = (len(vertices))\n",
    "    num_faces = len(triangles)\n",
    "    \n",
    "    #get the current file location\n",
    "    file_loc = pathlib.Path.cwd() / folder\n",
    "    filename = \"neuron_\" + str(neuron_ID)\n",
    "    path_and_filename = file_loc / filename\n",
    "    \n",
    "    #print(file_loc)\n",
    "    #print(path_and_filename)\n",
    "    \n",
    "    #open the file and start writing to it    \n",
    "    f = open(str(path_and_filename) + \".off\", \"w\")\n",
    "    f.write(\"OFF\\n\")\n",
    "    f.write(str(num_vertices) + \" \" + str(num_faces) + \" 0\\n\" )\n",
    "    \n",
    "    \n",
    "    #iterate through and write all of the vertices in the file\n",
    "    for verts in vertices:\n",
    "        f.write(str(verts[0]) + \" \" + str(verts[1]) + \" \" + str(verts[2])+\"\\n\")\n",
    "    \n",
    "    #print(\"Done writing verts\")\n",
    "        \n",
    "    for faces in triangles:\n",
    "        f.write(\"3 \" + str(faces[0]) + \" \" + str(faces[1]) + \" \" + str(faces[2])+\"\\n\")\n",
    "    \n",
    "    print(\"Done writing OFF file\")\n",
    "    #f.write(\"end\")\n",
    "    \n",
    "    return str(path_and_filename),str(filename),str(file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimated_mesh = trimesh.load_mesh(\"96631955273149705_decimated.off\")\n",
    "\n",
    "files = write_Whole_Neuron_Off_file(\"96631955273149705_decimated_bac\",\n",
    "                                vertices=decimated_mesh.vertices, \n",
    "                                triangles=decimated_mesh.faces,\n",
    "                                folder=\"temp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------visualizing the skeletonization------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example ipyvolume visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyvolume as ipv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example ipyvolume\n",
    "\n",
    "# s = 1/2**2\n",
    "# # 4 vertices for the tetrahedron\n",
    "# x = np.array([1.,  -1, 0,  0])\n",
    "# y = np.array([0,   0, 1., -1])\n",
    "# z = np.array([-s, -s, s,  s])\n",
    "# # and 4 surfaces (triangles), where the number refer to the vertex index\n",
    "# triangles = [(0, 1, 2), (0, 1, 3), (0, 2, 3), (1,3,2)]\n",
    "\n",
    "# ipv.figure()\n",
    "# # we draw the tetrahedron\n",
    "# mesh = ipv.plot_trisurf(x, y, z, triangles=triangles, color='orange')\n",
    "# # and also mark the vertices\n",
    "# ipv.scatter(x, y, z, marker='sphere', color='blue')\n",
    "# ipv.xyzlim(-2, 2)\n",
    "# ipv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing A whole neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipv.figure()\n",
    "# we draw the tetrahedron\n",
    "mesh = ipv.plot_trisurf(largest_mesh.vertices[:,0], largest_mesh.vertices[:,1], largest_mesh.vertices[:,2], triangles=largest_mesh.faces, color='orange')\n",
    "# and also mark the vertices\n",
    "\n",
    "volume_maxs = np.max(largest_mesh.vertices,axis=0)\n",
    "volume_mins = np.min(largest_mesh.vertices,axis=0)\n",
    "ranges = volume_maxs - volume_mins\n",
    "index = [0,1,2]\n",
    "max_index = np.argmax(ranges)\n",
    "min_limits = [0,0,0]\n",
    "max_limits = [0,0,0]\n",
    "\n",
    "buffer = 10000\n",
    "for i in index:\n",
    "    if i == max_index:\n",
    "        min_limits[i] = volume_mins[i] - buffer\n",
    "        max_limits[i] = volume_maxs[i] + buffer \n",
    "        continue\n",
    "    else:\n",
    "        difference = ranges[max_index] - ranges[i]\n",
    "        min_limits[i] = volume_mins[i] - difference/2  - buffer\n",
    "        max_limits[i] = volume_maxs[i] + difference/2 + buffer\n",
    "\n",
    "#ipv.xyzlim(-2, 2)\n",
    "ipv.xlim(min_limits[0],max_limits[0])\n",
    "ipv.ylim(min_limits[1],max_limits[1])\n",
    "ipv.zlim(min_limits[2],max_limits[2])\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the 3D skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the skeleton files into an array\n",
    "def read_skeleton_revised(file_path):\n",
    "    with open(file_path) as f:\n",
    "        bones = np.array([])\n",
    "        for line in f.readlines():\n",
    "            #print(line)\n",
    "            line = (np.array(line.split()[1:], float).reshape(-1, 3))\n",
    "            #print(line[:-1])\n",
    "            #print(line[1:])\n",
    "\n",
    "            #print(bones.size)\n",
    "            if bones.size <= 0:\n",
    "                bones = np.stack((line[:-1],line[1:]),axis=1)\n",
    "            else:\n",
    "                bones = np.vstack((bones,(np.stack((line[:-1],line[1:]),axis=1))))\n",
    "            #print(bones)\n",
    "\n",
    "\n",
    "    return np.array(bones).astype(float)\n",
    "path_and_filename = \"temp/96631955273149705_decimated_poisson_largest_piece\"\n",
    "bone_array = read_skeleton_revised(path_and_filename+\"_skeleton.cgal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_skeleton_verts = bone_array.reshape(-1,3)\n",
    "edges = np.arange(0,len(unique_skeleton_verts)).astype(\"int\").reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipv.figure()\n",
    "# we draw the tetrahedron\n",
    "\n",
    "mesh = ipv.plot_trisurf(unique_skeleton_verts[:,0], \n",
    "                        unique_skeleton_verts[:,1], \n",
    "                        unique_skeleton_verts[:,2], \n",
    "                        lines=edges, color='blue')\n",
    "\n",
    "volume_maxs = np.max(unique_skeleton_verts,axis=0)\n",
    "volume_mins = np.min(unique_skeleton_verts,axis=0)\n",
    "ranges = volume_maxs - volume_mins\n",
    "index = [0,1,2]\n",
    "max_index = np.argmax(ranges)\n",
    "min_limits = [0,0,0]\n",
    "max_limits = [0,0,0]\n",
    "\n",
    "buffer = 10000\n",
    "for i in index:\n",
    "    if i == max_index:\n",
    "        min_limits[i] = volume_mins[i] - buffer\n",
    "        max_limits[i] = volume_maxs[i] + buffer \n",
    "        continue\n",
    "    else:\n",
    "        difference = ranges[max_index] - ranges[i]\n",
    "        min_limits[i] = volume_mins[i] - difference/2  - buffer\n",
    "        max_limits[i] = volume_maxs[i] + difference/2 + buffer\n",
    "\n",
    "#ipv.xyzlim(-2, 2)\n",
    "ipv.xlim(min_limits[0],max_limits[0])\n",
    "ipv.ylim(min_limits[1],max_limits[1])\n",
    "ipv.zlim(min_limits[2],max_limits[2])\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Neuron and skeleton at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipv.figure()\n",
    "# we draw the tetrahedron\n",
    "mesh = ipv.plot_trisurf(largest_mesh.vertices[:,0], largest_mesh.vertices[:,1], largest_mesh.vertices[:,2], triangles=largest_mesh.faces, color='orange')\n",
    "mesh.color = [0., 1., 0., 0.5]\n",
    "mesh.material.transparent = True\n",
    "# and also mark the vertices\n",
    "mesh2 = ipv.plot_trisurf(unique_skeleton_verts[:,0], \n",
    "                        unique_skeleton_verts[:,1], \n",
    "                        unique_skeleton_verts[:,2], \n",
    "                        lines=edges, color='blue')\n",
    "\n",
    "volume_maxs = np.max(largest_mesh.vertices,axis=0)\n",
    "volume_mins = np.min(largest_mesh.vertices,axis=0)\n",
    "ranges = volume_maxs - volume_mins\n",
    "index = [0,1,2]\n",
    "max_index = np.argmax(ranges)\n",
    "min_limits = [0,0,0]\n",
    "max_limits = [0,0,0]\n",
    "\n",
    "buffer = 10000\n",
    "for i in index:\n",
    "    if i == max_index:\n",
    "        min_limits[i] = volume_mins[i] - buffer\n",
    "        max_limits[i] = volume_maxs[i] + buffer \n",
    "        continue\n",
    "    else:\n",
    "        difference = ranges[max_index] - ranges[i]\n",
    "        min_limits[i] = volume_mins[i] - difference/2  - buffer\n",
    "        max_limits[i] = volume_maxs[i] + difference/2 + buffer\n",
    "\n",
    "#ipv.xyzlim(-2, 2)\n",
    "ipv.xlim(min_limits[0],max_limits[0])\n",
    "ipv.ylim(min_limits[1],max_limits[1])\n",
    "ipv.zlim(min_limits[2],max_limits[2])\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Meshlab decimation script working in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_meshlab_script(mlx_script,input_mesh_file,output_mesh_file):\n",
    "    script_command = (\" -i \" + str(input_mesh_file) + \" -o \" + \n",
    "                                    str(output_mesh_file) + \" -s \" + str(mlx_script))\n",
    "    #return script_command\n",
    "    command_to_run = 'xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@ ' + script_command\n",
    "    #command_to_run = 'meshlabserver ' + script_command\n",
    "    \n",
    "    print(command_to_run)\n",
    "    subprocess_result = subprocess.run(command_to_run,shell=True)\n",
    "    \n",
    "    return subprocess_result\n",
    "\n",
    "import os, contextlib\n",
    "import pathlib\n",
    "import subprocess\n",
    "def meshlab_fix_manifold_path_specific_mls(input_path_and_filename,\n",
    "                                           output_path_and_filename=\"\",\n",
    "                                           segment_id=-1,meshlab_script=\"\"):\n",
    "    #fix the path if it comes with the extension\n",
    "    if input_path_and_filename[-4:] == \".off\":\n",
    "        path_and_filename = input_path_and_filename[:-4]\n",
    "        input_mesh = input_path_and_filename\n",
    "    else:\n",
    "        raise Exception(\"Not passed off file\")\n",
    "    \n",
    "    \n",
    "    if output_path_and_filename == \"\":\n",
    "        output_mesh = path_and_filename+\"_mls.off\"\n",
    "    else:\n",
    "        output_mesh = output_path_and_filename\n",
    "    \n",
    "    if meshlab_script == \"\":\n",
    "        meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"remeshing_remove_non_man_edges.mls\"\n",
    "    \n",
    "    #print(\"meshlab_script = \" + str(meshlab_script))\n",
    "    #print(\"starting meshlabserver fixing non-manifolds\")\n",
    "    subprocess_result_1 = run_meshlab_script(meshlab_script,\n",
    "                      input_mesh,\n",
    "                      output_mesh)\n",
    "    #print(\"Poisson subprocess_result= \"+ str(subprocess_result_1))\n",
    "    \n",
    "    if str(subprocess_result_1)[-13:] != \"returncode=0)\":\n",
    "        raise Exception('neuron' + str(segment_id) + \n",
    "                         ' did not fix the manifold edges')\n",
    "    \n",
    "    return output_mesh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to do the screened poisson with meshlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_name = \"poisson_working_meshlab.mls\"\n",
    "\n",
    "input_file_base = \"/notebooks/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum_Blender/Decimation/temp/neuron_96631955273149705_decimated_bac\"\n",
    "output_file = input_file_base + \"_poisson\"\n",
    "meshlab_script_path_and_name = str(pathlib.Path.cwd()) + \"/\" + script_name\n",
    "\n",
    "\n",
    "meshlab_fix_manifold_path_specific_mls(input_path_and_filename=input_file_base + \".off\",\n",
    "                                                   output_path_and_filename=output_file + \".off\",\n",
    "                                                   meshlab_script=meshlab_script_path_and_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how to do the decimation with meshlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum_Blender/Decimation/107816118160698192_original.off -o /notebooks/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum_Blender/Decimation/107816118160698192_original_decimated.off -s /notebooks/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum_Blender/Decimation/decimation_meshlab.mls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/notebooks/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum_Blender/Decimation/107816118160698192_original_decimated.off'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_name = \"decimation_meshlab.mls\"\n",
    "\n",
    "input_file_base = \"/notebooks/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum_Blender/Decimation/107816118160698192_original\"\n",
    "output_file = input_file_base + \"_decimated\"\n",
    "meshlab_script_path_and_name = str(pathlib.Path.cwd()) + \"/\" + script_name\n",
    "\n",
    "\n",
    "meshlab_fix_manifold_path_specific_mls(input_path_and_filename=input_file_base + \".off\",\n",
    "                                                   output_path_and_filename=output_file + \".off\",\n",
    "                                                   meshlab_script=meshlab_script_path_and_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing theh boolean difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykdtree.kdtree import KDTree\n",
    "import time\n",
    "import trimesh\n",
    "import numpy as np\n",
    "\n",
    "def filter_mesh_significant_outside_pieces(unfiltered_mesh,main_mesh,\n",
    "                                           significance_threshold=2000,\n",
    "                                           n_sample_points=3,\n",
    "                                          print_flag=False):\n",
    "    \"\"\"\n",
    "    Purpose; will take in a full, unfiltered mesh and find the biggest mesh piece, and then return a list of that mesh \n",
    "    with all of the other mesh fragments that are both above the significance_threshold AND outside of the biggest mesh piece\n",
    "\n",
    "    Pseudocode: \n",
    "    1) split the meshes to unconnected pieces\n",
    "    2) Filter the meshes for only those above the significance_threshold\n",
    "    3) find the biggest mesh piece\n",
    "    4) Iterate through all of the remaining pieces:\n",
    "        a. Determine if mesh inside or outside main mesh\n",
    "        b. If outside add to final list to return\n",
    "\n",
    "    Returns: \n",
    "    1) list of significant mesh pieces that are not inside of main mesh\n",
    "\n",
    "    \"\"\"\n",
    "    if print_flag:\n",
    "        print(\"------Starting the mesh filter for significant outside pieces-------\")\n",
    "\n",
    "    mesh_pieces = unfiltered_mesh.split(only_watertight=False)\n",
    "    \n",
    "    if print_flag:\n",
    "        print(f\"There were {len(mesh_pieces)} pieces after mesh split\")\n",
    "\n",
    "    significant_pieces = [m for m in mesh_pieces if len(m.faces) > significance_threshold]\n",
    "\n",
    "    if print_flag:\n",
    "        print(f\"There were {len(significant_pieces)} pieces found after size threshold\")\n",
    "    if len(significant_pieces) <=0:\n",
    "        print(\"THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\")\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "    final_mesh_pieces = []\n",
    "\n",
    "    #final_mesh_pieces.append(main_mesh)\n",
    "    for i,mesh in enumerate(significant_pieces):\n",
    "        #get a random sample of points\n",
    "        # points = np.array(mesh.vertices[:n_sample_points,:]) # OLD WAY OF DOING THIS\n",
    "        idx = np.random.randint(len(mesh.vertices), size=n_sample_points)\n",
    "        points = mesh.vertices[idx,:]\n",
    "\n",
    "\n",
    "        start_time = time.time()\n",
    "        signed_distance = trimesh.proximity.signed_distance(main_mesh,points)\n",
    "        #print(f\"Total time = {time.time() - start_time}\")\n",
    "\n",
    "        outside_percentage = sum(signed_distance <= 0)/n_sample_points\n",
    "        if outside_percentage > 0.9:\n",
    "            final_mesh_pieces.append(mesh)\n",
    "            #print(f\"Mesh piece {i} OUTSIDE mesh\")\n",
    "        else:\n",
    "            #print(f\"Mesh piece {i} inside mesh :( \")\n",
    "            pass\n",
    "                \n",
    "    return final_mesh_pieces\n",
    "    \n",
    "def neuron_boolean_difference(main_mesh_verts,\n",
    "                             main_mesh_faces,\n",
    "                             child_mesh_verts,\n",
    "                             child_mesh_faces,\n",
    "                             distance_threshold=5,\n",
    "                             significance_threshold=1000,\n",
    "                             n_sample_points=3,\n",
    "                             print_flag=False):\n",
    "    \"\"\"\n",
    "    returns the boolean difference of two meshes passed. Only returns meshes pieces that \n",
    "    are greater than the size threshold and outside of the main mesh\n",
    "    \n",
    "    Function operation: child_mesh - main_mesh\n",
    "  \n",
    "\n",
    "    Parameters: \n",
    "    main_mesh_verts (np.array): array of the reference mesh vertices\n",
    "    main_mesh_faces (np.array): array of the reference mesh faces\n",
    "    child_mesh_verts (np.array): array of the child mesh vertices that is to be compared to the main mesh\n",
    "    child_mesh_faces (np.array): array of the child mesh faces that is to be compared to the main mesh\n",
    "    \n",
    "    Optional parameters:\n",
    "    -- for controlling the mesh returned --\n",
    "    distance_threshold (int) : distance away from the reference mesh that vertices from the child\n",
    "                                mesh will considered distinct and part of the difference mesh \n",
    "                                (default=5)\n",
    "    significance_threshold (int) : number of faces necessary for any distinct/unconnected part of the \n",
    "                                    difference mesh to be considered relevant and included in the difference mesh\n",
    "                                (default=1000)\n",
    "    n_sample_points (int) : number of vertices to check to see if submesh is a mesh located inside of the main mesh.\n",
    "                            The less there are the quicker the speed for filtering the difference mesh\n",
    "                            (default=3)\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    difference_mesh_verts (np.array): array of vertices from the mesh boolean operation of child - main mesh\n",
    "    difference_mesh_faces (np.array): array of faces from the mesh boolean operation of child - main mesh\n",
    "    \"\"\"\n",
    "    \n",
    "    #Create the kdtree from main mesh and run the queries\n",
    "    \n",
    "    import time\n",
    "    global_time = time.time()\n",
    "    start_time = time.time()\n",
    "    mesh_tree = KDTree(main_mesh_verts)\n",
    "    distances,closest_node = mesh_tree.query(child_mesh_verts)\n",
    "    if print_flag:\n",
    "        print(f\"Total time for KDTree creation and queries: {time.time() - start_time}\")\n",
    "    \n",
    "    if print_flag:\n",
    "        print(\"Original number vertices in child mesh = \" + str(len(child_mesh_verts)))\n",
    "    vertex_indices = np.where(distances > distance_threshold)[0]\n",
    "    if print_flag:\n",
    "        print(\"Number of vertices after distance threshold applied =  \" + str(len(vertex_indices)))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    set_vertex_indices = set(list(vertex_indices))\n",
    "    face_indices_lookup = np.linspace(0,len(child_mesh_faces)-1,len(child_mesh_faces)).astype('int')\n",
    "    face_indices_lookup_bool = [len(set_vertex_indices.intersection(set(tri))) > 0 for tri in child_mesh_faces]\n",
    "    face_indices_lookup = face_indices_lookup[face_indices_lookup_bool]\n",
    "\n",
    "    if print_flag:\n",
    "        print(f\"Total time for finding faces after distance threshold applied: {time.time() - start_time}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    trimesh_original = trimesh.Trimesh(child_mesh_verts,child_mesh_faces,process=False) \n",
    "    new_submesh = trimesh_original.submesh([face_indices_lookup],only_watertight=False,append=True)\n",
    "    \n",
    "    pymesh_mesh = trimesh.Trimesh(main_mesh_verts,main_mesh_faces)\n",
    "    #return new_submesh\n",
    "    #filter the mesh for only significant pieces on the outside\n",
    "    returned_mesh = filter_mesh_significant_outside_pieces(new_submesh,pymesh_mesh,\n",
    "                                                           significance_threshold,\n",
    "                                                           n_sample_points=n_sample_points,\n",
    "                                                          print_flag=print_flag)\n",
    "    \n",
    "    total_returned_mesh = trimesh.Trimesh(vertices = np.array([]),\n",
    "                                     faces = np.array([]))\n",
    "    for r in returned_mesh:\n",
    "        total_returned_mesh = total_returned_mesh + r\n",
    "\n",
    "    if print_flag:\n",
    "        print(f\"Total time for filtering: {time.time() - start_time}\")\n",
    "    \n",
    "    if print_flag:\n",
    "        print(f\"Total time for boolean difference: {time.time() - global_time}\")\n",
    "    return total_returned_mesh.vertices,total_returned_mesh.faces\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_mesh = trimesh.load_mesh(\"temp/96631955273149705_decimated_poisson_largest_piece.off\")\n",
    "original_mesh = trimesh.load_mesh(\"temp/neuron_96631955273149705_decimated_bac.off\")\n",
    "\n",
    "mesh_pieces =neuron_boolean_difference( largest_mesh.vertices,\n",
    "                                               largest_mesh.faces,\n",
    "                                                original_mesh.vertices,\n",
    "                                               original_mesh.faces,\n",
    "                                       \n",
    "                                               distance_threshold=1000,\n",
    "                                               significance_threshold=1000,\n",
    "                                               n_sample_points=10)\n",
    "\n",
    "significant_leftovers = trimesh.Trimesh(vertices = mesh_pieces[0],\n",
    "                                        faces = mesh_pieces[1]\n",
    "                                       )\n",
    "\n",
    "significant_leftovers.export(\"temp/significant_leftovers.off\")dd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
