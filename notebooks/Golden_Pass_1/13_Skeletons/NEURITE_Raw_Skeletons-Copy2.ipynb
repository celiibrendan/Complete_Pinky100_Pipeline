{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWill generate the skeletons for all of the\\nExhitatory Neurons and Orphan Neurons\\n\\nProcess: \\n1) Check which table the neuron is in\\n2) Filter away any error labels \\n3) Run pymeshfix on neuron\\n4) Run skeletonization\\n5) Write to datajoint as array\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Will generate the skeletons for all of the\n",
    "Exhitatory Neurons and Orphan Neurons\n",
    "\n",
    "Process: \n",
    "1) Check which table the neuron is in\n",
    "2) Filter away any error labels \n",
    "3) Run pymeshfix on neuron\n",
    "4) Run skeletonization\n",
    "5) Write to datajoint as array\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import time\n",
    "import pymeshfix\n",
    "import os\n",
    "import datetime\n",
    "import calcification_Module as cm\n",
    "from meshparty import trimesh_io\n",
    "\n",
    "#for supressing the output\n",
    "import os, contextlib\n",
    "import pathlib\n",
    "import subprocess\n",
    "\n",
    "#for error counting\n",
    "from collections import Counter\n",
    "\n",
    "#for reading in the new raw_skeleton files\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@10.28.0.34:3306\n"
     ]
    }
   ],
   "source": [
    "#setting the address and the username\n",
    "dj.config['database.host'] = '10.28.0.34'\n",
    "dj.config['database.user'] = 'celiib'\n",
    "dj.config['database.password'] = 'newceliipass'\n",
    "dj.config['safemode']=True\n",
    "dj.config[\"display.limit\"] = 20\n",
    "\n",
    "schema = dj.schema('microns_ta3p100')\n",
    "ta3p100 = dj.create_virtual_module('ta3p100', 'microns_ta3p100')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output for the skeleton edges to be stored by datajoint\n",
    "\"\"\" OLD WAY THAT DATAJOINT WAS GETTING MAD AT \n",
    "def read_skeleton(file_path):\n",
    "    with open(file_path) as f:\n",
    "        bones = list()\n",
    "        for line in f.readlines():\n",
    "            bones.append(np.array(line.split()[1:], float).reshape(-1, 3))\n",
    "    return np.array(bones)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" NEW FLAT LIST WAY\"\"\"\n",
    "#practice reading in dummy skeleton file\n",
    "def read_skeleton_flat(file_path):\n",
    "    with open(file_path) as f:\n",
    "        bones = list()\n",
    "        for line in f.readlines():\n",
    "            for r in (np.array(line.split()[1:], float).reshape(-1, 3)):\n",
    "                bones.append(r)\n",
    "            bones.append([np.nan,np.nan,np.nan])\n",
    "    return np.array(bones).astype(float)\n",
    "\n",
    "\n",
    "\"\"\" New read function: for adjusted 2 vert skeleton output\"\"\"\n",
    "def read_raw_skeleton(file_path):\n",
    "    edges = list()\n",
    "    with open(file_path) as f:\n",
    "        reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONE)\n",
    "        for i,row in enumerate(reader):\n",
    "            v1 = (float(row[1]),float(row[2]),float(row[3]))\n",
    "            v2 = (float(row[4]),float(row[5]),float(row[6]))\n",
    "            edges.append((v1,v2))\n",
    "    return np.array(edges).astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure there is a temp file in the directory, if not then make one\n",
    "#if temp folder doesn't exist then create it\n",
    "if (os.path.isdir(os.getcwd() + \"/pymesh_NEURITES\")) == False:\n",
    "    os.mkdir(\"pymesh_NEURITES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the output file\n",
    "##write the OFF file for the neuron\n",
    "import pathlib\n",
    "def write_Whole_Neuron_Off_file(neuron_ID,\n",
    "                                vertices=[], \n",
    "                                triangles=[],\n",
    "                                folder=\"pymesh_NEURITES\"):\n",
    "    #primary_key = dict(segmentation=1, segment_id=segment_id, decimation_ratio=0.35)\n",
    "    #vertices, triangles = (mesh_Table_35 & primary_key).fetch1('vertices', 'triangles')\n",
    "    \n",
    "    num_vertices = (len(vertices))\n",
    "    num_faces = len(triangles)\n",
    "    \n",
    "    #get the current file location\n",
    "    file_loc = pathlib.Path.cwd() / folder\n",
    "    filename = \"neuron_\" + str(neuron_ID)\n",
    "    path_and_filename = file_loc / filename\n",
    "    \n",
    "    #print(file_loc)\n",
    "    #print(path_and_filename)\n",
    "    \n",
    "    #open the file and start writing to it    \n",
    "    f = open(str(path_and_filename) + \".off\", \"w\")\n",
    "    f.write(\"OFF\\n\")\n",
    "    f.write(str(num_vertices) + \" \" + str(num_faces) + \" 0\\n\" )\n",
    "    \n",
    "    \n",
    "    #iterate through and write all of the vertices in the file\n",
    "    for verts in vertices:\n",
    "        f.write(str(verts[0]) + \" \" + str(verts[1]) + \" \" + str(verts[2])+\"\\n\")\n",
    "    \n",
    "    #print(\"Done writing verts\")\n",
    "        \n",
    "    for faces in triangles:\n",
    "        f.write(\"3 \" + str(faces[0]) + \" \" + str(faces[1]) + \" \" + str(faces[2])+\"\\n\")\n",
    "    \n",
    "    print(\"Done writing OFF file\")\n",
    "    #f.write(\"end\")\n",
    "    \n",
    "    return str(path_and_filename),str(filename),str(file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meshlab_fix_manifold(key,folder=\"pymesh_NEURITES\"):\n",
    "    \n",
    "    file_loc = pathlib.Path.cwd() / folder\n",
    "    filename = \"neuron_\" + str(key[\"segment_id\"])\n",
    "    path_and_filename = str(file_loc / filename)\n",
    "    \n",
    "    \n",
    "    input_mesh = path_and_filename + \".off\"\n",
    "    output_mesh = path_and_filename+\"_mls.off\"\n",
    "    \n",
    "    \n",
    "    meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"remeshing_remove_non_man_edges.mls\"\n",
    "    \n",
    "    print(\"starting meshlabserver fixing non-manifolds\")\n",
    "    subprocess_result_1 = run_meshlab_script(meshlab_script,\n",
    "                      input_mesh,\n",
    "                      output_mesh)\n",
    "    #print(\"Poisson subprocess_result= \"+ str(subprocess_result_1))\n",
    "    \n",
    "    if str(subprocess_result_1)[-13:] != \"returncode=0)\":\n",
    "        raise Exception('neuron' + str(key[\"segment_id\"]) + \n",
    "                         ' did not fix the manifold edges')\n",
    "    \n",
    "    return output_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_meshlab_script(mlx_script,input_mesh_file,output_mesh_file):\n",
    "    script_command = (\" -i \" + str(input_mesh_file) + \" -o \" + \n",
    "                                    str(output_mesh_file) + \" -s \" + str(mlx_script))\n",
    "    #return script_command\n",
    "    subprocess_result = subprocess.run('xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@ ' + \n",
    "                   script_command,shell=True)\n",
    "    \n",
    "    return subprocess_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class NeuriteRawSkeleton(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> ta3p100.Mesh\n",
    "    time_updated      :timestamp    # the time at which the skeleton was generated\n",
    "    ---\n",
    "    n_edges   :int unsigned #number of edges stored\n",
    "    edges     :longblob #array storing edges on each row\n",
    "    n_bodies    :tinyint unsigned #the amount of segments the neurite was originally split into\n",
    "    lagest_mesh_perc : float #the percentage of the entire mesh that the largest submesh makes up\n",
    "     \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    key_source = ta3p100.Mesh() & ta3p100.NeuriteRevised() & ta3p100.CurrentSegmentation\n",
    "    #how you get the date and time  datetime.datetime.now()\n",
    "    \n",
    "    def make(self, key):\n",
    "        global_time = time.time()\n",
    "        #get the mesh with the error segments filtered away\n",
    "        start_time = time.time()\n",
    "        print(str(key['segment_id']) +  \":\")\n",
    "        my_dict = (ta3p100.Mesh & ta3p100.NeuriteRevised.proj() & ta3p100.CurrentSegmentation\n",
    "                           & key).fetch1()\n",
    "        print(f\"Step 1: Retrieving Mesh and removing error segments: {time.time() - start_time}\")\n",
    "        new_key = dict(segmentation=key[\"segmentation\"],\n",
    "                       segment_id=key[\"segment_id\"])\n",
    "        \n",
    "        \n",
    "# Don't need these attributes      \n",
    "#vertices=key[\"vertices\"],\n",
    "#                       triangles=new_key[\"triangles\"],n_vertices=key[\"n_vertices\"],\n",
    "#                       n_triangles=key[\"n_triangles\"])\n",
    "        \n",
    "        \n",
    "        start_time = time.time()\n",
    "        #pass the vertices and faces to pymeshfix to become watertight\n",
    "        \n",
    "        mesh = trimesh_io.Mesh(vertices=my_dict[\"vertices\"], faces=my_dict[\"triangles\"])\n",
    "        count, labels = trimesh_io.trimesh.graph.csgraph.connected_components(\n",
    "                                                            mesh.edges_sparse,\n",
    "                                                            directed=False,\n",
    "                                                            return_labels=True)\n",
    "        \n",
    "        new_key[\"n_bodies\"] = count\n",
    "        values = np.array(labels)\n",
    "        searchval = 0\n",
    "        ii = np.where(values == searchval)[0]\n",
    "        new_key[\"lagest_mesh_perc\"] = len(ii)/len(labels)\n",
    "        \n",
    "        print(f\"Step 2a: Getting the number of splits: {time.time() - start_time}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        start_time = time.time()\n",
    "        #pass the vertices and faces to pymeshfix to become watertight\n",
    "        meshfix = pymeshfix.MeshFix(my_dict[\"vertices\"],my_dict[\"triangles\"])\n",
    "        meshfix.repair(verbose=False,joincomp=True,remove_smallest_components=False)\n",
    "        print(f\"Step 2b: Pymesh shrinkwrapping: {time.time() - start_time}\")\n",
    "        \n",
    "        #print(\"Step 2: Writing Off File\")\n",
    "        start_time = time.time()\n",
    "        #write the new mesh to off file\n",
    "        path_and_filename,filename,file_loc = write_Whole_Neuron_Off_file(str(new_key[\"segment_id\"]),meshfix.v,meshfix.f)\n",
    "        print(f\"Step 3: Writing shrinkwrap off file: {time.time() - start_time}\")\n",
    "        \n",
    "        #Run the meshlabserver scripts\n",
    "        start_time = time.time()\n",
    "        output_mesh = meshlab_fix_manifold(key)\n",
    "        print(f\"Step 4: Meshlab fixing non-manifolds: {time.time() - start_time}\")\n",
    "\n",
    "        print(output_mesh[:-4])\n",
    "              \n",
    "        #send to be skeletonized\n",
    "        start_time = time.time()\n",
    "        return_value = cm.calcification(output_mesh[:-4])\n",
    "        if return_value > 0:\n",
    "            raise Exception('skeletonization for neuron ' + str(new_key[\"segment_id\"]) + \n",
    "                            ' did not finish... exited with error code: ' + str(return_value))\n",
    "        #print(f\"Step 5: Generating Skeleton: {time.time() - start_time}\")\n",
    "        \n",
    "              \n",
    "              \n",
    "        #read in the skeleton files into an array\n",
    "        bone_array = read_raw_skeleton(output_mesh[:-4]+\"_skeleton.cgal\")\n",
    "            \n",
    "        #print(bone_array)\n",
    "        if len(bone_array) <= 0:\n",
    "            raise Exception('No skeleton generated for ' + str(new_key[\"segment_id\"]))\n",
    "        print(f\"Step 5: Generating and reading Skeleton: {time.time() - start_time}\")\n",
    "        \n",
    "              \n",
    "        start_time = time.time()\n",
    "        new_key[\"n_edges\"] = len(bone_array)\n",
    "        new_key[\"edges\"] = bone_array\n",
    "        #new_key[\"branches\"] = []\n",
    "        \n",
    "        \n",
    "        new_key[\"time_updated\"]=str(datetime.datetime.now())\n",
    "        #print(key)\n",
    "        #if all goes well then write to database\n",
    "        self.insert1(new_key,skip_duplicates=True)\n",
    "        os.system(\"rm \"+str(path_and_filename)+\"*\")\n",
    "        print(f\"Step 6: Inserting dictionary: {time.time() - start_time}\")\n",
    "        print(f\"Total time: {time.time() - global_time}\")\n",
    "        print(\"\\n\\n\")\n",
    "          \n",
    "                         \n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "NeuriteRawSkeleton.populate(reserve_jobs=True)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(schema.jobs & \"table_name='__neurite_skeletons'\").delete()\n",
    "#ta3p100.NeuriteSkeletons()#.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
