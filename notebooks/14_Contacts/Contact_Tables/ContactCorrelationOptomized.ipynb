{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import time\n",
    "import pymeshfix\n",
    "import os\n",
    "import datetime\n",
    "import calcification_Module as cm\n",
    "from meshparty import trimesh_io\n",
    "\n",
    "#for supressing the output\n",
    "import os, contextlib\n",
    "import pathlib\n",
    "import subprocess\n",
    "\n",
    "#for error counting\n",
    "from collections import Counter\n",
    "\n",
    "#for reading in the new raw_skeleton files\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the address and the username\n",
    "dj.config['database.host'] = '10.28.0.34'\n",
    "dj.config['database.user'] = 'celiib'\n",
    "dj.config['database.password'] = 'newceliipass'\n",
    "dj.config['safemode']=True\n",
    "dj.config[\"display.limit\"] = 20\n",
    "\n",
    "schema = dj.schema('microns_ta3p100')\n",
    "ta3p100 = dj.create_virtual_module('ta3p100', 'microns_ta3p100')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABLE DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates the pearson correlation and cosine similarity while accounting for the corner cases\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "\n",
    "def find_pearson(v1,v2):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        if np.array_equal(v1,v2):\n",
    "            return 1\n",
    "        elif abs(sum(v1 - v2)) == v1.size:\n",
    "            return -1\n",
    "        else:\n",
    "            #perform the pearson correlation\n",
    "            corr_conversion, p_value_conversion = pearsonr(v1, v2)\n",
    "            return corr_conversion\n",
    "\n",
    "def find_cosine(v1,v2):\n",
    "    if np.array_equal(v1,v2):\n",
    "        return 1\n",
    "    elif abs(sum(v1 - v2)) == v1.size:\n",
    "        return 0\n",
    "    else:\n",
    "        v1 = v1.reshape(1,len(v1))\n",
    "        v2 = v2.reshape(1,len(v2))\n",
    "        return cosine_similarity(v1, v2)[0][0]\n",
    "\n",
    "def jaccard_similarity(x,y):\n",
    "\n",
    "    \"\"\" returns the jaccard similarity between two lists \"\"\"\n",
    "\n",
    "    intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
    "    union_cardinality = len(set.union(*[set(x), set(y)]))\n",
    "    return intersection_cardinality/float(union_cardinality)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.24999999999999994\n",
      "cohen = 0.11764705882352944\n",
      "total time = 0.0007026195526123047\n"
     ]
    }
   ],
   "source": [
    "# v1 = np.array([1,1,1,1,1])\n",
    "# v2 = np.array([0,0,0,0,0])\n",
    "# print(find_cosine(v1,v2))\n",
    "# v1 = np.array([0,0,0,0,0])\n",
    "# v2 = np.array([0,0,0,0,0])\n",
    "# print(find_cosine(v1,v2))\n",
    "v1 = np.array([0,1,0,0,0]*100)\n",
    "v2 = np.array([1,1,1,1,0]*100)\n",
    "print(find_cosine(v1,v2))\n",
    "print(find_pearson(v1,v2))\n",
    "# v1 = v1.reshape(1,len(v1))\n",
    "# v2 = v2.reshape(1,len(v2))\n",
    "# print(cosine_similarity(v1, v2))\n",
    "print(\"cohen = \" + str(sklearn.metrics.cohen_kappa_score(v1,v2)))\n",
    "\n",
    "#can be how to get the number of matches (but not tell what type)\n",
    "start_time = time.time()\n",
    "similar = np.dot((np.vstack((v1,v2)).T),np.array([-0.5,0.5])) == 0\n",
    "print(f\"total time = {time.time()-start_time}\")\n",
    "\n",
    "# start_time = time.time()\n",
    "# greater = sum(v1 > v2\n",
    "# less = v1 < v2\n",
    "# equal = v1==v2 \n",
    "# ones = v1[v1==v2] == 1\n",
    "# print(f\"total time = {time.time()-start_time}\")\n",
    "# #print(greater)\n",
    "\n",
    "\n",
    "# different = similar == False\n",
    "# higher np.dot((np.vstack((v1,v2)).T),np.array([-0.5,0.5])) == 0\n",
    "# print(similar)\n",
    "# print(different)\n",
    "#represents the mismatches\n",
    "#b,c = \n",
    "\n",
    "# print(jaccard_similarity(v1,v2)) #non-correlation based similarity measurement, alright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100   0]\n",
      " [200 100]]\n",
      "total time = 0.0013179779052734375\n",
      "total time = 0.0009391307830810547\n",
      "100 200 0 100\n",
      "total time = 0.003767251968383789\n"
     ]
    }
   ],
   "source": [
    "v1 = np.array([1,0,0,0]*100)\n",
    "v2 = np.array([1,1,1,0]*100)\n",
    "\n",
    "np.vstack((v1,1-v1))\n",
    "np.vstack((v2,1-v2))\n",
    "\n",
    "start_time = time.time()\n",
    "print(np.dot(np.vstack((v1,1-v1)),np.vstack((v2,1-v2)).T))\n",
    "print(f\"total time = {time.time()-start_time}\")\n",
    "\n",
    "start_time = time.time()\n",
    "a = np.dot(v1,v2)\n",
    "b = np.dot(1-v1,v2)\n",
    "c = np.dot(v1,1-v2)\n",
    "d = np.dot(1-v1,1-v2)\n",
    "(a + d)/(a + b + c + d)\n",
    "print(f\"total time = {time.time()-start_time}\")\n",
    "print(a,b,c,d)\n",
    "\n",
    "start_time = time.time()\n",
    "sklearn.metrics.jaccard_similarity_score(v1,v2)\n",
    "print(f\"total time = {time.time()-start_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tarantula(v1,v2):\n",
    "    a = np.dot(v1,v2)\n",
    "    b = np.dot(1-v1,v2)\n",
    "    c = np.dot(v1,1-v2)\n",
    "    d = np.dot(1-v1,1-v2)\n",
    "    #print(a,b,c,d)\n",
    "\n",
    "    return (a*(c+d))/(c*(a+b))\n",
    "\n",
    "\n",
    "def jaccard_bac(v1,v2):\n",
    "    a = np.dot(v1,v2)\n",
    "    b = np.dot(1-v1,v2)\n",
    "    c = np.dot(v1,1-v2)\n",
    "    d = np.dot(1-v1,1-v2)\n",
    "    #print(a,b,c,d)\n",
    "\n",
    "    return (a + d)/(a + b + c + d)\n",
    "\n",
    "def jaccard_bac_stacked(v1,v2):\n",
    "    v_total = np.dot()\n",
    "    \n",
    "    a = np.dot(v1,v2)\n",
    "    b = np.dot(1-v1,v2)\n",
    "    c = np.dot(v1,1-v2)\n",
    "    d = np.dot(1-v1,1-v2)\n",
    "    #print(a,b,c,d)\n",
    "\n",
    "    return (a + d)/(a + b + c + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson = 0.6123724356957947\n",
      "cosine = 0.7071067811865475\n",
      "jaccard_bac = 0.8\n",
      "jaccard_similarity = 0.3333333333333333\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-19d37ac69b14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"jaccard_bac = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaccard_bac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"jaccard_similarity = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaccard_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"jaccard_similarity_score sklearn = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaccard_similarity_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"total time = {time.time()-start_time}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mjaccard_similarity_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "v1 = np.array([0,0,0,0,1]*100)\n",
    "v2 = np.array([0,0,0,0.1,0.1]*100)\n",
    "#print(tarantula(v1,v2))\n",
    "print(\"pearson = \"+str(find_pearson(v1,v2)))\n",
    "print(\"cosine = \"+str(find_cosine(v1,v2)))\n",
    "print(\"jaccard_bac = \" + str(jaccard_bac(v1,v2)))\n",
    "print(\"jaccard_similarity = \" + str(jaccard_similarity(v1,v2)))\n",
    "print(\"jaccard_similarity_score sklearn = \" + str(sklearn.metrics.jaccard_similarity_score(v1,v2)))\n",
    "\n",
    "print(f\"total time = {time.time()-start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SCORERS',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'accuracy_score',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'auc',\n",
       " 'average_precision_score',\n",
       " 'balanced_accuracy_score',\n",
       " 'base',\n",
       " 'brier_score_loss',\n",
       " 'calinski_harabaz_score',\n",
       " 'check_scoring',\n",
       " 'classification',\n",
       " 'classification_report',\n",
       " 'cluster',\n",
       " 'cohen_kappa_score',\n",
       " 'completeness_score',\n",
       " 'confusion_matrix',\n",
       " 'consensus_score',\n",
       " 'coverage_error',\n",
       " 'davies_bouldin_score',\n",
       " 'euclidean_distances',\n",
       " 'explained_variance_score',\n",
       " 'f1_score',\n",
       " 'fbeta_score',\n",
       " 'fowlkes_mallows_score',\n",
       " 'get_scorer',\n",
       " 'hamming_loss',\n",
       " 'hinge_loss',\n",
       " 'homogeneity_completeness_v_measure',\n",
       " 'homogeneity_score',\n",
       " 'jaccard_similarity_score',\n",
       " 'label_ranking_average_precision_score',\n",
       " 'label_ranking_loss',\n",
       " 'log_loss',\n",
       " 'make_scorer',\n",
       " 'matthews_corrcoef',\n",
       " 'mean_absolute_error',\n",
       " 'mean_squared_error',\n",
       " 'mean_squared_log_error',\n",
       " 'median_absolute_error',\n",
       " 'mutual_info_score',\n",
       " 'normalized_mutual_info_score',\n",
       " 'pairwise',\n",
       " 'pairwise_distances',\n",
       " 'pairwise_distances_argmin',\n",
       " 'pairwise_distances_argmin_min',\n",
       " 'pairwise_distances_chunked',\n",
       " 'pairwise_fast',\n",
       " 'pairwise_kernels',\n",
       " 'precision_recall_curve',\n",
       " 'precision_recall_fscore_support',\n",
       " 'precision_score',\n",
       " 'r2_score',\n",
       " 'ranking',\n",
       " 'recall_score',\n",
       " 'regression',\n",
       " 'roc_auc_score',\n",
       " 'roc_curve',\n",
       " 'scorer',\n",
       " 'silhouette_samples',\n",
       " 'silhouette_score',\n",
       " 'v_measure_score',\n",
       " 'zero_one_loss']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myArray  = [1.2 0.2 0.6 0.  2.2 0.  0.2 0.  0.1 2.9 0.1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "myArray = np.array([1.2,0.2,0.6,0,2.2,0,.2,0,0.1,2.9,0.1])\n",
    "print(\"myArray  = \" + str(myArray))\n",
    "myArray[myArray>1] = 1\n",
    "sum(np.ceil(myArray))\n",
    "# myArray[myArray>1] = 1\n",
    "# print(\"myArray  = \" + str(myArray))\n",
    "# print(np.ceil(myArray))\n",
    "# sum(np.ceil(myArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class ContactCorrelation(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> ta3p100.Segment\n",
    "    segment_b :bigint unsigned #id of the postsynaptic neuron\n",
    "    ---\n",
    "    n_seg_a =              :bigint unsigned #n_presyns contacting onto segment_id\n",
    "    n_seg_b =              :bigint unsigned #n_presyns contacting onto segment_b\n",
    "    n_seg_shared           :bigint unsigned #n_presyns contacting onto both segment_id and segment_b\n",
    "    n_seg_union            :bigint unsigned #n_presyns contacting either segment_id or segment_b\n",
    "    n_seg_shared_converted :bigint unsigned #n_presyns contacting onto both and converting on at least 1 postsyn\n",
    "    n_seg_a_converted      :bigint unsigned #n_presyns contacting onto both and converting on postsyna a\n",
    "    n_seg_a_converted_prop :float           #proportion of n_presyns contacting onto both which convert at least onto postsyna a\n",
    "    n_seg_b_converted      :bigint unsigned #n_presyns contacting onto both and converting on postsyna b\n",
    "    n_seg_b_converted_prop :float           #proportion of n_presyns contacting onto both which convert at least onto postsyna b\n",
    "    binary_conversion_pearson=null :float   #pearson correlation for binary n_synapse/n_contact rate\n",
    "    binary_conversion_cosine=null :float    #cosine similarity correlation for binary n_synapse/n_contact rate\n",
    "    conversion_pearson=null :float          #Pearson correlation for n_synapse/n_contact rate\n",
    "    conversion_cosine=null :float           #cosine similarity for n_synapse/n_contact rate\n",
    "    density_pearson=null :float             #Pearson correlation for n_synapse/postsyn_length rate\n",
    "    density_cosine=null :float              #cosine similarity for n_synapse/postsyn_length rate\n",
    "    syn_volume_mean_pearson=null :float     #Pearson correlation for mean of synaptic volume\n",
    "    syn_volume_mean_cosine=null :float      #cosine similarity for mean of synaptic volume\n",
    "    syn_density_pearson=null :float         #Pearson correlation for n_synapses*synapse_sizes_mean/postsyn_length rate\n",
    "    syn_density_cosine=null :float          #cosine similarity for n_synapses*synapse_sizes_mean/postsyn_length rate\n",
    "    binary_conversion_pearson_converted=null :float   #pearson correlation for binary n_synapse/n_contact rate for axon group with at least 1 conversion\n",
    "    binary_conversion_cosine_converted=null :float    #cosine similarity correlation for binary n_synapse/n_contact rate for axon group with at least 1 conversion\n",
    "    conversion_pearson_converted=null :float          #Pearson correlation for n_synapse/n_contact rate for axon group with at least 1 conversion\n",
    "    conversion_cosine_converted=null :float           #cosine similarity for n_synapse/n_contact rate for axon group with at least 1 conversion\n",
    "    density_pearson_converted=null :float             #Pearson correlation for n_synapse/postsyn_length rate for axon group with at least 1 conversion\n",
    "    density_cosine_converted=null :float              #cosine similarity for n_synapse/postsyn_length rate for axon group with at least 1 conversion\n",
    "    syn_volume_mean_pearson_converted=null :float     #Pearson correlation for mean of synaptic volume for axon group with at least 1 conversion\n",
    "    syn_volume_mean_cosine_converted=null :float      #cosine similarity for mean of synaptic volume for axon group with at least 1 conversion\n",
    "    syn_density_pearson_converted=null :float         #Pearson correlation for n_synapses*synapse_sizes_mean/postsyn_length rate for axon group with at least 1 conversion\n",
    "    syn_density_cosine_converted=null :float          #cosine similarity for n_synapses*synapse_sizes_mean/postsyn_length rate for axon group with at least 1 conversion\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    key_source = ta3p100.Segmentation & ta3p100.CurrentSegmentation\n",
    "    \n",
    "    def make(self,key):\n",
    "        #Retrieves the PrePost table that will be using in an all in one insertion (MAY HAVE TO ADJUST FOR BIGGER DATA SETS IN FUTURE)\n",
    "        prepost_data = ta3p100.ContactPrePost2.proj(\"postsyn\",\"total_contact_conversion\",\n",
    "                \"total_contact_density\",\"total_synapse_sizes_mean\",\n",
    "                syn_density=\"(total_n_synapses*total_synapse_sizes_mean)/total_postsyn_length\",\n",
    "                presyn=\"segment_id\").fetch()\n",
    "        df = pd.DataFrame(prepost_data)\n",
    "\n",
    "        #gets all the combinations of postsyn-postsyn without any repeats\n",
    "        targets = (dj.U(\"postsyn\") & ta3p100.Contact).proj(segment_id=\"postsyn\") - ta3p100.SegmentExclude\n",
    "        info = targets * targets.proj(segment_b='segment_id') & 'segment_id < segment_b'\n",
    "        segment_pairs = info.fetch()\n",
    "        \n",
    "        total_correlations = []\n",
    "\n",
    "        for postsyn1,postsyn2 in segment_pairs:\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "            #print(\"postsyn1 = \" + str(postsyn1))\n",
    "            #print(\"postsyn2 = \" + str(postsyn2))\n",
    "\n",
    "            #get all of the rows with postsyn 1 and 2\n",
    "            df_1 = df[df[\"postsyn\"]==postsyn1]\n",
    "            df_2 = df[df[\"postsyn\"]==postsyn2]\n",
    "\n",
    "            #find the number of presyns for each\n",
    "\n",
    "            #how you restrict a table by the values in the other table\n",
    "            df_1_common = df_1[df_1[\"presyn\"].isin(df_2[\"presyn\"])].sort_values(by=['presyn'])\n",
    "            df_2_common = df_2[df_2[\"presyn\"].isin(df_1[\"presyn\"])].sort_values(by=['presyn'])\n",
    "\n",
    "\n",
    "            ###########------------------------------------------------------###########\n",
    "            #need to get the common axons that have at least one converted contact on one of the postsyns\n",
    "            \"\"\"pseudocode\n",
    "            #get the conversion rates for both tables\n",
    "            #add them up\n",
    "            #get the indices that are greater than 0\n",
    "            #get the presyn ids that match those rows\n",
    "            #further restrict both groups by those ids\n",
    "            \"\"\"\n",
    "\n",
    "            #get both of their conversion rates\n",
    "            test_1_conv = df_1_common[\"total_contact_conversion\"].to_numpy()\n",
    "            test_2_conv = df_2_common[\"total_contact_conversion\"].to_numpy()\n",
    "\n",
    "            test_1_presyn = df_1_common[\"presyn\"].to_numpy()\n",
    "            new_presyns = test_1_presyn[(test_1_conv + test_2_conv) > 0]\n",
    "\n",
    "            df_1_common_converted = df_1_common[df_1_common[\"presyn\"].isin(new_presyns)]\n",
    "            df_2_common_converted = df_2_common[df_2_common[\"presyn\"].isin(new_presyns)]\n",
    "            ###########------------------------------------------------------###########\n",
    "\n",
    "            dict_segmenation=2\n",
    "            dict_segment_id=postsyn1\n",
    "            dict_segment_b=postsyn2\n",
    "\n",
    "\n",
    "            #finds the number of segments, shared_segments and union segments\n",
    "            n_seg_a = df_1.shape[0]\n",
    "            n_seg_b = df_2.shape[0]\n",
    "            n_seg_shared = df_1_common.shape[0]\n",
    "            n_seg_shared_converted = df_1_common_converted.shape[0]\n",
    "            n_seg_union = n_seg_a + n_seg_b - n_seg_shared\n",
    "            \n",
    "            \n",
    "            #get the number and proportion on presyns that convert onto each segment inside the converted axon group\n",
    "            test_1_conv[test_1_conv>1] = 1\n",
    "            n_seg_a_converted = sum(np.ceil(test_1_conv))\n",
    "            test_2_conv[test_2_conv>1] = 1\n",
    "            n_seg_b_converted = sum(np.ceil(test_2_conv))\n",
    "            \n",
    "            n_seg_a_converted_prop = n_seg_a_converted/n_seg_shared_converted\n",
    "            n_seg_b_converted_prop = n_seg_b_converted/n_seg_shared_converted\n",
    "     \n",
    "\n",
    "            #initialize the dictionary that will be saved:\n",
    "            corr_dict = dict(segmentation=2,segment_id=postsyn1,\n",
    "                                          segment_b=postsyn2,\n",
    "                                          n_seg_a=n_seg_a,\n",
    "                                            n_seg_b=n_seg_b,\n",
    "                                            n_seg_shared=n_seg_shared,\n",
    "                                            n_seg_shared_converted=n_seg_shared_converted,\n",
    "                                            n_seg_union=n_seg_union,\n",
    "                                            n_seg_a_converted=n_seg_a_converted,\n",
    "                                            n_seg_b_converted=n_seg_b_converted,\n",
    "                                            n_seg_a_converted_prop=n_seg_a_converted_prop,\n",
    "                                            n_seg_b_converted_prop=n_seg_b_converted_prop)\n",
    "\n",
    "\n",
    "            #initialize the variables that need to be set in the dictionary\n",
    "\n",
    "\n",
    "            #ones that are set by 1st group\n",
    "            binary_conversion_pearson = np.NaN\n",
    "            binary_conversion_cosine = np.NaN\n",
    "            conversion_pearson = np.NaN\n",
    "            conversion_cosine = np.NaN\n",
    "            density_pearson = np.NaN\n",
    "            density_cosine = np.NaN\n",
    "            syn_volume_mean_pearson = np.NaN\n",
    "            syn_volume_mean_cosine = np.NaN\n",
    "            syn_density_pearson = np.NaN\n",
    "            syn_density_cosine = np.NaN\n",
    "\n",
    "            #ones that are set by 2nd group\n",
    "            binary_conversion_pearson_converted = np.NaN\n",
    "            binary_conversion_cosine_converted = np.NaN\n",
    "            conversion_pearson_converted = np.NaN\n",
    "            conversion_cosine_converted = np.NaN\n",
    "            density_pearson_converted = np.NaN\n",
    "            density_cosine_converted = np.NaN\n",
    "            syn_volume_mean_pearson_converted = np.NaN\n",
    "            syn_volume_mean_cosine_converted = np.NaN\n",
    "            syn_density_pearson_converted = np.NaN\n",
    "            syn_density_cosine_converted = np.NaN\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if (not df_1_common.to_numpy().any()) or (not df_2_common.to_numpy().any()):\n",
    "                #total_correlations.append(corr_dict)\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                df_1_common_conversion = df_1_common[\"total_contact_conversion\"].to_numpy()\n",
    "                df_2_common_conversion = df_2_common[\"total_contact_conversion\"].to_numpy()\n",
    "\n",
    "                df_1_common_binary_conversion = np.copy(df_1_common_conversion)\n",
    "                df_2_common_binary_conversion = np.copy(df_2_common_conversion)\n",
    "\n",
    "\n",
    "                df_1_common_binary_conversion[df_1_common_binary_conversion>0] = 1.0\n",
    "                df_2_common_binary_conversion[df_2_common_binary_conversion>0] = 1.0\n",
    "\n",
    "                df_1_common_density = df_1_common[\"total_contact_density\"].to_numpy()\n",
    "                df_2_common_density = df_2_common[\"total_contact_density\"].to_numpy()\n",
    "\n",
    "                df_1_common_synaptic_size = df_1_common[\"total_synapse_sizes_mean\"].to_numpy()\n",
    "                df_2_common_synaptic_size = df_2_common[\"total_synapse_sizes_mean\"].to_numpy()\n",
    "\n",
    "                df_1_common_syn_density = df_1_common[\"syn_density\"].to_numpy()\n",
    "                df_2_common_syn_density = df_2_common[\"syn_density\"].to_numpy()\n",
    "\n",
    "\n",
    "                binary_conversion_pearson = find_pearson(df_1_common_binary_conversion, df_2_common_binary_conversion)\n",
    "                binary_conversion_cosine = find_cosine(df_1_common_binary_conversion, df_2_common_binary_conversion)\n",
    "                conversion_pearson = find_pearson(df_1_common_conversion, df_2_common_conversion)\n",
    "                conversion_cosine = find_cosine(df_1_common_conversion, df_2_common_conversion)\n",
    "                density_pearson = find_pearson(df_1_common_density, df_2_common_density)\n",
    "                density_cosine = find_cosine(df_1_common_density, df_2_common_density)\n",
    "                syn_volume_mean_pearson = find_pearson(df_1_common_synaptic_size, df_2_common_synaptic_size)\n",
    "                syn_volume_mean_cosine = find_cosine(df_1_common_synaptic_size, df_2_common_synaptic_size)\n",
    "                syn_density_pearson = find_pearson(df_1_common_synaptic_size, df_2_common_synaptic_size)\n",
    "                syn_density_cosine = find_cosine(df_1_common_synaptic_size, df_2_common_synaptic_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                ####reset the df_1_common and df_1_common to reuse code\n",
    "                df_1_common = df_1_common_converted\n",
    "                df_2_common = df_2_common_converted\n",
    "\n",
    "                if (not df_1_common.to_numpy().any()) or (not df_2_common.to_numpy().any()):\n",
    "                    #print(\"none_in_converted\")\n",
    "                    pass\n",
    "                else:\n",
    "                    df_1_common_conversion = df_1_common[\"total_contact_conversion\"].to_numpy()\n",
    "                    df_2_common_conversion = df_2_common[\"total_contact_conversion\"].to_numpy()\n",
    "\n",
    "                    df_1_common_binary_conversion = np.copy(df_1_common_conversion)\n",
    "                    df_2_common_binary_conversion = np.copy(df_2_common_conversion)\n",
    "\n",
    "\n",
    "                    df_1_common_binary_conversion[df_1_common_binary_conversion>0] = 1.0\n",
    "                    df_2_common_binary_conversion[df_2_common_binary_conversion>0] = 1.0\n",
    "\n",
    "                    df_1_common_density = df_1_common[\"total_contact_density\"].to_numpy()\n",
    "                    df_2_common_density = df_2_common[\"total_contact_density\"].to_numpy()\n",
    "\n",
    "\n",
    "                    df_1_common_synaptic_size = df_1_common[\"total_synapse_sizes_mean\"].to_numpy()\n",
    "                    df_2_common_synaptic_size = df_2_common[\"total_synapse_sizes_mean\"].to_numpy()\n",
    "\n",
    "                    df_1_common_syn_density = df_1_common[\"syn_density\"].to_numpy()\n",
    "                    df_2_common_syn_density = df_2_common[\"syn_density\"].to_numpy()\n",
    "\n",
    "                    \n",
    "\n",
    "                    binary_conversion_pearson_converted = find_pearson(df_1_common_binary_conversion, df_2_common_binary_conversion)\n",
    "                    binary_conversion_cosine_converted = find_cosine(df_1_common_binary_conversion, df_2_common_binary_conversion)\n",
    "                    conversion_pearson_converted = find_pearson(df_1_common_conversion, df_2_common_conversion)\n",
    "                    conversion_cosine_converted = find_cosine(df_1_common_conversion, df_2_common_conversion)\n",
    "                    density_pearson_converted = find_pearson(df_1_common_density, df_2_common_density)\n",
    "                    density_cosine_converted = find_cosine(df_1_common_density, df_2_common_density)\n",
    "                    syn_volume_mean_pearson_converted = find_pearson(df_1_common_synaptic_size, df_2_common_synaptic_size)\n",
    "                    syn_volume_mean_cosine_converted = find_cosine(df_1_common_synaptic_size, df_2_common_synaptic_size)\n",
    "                    syn_density_pearson_converted = find_pearson(df_1_common_synaptic_size, df_2_common_synaptic_size)\n",
    "                    syn_density_cosine_converted = find_cosine(df_1_common_synaptic_size, df_2_common_synaptic_size)\n",
    "\n",
    "\n",
    "\n",
    "            corr_dict[\"binary_conversion_pearson\"] = binary_conversion_pearson\n",
    "            corr_dict[\"binary_conversion_cosine\"] = binary_conversion_cosine\n",
    "            corr_dict[\"conversion_pearson\"] = conversion_pearson\n",
    "            corr_dict[\"conversion_cosine\"] = conversion_cosine\n",
    "            corr_dict[\"density_pearson\"] = density_pearson\n",
    "            corr_dict[\"density_cosine\"] = density_cosine\n",
    "            corr_dict[\"syn_volume_mean_pearson\"] = syn_volume_mean_pearson\n",
    "            corr_dict[\"syn_volume_mean_cosine\"] = syn_volume_mean_cosine\n",
    "            corr_dict[\"syn_density_pearson\"] = syn_density_pearson\n",
    "            corr_dict[\"syn_density_cosine\"] = syn_density_cosine\n",
    "\n",
    "            corr_dict[\"binary_conversion_pearson_converted\"] = binary_conversion_pearson_converted\n",
    "            corr_dict[\"binary_conversion_cosine_converted\"] = binary_conversion_cosine_converted\n",
    "            corr_dict[\"conversion_pearson_converted\"] = conversion_pearson_converted\n",
    "            corr_dict[\"conversion_cosine_converted\"] = conversion_cosine_converted\n",
    "            corr_dict[\"density_pearson_converted\"] = density_pearson_converted\n",
    "            corr_dict[\"density_cosine_converted\"] = density_cosine_converted\n",
    "            corr_dict[\"syn_volume_mean_pearson_converted\"] = syn_volume_mean_pearson_converted\n",
    "            corr_dict[\"syn_volume_mean_cosine_converted\"] = syn_volume_mean_cosine_converted\n",
    "            corr_dict[\"syn_density_pearson_converted\"] = syn_density_pearson_converted\n",
    "            corr_dict[\"syn_density_cosine_converted\"] = syn_density_cosine_converted\n",
    "\n",
    "\n",
    "\n",
    "            total_correlations.append(corr_dict)\n",
    "\n",
    "\n",
    "        #write all of the dictionaries to the database\n",
    "        self.insert(total_correlations,skip_duplicates=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 6296.99595284462\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "ContactCorrelation.populate()\n",
    "print(f\"Total time: {time.time()-start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <b></b>\n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">segmentation</p>\n",
       "                                <span class=\"djtooltiptext\">segmentation id</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">segment_id</p>\n",
       "                                <span class=\"djtooltiptext\">segment id unique within each Segmentation</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">segment_b</p>\n",
       "                                <span class=\"djtooltiptext\">id of the postsynaptic neuron</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">n_seg_a</p>\n",
       "                                <span class=\"djtooltiptext\">n_presyns contacting onto segment_id</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">n_seg_b</p>\n",
       "                                <span class=\"djtooltiptext\">n_presyns contacting onto segment_b</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">n_seg_shared</p>\n",
       "                                <span class=\"djtooltiptext\">n_presyns contacting onto both segment_id and segment_b</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">n_seg_shared_converted</p>\n",
       "                                <span class=\"djtooltiptext\">n_presyns contacting onto both and converting on at least 1 postsyn</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">n_seg_union</p>\n",
       "                                <span class=\"djtooltiptext\">n_presyns contacting either segment_id or segment_b</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">binary_conversion_pearson</p>\n",
       "                                <span class=\"djtooltiptext\">pearson correlation for binary n_synapse/n_contact rate</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">binary_conversion_cosine</p>\n",
       "                                <span class=\"djtooltiptext\">cosine similarity correlation for binary n_synapse/n_contact rate</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">conversion_pearson</p>\n",
       "                                <span class=\"djtooltiptext\">Pearson correlation for n_synapse/n_contact rate</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">conversion_cosine</p>\n",
       "                                <span class=\"djtooltiptext\">cosine similarity for n_synapse/n_contact rate</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">density_pearson</p>\n",
       "                                <span class=\"djtooltiptext\">Pearson correlation for n_synapse/postsyn_length rate</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">density_cosine</p>\n",
       "                                <span class=\"djtooltiptext\">cosine similarity for n_synapse/postsyn_length rate</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">syn_volume_mean_pearson</p>\n",
       "                                <span class=\"djtooltiptext\">Pearson correlation for mean of synaptic volume</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">syn_volume_mean_cosine</p>\n",
       "                                <span class=\"djtooltiptext\">cosine similarity for mean of synaptic volume</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">syn_density_pearson</p>\n",
       "                                <span class=\"djtooltiptext\">Pearson correlation for n_synapses*synapse_sizes_mean/postsyn_length rate</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">syn_density_cosine</p>\n",
       "                                <span class=\"djtooltiptext\">cosine similarity for n_synapses*synapse_sizes_mean/postsyn_length rate</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">binary_conversion_pearson_converted</p>\n",
       "                                <span class=\"djtooltiptext\">pearson correlation for binary n_synapse/n_contact rate for axon group with at least 1 conversion</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">binary_conversion_cosine_converted</p>\n",
       "                                <span class=\"djtooltiptext\">cosine similarity correlation for binary n_synapse/n_contact rate for axon group with at least 1 conversion</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">conversion_pearson_converted</p>\n",
       "                                <span class=\"djtooltiptext\">Pearson correlation for n_synapse/n_contact rate for axon group with at least 1 conversion</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">conversion_cosine_converted</p>\n",
       "                                <span class=\"djtooltiptext\">cosine similarity for n_synapse/n_contact rate for axon group with at least 1 conversion</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">density_pearson_converted</p>\n",
       "                                <span class=\"djtooltiptext\">Pearson correlation for n_synapse/postsyn_length rate for axon group with at least 1 conversion</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">density_cosine_converted</p>\n",
       "                                <span class=\"djtooltiptext\">cosine similarity for n_synapse/postsyn_length rate for axon group with at least 1 conversion</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">syn_volume_mean_pearson_converted</p>\n",
       "                                <span class=\"djtooltiptext\">Pearson correlation for mean of synaptic volume for axon group with at least 1 conversion</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">syn_volume_mean_cosine_converted</p>\n",
       "                                <span class=\"djtooltiptext\">cosine similarity for mean of synaptic volume for axon group with at least 1 conversion</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">syn_density_pearson_converted</p>\n",
       "                                <span class=\"djtooltiptext\">Pearson correlation for n_synapses*synapse_sizes_mean/postsyn_length rate for axon group with at least 1 conversion</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">syn_density_cosine_converted</p>\n",
       "                                <span class=\"djtooltiptext\">cosine similarity for n_synapses*synapse_sizes_mean/postsyn_length rate for axon group with at least 1 conversion</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr> <td>2</td>\n",
       "<td>648518346341352006</td>\n",
       "<td>648518346341352223</td>\n",
       "<td>1420</td>\n",
       "<td>1262</td>\n",
       "<td>171</td>\n",
       "<td>15</td>\n",
       "<td>2511</td>\n",
       "<td>0.0820552</td>\n",
       "<td>0.125</td>\n",
       "<td>0.0638036</td>\n",
       "<td>0.102839</td>\n",
       "<td>-0.00671485</td>\n",
       "<td>0.0206681</td>\n",
       "<td>0.0701855</td>\n",
       "<td>0.0994539</td>\n",
       "<td>0.0701855</td>\n",
       "<td>0.0994539</td>\n",
       "<td>-0.875</td>\n",
       "<td>0.125</td>\n",
       "<td>-0.710552</td>\n",
       "<td>0.102839</td>\n",
       "<td>-0.420466</td>\n",
       "<td>0.0206681</td>\n",
       "<td>-0.406452</td>\n",
       "<td>0.0994539</td>\n",
       "<td>-0.406452</td>\n",
       "<td>0.0994539</td></tr><tr><td>2</td>\n",
       "<td>648518346341352006</td>\n",
       "<td>648518346341353019</td>\n",
       "<td>1420</td>\n",
       "<td>76</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>1496</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr><tr><td>2</td>\n",
       "<td>648518346341352006</td>\n",
       "<td>648518346341353186</td>\n",
       "<td>1420</td>\n",
       "<td>1420</td>\n",
       "<td>119</td>\n",
       "<td>6</td>\n",
       "<td>2721</td>\n",
       "<td>-0.0258621</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0258621</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0173294</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0215825</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0215825</td>\n",
       "<td>0.0</td>\n",
       "<td>-1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>-1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.540649</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.721201</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.721201</td>\n",
       "<td>0.0</td></tr><tr><td>2</td>\n",
       "<td>648518346341352006</td>\n",
       "<td>648518346341353574</td>\n",
       "<td>1420</td>\n",
       "<td>208</td>\n",
       "<td>1</td>\n",
       "<td>0</td>\n",
       "<td>1627</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr><tr><td>2</td>\n",
       "<td>648518346341352006</td>\n",
       "<td>648518346341353607</td>\n",
       "<td>1420</td>\n",
       "<td>1759</td>\n",
       "<td>249</td>\n",
       "<td>24</td>\n",
       "<td>2930</td>\n",
       "<td>0.107236</td>\n",
       "<td>0.153846</td>\n",
       "<td>0.0496818</td>\n",
       "<td>0.0937615</td>\n",
       "<td>-0.0104966</td>\n",
       "<td>0.0250892</td>\n",
       "<td>0.0180388</td>\n",
       "<td>0.0449948</td>\n",
       "<td>0.0180388</td>\n",
       "<td>0.0449948</td>\n",
       "<td>-0.846154</td>\n",
       "<td>0.153846</td>\n",
       "<td>-0.754</td>\n",
       "<td>0.0937615</td>\n",
       "<td>-0.536339</td>\n",
       "<td>0.0250892</td>\n",
       "<td>-0.34113</td>\n",
       "<td>0.0449948</td>\n",
       "<td>-0.34113</td>\n",
       "<td>0.0449948</td></tr><tr><td>2</td>\n",
       "<td>648518346341352006</td>\n",
       "<td>648518346341353788</td>\n",
       "<td>1420</td>\n",
       "<td>13</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>1433</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr><tr><td>2</td>\n",
       "<td>648518346341352006</td>\n",
       "<td>648518346341353883</td>\n",
       "<td>1420</td>\n",
       "<td>166</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>1586</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr><tr><td>2</td>\n",
       "<td>648518346341352006</td>\n",
       "<td>648518346341354048</td>\n",
       "<td>1420</td>\n",
       "<td>2</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>1422</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr><tr><td>2</td>\n",
       "<td>648518346341352006</td>\n",
       "<td>648518346341354962</td>\n",
       "<td>1420</td>\n",
       "<td>121</td>\n",
       "<td>12</td>\n",
       "<td>4</td>\n",
       "<td>1529</td>\n",
       "<td>-0.2</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.187867</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.198999</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.122994</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.122994</td>\n",
       "<td>0.0</td>\n",
       "<td>-1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.904534</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.991701</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.489417</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.489417</td>\n",
       "<td>0.0</td></tr><tr><td>2</td>\n",
       "<td>648518346341352006</td>\n",
       "<td>648518346341355539</td>\n",
       "<td>1420</td>\n",
       "<td>2680</td>\n",
       "<td>185</td>\n",
       "<td>18</td>\n",
       "<td>3915</td>\n",
       "<td>-0.0482188</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0397768</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0299615</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0241347</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0241347</td>\n",
       "<td>0.0</td>\n",
       "<td>-1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.703213</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.438211</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.324891</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.324891</td>\n",
       "<td>0.0</td></tr><tr><td>2</td>\n",
       "<td>648518346341352006</td>\n",
       "<td>648518346341356260</td>\n",
       "<td>1420</td>\n",
       "<td>963</td>\n",
       "<td>57</td>\n",
       "<td>6</td>\n",
       "<td>2326</td>\n",
       "<td>-0.0555556</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0555556</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0489772</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0403554</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0403554</td>\n",
       "<td>0.0</td>\n",
       "<td>-1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>-1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.80302</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.583979</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.583979</td>\n",
       "<td>0.0</td></tr><tr><td>2</td>\n",
       "<td>648518346341352006</td>\n",
       "<td>648518346341356825</td>\n",
       "<td>1420</td>\n",
       "<td>34</td>\n",
       "<td>2</td>\n",
       "<td>0</td>\n",
       "<td>1452</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr><tr><td>2</td>\n",
       "<td>648518346341352006</td>\n",
       "<td>648518346341357297</td>\n",
       "<td>1420</td>\n",
       "<td>5077</td>\n",
       "<td>464</td>\n",
       "<td>69</td>\n",
       "<td>6033</td>\n",
       "<td>-0.0193943</td>\n",
       "<td>0.0573068</td>\n",
       "<td>-0.0139197</td>\n",
       "<td>0.0542704</td>\n",
       "<td>0.087484</td>\n",
       "<td>0.126612</td>\n",
       "<td>0.0961249</td>\n",
       "<td>0.130221</td>\n",
       "<td>0.0961249</td>\n",
       "<td>0.130221</td>\n",
       "<td>-0.941647</td>\n",
       "<td>0.0573068</td>\n",
       "<td>-0.736381</td>\n",
       "<td>0.0542704</td>\n",
       "<td>-0.227271</td>\n",
       "<td>0.126612</td>\n",
       "<td>-0.166053</td>\n",
       "<td>0.130221</td>\n",
       "<td>-0.166053</td>\n",
       "<td>0.130221</td></tr><tr><td>2</td>\n",
       "<td>648518346341352006</td>\n",
       "<td>648518346341357549</td>\n",
       "<td>1420</td>\n",
       "<td>61</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>1481</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr><tr><td>2</td>\n",
       "<td>648518346341352006</td>\n",
       "<td>648518346341359123</td>\n",
       "<td>1420</td>\n",
       "<td>3112</td>\n",
       "<td>171</td>\n",
       "<td>19</td>\n",
       "<td>4361</td>\n",
       "<td>-0.0580881</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0547434</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0343542</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0228732</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0228732</td>\n",
       "<td>0.0</td>\n",
       "<td>-1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.903089</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.426582</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.253589</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.253589</td>\n",
       "<td>0.0</td></tr><tr><td>2</td>\n",
       "<td>648518346341352006</td>\n",
       "<td>648518346341359289</td>\n",
       "<td>1420</td>\n",
       "<td>2459</td>\n",
       "<td>277</td>\n",
       "<td>28</td>\n",
       "<td>3602</td>\n",
       "<td>0.0877843</td>\n",
       "<td>0.136083</td>\n",
       "<td>0.0417438</td>\n",
       "<td>0.0884964</td>\n",
       "<td>0.160272</td>\n",
       "<td>0.191462</td>\n",
       "<td>0.13344</td>\n",
       "<td>0.164471</td>\n",
       "<td>0.13344</td>\n",
       "<td>0.164471</td>\n",
       "<td>-0.860663</td>\n",
       "<td>0.136083</td>\n",
       "<td>-0.828788</td>\n",
       "<td>0.0884964</td>\n",
       "<td>-0.279128</td>\n",
       "<td>0.191462</td>\n",
       "<td>-0.300596</td>\n",
       "<td>0.164471</td>\n",
       "<td>-0.300596</td>\n",
       "<td>0.164471</td></tr><tr><td>2</td>\n",
       "<td>648518346341352006</td>\n",
       "<td>648518346341359804</td>\n",
       "<td>1420</td>\n",
       "<td>549</td>\n",
       "<td>48</td>\n",
       "<td>5</td>\n",
       "<td>1921</td>\n",
       "<td>-0.0538382</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0538382</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0525473</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0431686</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0431686</td>\n",
       "<td>0.0</td>\n",
       "<td>-1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>-1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.946363</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.664929</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.664929</td>\n",
       "<td>0.0</td></tr><tr><td>2</td>\n",
       "<td>648518346341352006</td>\n",
       "<td>648518346341360407</td>\n",
       "<td>1420</td>\n",
       "<td>1</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>1421</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr><tr><td>2</td>\n",
       "<td>648518346341352006</td>\n",
       "<td>648518346341360739</td>\n",
       "<td>1420</td>\n",
       "<td>3294</td>\n",
       "<td>624</td>\n",
       "<td>86</td>\n",
       "<td>4090</td>\n",
       "<td>-0.0482992</td>\n",
       "<td>0.0234404</td>\n",
       "<td>-0.0318617</td>\n",
       "<td>0.0291684</td>\n",
       "<td>-0.0256164</td>\n",
       "<td>0.00798232</td>\n",
       "<td>-0.019553</td>\n",
       "<td>0.0145738</td>\n",
       "<td>-0.019553</td>\n",
       "<td>0.0145738</td>\n",
       "<td>-0.976088</td>\n",
       "<td>0.0234404</td>\n",
       "<td>-0.705387</td>\n",
       "<td>0.0291684</td>\n",
       "<td>-0.311954</td>\n",
       "<td>0.00798232</td>\n",
       "<td>-0.306585</td>\n",
       "<td>0.0145738</td>\n",
       "<td>-0.306585</td>\n",
       "<td>0.0145738</td></tr><tr><td>2</td>\n",
       "<td>648518346341352006</td>\n",
       "<td>648518346341361930</td>\n",
       "<td>1420</td>\n",
       "<td>11</td>\n",
       "<td>1</td>\n",
       "<td>0</td>\n",
       "<td>1430</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td> </tr> </tbody>\n",
       "            </table>\n",
       "            <p>...</p>\n",
       "            <p>337431 tuples</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*segmentation  *segment_id    *segment_b     n_seg_a     n_seg_b     n_seg_shared   n_seg_shared_c n_seg_union    binary_convers binary_convers conversion_pea conversion_cos density_pearso density_cosine syn_volume_mea syn_volume_mea syn_density_pe syn_density_co binary_convers binary_convers conversion_pea conversion_cos density_pearso density_cosine syn_volume_mea syn_volume_mea syn_density_pe syn_density_co\n",
       "+------------+ +------------+ +------------+ +---------+ +---------+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+\n",
       "2              64851834634135 64851834634135 1420        1262        171            15             2511           0.0820552      0.125          0.0638036      0.102839       -0.00671485    0.0206681      0.0701855      0.0994539      0.0701855      0.0994539      -0.875         0.125          -0.710552      0.102839       -0.420466      0.0206681      -0.406452      0.0994539      -0.406452      0.0994539     \n",
       "2              64851834634135 64851834634135 1420        76          0              0              1496           nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan           \n",
       "2              64851834634135 64851834634135 1420        1420        119            6              2721           -0.0258621     0.0            -0.0258621     0.0            -0.0173294     0.0            -0.0215825     0.0            -0.0215825     0.0            -1.0           0.0            -1.0           0.0            -0.540649      0.0            -0.721201      0.0            -0.721201      0.0           \n",
       "2              64851834634135 64851834634135 1420        208         1              0              1627           1.0            1.0            1.0            1.0            1.0            1.0            1.0            1.0            1.0            1.0            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan           \n",
       "2              64851834634135 64851834634135 1420        1759        249            24             2930           0.107236       0.153846       0.0496818      0.0937615      -0.0104966     0.0250892      0.0180388      0.0449948      0.0180388      0.0449948      -0.846154      0.153846       -0.754         0.0937615      -0.536339      0.0250892      -0.34113       0.0449948      -0.34113       0.0449948     \n",
       "2              64851834634135 64851834634135 1420        13          0              0              1433           nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan           \n",
       "2              64851834634135 64851834634135 1420        166         0              0              1586           nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan           \n",
       "2              64851834634135 64851834634135 1420        2           0              0              1422           nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan           \n",
       "2              64851834634135 64851834634135 1420        121         12             4              1529           -0.2           0.0            -0.187867      0.0            -0.198999      0.0            -0.122994      0.0            -0.122994      0.0            -1.0           0.0            -0.904534      0.0            -0.991701      0.0            -0.489417      0.0            -0.489417      0.0           \n",
       "2              64851834634135 64851834634135 1420        2680        185            18             3915           -0.0482188     0.0            -0.0397768     0.0            -0.0299615     0.0            -0.0241347     0.0            -0.0241347     0.0            -1.0           0.0            -0.703213      0.0            -0.438211      0.0            -0.324891      0.0            -0.324891      0.0           \n",
       "2              64851834634135 64851834634135 1420        963         57             6              2326           -0.0555556     0.0            -0.0555556     0.0            -0.0489772     0.0            -0.0403554     0.0            -0.0403554     0.0            -1.0           0.0            -1.0           0.0            -0.80302       0.0            -0.583979      0.0            -0.583979      0.0           \n",
       "2              64851834634135 64851834634135 1420        34          2              0              1452           1.0            1.0            1.0            1.0            1.0            1.0            1.0            1.0            1.0            1.0            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan           \n",
       "2              64851834634135 64851834634135 1420        5077        464            69             6033           -0.0193943     0.0573068      -0.0139197     0.0542704      0.087484       0.126612       0.0961249      0.130221       0.0961249      0.130221       -0.941647      0.0573068      -0.736381      0.0542704      -0.227271      0.126612       -0.166053      0.130221       -0.166053      0.130221      \n",
       "2              64851834634135 64851834634135 1420        61          0              0              1481           nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan           \n",
       "2              64851834634135 64851834634135 1420        3112        171            19             4361           -0.0580881     0.0            -0.0547434     0.0            -0.0343542     0.0            -0.0228732     0.0            -0.0228732     0.0            -1.0           0.0            -0.903089      0.0            -0.426582      0.0            -0.253589      0.0            -0.253589      0.0           \n",
       "2              64851834634135 64851834634135 1420        2459        277            28             3602           0.0877843      0.136083       0.0417438      0.0884964      0.160272       0.191462       0.13344        0.164471       0.13344        0.164471       -0.860663      0.136083       -0.828788      0.0884964      -0.279128      0.191462       -0.300596      0.164471       -0.300596      0.164471      \n",
       "2              64851834634135 64851834634135 1420        549         48             5              1921           -0.0538382     0.0            -0.0538382     0.0            -0.0525473     0.0            -0.0431686     0.0            -0.0431686     0.0            -1.0           0.0            -1.0           0.0            -0.946363      0.0            -0.664929      0.0            -0.664929      0.0           \n",
       "2              64851834634135 64851834634136 1420        1           0              0              1421           nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan           \n",
       "2              64851834634135 64851834634136 1420        3294        624            86             4090           -0.0482992     0.0234404      -0.0318617     0.0291684      -0.0256164     0.00798232     -0.019553      0.0145738      -0.019553      0.0145738      -0.976088      0.0234404      -0.705387      0.0291684      -0.311954      0.00798232     -0.306585      0.0145738      -0.306585      0.0145738     \n",
       "2              64851834634135 64851834634136 1420        11          1              0              1430           1.0            1.0            1.0            1.0            1.0            1.0            1.0            1.0            1.0            1.0            nan            nan            nan            nan            nan            nan            nan            nan            nan            nan           \n",
       "   ...\n",
       " (337431 tuples)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ContactCorrelation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
