{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPurpose: \\nWill populate the SynapseCompartmentLabels table\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose: \n",
    "Will populate the SynapseCompartmentLabels table\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "import numpy as np\n",
    "\n",
    "import datajoint as dj\n",
    "import numpy as np\n",
    "from pykdtree.kdtree import KDTree\n",
    "import time\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@10.28.0.34:3306\n"
     ]
    }
   ],
   "source": [
    "m65 = dj.create_virtual_module('m65', 'microns_minnie65_01')\n",
    "schema = dj.schema(\"microns_minnie65_01\")\n",
    "pinky = dj.create_virtual_module(\"pinky\",\"microns_pinky\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all the meshes into one mesh\n",
    "def add_mesh_piece(main_mesh_vertices,main_mesh_faces,sub_mesh_vertices,sub_mesh_faces):\n",
    "    \"\"\"\n",
    "    Purpose: Takes in a large mesh piece and an array of other meshes and \n",
    "    returns a large mesh with all meshes appended\n",
    "    \n",
    "    Parameters:\n",
    "    main_mesh_vertices (np.array) : np array store the vertices as rows and the elements as the coordinates\n",
    "    main_mesh_faces (np.array) : np array store the faces as rows and the elements as the referenced vertices\n",
    "    sub_mesh_vertices(list of np.arrays) : list of np arrays with the vertices arrays for all subsegments to be added\n",
    "    sub_mesh_faces(list of np.arrays) : list of np arrays with the faces arrays for all subsegments to be added\n",
    "    \n",
    "    Returns:\n",
    "    mesh_vertices (np.array) : np array store the vertices as rows and the elements as the coordinates for NEW CONCATENATED MESH\n",
    "    mesh_faces (np.array) : np array store the faces as rows and the elements as the referenced vertices for NEW CONCATENATED MESH\n",
    "    \n",
    "    \n",
    "    Pseudocode: \n",
    "    - Checks: \n",
    "    a. Make sure there sub_mesh arrays are greater than 0 and of the same length\n",
    "\n",
    "    1) Count the number of vertices and faces in the main mesh\n",
    "    2) Iterate through the submesh vertices and faces. In loop:\n",
    "    a. Count the number of vertices in the submesh and concate the vertices arrays to the main mesh array\n",
    "    b. Add the vertices_count and add that to every number in the faces array\n",
    "    c. Concatenate the submesh faces onto the larger mesh face\n",
    "    d. Save this new vertices and faces as the main_mesh verts and faces\n",
    "    e. Print out how many new vertices and faces added\n",
    "    3) Print out number of segments added, total faces/vertices for new mesh\n",
    "    4) Return the main mesh vertices and faces\n",
    "    \n",
    "    \"\"\"\n",
    "    #a. Make sure there sub_mesh arrays are greater than 0 and of the same length\n",
    "    if len(sub_mesh_vertices) <= 0:\n",
    "        print(\"There were no vertices in submesh to add, returning main mesh\")\n",
    "        return main_mesh_vertices, main_mesh_faces\n",
    "    if len(sub_mesh_faces) <= 0:\n",
    "        print(\"There were no face in submesh to add, returning main mesh\")\n",
    "        return main_mesh_vertices, main_mesh_faces\n",
    "    if len(sub_mesh_faces) != len(sub_mesh_vertices):\n",
    "        raise Exception(\"The sub_mesh_faces and sub_mesh_vertices length did not match\")\n",
    "        \n",
    "    \n",
    "    #1) Count the number of vertices and faces in the main mesh\n",
    "    n_main_vertices = len(main_mesh_vertices)\n",
    "    n_main_faces = len(main_mesh_faces)\n",
    "    \n",
    "    \n",
    "    #2) Iterate through the submesh vertices and faces. In loop:\n",
    "    for i,(sub_verts, sub_faces) in enumerate(zip(sub_mesh_vertices,sub_mesh_faces)):\n",
    "        #a. Count the number of vertices in the submesh and concate the vertices arrays to the main mesh array\n",
    "        n_sub_verts = len(sub_verts)\n",
    "        n_sub_faces = len(sub_faces)\n",
    "        \n",
    "        main_mesh_vertices = np.vstack([main_mesh_vertices,sub_verts])\n",
    "\n",
    "        \n",
    "        #b. Add the vertices_count of main to every number in the faces array\n",
    "        sub_faces = sub_faces + n_main_vertices\n",
    "        \n",
    "        #c. Concatenate the submesh faces onto the larger mesh face\n",
    "        main_mesh_faces = np.vstack([main_mesh_faces,sub_faces])\n",
    "        \n",
    "        #d. Save this new vertices and faces as the main_mesh verts and faces (DONE)\n",
    "        \n",
    "        #e. Print out how many new vertices and faces added\n",
    "        #print(f\"Added subsegment {i} with {n_sub_verts} vertices and {n_sub_faces} faces\")\n",
    "        \n",
    "        n_main_vertices = len(main_mesh_vertices)\n",
    "        n_main_faces = len(main_mesh_faces)\n",
    "    \n",
    "    #3) Print out number of segments added, total faces/vertices for new mesh  \n",
    "    print(f\"Added {len(sub_mesh_vertices)} subsegements \\n  --> final mesh: {len(main_mesh_vertices)} vertices and {len(main_mesh_faces)} faces\")\n",
    "        \n",
    "    return main_mesh_vertices,main_mesh_faces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_synapse_labels_to_database(complete_proofread_key,criteria_id=1):\n",
    "    #get all the neurons for that user that have complete status (aka have been proofread)\n",
    "    proofread_segment_ids = (m65.ProofreadLabel & complete_proofread_key).fetch(\"segment_id\")\n",
    "    proofread_segment_ids\n",
    "\n",
    "\n",
    "    meshes = dict()\n",
    "    labels = dict()\n",
    "    kdtrees = dict()\n",
    "    mesh_synapses = dict()\n",
    "\n",
    "    version = complete_proofread_key[\"version\"]\n",
    "    decimation_ratio = complete_proofread_key[\"decimation_ratio\"]\n",
    "    author = complete_proofread_key[\"author\"]\n",
    "    criteria_id=criteria_id \n",
    "\n",
    "\n",
    "    for segment_id in proofread_segment_ids:\n",
    "        # Practicing how to get the mesh and the full subsegments list\n",
    "\n",
    "        version = complete_proofread_key[\"version\"]\n",
    "        decimation_ratio = complete_proofread_key[\"decimation_ratio\"]\n",
    "        author = complete_proofread_key[\"author\"]\n",
    "\n",
    "        key = dict(segment_id=segment_id, version = version)\n",
    "        n = (m65.FromNeuromancer & key).fetch1()\n",
    "\n",
    "        #get all of the segments and their data=\n",
    "        subsegments = (m65.FromNeuromancer.Subsegment & key).fetch(as_dict=True)\n",
    "        subsegment_dicts = dict([(k[\"subsegment_id\"],dict(vertices=k[\"vertices\"],faces=k[\"faces\"])) for k in subsegments])\n",
    "\n",
    "        subsegment_ordered_list = np.sort(np.array(list(subsegment_dicts.keys())))\n",
    "        subsegments_vertices = [subsegment_dicts[k][\"vertices\"] for k in subsegment_ordered_list]\n",
    "        subsegments_faces = [subsegment_dicts[k][\"faces\"] for k in subsegment_ordered_list]\n",
    "\n",
    "        # creating the entire mesh from the main mesh and all of its sub meshes: \n",
    "        new_mesh_vertices, new_mesh_faces = add_mesh_piece(main_mesh_vertices=n[\"vertices\"],\n",
    "                           main_mesh_faces=n[\"faces\"],\n",
    "                           sub_mesh_vertices = subsegments_vertices,\n",
    "                           sub_mesh_faces=subsegments_faces)\n",
    "\n",
    "        #get the segment labels\n",
    "\n",
    "\n",
    "        #find the synapses for neuron and all subsegments\n",
    "        lookup_key = dict(segment_id=segment_id,version = version)\n",
    "        subsegment_ids = list((m65.FromNeuromancer.Subsegment & lookup_key).fetch(\"subsegment_id\"))\n",
    "        subsegment_ids.append(segment_id)\n",
    "        segment_synapses = np.array((m65.Synapse() & [dict(presyn=k) for k in subsegment_ids]).fetch('synapse_id', 'centroid_x', 'centroid_y', 'centroid_z')).T\n",
    "\n",
    "        #\n",
    "        labels_search_key = dict(complete_proofread_key,\n",
    "                                segment_id=segment_id)\n",
    "\n",
    "        segment_vert_labels, segment_tri_labels = (m65.ProofreadLabel() & labels_search_key).fetch1(\"vertices\",\"triangles\")\n",
    "        len(segment_vert_labels)\n",
    "\n",
    "        if len(segment_vert_labels) <= 0:\n",
    "            print(f\"Skipping the mesh {segment_id} because it has no labels\")\n",
    "\n",
    "        #Add the data to the corresponding lists\n",
    "        meshes[segment_id] = (new_mesh_vertices, new_mesh_faces)\n",
    "        labels[segment_id] = (segment_vert_labels, segment_tri_labels)\n",
    "        kdtrees[segment_id] = KDTree(meshes[segment_id][0])\n",
    "        mesh_synapses[segment_id]  = segment_synapses\n",
    "        \n",
    "    matched_synapses = dict()\n",
    "    synapses_to_exclude = []\n",
    "    for segment_id in tqdm(proofread_segment_ids):\n",
    "        synapses = mesh_synapses[segment_id]\n",
    "        synapse_ids, postsyn_coords = synapses.T[0], synapses.T[1:].T\n",
    "        kdtree = kdtrees[segment_id]\n",
    "        distances, nearest_nodes = kdtree.query(postsyn_coords * [4, 4, 40])\n",
    "        vertex_labels = labels[segment_id][0]\n",
    "        synapse_labels = dict()\n",
    "\n",
    "        for synapse_id, nearest_node, distance_node in tqdm(zip(synapse_ids, nearest_nodes,distances)):\n",
    "            if distance_node > 5000:\n",
    "                synapses_to_exclude.append(dict(version=version,synapse_id=synapse_id,\n",
    "                                               criteria_id=criteria_id))\n",
    "            else:\n",
    "                synapse_labels[synapse_id] = vertex_labels[nearest_node]\n",
    "        matched_synapses[segment_id] = synapse_labels\n",
    "        \n",
    "    #add to synapse exclude\n",
    "    m65.SynapseExclude.insert(synapses_to_exclude,skip_duplicates=True)\n",
    "    \n",
    "    all_synapse_labels = list()\n",
    "    for segment_id,labeled_synapses in tqdm(matched_synapses.items()):\n",
    "        version_array = np.array([version] * len(labeled_synapses))\n",
    "        decimation_ratio_array = np.array([decimation_ratio] * len(labeled_synapses))\n",
    "        segment_id_array = np.array([segment_id] * len(labeled_synapses))\n",
    "        synapse_to_label = np.array(list(labeled_synapses.items())).T\n",
    "        proper_label_array = np.array((segment_id_array,\n",
    "                                       version_array,\n",
    "                                       decimation_ratio_array,\n",
    "                                        *synapse_to_label)).T\n",
    "        all_synapse_labels.extend(proper_label_array)\n",
    "    all_synapse_labels_array = np.array(all_synapse_labels)\n",
    "\n",
    "    all_synapse_labels_array = [ [int(seg_id), int(k[1]), float(k[2]), int(k[3]), int(k[4])] for k,seg_id in   zip(all_synapse_labels_array,segment_id_array)]\n",
    "\n",
    "    start = time.time()\n",
    "    SynapseCompartmentLabel.insert(all_synapse_labels_array, skip_duplicates=True)\n",
    "    print(f\"Fininshed inserting synapse labels: Took {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class SynapseCompartmentLabel(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    -> m65.FromNeuromancer\n",
    "    decimation_ratio     : decimal(3,2)                 # percentage that the faces are decimated\n",
    "    -> m65.Synapse\n",
    "    ---\n",
    "    (presynaptic_label)->m65.LabelKey\n",
    "    \"\"\" # (postsynaptic_label)->pinky.LabelKey : tinyint unsigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 80 subsegements \n",
      "  --> final mesh: 1862086 vertices and 3546312 faces\n",
      "Added 46 subsegements \n",
      "  --> final mesh: 1252162 vertices and 2390205 faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "188it [00:00, 296551.02it/s]\n",
      "\n",
      "201it [00:00, 226993.84it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 115.70it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1008.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fininshed inserting synapse labels: Took 0.05410003662109375 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "complete_proofread_key = dict(version = 0,\n",
    "                    decimation_ratio = 1.00,\n",
    "                    author = \"celiib\",\n",
    "                    status=\"complete\")\n",
    "\n",
    "criteria_id = 1 # ******* RIGHT NOW SET TO A CELII TEST SO NEED TO CHANGE ON REAL RUN******\n",
    "\n",
    "write_synapse_labels_to_database(complete_proofread_key,criteria_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
