{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import time\n",
    "import pymeshfix\n",
    "import os\n",
    "import datetime\n",
    "import calcification_Module as cm\n",
    "from meshparty import trimesh_io\n",
    "import trimesh\n",
    "\n",
    "#for supressing the output\n",
    "import os, contextlib\n",
    "import pathlib\n",
    "import subprocess\n",
    "\n",
    "#for error counting\n",
    "from collections import Counter\n",
    "\n",
    "#for reading in the new raw_skeleton files\n",
    "import csv\n",
    "\n",
    "from Skeleton_Stitcher import stitch_skeleton_with_degree_check, find_skeleton_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the address and the username\n",
    "dj.config['database.host'] = '10.28.0.34'\n",
    "dj.config['database.user'] = 'celiib'\n",
    "dj.config['database.password'] = 'newceliipass'\n",
    "dj.config['safemode']=True\n",
    "dj.config[\"display.limit\"] = 100\n",
    "\n",
    "schema = dj.schema('microns_pinky')\n",
    "pinky = dj.create_virtual_module('pinky', 'microns_pinky')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <b></b>\n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">segmentation</p>\n",
       "                                <span class=\"djtooltiptext\">segmentation id</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">segment_id</p>\n",
       "                                <span class=\"djtooltiptext\">segment id unique within each Segmentation</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">n_edges</p>\n",
       "                                <span class=\"djtooltiptext\">number of edges stored</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">edges</p>\n",
       "                                <span class=\"djtooltiptext\">array storing edges on each row</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">n_bodies</p>\n",
       "                                <span class=\"djtooltiptext\">the amount of segments the neurite was originally split into</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">n_bodies_stitched</p>\n",
       "                                <span class=\"djtooltiptext\">the amount of segments whose skeletons were stitched back together (aka above the significance threshold)</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">largest_mesh_perc</p>\n",
       "                                <span class=\"djtooltiptext\">number of faces of largest submesh / number of faces of entire skeletal mesh</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">largest_mesh_distance_perc</p>\n",
       "                                <span class=\"djtooltiptext\">skeleton length of largest submesh / skeleton length of entire stitched mesh</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr> <td>3</td>\n",
       "<td>648518346341395072</td>\n",
       "<td>356</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>6</td>\n",
       "<td>2</td>\n",
       "<td>0.988455</td>\n",
       "<td>0.998262</td> </tr> </tbody>\n",
       "            </table>\n",
       "            \n",
       "            <p>1 tuples</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*segmentation  *segment_id    n_edges     edges      n_bodies     n_bodies_stitc largest_mesh_p largest_mesh_d\n",
       "+------------+ +------------+ +---------+ +--------+ +----------+ +------------+ +------------+ +------------+\n",
       "3              64851834634139 356         =BLOB=     6            2              0.988455       0.998262      \n",
       " (1 tuples)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinky.NeuriteSkeletonStitchTest & \"segment_id=648518346341395072\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinky.NeuriteSkeletonStitchTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_skeleton_revised(file_path):\n",
    "    with open(file_path) as f:\n",
    "        bones = np.array([])\n",
    "        for line in f.readlines():\n",
    "            #print(line)\n",
    "            line = (np.array(line.split()[1:], float).reshape(-1, 3))\n",
    "            #print(line[:-1])\n",
    "            #print(line[1:])\n",
    "\n",
    "            #print(bones.size)\n",
    "            if bones.size <= 0:\n",
    "                bones = np.stack((line[:-1],line[1:]),axis=1)\n",
    "            else:\n",
    "                bones = np.vstack((bones,(np.stack((line[:-1],line[1:]),axis=1))))\n",
    "            #print(bones)\n",
    "\n",
    "\n",
    "    return np.array(bones).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the output file\n",
    "##write the OFF file for the neuron\n",
    "import pathlib\n",
    "def write_Whole_Neuron_Off_file(neuron_ID,\n",
    "                                vertices=[], \n",
    "                                triangles=[],\n",
    "                                folder=\"pymesh_NEURITES\"):\n",
    "    #primary_key = dict(segmentation=1, segment_id=segment_id, decimation_ratio=0.35)\n",
    "    #vertices, triangles = (mesh_Table_35 & primary_key).fetch1('vertices', 'triangles')\n",
    "    \n",
    "    num_vertices = (len(vertices))\n",
    "    num_faces = len(triangles)\n",
    "    \n",
    "    #get the current file location\n",
    "    file_loc = pathlib.Path.cwd() / folder\n",
    "    filename = \"neuron_\" + str(neuron_ID)\n",
    "    path_and_filename = file_loc / filename\n",
    "    \n",
    "    #print(file_loc)\n",
    "    #print(path_and_filename)\n",
    "    \n",
    "    #open the file and start writing to it    \n",
    "    f = open(str(path_and_filename) + \".off\", \"w\")\n",
    "    f.write(\"OFF\\n\")\n",
    "    f.write(str(num_vertices) + \" \" + str(num_faces) + \" 0\\n\" )\n",
    "    \n",
    "    \n",
    "    #iterate through and write all of the vertices in the file\n",
    "    for verts in vertices:\n",
    "        f.write(str(verts[0]) + \" \" + str(verts[1]) + \" \" + str(verts[2])+\"\\n\")\n",
    "    \n",
    "    #print(\"Done writing verts\")\n",
    "        \n",
    "    for faces in triangles:\n",
    "        f.write(\"3 \" + str(faces[0]) + \" \" + str(faces[1]) + \" \" + str(faces[2])+\"\\n\")\n",
    "    \n",
    "    print(\"Done writing OFF file\")\n",
    "    #f.write(\"end\")\n",
    "    \n",
    "    return str(path_and_filename),str(filename),str(file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meshlab_fix_manifold(key,folder=\"pymesh_NEURITES\"):\n",
    "    \n",
    "    file_loc = pathlib.Path.cwd() / folder\n",
    "    filename = \"neuron_\" + str(key[\"segment_id\"])\n",
    "    path_and_filename = str(file_loc / filename)\n",
    "    \n",
    "    \n",
    "    input_mesh = path_and_filename + \".off\"\n",
    "    output_mesh = path_and_filename+\"_mls.off\"\n",
    "    \n",
    "    \n",
    "    meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"remeshing_remove_non_man_edges.mls\"\n",
    "    \n",
    "    print(\"starting meshlabserver fixing non-manifolds\")\n",
    "    subprocess_result_1 = run_meshlab_script(meshlab_script,\n",
    "                      input_mesh,\n",
    "                      output_mesh)\n",
    "    #print(\"Poisson subprocess_result= \"+ str(subprocess_result_1))\n",
    "    \n",
    "    if str(subprocess_result_1)[-13:] != \"returncode=0)\":\n",
    "        raise Exception('neuron' + str(key[\"segment_id\"]) + \n",
    "                         ' did not fix the manifold edges')\n",
    "    \n",
    "    return output_mesh\n",
    "\n",
    "def meshlab_fix_manifold_path(path_and_filename,segment_id=-1):\n",
    "    #fix the path if it comes with the extension\n",
    "    if path_and_filename[-4:] == \".off\":\n",
    "        path_and_filename = path_and_filename[-4:]\n",
    "    \n",
    "    input_mesh = path_and_filename + \".off\"\n",
    "    output_mesh = path_and_filename+\"_mls.off\"\n",
    "    \n",
    "    #print(\"input_mesh = \" + str(input_mesh))\n",
    "    #print(\"output_mesh = \" + str(output_mesh))\n",
    "    \n",
    "    meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"remeshing_remove_non_man_edges.mls\"\n",
    "    \n",
    "    print(\"starting meshlabserver fixing non-manifolds\")\n",
    "    subprocess_result_1 = run_meshlab_script(meshlab_script,\n",
    "                      input_mesh,\n",
    "                      output_mesh)\n",
    "    #print(\"Poisson subprocess_result= \"+ str(subprocess_result_1))\n",
    "    \n",
    "    if str(subprocess_result_1)[-13:] != \"returncode=0)\":\n",
    "        raise Exception('neuron' + str(segment_id) + \n",
    "                         ' did not fix the manifold edges')\n",
    "    \n",
    "    return output_mesh\n",
    "\n",
    "def meshlab_fix_manifold_path_specific_mls(path_and_filename,segment_id=-1,meshlab_script=\"\"):\n",
    "    #fix the path if it comes with the extension\n",
    "    if path_and_filename[-4:] == \".off\":\n",
    "        path_and_filename = path_and_filename[-4:]\n",
    "    \n",
    "    input_mesh = path_and_filename + \".off\"\n",
    "    output_mesh = path_and_filename+\"_mls.off\"\n",
    "    print(\"input mesh = \" + str(input_mesh))\n",
    "    print(\"output_mesh mesh = \" + str(output_mesh))\n",
    "    \n",
    "    \n",
    "    #print(\"input_mesh = \" + str(input_mesh))\n",
    "    #print(\"output_mesh = \" + str(output_mesh))\n",
    "    if meshlab_script == \"\":\n",
    "        meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"remeshing_remove_non_man_edges.mls\"\n",
    "    \n",
    "    print(\"meshlab_script = \" + str(meshlab_script))\n",
    "    print(\"starting meshlabserver fixing non-manifolds\")\n",
    "    subprocess_result_1 = run_meshlab_script(meshlab_script,\n",
    "                      input_mesh,\n",
    "                      output_mesh)\n",
    "    #print(\"Poisson subprocess_result= \"+ str(subprocess_result_1))\n",
    "    \n",
    "    if str(subprocess_result_1)[-13:] != \"returncode=0)\":\n",
    "        raise Exception('neuron' + str(segment_id) + \n",
    "                         ' did not fix the manifold edges')\n",
    "    \n",
    "    return output_mesh\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_meshlab_script(mlx_script,input_mesh_file,output_mesh_file):\n",
    "    script_command = (\" -i \" + str(input_mesh_file) + \" -o \" + \n",
    "                                    str(output_mesh_file) + \" -s \" + str(mlx_script))\n",
    "    print('xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@ ' + \n",
    "                   script_command)\n",
    "    #return script_command\n",
    "    subprocess_result = subprocess.run('xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@ ' + \n",
    "                   script_command,shell=True)\n",
    "    \n",
    "    return subprocess_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key = dict(segmentation=3,segment_id=648518346349494542)\n",
    "\n",
    "split_significance_threshold = 100\n",
    "\n",
    "global_time = time.time()\n",
    "#get the mesh with the error segments filtered away\n",
    "start_time = time.time()\n",
    "print(str(key['segment_id']) +  \":\")\n",
    "my_dict = (pinky.Mesh & pinky.Neurite.proj() & pinky.CurrentSegmentation\n",
    "                   & key).fetch1()\n",
    "print(f\"Step 1: Retrieving Mesh and removing error segments: {time.time() - start_time}\")\n",
    "new_key = dict(segmentation=key[\"segmentation\"],\n",
    "               segment_id=key[\"segment_id\"])\n",
    "\n",
    "\n",
    "# Don't need these attributes      \n",
    "#vertices=key[\"vertices\"],\n",
    "#                       triangles=new_key[\"triangles\"],n_vertices=key[\"n_vertices\"],\n",
    "#                       n_triangles=key[\"n_triangles\"])\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "#pass the vertices and faces to pymeshfix to become watertight\n",
    "\n",
    "mesh = trimesh_io.Mesh(vertices=my_dict[\"vertices\"], faces=my_dict[\"triangles\"])\n",
    "\n",
    "\"\"\" OLDER WAY OF JUST GETTING THE LARGEST MESH PIECE\n",
    "count, labels = trimesh_io.trimesh.graph.csgraph.connected_components(\n",
    "                                                    mesh.edges_sparse,\n",
    "                                                    directed=False,\n",
    "                                                    return_labels=True)\n",
    "\n",
    "\n",
    "label_counter = Counter(labels)\n",
    "\n",
    "\n",
    "new_key[\"n_bodies\"] = count\n",
    "values = np.array(labels)\n",
    "\n",
    "\n",
    "list_counter = Counter(labels)\n",
    "max_counter = max(list_counter.values())\n",
    "\n",
    "max_label = -1\n",
    "for label_key,label_number in list_counter.items():\n",
    "    if label_number==max_counter:\n",
    "        max_label = label_key\n",
    "print(\"max label = \" + str(max_label))\n",
    "\n",
    "searchval = max_label\n",
    "\n",
    "ii = np.where(values == searchval)[0]\n",
    "new_key[\"largest_mesh_perc\"] = len(ii)/len(labels)\n",
    "\n",
    "print(\"n_bodies = \" + str(new_key[\"n_bodies\"]))\n",
    "print(\"largest mesh perc = \" + str(new_key[\"largest_mesh_perc\"]))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "total_splits = mesh.split(only_watertight=False)\n",
    "print(f\"There were {len(total_splits)} after split and significance threshold\")\n",
    "mesh_pieces = [k for k in total_splits if len(k.faces) > split_significance_threshold]\n",
    "print(f\"There were {len(mesh_pieces)} after split and significance threshold\")\n",
    "for g,mh in enumerate(mesh_pieces):\n",
    "    print(f\"Mesh piece {g} with number of faces {len(mh.faces)}\")\n",
    "    \n",
    "print(f\"Step 2a: Getting the number of splits: {time.time() - start_time}\")\n",
    "\n",
    "#get the largest mesh piece\n",
    "largest_mesh_index = -1\n",
    "largest_mesh_size = 0\n",
    "\n",
    "\n",
    "\n",
    "for t,msh in enumerate(mesh_pieces):\n",
    "    if len(msh.faces) > largest_mesh_size:\n",
    "        largest_mesh_index = t\n",
    "        largest_mesh_size = len(msh.faces) \n",
    "\n",
    "#largest mesh piece\n",
    "largest_mesh_perc = largest_mesh_size/len(mesh.faces)\n",
    "new_key[\"largest_mesh_perc\"] = largest_mesh_perc\n",
    "print(\"largest mesh perc = \" + str(largest_mesh_perc))\n",
    "\n",
    "largest_mesh_skeleton_distance = -1\n",
    "\n",
    "paths_used = []\n",
    "total_edges = np.array([])\n",
    "for h,m in enumerate(mesh_pieces): \n",
    "    \n",
    "    print(f\"Working on split {h} with face total = {len(m.faces)}\")\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    #pass the vertices and faces to pymeshfix to become watertight\n",
    "    meshfix = pymeshfix.MeshFix(m.vertices,m.faces)\n",
    "    #meshfix.repair(verbose=False,joincomp=True,remove_smallest_components=False)\n",
    "    print(f\"Step 2b: Pymesh shrinkwrapping: {time.time() - start_time}\")\n",
    "\n",
    "    #print(\"Step 2: Writing Off File\")\n",
    "    start_time = time.time()\n",
    "    #write the new mesh to off file\n",
    "    path_and_filename,filename,file_loc = write_Whole_Neuron_Off_file(str(new_key[\"segment_id\"]) + \"_piece_\" + str(h),meshfix.v,meshfix.f)\n",
    "    print(f\"Step 3: Writing shrinkwrap off file: {time.time() - start_time}\")\n",
    "    #add the path to be deleted later\n",
    "    #path_and_filename,filename,file_loc = write_Whole_Neuron_Off_file(str(new_key[\"segment_id\"]) + \"_piece_\" + str(h),m.vertices,m.faces)\n",
    "\n",
    "    paths_used.append(path_and_filename)\n",
    "\n",
    "\n",
    "    #Run the meshlabserver scripts\n",
    "    start_time = time.time()\n",
    "    #output_mesh = meshlab_fix_manifold_path(path_and_filename,key[\"segment_id\"])\n",
    "    meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"pymesh_fix_substitute.mls\"\n",
    "    output_mesh = meshlab_fix_manifold_path_specific_mls(path_and_filename,key[\"segment_id\"],meshlab_script)\n",
    "    #meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"close_holes.mls\"\n",
    "    #output_mesh = meshlab_fix_manifold_path_specific_mls(output_mesh,key[\"segment_id\"],meshlab_script)\n",
    "    \n",
    "    print(f\"Step 4: Meshlab fixing non-manifolds: {time.time() - start_time}\")\n",
    "\n",
    "    print(output_mesh[:-4])\n",
    "\n",
    "    #send to be skeletonized\n",
    "    start_time = time.time()\n",
    "    return_value = cm.calcification(output_mesh[:-4])\n",
    "    if return_value > 0:\n",
    "        raise Exception('skeletonization for neuron ' + str(new_key[\"segment_id\"]) + \n",
    "                        ' did not finish... exited with error code: ' + str(return_value))\n",
    "    #print(f\"Step 5: Generating Skeleton: {time.time() - start_time}\")\n",
    "\n",
    "\n",
    "\n",
    "    #read in the skeleton files into an array\n",
    "    bone_array = read_skeleton_revised(output_mesh[:-4]+\"_skeleton.cgal\")\n",
    "\n",
    "    #print(bone_array)\n",
    "    if len(bone_array) <= 0:\n",
    "        raise Exception('No skeleton generated for ' + str(new_key[\"segment_id\"]))\n",
    "    print(f\"Step 5: Generating and reading Skeleton: {time.time() - start_time}\")\n",
    "\n",
    "    #get the largest mesh skeleton distance\n",
    "    if h == largest_mesh_index:\n",
    "        largest_mesh_skeleton_distance = find_skeleton_distance(bone_array)\n",
    "\n",
    "    #add the skeleton edges to the total edges\n",
    "    if not total_edges.any():\n",
    "        total_edges = bone_array\n",
    "    else:\n",
    "        total_edges = np.vstack([total_edges,bone_array])\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "total_edges_stitched = stitch_skeleton_with_degree_check(total_edges)\n",
    "\n",
    "#get the total skeleton distance for the stitched skeleton\n",
    "total_skeleton_distance = find_skeleton_distance(total_edges_stitched)\n",
    "\n",
    "largest_mesh_distance_perc = largest_mesh_skeleton_distance/total_skeleton_distance\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "new_key[\"n_edges\"] = len(total_edges_stitched)\n",
    "new_key[\"edges\"] = bone_array\n",
    "new_key[\"n_bodies\"] = len(total_splits)\n",
    "new_key[\"n_bodies_stitched\"] = len(mesh_pieces)\n",
    "new_key[\"largest_mesh_perc\"] = largest_mesh_perc\n",
    "new_key[\"largest_mesh_distance_perc\"] = largest_mesh_distance_perc\n",
    "\n",
    "#self.insert1(new_key,skip_duplicates=True)\n",
    "print(f\"Step 6: Inserting dictionary: {time.time() - start_time}\")\n",
    "#raise Exception(\"done with one neuron\")\n",
    "#for path_and_filename in paths_used:\n",
    "#    os.system(\"rm \"+str(path_and_filename)+\"*\")\n",
    "\n",
    "print(f\"Total time: {time.time() - global_time}\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinky.NeuriteSkeletonStitchTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 2 of Skeletonization Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = dict(segmentation=3,segment_id=648518346349508957)\n",
    "\n",
    "split_significance_threshold = 100\n",
    "\n",
    "global_time = time.time()\n",
    "#get the mesh with the error segments filtered away\n",
    "start_time = time.time()\n",
    "print(str(key['segment_id']) +  \":\")\n",
    "my_dict = (pinky.Mesh & pinky.Neurite.proj() & pinky.CurrentSegmentation\n",
    "                   & key).fetch1()\n",
    "print(f\"Step 1: Retrieving Mesh and removing error segments: {time.time() - start_time}\")\n",
    "new_key = dict(segmentation=key[\"segmentation\"],\n",
    "               segment_id=key[\"segment_id\"])\n",
    "\n",
    "\n",
    "# Don't need these attributes      \n",
    "#vertices=key[\"vertices\"],\n",
    "#                       triangles=new_key[\"triangles\"],n_vertices=key[\"n_vertices\"],\n",
    "#                       n_triangles=key[\"n_triangles\"])\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "#pass the vertices and faces to pymeshfix to become watertight\n",
    "\n",
    "mesh = trimesh_io.Mesh(vertices=my_dict[\"vertices\"], faces=my_dict[\"triangles\"])\n",
    "\n",
    "\"\"\" OLDER WAY OF JUST GETTING THE LARGEST MESH PIECE\n",
    "count, labels = trimesh_io.trimesh.graph.csgraph.connected_components(\n",
    "                                                    mesh.edges_sparse,\n",
    "                                                    directed=False,\n",
    "                                                    return_labels=True)\n",
    "\n",
    "\n",
    "label_counter = Counter(labels)\n",
    "\n",
    "\n",
    "new_key[\"n_bodies\"] = count\n",
    "values = np.array(labels)\n",
    "\n",
    "\n",
    "list_counter = Counter(labels)\n",
    "max_counter = max(list_counter.values())\n",
    "\n",
    "max_label = -1\n",
    "for label_key,label_number in list_counter.items():\n",
    "    if label_number==max_counter:\n",
    "        max_label = label_key\n",
    "print(\"max label = \" + str(max_label))\n",
    "\n",
    "searchval = max_label\n",
    "\n",
    "ii = np.where(values == searchval)[0]\n",
    "new_key[\"largest_mesh_perc\"] = len(ii)/len(labels)\n",
    "\n",
    "print(\"n_bodies = \" + str(new_key[\"n_bodies\"]))\n",
    "print(\"largest mesh perc = \" + str(new_key[\"largest_mesh_perc\"]))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "total_splits = mesh.split(only_watertight=False)\n",
    "print(f\"There were {len(total_splits)} after split and significance threshold\")\n",
    "mesh_pieces = [k for k in total_splits if len(k.faces) > split_significance_threshold]\n",
    "print(f\"There were {len(mesh_pieces)} after split and significance threshold\")\n",
    "for g,mh in enumerate(mesh_pieces):\n",
    "    print(f\"Mesh piece {g} with number of faces {len(mh.faces)}\")\n",
    "\n",
    "print(f\"Step 2a: Getting the number of splits: {time.time() - start_time}\")\n",
    "\n",
    "#get the largest mesh piece\n",
    "largest_mesh_index = -1\n",
    "largest_mesh_size = 0\n",
    "\n",
    "for t,msh in enumerate(mesh_pieces):\n",
    "    if len(msh.faces) > largest_mesh_size:\n",
    "        largest_mesh_index = t\n",
    "        largest_mesh_size = len(msh.faces) \n",
    "\n",
    "#largest mesh piece\n",
    "largest_mesh_perc = largest_mesh_size/len(mesh.faces)\n",
    "new_key[\"largest_mesh_perc\"] = largest_mesh_perc\n",
    "print(\"largest mesh perc = \" + str(largest_mesh_perc))\n",
    "\n",
    "largest_mesh_skeleton_distance = -1\n",
    "\n",
    "paths_used = []\n",
    "total_edges = np.array([])\n",
    "for h,m in enumerate(mesh_pieces): \n",
    "    print(f\"Working on split {h} with face total = {len(m.faces)}\")\n",
    "\n",
    "\n",
    "#             start_time = time.time()\n",
    "#             #pass the vertices and faces to pymeshfix to become watertight\n",
    "#             meshfix = pymeshfix.MeshFix(m.vertices,m.faces)\n",
    "#             meshfix.repair(verbose=False,joincomp=True,remove_smallest_components=False)\n",
    "#             print(f\"Step 2b: Pymesh shrinkwrapping: {time.time() - start_time}\")\n",
    "\n",
    "#             #print(\"Step 2: Writing Off File\")\n",
    "#             start_time = time.time()\n",
    "#             #write the new mesh to off file\n",
    "#             path_and_filename,filename,file_loc = write_Whole_Neuron_Off_file(str(new_key[\"segment_id\"]) + \"_piece_\" + str(h),meshfix.v,meshfix.f)\n",
    "#             print(f\"Step 3: Writing shrinkwrap off file: {time.time() - start_time}\")\n",
    "    #add the path to be deleted later\n",
    "    path_and_filename,filename,file_loc = write_Whole_Neuron_Off_file(str(new_key[\"segment_id\"]) + \"_piece_\" + str(h),m.vertices,m.faces)\n",
    "\n",
    "    paths_used.append(path_and_filename)\n",
    "\n",
    "\n",
    "    #Run the meshlabserver scripts\n",
    "    start_time = time.time()\n",
    "\n",
    "    #output_mesh = meshlab_fix_manifold_path(path_and_filename,key[\"segment_id\"])\n",
    "    meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"pymesh_fix_substitute.mls\"\n",
    "    output_mesh = meshlab_fix_manifold_path_specific_mls(path_and_filename,key[\"segment_id\"],meshlab_script)\n",
    "\n",
    "    print(f\"Step 4: Meshlab fixing non-manifolds: {time.time() - start_time}\")\n",
    "\n",
    "    print(output_mesh[:-4])\n",
    "\n",
    "    #send to be skeletonized\n",
    "    start_time = time.time()\n",
    "\n",
    "    mls_mesh = trimesh.load_mesh(output_mesh)\n",
    "\n",
    "    if len(mls_mesh.faces) < 20:\n",
    "        print(\"Number of faces are less than 20 so not generating skeleton\")\n",
    "        continue\n",
    "\n",
    "    return_value = cm.calcification(output_mesh[:-4])\n",
    "    if return_value > 0:\n",
    "        print('skeletonization for neuron ' + str(new_key[\"segment_id\"]) + \n",
    "                        ' did not finish... exited with error code: ' + str(return_value))\n",
    "\n",
    "        print(\"Trying skeletonization with pymesh\")\n",
    "\n",
    "        #try to run the same skeletonization but now with skeletonization\n",
    "\n",
    "        #             start_time = time.time()\n",
    "        #pass the vertices and faces to pymeshfix to become watertight\n",
    "\n",
    "\n",
    "        meshfix = pymeshfix.MeshFix(mls_mesh.vertices,mls_mesh.faces)\n",
    "        meshfix.repair(verbose=False,joincomp=True,remove_smallest_components=False)\n",
    "        print(f\"Step 2b: Pymesh shrinkwrapping: {time.time() - start_time}\")\n",
    "\n",
    "        if len(meshfix.f) < 20:\n",
    "            print(\"Number of faces are less than 20 so not generating skeleton\")\n",
    "            continue\n",
    "\n",
    "        #print(\"Step 2: Writing Off File\")\n",
    "        start_time = time.time()\n",
    "        #write the new mesh to off file\n",
    "        path_and_filename,filename,file_loc = write_Whole_Neuron_Off_file(str(new_key[\"segment_id\"]) + \"_piece_\" + str(h),meshfix.v,meshfix.f)\n",
    "        print(f\"Step 3: Writing shrinkwrap off file: {time.time() - start_time}\")\n",
    "        #add the path to be deleted later\n",
    "        paths_used.append(path_and_filename)\n",
    "\n",
    "        #Run the meshlabserver scripts\n",
    "        start_time = time.time()\n",
    "\n",
    "        #output_mesh = meshlab_fix_manifold_path(path_and_filename,key[\"segment_id\"])\n",
    "        meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"pymesh_fix_substitute.mls\"\n",
    "        output_mesh = meshlab_fix_manifold_path_specific_mls(path_and_filename,key[\"segment_id\"],meshlab_script)\n",
    "\n",
    "        print(f\"Step 4: Meshlab fixing non-manifolds: {time.time() - start_time}\")\n",
    "\n",
    "        print(output_mesh[:-4])\n",
    "\n",
    "        #send to be skeletonized\n",
    "        start_time = time.time()\n",
    "\n",
    "        mls_mesh = trimesh.load_mesh(output_mesh)\n",
    "\n",
    "        if len(mls_mesh.faces) < 20:\n",
    "            print(\"Number of faces are less than 20 so not generating skeleton\")\n",
    "            continue\n",
    "\n",
    "        return_value = cm.calcification(output_mesh[:-4])\n",
    "\n",
    "        if return_value > 0:\n",
    "            raise Exception('skeletonization for neuron ' + str(new_key[\"segment_id\"]) + \n",
    "                        ' did not finish EVEN AFTER TRYING PYMESH... exited with error code: ' + str(return_value))\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"Step 5: Generating Skeleton: {time.time() - start_time}\")\n",
    "\n",
    "\n",
    "\n",
    "        #read in the skeleton files into an array\n",
    "        bone_array = read_skeleton_revised(output_mesh[:-4]+\"_skeleton.cgal\")\n",
    "\n",
    "        #print(bone_array)\n",
    "        if len(bone_array) <= 0:\n",
    "            raise Exception('No skeleton generated for ' + str(new_key[\"segment_id\"]))\n",
    "        print(f\"Step 5: Generating and reading Skeleton: {time.time() - start_time}\")\n",
    "\n",
    "        #get the largest mesh skeleton distance\n",
    "        if h == largest_mesh_index:\n",
    "            largest_mesh_skeleton_distance = find_skeleton_distance(bone_array)\n",
    "\n",
    "        #add the skeleton edges to the total edges\n",
    "        if not total_edges.any():\n",
    "            total_edges = bone_array\n",
    "        else:\n",
    "            total_edges = np.vstack([total_edges,bone_array])\n",
    "        \n",
    "        print(\"total_edges = \" + str(total_edges.shape))\n",
    "\n",
    "\n",
    "total_edges_stitched = stitch_skeleton_with_degree_check(total_edges)\n",
    "\n",
    "#get the total skeleton distance for the stitched skeleton\n",
    "total_skeleton_distance = find_skeleton_distance(total_edges_stitched)\n",
    "\n",
    "largest_mesh_distance_perc = largest_mesh_skeleton_distance/total_skeleton_distance\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "new_key[\"n_edges\"] = len(total_edges_stitched)\n",
    "new_key[\"edges\"] = total_edges_stitched\n",
    "new_key[\"n_bodies\"] = len(total_splits)\n",
    "new_key[\"n_bodies_stitched\"] = len(mesh_pieces)\n",
    "new_key[\"largest_mesh_perc\"] = largest_mesh_perc\n",
    "new_key[\"largest_mesh_distance_perc\"] = largest_mesh_distance_perc\n",
    "\n",
    "#self.insert1(new_key,skip_duplicates=True)\n",
    "print(f\"Step 6: Inserting dictionary: {time.time() - start_time}\")\n",
    "#raise Exception(\"done with one neuron\")\n",
    "#for path_and_filename in paths_used:\n",
    "#    os.system(\"rm \"+str(path_and_filename)+\"*\")\n",
    "\n",
    "print(f\"Total time: {time.time() - global_time}\")\n",
    "print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"test_bones.npz\",total_edges=total_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package = np.load(\"test_bones.npz\")\n",
    "package[\"total_edges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Conclusion: the skeleton for piece 1 isn't being fully completed\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_Whole_Neuron_Off_file(\"test\",mesh_pieces[0].vertices,mesh_pie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(mesh_pieces[0]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(mesh_pieces[0] + mesh_pieces[1]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(mesh_pieces[0] + mesh_pieces[1] + mesh_pieces[2]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(mesh_pieces[0] + mesh_pieces[1] + mesh_pieces[2] + mesh_pieces[3]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(mesh_pieces[0] + mesh_pieces[1] + mesh_pieces[2] + mesh_pieces[3] + mesh_pieces[4]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Conclusion:\n",
    "1) Piece 2 is a connector piece\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
