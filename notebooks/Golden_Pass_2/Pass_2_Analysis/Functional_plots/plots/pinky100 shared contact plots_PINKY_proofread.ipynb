{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import datajoint as dj\n",
    "from collections import defaultdict\n",
    "import pycircstat as pycs\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@10.28.0.34:3306\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "(2003, \"Can't connect to MySQL server on '10.28.0.34' (timed out)\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymysql/connections.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, sock)\u001b[0m\n\u001b[1;32m    582\u001b[0m                                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                                 **kwargs)\n\u001b[0m\u001b[1;32m    584\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    712\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m             \u001b[0;31m# Break explicitly a reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mtimeout\u001b[0m: timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a9d03a32e99f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpinky\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_virtual_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pinky'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'microns_pinky'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mndap100\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_virtual_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pinky_nda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'microns_pinky_nda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mradtune\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_virtual_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pinky_radtune'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'microns_pinky_radtune'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/datajoint/schema.py\u001b[0m in \u001b[0;36mcreate_virtual_module\u001b[0;34m(module_name, schema_name, create_schema, create_tables, connection)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \"\"\"\n\u001b[1;32m    252\u001b[0m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0m_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_schema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_tables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_tables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0m_schema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn_missing_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'schema'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_schema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/datajoint/schema.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, schema_name, context, connection, create_schema, create_tables)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \"\"\"\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconnection\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/datajoint/connection.py\u001b[0m in \u001b[0;36mconn\u001b[0;34m(host, user, password, init_fun, reset)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mpassword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Please enter DataJoint password: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0minit_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_fun\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_fun\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'connection.init_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_fun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/datajoint/connection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, host, user, password, init_fun)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Connecting {user}@{host}:{port}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconn_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_connected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Connected {user}@{host}:{port}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconn_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/datajoint/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m                          \u001b[0;34m\"STRICT_ALL_TABLES,NO_ENGINE_SUBSTITUTION\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mcharset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'connection.charset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 **self.conn_info)    \n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymysql/__init__.py\u001b[0m in \u001b[0;36mConnect\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \"\"\"\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconnections\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_orig_conn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymysql/connections.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, host, user, password, database, port, unix_socket, charset, sql_mode, read_default_file, conv, use_unicode, client_flag, cursorclass, init_command, connect_timeout, ssl, read_default_group, compress, named_pipe, autocommit, db, passwd, local_infile, max_allowed_packet, defer_connect, auth_plugin_map, read_timeout, write_timeout, bind_address, binary_prefix, program_name, server_public_key)\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_create_ssl_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msslp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymysql/connections.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, sock)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;31m# If e is neither DatabaseError or IOError, It's a bug.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (2003, \"Can't connect to MySQL server on '10.28.0.34' (timed out)\")"
     ]
    }
   ],
   "source": [
    "#setting the address and the username\n",
    "dj.config['database.host'] = '10.28.0.34'\n",
    "dj.config['database.user'] = 'celiib'\n",
    "dj.config['database.password'] = 'newceliipass'\n",
    "dj.config['safemode']=True\n",
    "dj.config[\"display.limit\"] = 20\n",
    "\n",
    "\n",
    "pinky = dj.create_virtual_module('pinky', 'microns_pinky')\n",
    "ndap100 = dj.create_virtual_module('pinky_nda', 'microns_pinky_nda')\n",
    "radtune = dj.create_virtual_module('pinky_radtune', 'microns_pinky_radtune')\n",
    "spattune = dj.create_virtual_module('pinky_spattune', 'microns_pinky_spattune')\n",
    "fc = dj.create_virtual_module('pinky_fc', 'microns_pinky_fc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#demonstrates that all the correlation tables have been fully run\n",
    "print((len(fc.ContactCorrelationShaft()),\n",
    "       len(fc.ContactCorrelationHead()),\n",
    "       len(fc.ContactCorrelationAxon()),\n",
    "       len(fc.ContactCorrelationSoma()),\n",
    "       len(fc.ContactCorrelationUnused())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segments that have dendrite verteces > restriction threshold\n",
    "\n",
    "dendrite_labels = [\"Apical\",\"Basal\",\"Oblique\",\"Dendrite\"]\n",
    "\n",
    "#dj.U(\"segment_id\").aggr(pinky.CompartmentFinal.ComponentFinal() & [dict(compartment_type=x) for x in dendrite_labels]\n",
    "#pinky.CompartmentFinal.ComponentFinal() & [dict(compartment_type=x) for x in dendrite_labels] & \"n_vertex_indices>500\"\n",
    "\"\"\"\n",
    "Gets the number of dendritic vertex counts for each nueron in excitatory and orphan table\n",
    "\"\"\"\n",
    "excitatory = dj.U(\"segment_id\").aggr(pinky.CompartmentFinal.ComponentFinal() & [dict(compartment_type=x) for x in dendrite_labels] & \"n_vertex_indices>500\",\n",
    "                       dendrite_vertex_count=\"sum(n_vertex_indices)\")\n",
    "\n",
    "orphan = dj.U(\"segment_id\").aggr(pinky.CompartmentOrphan.ComponentOrphan() & [dict(compartment_type=x) for x in dendrite_labels] & \"n_vertex_indices>500\",\n",
    "                       dendrite_vertex_count=\"sum(n_vertex_indices)\")\n",
    "\n",
    "#restricts to only those neurons that don't have 15000 vertex in the dendritic label group\n",
    "restriction_threshold = 15000\n",
    "dendrite_restriction = ((excitatory & \"dendrite_vertex_count >\" + str(restriction_threshold)).proj() + \n",
    "                            (orphan & \"dendrite_vertex_count >\" + str(restriction_threshold)).proj())\n",
    "\n",
    "dendrite_restriction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pinky.CompartmentFinal.ComponentFinal() - dendrite_restriction\n",
    "pinky.CompartmentOrphan.ComponentOrphan() - dendrite_restriction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pinky.SegmentExclude.describe()\n",
    "pinky.ExclusionCriteria()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude synapses, segments and restrict by functional confidence \n",
    "\n",
    "#gets rid of any synapse excludeds\n",
    "contact = pinky.SkeletonContact & pinky.CurrentSegmentation\n",
    "synapse = (pinky.Synapse - pinky.SynapseExclude) & pinky.CurrentSegmentation\n",
    "\n",
    "#gets rid of any segment excludes\n",
    "segment = (pinky.Segment - pinky.SegmentExclude) & pinky.CurrentSegmentation\n",
    "soma = (pinky.AllenSoma - pinky.SegmentExclude) & pinky.CurrentSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segments that have dendrite verteces > restriction threshold\n",
    "\n",
    "dendrite_labels = [\"Apical\",\"Basal\",\"Oblique\",\"Dendrite\"]\n",
    "\n",
    "#dj.U(\"segment_id\").aggr(pinky.CompartmentFinal.ComponentFinal() & [dict(compartment_type=x) for x in dendrite_labels]\n",
    "#pinky.CompartmentFinal.ComponentFinal() & [dict(compartment_type=x) for x in dendrite_labels] & \"n_vertex_indices>500\"\n",
    "\"\"\"\n",
    "Gets the number of dendritic vertex counts for each nueron in excitatory and orphan table\n",
    "\"\"\"\n",
    "excitatory = dj.U(\"segment_id\").aggr(pinky.CompartmentFinal.ComponentFinal() & [dict(compartment_type=x) for x in dendrite_labels] & \"n_vertex_indices>500\",\n",
    "                       dendrite_vertex_count=\"sum(n_vertex_indices)\")\n",
    "\n",
    "orphan = dj.U(\"segment_id\").aggr(pinky.CompartmentOrphan.ComponentOrphan() & [dict(compartment_type=x) for x in dendrite_labels] & \"n_vertex_indices>500\",\n",
    "                       dendrite_vertex_count=\"sum(n_vertex_indices)\")\n",
    "\n",
    "#restricts to only those neurons that don't have 15000 vertex in the dendritic label group\n",
    "restriction_threshold = 15000\n",
    "dendrite_restriction = ((excitatory & \"dendrite_vertex_count >\" + str(restriction_threshold)).proj() + \n",
    "                            (orphan & \"dendrite_vertex_count >\" + str(restriction_threshold)).proj())\n",
    "\n",
    "dendrite_restriction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orientation / Direction / Von fit correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reminder: \n",
    "1) ContactCorrelation table is for each segment pairs\n",
    "- n seg shared, union, and correlations of the vectors of presyn pairs\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain a list of all keys in fc.ContactCorrelation and \n",
    "df = pd.DataFrame(fc.ContactCorrelation.fetch())\n",
    "attrs = []\n",
    "for col in df.columns:\n",
    "    attrs.append(str(col))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spat_threshold=1.35\n",
    "ori_confidence=0.5\n",
    "von_p_value=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'von_p_value <= ' + str(von_p_value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned = 'confidence > ' + str(ori_confidence)\n",
    "# gets the number of segments with certain confidence and von_p_value less than threshold\n",
    "rad_units = radtune.BestVonFit.Unit & segment & tuned & 'von_p_value <= ' + str(von_p_value) \n",
    "rad_units\n",
    "\n",
    "\"\"\"\n",
    "gets a combination of all the segments that pass the orientation threshold\n",
    "\"\"\"\n",
    "\n",
    "rad_unit_pairs = (rad_units.proj(segment_id1 = 'segment_id') * \n",
    "                rad_units.proj(segment_id2 = 'segment_id')) & 'segment_id1 < segment_id2'\n",
    "\n",
    "\n",
    "rad_unit_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "gets the pairwise of significantly tuned neurons and their \n",
    "orientation and directional differences from BestVonCorr\n",
    "and appends the correlation data to it\n",
    "\n",
    "-- then puts it in a dataframe\n",
    "\"\"\"\n",
    "\n",
    "radsyncont_df = pd.DataFrame(((radtune.BestVonCorr & rad_unit_pairs) * \n",
    "                              fc.ContactCorrelationShaft.proj(*attrs, cont_seg_shared = 'n_seg_shared', cont_seg_union = 'n_seg_union', segment_id1 = 'segment_id', segment_id2 = 'segment_b')).fetch())\n",
    "radsyncont_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up bins for difference in prefered orientation \n",
    "rad2deg = 180/np.pi\n",
    "ori_edges = np.linspace(0, np.pi /2 , 5) #gets the edges for the orientation edges\n",
    "#generates labels for orientation\n",
    "oe = list(['{:.0f}'.format(ee) for ee in [np.round(e * rad2deg) for e in ori_edges]]) \n",
    "ori_labels = list(zip(oe[:-1], oe[1:]))#\n",
    "#generates the orientation centers\n",
    "ori_centers = np.round((ori_edges[1:] + ori_edges[:-1])/2 * rad2deg, decimals=2) \n",
    "ori_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up bins for difference in preferred direction (difference between direction can be at most pi)\n",
    "dir_edges = np.linspace(0, np.pi, 5)\n",
    "de = list(['{:.0f}'.format(ee) for ee in [np.round(e * rad2deg) for e in dir_edges]])\n",
    "dir_labels = list(zip(de[:-1], de[1:]))\n",
    "dir_centers = np.round((dir_edges[1:] + dir_edges[:-1])/2 * rad2deg, decimals=2) \n",
    "dir_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up bins for von_corr (creates 6 bins)\n",
    "vc_edges = np.linspace(min(radsyncont_df['von_corr']), max(radsyncont_df['von_corr']), 7)\n",
    "ve = list(['{:.1f}'.format(ee) for ee in vc_edges])\n",
    "vc_labels = list(zip(ve[:-1], ve[1:]))\n",
    "#puts nans on the \n",
    "vc_centers = np.hstack((np.nan, np.round((vc_edges[1:] + vc_edges[:-1])/2, decimals=2), np.nan)) \n",
    "vc_centers\n",
    "\n",
    "\n",
    "#### ***** for some reason wraps nans around the middles but didn't do that for the orientations ****** ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin diff_pref_ori, diff_pref_dir, von_corr and puts in dataframe\n",
    "\"\"\"\n",
    "stores the bin center for the bin that the difference delongs in\n",
    "np.digitize returns the bin index + 1 of the bin that the value would belong in\n",
    "\"\"\"\n",
    "\n",
    "radsyncont_df['bin_diff_pref_ori'] = ori_centers[(np.digitize(np.abs(radsyncont_df['diff_pref_ori']), ori_edges)) - 1]\n",
    "radsyncont_df['bin_diff_pref_dir'] = dir_centers[(np.digitize(np.abs(radsyncont_df['diff_pref_dir']), dir_edges)) - 1]\n",
    "#radsyncont_df['bin_diff_sharp'] = sharp_centers[(np.digitize(np.abs(radsyncont_df['diff_sharp']), sharp_edges))]\n",
    "radsyncont_df['bin_von_corr'] = vc_centers[(np.digitize(radsyncont_df['von_corr'], vc_edges))]\n",
    "\n",
    "radsyncont_df\n",
    "#-1.032120\t-1.032120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radsyncont_df[[\"diff_pref_ori\",\"bin_diff_pref_ori\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute n_seg_shared/n_seg_union for both synapse and contact vs functional differences\n",
    "radsyncont_df['cont_shared_percent'] = radsyncont_df['cont_seg_shared'] / radsyncont_df['cont_seg_union']\n",
    "radsyncont_df['syn_intersect'] = radsyncont_df['n_seg_a_converted'] + radsyncont_df['n_seg_b_converted'] - radsyncont_df['n_seg_shared_converted']\n",
    "radsyncont_df['syn_shared_percent'] = radsyncont_df['syn_intersect'] / radsyncont_df['n_seg_shared_converted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receptive field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For each neuron has the sta_snr that is used to restrict the receptive fields\n",
    "\"\"\"\n",
    "spat_units = spattune.BestSTA.Loc & 'sta_snr > '+ str(spat_threshold) & (segment & (spattune.BestSTA.Confidence() & tuned))\n",
    "spat_units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Gets all the pairs that have a significant receptive field (without any repeats)\n",
    "\"\"\"\n",
    "\n",
    "spat_unit_pairs = (spat_units.proj(segment_id1 = 'segment_id') * \n",
    "                  spat_units.proj(segment_id2 = 'segment_id')) & 'segment_id1 < segment_id2'\n",
    "spat_unit_pairs\n",
    "# spatsyncont_df = pd.DataFrame(((spattune.BestSTACorr & sig_unit_pairs) * \n",
    "#                               fc.ContactCorrelationHead.proj(*attrs, cont_seg_shared = 'n_seg_shared', cont_seg_union = 'n_seg_union', segment_id1 = 'segment_id', segment_id2 = 'segment_b')).fetch())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spattune.BestSTACorr() & \"segment_id1>=segment_id2\" #shows that segmnet1 is always less than segment2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Restricts the receptive field correlation  table to only the significant pairs\n",
    "Attaches the correlation statistics to the end\n",
    "\n",
    "-- stores it in a dataframe\n",
    "\"\"\"\n",
    "spatsyncon_df = pd.DataFrame(((spattune.BestSTACorr & spat_unit_pairs) * \n",
    "                              fc.ContactCorrelationHead.proj(*attrs, cont_seg_shared = 'n_seg_shared', cont_seg_union = 'n_seg_union', segment_id1 = 'segment_id', segment_id2 = 'segment_b')).fetch())\n",
    "spatsyncon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that returns the bin edges that will set up n_bins using equal depth (aka percentile)\n",
    "def perc_bins(vals,n_bins): return [np.percentile(vals,p) for p in np.linspace(0,100,n_bins+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up percentile bins for union_corr_r2\n",
    "\n",
    "r2_edges = perc_bins(spatsyncon_df['union_corr_r2'].values, 7)\n",
    "re = list(['{:.1f}'.format(ee) for ee in r2_edges])\n",
    "r2_labels = list(zip(re[:-1], re[1:]))\n",
    "r2_centers = np.hstack((np.nan, np.round((np.array(r2_edges[1:]) + np.array(r2_edges[:-1]))/2, decimals=2), np.nan))\n",
    "r2_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up percentile bins for center_dist\n",
    "\n",
    "dist_edges = perc_bins(spatsyncon_df['center_dist'].values, 7)\n",
    "de = list(['{:.1f}'.format(ee) for ee in r2_edges])\n",
    "dist_labels = list(zip(de[:-1], de[1:]))\n",
    "dist_centers = np.hstack((np.nan, np.round((np.array(dist_edges[1:]) + np.array(dist_edges[:-1]))/2, decimals=2), np.nan))\n",
    "spatsyncon_df['bin_center_dist'] = dist_centers[(np.digitize(spatsyncon_df['center_dist'], dist_edges))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatsyncon_df['bin_center_dist'] = dist_centers[(np.digitize(spatsyncon_df['center_dist'], dist_edges))]\n",
    "spatsyncon_df['bin_union_corr_r2'] = r2_centers[(np.digitize(spatsyncon_df['union_corr_r2'], r2_edges))]\n",
    "spatsyncon_df['cont_shared_percent'] = spatsyncon_df['cont_seg_shared'] / spatsyncon_df['cont_seg_union']\n",
    "spatsyncon_df['syn_intersect'] = spatsyncon_df['n_seg_a_converted'] + spatsyncon_df['n_seg_b_converted'] - spatsyncon_df['n_seg_shared_converted']\n",
    "spatsyncon_df['syn_shared_percent'] = spatsyncon_df['syn_intersect'] / spatsyncon_df['n_seg_shared_converted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Conclusion: the binning of the correlations was done correctly\n",
    "\"\"\"\n",
    "\n",
    "spatsyncon_df[['bin_union_corr_r2','union_corr_r2']] \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.ContactCorrelationHead.describe()\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude synapses, segments and restrict by functional confidence \n",
    "\n",
    "#gets rid of any synapse excludeds\n",
    "contact = pinky.SkeletonContact & pinky.CurrentSegmentation\n",
    "synapse = (pinky.Synapse - pinky.SynapseExclude) & pinky.CurrentSegmentation\n",
    "\n",
    "#gets rid of any segment excludes\n",
    "segment = (pinky.Segment - pinky.SegmentExclude) & pinky.CurrentSegmentation\n",
    "soma = (pinky.AllenSoma - pinky.SegmentExclude) & pinky.CurrentSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spat_threshold=1.35\n",
    "ori_confidence=0.5\n",
    "von_p_value=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up bins for difference in prefered orientation \n",
    "rad2deg = 180/np.pi\n",
    "ori_edges = np.linspace(0, np.pi /2 , 5) #gets the edges for the orientation edges\n",
    "#generates labels for orientation\n",
    "oe = list(['{:.0f}'.format(ee) for ee in [np.round(e * rad2deg) for e in ori_edges]]) \n",
    "ori_labels = list(zip(oe[:-1], oe[1:]))#\n",
    "#generates the orientation centers\n",
    "ori_centers = np.round((ori_edges[1:] + ori_edges[:-1])/2 * rad2deg, decimals=2) \n",
    "ori_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all of the significant units for the orientation\n",
    "tuned = 'confidence > ' + str(ori_confidence)\n",
    "# gets the number of segments with certain confidence and von_p_value less than threshold\n",
    "rad_units = radtune.BestVonFit.Unit & segment & tuned & 'von_p_value <= ' + str(von_p_value) \n",
    "rad_units\n",
    "\n",
    "\"\"\"\n",
    "gets a combination of all the segments that pass the orientation threshold\n",
    "\"\"\"\n",
    "\n",
    "rad_unit_pairs = (rad_units.proj(segment_id1 = 'segment_id') * \n",
    "                rad_units.proj(segment_id2 = 'segment_id')) & 'segment_id1 < segment_id2'\n",
    "\n",
    "\n",
    "rad_unit_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all of the significant units for receptive field:\n",
    "\"\"\"\n",
    "For each neuron has the sta_snr that is used to restrict the receptive fields\n",
    "\"\"\"\n",
    "spat_units = spattune.BestSTA.Loc & 'sta_snr > '+ str(spat_threshold) & (segment & (spattune.BestSTA.Confidence() & tuned))\n",
    "spat_units\n",
    "\"\"\"\n",
    "Gets all the pairs that have a significant receptive field (without any repeats)\n",
    "\"\"\"\n",
    "\n",
    "spat_unit_pairs = (spat_units.proj(segment_id1 = 'segment_id') * \n",
    "                  spat_units.proj(segment_id2 = 'segment_id')) & 'segment_id1 < segment_id2'\n",
    "spat_unit_pairs\n",
    "# spatsyncont_df = pd.DataFrame(((spattune.BestSTACorr & sig_unit_pairs) * \n",
    "#                               fc.ContactCorrelationHead.proj(*attrs, cont_seg_shared = 'n_seg_shared', cont_seg_union = 'n_seg_union', segment_id1 = 'segment_id', segment_id2 = 'segment_b')).fetch())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rels = [fc.ContactCorrelationHead, fc.ContactCorrelation]\n",
    "labels = ['Head', 'Total']\n",
    "colors = ['g', 'k']\n",
    "conn = ['cont_shared_percent', 'syn_shared_percent', 'density_pearson_converted']\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(6, 12))\n",
    "\n",
    "#loop through all of the relationships in the list\n",
    "for i in range(len(rels)):\n",
    "    #gets the correlation tables with the significant orientation pairs and appends the correlation attributes\n",
    "    \"\"\"\n",
    "    cont_seg_shared = 'n_seg_shared' -->n_presyns contacting onto both segment_id and segment_b\n",
    "    cont_seg_union = 'n_seg_union' --> n_presyns contacting either segment_id or segment_b\n",
    "    \"\"\"\n",
    "    radsyncont_df = pd.DataFrame(((radtune.BestVonCorr & rad_unit_pairs) * \n",
    "                              rels[i].proj(*attrs, cont_seg_shared = 'n_seg_shared', cont_seg_union = 'n_seg_union', segment_id1 = 'segment_id', segment_id2 = 'segment_b')).fetch())\n",
    "    \n",
    "    # set up bins for von_corr (creates 6 bins)\n",
    "    vc_edges = np.linspace(min(radsyncont_df['von_corr']), max(radsyncont_df['von_corr']), 7)\n",
    "    ve = list(['{:.1f}'.format(ee) for ee in vc_edges])\n",
    "    vc_labels = list(zip(ve[:-1], ve[1:]))\n",
    "    #puts nans on the \n",
    "    vc_centers = np.hstack((np.nan, np.round((vc_edges[1:] + vc_edges[:-1])/2, decimals=2), np.nan)) \n",
    "    vc_centers\n",
    "\n",
    "\n",
    "    #### ***** for some reason wraps nans around the middles but didn't do that for the orientations ****** ####\n",
    "    \n",
    "    \n",
    "   #computes the binned orientation preference difference\n",
    "    radsyncont_df['bin_diff_pref_ori'] = ori_centers[(np.digitize(np.abs(radsyncont_df['diff_pref_ori']), ori_edges)) - 1]\n",
    "    #computes the percentage of total contact segments shared in comparison to total union of contact presyns\n",
    "    radsyncont_df['cont_shared_percent'] = radsyncont_df['cont_seg_shared'] / radsyncont_df['cont_seg_union']\n",
    "    #the intersection of the shared contact segments\n",
    "    radsyncont_df['syn_intersect'] = radsyncont_df['n_seg_a_converted'] + radsyncont_df['n_seg_b_converted'] - radsyncont_df['n_seg_shared_converted']\n",
    "    #the intersection of contact presyns as a percentag of the union of contacts\n",
    "    radsyncont_df['syn_shared_percent'] = radsyncont_df['syn_intersect'] / radsyncont_df['n_seg_shared_converted']\n",
    "    \n",
    "    for k in range(len(conn)):\n",
    "        x_coords = ori_centers\n",
    "        #finds the average of each of the following stats for each bin ['cont_shared_percent', 'syn_shared_percent', 'density_pearson_converted']\n",
    "        y_coords = radsyncont_df.groupby('bin_diff_pref_ori').mean()[conn[k]]\n",
    "\n",
    "        ax[k].plot(x_coords, y_coords, label=labels[i], color=colors[i])\n",
    "        errors = radsyncont_df.groupby('bin_diff_pref_ori').sem()[conn[k]]  # compute SE\n",
    "        ax[k].errorbar(x_coords, y_coords, yerr=errors, ecolor=colors[i], fmt=' ', zorder=-1, label=None)\n",
    "        ax[k].set_xticks(ori_centers)\n",
    "        ax[k].set_xticklabels(['{}째-{}째'.format(*a) for a in ori_labels])\n",
    "        ax[k].tick_params(labelsize=14)\n",
    "        ax[k].set_xlabel(r'$\\Delta \\theta$', fontsize=16)\n",
    "        ax[k].spines['top'].set_color('none')\n",
    "        ax[k].spines['right'].set_color('none')\n",
    "ax[0].set_ylabel(r'$\\langle$Proportion Shared Contacts$\\rangle$', fontsize=16)\n",
    "ax[1].set_ylabel(r'$\\langle$Proportion Shared Synapses$\\rangle$', fontsize=16)\n",
    "ax[2].set_ylabel(r'$\\langle$Synapse Density Correlation$\\rangle$', fontsize=16)\n",
    "ax[0].legend(loc=9, frameon=False, fontsize=14)\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/cont_syn_density.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.ContactCorrelationShaft.describe()\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orientatin tuning \n",
    "\n",
    "rels = [fc.ContactCorrelationShaft, fc.ContactCorrelationHead, fc.ContactCorrelationSoma, fc.ContactCorrelationAxon]\n",
    "labels = ['Shaft', 'Head', 'Soma', 'Axon']\n",
    "colors = ['r', 'g', 'b', 'y']\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "    \n",
    "for i in range(len(rels)):\n",
    "    #gets the orientation difference between pairs\n",
    "    radsyncont_df = pd.DataFrame(((radtune.BestVonCorr & spat_unit_pairs) * \n",
    "                              rels[i].proj(*attrs, cont_seg_shared = 'n_seg_shared', cont_seg_union = 'n_seg_union', segment_id1 = 'segment_id', segment_id2 = 'segment_b')).fetch())\n",
    "    \n",
    "    #calculates the binned difference in preference orientation\n",
    "    \n",
    "    radsyncont_df['bin_diff_pref_ori'] = ori_centers[(np.digitize(np.abs(radsyncont_df['diff_pref_ori']), ori_edges)) - 1]\n",
    "    \n",
    "    x_coords = ori_centers\n",
    "    #groups by the binned difference in preferred orientation \n",
    "    #density_pearson_converted=null : float                        # Pearson correlation for n_synapse/postsyn_length rate for axon group with at least 1 conversion\n",
    "    y_coords = radsyncont_df.groupby('bin_diff_pref_ori').mean()['density_pearson']\n",
    "    \n",
    "    ax.plot(x_coords, y_coords, label=labels[i], color=colors[i])\n",
    "\n",
    "    errors = radsyncont_df.groupby('bin_diff_pref_ori').sem()['density_pearson_converted']  # compute SE\n",
    "    ax.errorbar(x_coords, y_coords, yerr=errors, ecolor=colors[i], fmt=' ', zorder=-1, label=None)\n",
    "    \n",
    "ax.legend(frameon=False, loc=0, fontsize=12)\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.set_xticks(ori_centers)\n",
    "ax.set_xticklabels(['{}째-{}째'.format(*a) for a in ori_labels])\n",
    "ax.set_xlabel(r'$\\Delta \\theta$', fontsize = 14)\n",
    "ax.set_ylabel(r'$\\langle$Synapse Density Correlation$\\rangle$', fontsize = 14)\n",
    "fig.savefig('figures/density_four_classes.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "pearson_list = np.array(radsyncont_df[\"density_pearson_converted\"].tolist())\n",
    "correlation_numbers = pearson_list[np.where(~np.isnan(pearson_list))[0].astype(\"int\")]\n",
    "sns.distplot(correlation_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Conclusion: the synaptic densities are pearson correlations and a majority are negative\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "ax.plot(x_coords, y_coords, label=labels[i], color=colors[i])\n",
    "errors = spatsyncont_df.groupby('bin_center_dist').sem()['density_pearson_converted']  # compute SE\n",
    "ax.errorbar(x_coords, y_coords, yerr=errors, ecolor=colors[i], fmt=' ', zorder=-1, label=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spat_units = spattune.BestSTA.Loc & 'sta_snr > 1.5' & (segment & (spattune.BestSTA.Confidence() & tuned))\n",
    "spat_unit_pairs = (spat_units.proj(segment_id1 = 'segment_id') * \n",
    "                  spat_units.proj(segment_id2 = 'segment_id')) & 'segment_id1 < segment_id2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF distance\n",
    "\n",
    "rels = [fc.ContactCorrelationShaft, fc.ContactCorrelationHead, fc.ContactCorrelationSoma, fc.ContactCorrelationAxon]\n",
    "labels = ['Shaft', 'Head', 'Soma', 'Axon']\n",
    "colors = ['r', 'g', 'b', 'y']\n",
    "\n",
    "#rels = [ta3p100.ContactCorrelation]\n",
    "#labels = ['Total']\n",
    "#colors = ['k']\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "    \n",
    "for i in range(len(rels)):\n",
    "    spatsyncont_df = pd.DataFrame(((spattune.BestSTACorr & spat_unit_pairs) * \n",
    "                              rels[i].proj(*attrs, cont_seg_shared = 'n_seg_shared', cont_seg_union = 'n_seg_union', segment_id1 = 'segment_id', segment_id2 = 'segment_b')).fetch())\n",
    "    \n",
    "    dist_edges = np.linspace(min(spatsyncont_df['center_dist']), max(spatsyncont_df['center_dist']), 8)\n",
    "    de = list(['{:.1f}'.format(ee) for ee in dist_edges])\n",
    "    dist_labels = list(zip(de[:-1], de[1:]))\n",
    "    dist_centers = np.hstack((np.nan, np.round((np.array(dist_edges[1:]) + np.array(dist_edges[:-1]))/2, decimals=2), np.nan))\n",
    "    spatsyncont_df['bin_center_dist'] = dist_centers[(np.digitize(spatsyncont_df['center_dist'], dist_edges))]\n",
    "    \n",
    "    x_coords = dist_centers[1:-1]\n",
    "    y_coords = spatsyncont_df.groupby('bin_center_dist').mean()['density_pearson_converted']\n",
    "    #print(x_coords, y_coords)\n",
    "    ax.plot(x_coords, y_coords, label=labels[i], color=colors[i])\n",
    "    #ax.scatter(x_coords, y_coords, label=labels[i], color=colors[i])\n",
    "\n",
    "    errors = spatsyncont_df.groupby('bin_center_dist').sem()['density_pearson_converted']  # compute SE\n",
    "    ax.errorbar(x_coords, y_coords, yerr=errors, ecolor=colors[i], fmt=' ', zorder=-1, label=None)\n",
    "    \n",
    "ax.legend(frameon=False, loc=0, fontsize=12)\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.set_xticks(dist_centers[1:-1])\n",
    "ax.set_xticklabels(['[{},{}]'.format(*a) for a in dist_labels], rotation=15)\n",
    "ax.set_xlabel('RF distance', fontsize = 15)\n",
    "ax.set_ylabel(r'$\\langle$Synapse Density Correlation$\\rangle$', fontsize = 15)\n",
    "fig.savefig('figures/RFdistance_density_four_classes.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# receptive field\n",
    "\n",
    "functional = ['bin_center_dist']    \n",
    "connectomics = ['cont_shared_percent', 'syn_shared_percent', 'binary_conversion_pearson',\n",
    "       'binary_conversion_cosine', 'binary_conv_jaccard_ones_ratio',\n",
    "       'binary_conv_jaccard_matching_ratio', 'conversion_pearson',\n",
    "       'conversion_cosine', 'density_pearson', 'density_cosine',\n",
    "       'synapse_volume_mean_pearson', 'synapse_volume_mean_cosine',\n",
    "       'synapse_vol_density_pearson', 'synapse_vol_density_cosine',\n",
    "       'binary_conversion_pearson_converted',\n",
    "       'binary_conversion_cosine_converted',\n",
    "       'binary_conv_jaccard_ones_ratio_converted',\n",
    "       'binary_conv_jaccard_matching_ratio_converted',\n",
    "       'conversion_pearson_converted', 'conversion_cosine_converted',\n",
    "       'density_pearson_converted', 'density_cosine_converted',\n",
    "       'synapse_volume_mean_pearson_converted',\n",
    "       'synapse_volume_mean_cosine_converted',\n",
    "       'synapse_vol_density_pearson_converted',\n",
    "       'synapse_vol_density_cosine_converted']\n",
    "\n",
    "with sns.axes_style('ticks'):\n",
    "    fig, ax = plt.subplots(len(connectomics), len(functional), figsize=(5*len(functional), 3*len(connectomics)))\n",
    "\n",
    "for i, pair in enumerate(itertools.product(functional, connectomics)):\n",
    "    #sns.pointplot(pair[0], pair[1], data = spatsyncont_df, ax=ax[i], ci=None) \n",
    "    \n",
    "    x_coords = dist_centers[1:-1]\n",
    "    y_coords = spatsyncont_df.groupby(pair[0]).mean()[pair[1]] \n",
    "    ax[i].plot(x_coords, y_coords)\n",
    "    \n",
    "    errors = spatsyncont_df.groupby(pair[0]).sem()[pair[1]]  # compute SE\n",
    "    ax[i].errorbar(x_coords, y_coords, yerr=errors, ecolor='k', fmt=' ', zorder=-1)\n",
    "    \n",
    "    ax[i].set_title(connectomics[i], fontsize=15)\n",
    "\n",
    "sns.despine(trim=True)\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/Head_union_corr.png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot n_seg_shared/n_seg_union for both synapse and contact vs functional differences\n",
    "\n",
    "functional = ['bin_diff_pref_ori', 'bin_diff_pref_dir', 'bin_von_corr']    \n",
    "connectomics = ['cont_shared_percent', 'syn_shared_percent', 'binary_conversion_pearson',\n",
    "       'binary_conversion_cosine', 'binary_conv_jaccard_ones_ratio',\n",
    "       'binary_conv_jaccard_matching_ratio', 'conversion_pearson',\n",
    "       'conversion_cosine', 'density_pearson', 'density_cosine',\n",
    "       'synapse_volume_mean_pearson', 'synapse_volume_mean_cosine',\n",
    "       'synapse_vol_density_pearson', 'synapse_vol_density_cosine',\n",
    "       'binary_conversion_pearson_converted',\n",
    "       'binary_conversion_cosine_converted',\n",
    "       'binary_conv_jaccard_ones_ratio_converted',\n",
    "       'binary_conv_jaccard_matching_ratio_converted',\n",
    "       'conversion_pearson_converted', 'conversion_cosine_converted',\n",
    "       'density_pearson_converted', 'density_cosine_converted',\n",
    "       'synapse_volume_mean_pearson_converted',\n",
    "       'synapse_volume_mean_cosine_converted',\n",
    "       'synapse_vol_density_pearson_converted',\n",
    "       'synapse_vol_density_cosine_converted']\n",
    "\n",
    "with sns.axes_style('ticks'):\n",
    "    fig, ax = plt.subplots(len(connectomics), len(functional), figsize=(5*len(functional), 3*len(connectomics)))\n",
    "\n",
    "for i, pair in enumerate(itertools.product(functional, connectomics)):\n",
    "    sns.pointplot(pair[0], pair[1], data = radsyncont_df, ax=ax[i%len(connectomics), i//len(connectomics)], ci=None) \n",
    "    \n",
    "    # manually plot error bars\n",
    "    x_coords = []\n",
    "    y_coords = []\n",
    "    for point_pair in ax[i%len(connectomics), i//len(connectomics)].collections:\n",
    "        for x, y in point_pair.get_offsets():\n",
    "            x_coords.append(x)\n",
    "            y_coords.append(y)\n",
    "    errors = radsyncont_df.groupby(pair[0]).sem()[pair[1]]  # compute SE\n",
    "    \n",
    "    ax[i%len(connectomics), i//len(connectomics)].errorbar(x_coords, y_coords, yerr=errors, ecolor='k', fmt=' ', zorder=-1)\n",
    "\n",
    "for i in range(len(connectomics)):\n",
    "    ax[i, 1].set_title(connectomics[i], fontsize=15)\n",
    "\n",
    "#sns.pointplot('bin_diff_pref_ori', 'cont_shared_percent', ci=None, data = radsyncont_df, ax=ax[0,0], linestyles='--', color='k')    \n",
    "#sns.pointplot('bin_diff_pref_dir', 'cont_shared_percent', ci=None, data = radsyncont_df, ax=ax[0,1], linestyles='--', color='k')    \n",
    "#sns.pointplot('bin_von_corr', 'cont_shared_percent', ci=None, data = radsyncont_df, ax=ax[0,2], linestyles='--', color='k')    \n",
    "#sns.pointplot('bin_diff_pref_ori', 'syn_shared_percent', ci=None, data = radsyncont_df, ax=ax[1,0], color='k')    \n",
    "#sns.pointplot('bin_diff_pref_dir', 'syn_shared_percent', ci=None, data = radsyncont_df, ax=ax[1,1], color='k')    \n",
    "#sns.pointplot('bin_von_corr', 'syn_shared_percent', ci=None, data = radsyncont_df, ax=ax[1,2], color='k')  \n",
    "'''\n",
    "l = ['Contact', 'Synapse']\n",
    "for i in range(2):\n",
    "    ax[i, 0].set_title('{} percent shared seg vs diff in orientation'.format(l[i]))\n",
    "    ax[i, 0].set_xticklabels(['{}째-{}째'.format(*a) for a in ori_labels])\n",
    "    ax[i, 0].set_xlabel(r'$\\Delta \\theta$')\n",
    "    ax[i, 0].set_ylabel('$<Shared/Union>$')\n",
    "\n",
    "    ax[i, 1].set_title('{} percent shared seg vs diff in direction'.format(l[i]))\n",
    "    ax[i, 1].set_xticklabels(['{}째-{}째'.format(*a) for a in dir_labels])\n",
    "    ax[i, 1].set_xlabel(r'$\\Delta \\theta$')\n",
    "    ax[i, 1].set_ylabel('$<Shared/Union>$')\n",
    "\n",
    "    ax[i, 2].set_title('{} percent shared seg vs von corr'.format(l[i]))\n",
    "    ax[i, 2].set_xticklabels(['[{},{}]'.format(*a) for a in vc_labels])\n",
    "    ax[i, 2].set_xlabel('Von corr')\n",
    "    ax[i, 2].set_ylabel('$<Shared/Union>$')\n",
    "\n",
    "'''\n",
    "sns.despine(trim=True)\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/Head_confidence1.0_percent_shared_seg_by_functional_difference.png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
