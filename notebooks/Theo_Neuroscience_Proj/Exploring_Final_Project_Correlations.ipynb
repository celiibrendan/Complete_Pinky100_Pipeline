{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPurpose: To gather the orientation preferences and the soma center data and try to find different ways to correlate\\n\\nPseudocode:\\n1) Find the data for the oma locations\\n2) Find way to extract the orientation preferences and bin them\\n3) Get the total distributions the orientation| preferences from inside the volume\\n4) Start with a given neuron: \\na. Do radius testing:\\n    - plot the overall distribution of circular orinetation difference from that neuron for the whole volume\\n    - gather all of the neurons that are within a certain radius\\n    - plot the distirbutions of circular orinetation difference from that neuron for neurons within that radius\\n    - continue and vary the size of the radius\\nb. Columns of X, Y, Z (same as radius testing)\\n    - need to vary the widths and sizes of the columns like varying the size of the radius\\n\\n'"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose: To gather the orientation preferences and the soma center data and try to find different ways to correlate\n",
    "\n",
    "Pseudocode:\n",
    "1) Find the data for the oma locations\n",
    "2) Find way to extract the orientation preferences and bin them\n",
    "3) Get the total distributions the orientation| preferences from inside the volume\n",
    "4) Start with a given neuron: \n",
    "a. Do radius testing:\n",
    "    - plot the overall distribution of circular orinetation difference from that neuron for the whole volume\n",
    "    - gather all of the neurons that are within a certain radius\n",
    "    - plot the distirbutions of circular orinetation difference from that neuron for neurons within that radius\n",
    "    - continue and vary the size of the radius\n",
    "b. Columns of X, Y, Z (same as radius testing)\n",
    "    - need to vary the widths and sizes of the columns like varying the size of the radius\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinky = dj.create_virtual_module(\"pinky\",\"microns_pinky\")\n",
    "schema = dj.schema(\"microns_pinky\")\n",
    "pinky_nda = dj.create_virtual_module('pinky_nda', 'microns_pinky_nda')\n",
    "radtune = dj.create_virtual_module('pinky_radtune', 'microns_pinky_radtune')\n",
    "spattune = dj.create_virtual_module('pinky_spattune', 'microns_pinky_spattune')\n",
    "fc = dj.create_virtual_module('pinky_fc', 'microns_pinky_fc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting the Soma Centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations of all of the cell somas\n",
    "pinky.AllenSoma()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET THE SIGNIFICANTLY TUNED NEURONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attrs = ['segment_a', 'segment_b', 'connection', 'n_seg_shared']\n",
    "good_rf = 'mscore > 1.25'\n",
    "\n",
    "rf_bin_edges = np.linspace(-.7, .7, 6) #setting the bin boundaries\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Calculate the bins and centers for the orientational preference\n",
    "\"\"\"\n",
    "#defines how to find the \"tuned\" segments of the orientation\n",
    "dori_resolution = np.pi / 2 / 4 #setting the width size of the bins to be 22.5 degrees\n",
    "rad2deg = 180/np.pi\n",
    "bin_edges = np.linspace(0, np.pi,9) #creates 8 bins between boundaries between 0 and pi\n",
    "\n",
    "\n",
    "#sets the threshold for the \n",
    "stat_choice = [\"synapse_vol_density_pearson\"]\n",
    "\n",
    "ori_confidence=0.5\n",
    "von_p_value=0.05\n",
    "\n",
    "rf_bin_edges=rf_bin_edges\n",
    "ori_bin_edges=bin_edges\n",
    "n_seg_shared_threshold = 10\n",
    "n_seg_shared_converted_threshold = 10\n",
    "rf_threshold=1.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the significantly tuned neurons: \n",
    "\n",
    "\n",
    "synapse = (pinky.Synapse - pinky.SynapseExclude) & pinky.CurrentSegmentation\n",
    "segment = (pinky.Segment - pinky.SegmentExclude) & pinky.CurrentSegmentation\n",
    "soma = (pinky.AllenSoma - pinky.SegmentExclude) & pinky.CurrentSegmentation\n",
    "soma = soma & \"cell_class='excitatory'\"\n",
    "\n",
    "\"\"\"calculate the specifics for the bins based on the bin edges given\"\"\"\n",
    "###Receptive Field\n",
    "#calculates the centers of the bins used for the receptive field\n",
    "cbin_centers = np.hstack((np.nan, np.round((rf_bin_edges[1:] + rf_bin_edges[:-1])/2, decimals=2), np.nan))\n",
    "#creates labels for the receptive field edges\n",
    "cbin_labels = ['[{:.1f},{:.1f}]'.format(*a) for a in zip(rf_bin_edges[:-1], rf_bin_edges[1:])]\n",
    "cbin_labels\n",
    "\n",
    "###Orientation\n",
    "rad2deg = 180/np.pi\n",
    "# turns all of the bin edges into degrees with no decimal\n",
    "be = list(['{:.0f}'.format(ee) for ee in [np.round(e * rad2deg) for e in ori_bin_edges]])\n",
    "#creates the bin boundary markings with [low - high]\n",
    "bin_labels = list(zip(be[:-1], be[1:]))\n",
    "\n",
    "#calculates the bin centers\n",
    "bin_centers = np.round((ori_bin_edges[1:] + ori_bin_edges[:-1])/2 * rad2deg, decimals=2)\n",
    "\n",
    "\"\"\"\n",
    "Gets the segments with the acceptable rf thresholds\n",
    "\"\"\"\n",
    "\n",
    "# functional metrics for each functional soma pair (restricting by spattune fitting significance)\n",
    "\n",
    "sig_units_rf = spattune.BestSTA.Loc & 'sta_snr > ' + str(rf_threshold) & segment\n",
    "sig_unit_pairs_rf = (sig_units_rf.proj(segment_id1 = 'segment_id') * \n",
    "                  sig_units_rf.proj(segment_id2 = 'segment_id')) & 'segment_id1 < segment_id2'\n",
    "\n",
    "print(\"Number of significant receptive field neurons = \" + str(len(sig_units_rf)))\n",
    "\n",
    "rf_table = (spattune.BestSTACorr.proj(rf_corr_coef=\"union_corr_r2\",\n",
    "                          segment_a=\"segment_id1\",segment_b=\"segment_id2\")\n",
    "                          & sig_units_rf.proj(segment_a=\"segment_id\") &\n",
    "                          sig_units_rf.proj(segment_b=\"segment_id\"))\n",
    "print(\"Length of rf correlation = \" + str(len(rf_table)))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned = 'confidence > ' + str(ori_confidence)\n",
    "#get the significantly tuned segments\n",
    "sig_units_op = radtune.BestVonFit.Unit & 'von_p_value <= ' + str(von_p_value) & tuned & segment\n",
    "print(\"Number of significanlty orientationally tuned neurons = \" + str(len(sig_units_op)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets the significantly tuned neurons and their differences in combinational pairs \n",
    "sig_unit_pairs_op = (radtune.BestVonCorr() & sig_units_op.proj(segment_id1=\"segment_id\") \n",
    "                 & sig_units_op.proj(segment_id2=\"segment_id\")).proj(\"diff_pref_ori\")\n",
    "sig_unit_pairs_op = sig_unit_pairs_op.proj(segment_a=\"segment_id1\",\n",
    "                                           segment_b=\"segment_id2\",\n",
    "                                           dori=\"diff_pref_ori\")\n",
    "sig_unit_pairs_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checked correct number of pairwise\n",
    "n_units = 299\n",
    "(n_units)*(n_units-1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_units_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_ids, thetas, amps = sig_units_op.fetch(\"segment_id\",\"thetas\",\"amps\")\n",
    "direction_preference = [thetas[index][np.argmax(amps[index])] for index in range(0,len(thetas))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientation_preference = [k if k<np.pi else k - np.pi for k in direction_preference]\n",
    "len(orientation_preference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the soma centers and save offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinky.AllenSoma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_soma_center_cells = pinky.AllenSoma() & sig_units_op.proj() & \"cell_class='excitatory'\"\n",
    "tuned_soma_center_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_cell_data = tuned_soma_center_cells.fetch(as_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"orientation_center_data.npz\",soma_cell_data = soma_cell_data,\n",
    "         orientation_preference = orientation_preference,\n",
    "         seg_ids = seg_ids\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ********************load the data from local file******************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "\n",
    "orientation_center_data = np.load(\"orientation_center_data.npz\",allow_pickle=True)\n",
    "orientation_center_data.files\n",
    "soma_cell_data = orientation_center_data[\"soma_cell_data\"] #stores the soma id, segment_id and the x,y,z coordinates as well as the cell_class = excitatory\n",
    "orientation_preference = orientation_center_data[\"orientation_preference\"] #the orientation preferences in radians that correspond tot he \n",
    "seg_ids = orientation_center_data[\"seg_ids\"] #the segment ids for the orientation preferences\n",
    "\n",
    "#build a lookup dictionary for segment ids to orientation\n",
    "seg_id_to_orientation = dict([(seg_ids[k],orientation_preference[k]) for k in range(0,len(seg_ids))])\n",
    "#seg_id_to_orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where to start in offline version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attrs = ['segment_a', 'segment_b', 'connection', 'n_seg_shared']\n",
    "good_rf = 'mscore > 1.25'\n",
    "\n",
    "rf_bin_edges = np.linspace(-.7, .7, 6) #setting the bin boundaries\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Calculate the bins and centers for the orientational preference\n",
    "\"\"\"\n",
    "#defines how to find the \"tuned\" segments of the orientation\n",
    "dori_resolution = np.pi / 2 / 4 #setting the width size of the bins to be 22.5 degrees\n",
    "rad2deg = 180/np.pi\n",
    "bin_edges = np.linspace(0, np.pi,9) #creates 8 bins between boundaries between 0 and pi\n",
    "\n",
    "\n",
    "#sets the threshold for the \n",
    "stat_choice = [\"synapse_vol_density_pearson\"]\n",
    "\n",
    "ori_confidence=0.5\n",
    "von_p_value=0.05\n",
    "\n",
    "rf_bin_edges=rf_bin_edges\n",
    "ori_bin_edges=bin_edges\n",
    "n_seg_shared_threshold = 10\n",
    "n_seg_shared_converted_threshold = 10\n",
    "rf_threshold=1.45\n",
    "\n",
    "###Orientation\n",
    "rad2deg = 180/np.pi\n",
    "# turns all of the bin edges into degrees with no decimal\n",
    "be = list(['{:.0f}'.format(ee) for ee in [np.round(e * rad2deg) for e in ori_bin_edges]])\n",
    "#creates the bin boundary markings with [low - high]\n",
    "bin_labels = list(zip(be[:-1], be[1:]))\n",
    "\n",
    "#calculates the bin centers\n",
    "bin_centers = np.round((ori_bin_edges[1:] + ori_bin_edges[:-1])/2 * rad2deg, decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The cdiff computes the angle \n",
    "that the second angle has to move in order to meet\n",
    "up with the first angle\n",
    "\n",
    "Where if you have to move counterclockwise --> positive\n",
    "If you have to move clockwise --> negative\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pycircstat as pycs\n",
    "\n",
    "def center_angle(angle):\n",
    "    return (angle + np.pi) % (2*np.pi) - np.pi\n",
    "\n",
    "def cdiff(alpha, beta):\n",
    "    \"\"\"\n",
    "    Difference between pairs :math:`x_i-y_i` around the circle,\n",
    "    computed efficiently.\n",
    "    :param alpha:  sample of circular random variable\n",
    "    :param beta:   sample of circular random variable\n",
    "    :return: distance between the pairs\n",
    "    \"\"\"\n",
    "    return center_angle(alpha - beta)\n",
    "def cdiff_orientation(alpha,beta):\n",
    "    return center_angle(alpha*2 - beta*2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Testing out the circular functions\n",
    "\n",
    "functions that will be helpful to use from pycircstat: \n",
    "mean\n",
    "pairwise_cdiff\n",
    "cdiff: Difference between pairs\n",
    "(angle + np.pi) % (2*np.pi) - np.pi\n",
    "median\n",
    "\n",
    "\"\"\"\n",
    "# # get the circular angular difference between the two\n",
    "# segment_1_ori = orientation_preference[0]\n",
    "# segment_2_ori = orientation_preference[1]\n",
    "# segment_1_ori = 1.4\n",
    "# segment_2_ori = 1.39\n",
    "# cdiff_orientation(segment_1_ori,segment_2_ori)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Data (for the whole volume): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(20,20)) #2nd does the height\n",
    "# n_subplot = 4\n",
    "\n",
    "\n",
    "# \"\"\" horizontal implementation\"\"\"\n",
    "# currnet_subplot = 1\n",
    "# ax = plt.subplot(1,n_subplot,currnet_subplot)\n",
    "# currnet_subplot += 1\n",
    "# ax = plt.subplot(1,n_subplot,currnet_subplot)\n",
    "# currnet_subplot += 1\n",
    "# ax = plt.subplot(1,n_subplot,currnet_subplot)\n",
    "# currnet_subplot += 1\n",
    "# ax = plt.subplot(1,n_subplot,currnet_subplot)\n",
    "\n",
    "# \"\"\" vertical implementation\"\"\"\n",
    "# currnet_subplot = 1\n",
    "# ax = plt.subplot(n_subplot,1,currnet_subplot)\n",
    "# currnet_subplot += 1\n",
    "# ax = plt.subplot(n_subplot,1,currnet_subplot)\n",
    "# currnet_subplot += 1\n",
    "# ax = plt.subplot(n_subplot,1,currnet_subplot)\n",
    "# currnet_subplot += 1\n",
    "# ax = plt.subplot(n_subplot,1,currnet_subplot)\n",
    "\n",
    "# # g.set_yticklabels(['{}°-{}°'.format(*a) for a in bin_labels], rotation=0)\n",
    "# # #sets the rf labels and rotates them slightly\n",
    "# # g.set_xticklabels(cbin_labels, rotation=30)\n",
    "# # #inverts the y axis so that they are going up in value as graph goes up\n",
    "# # g.invert_yaxis()\n",
    "# # #sets no tick marks\n",
    "# # g.tick_params(length=0)\n",
    "# # #set labels\n",
    "# # g.set_xlabel(r'$\\rho$(RF$_1$, RF$_2$)')\n",
    "# # g.set_ylabel(r'$\\langle$Number of pairs in bin$\\rangle$')\n",
    "\n",
    "# # #Add title based on all the parameters\n",
    "\n",
    "# # # g.set_title('add title here')\n",
    "# # g.set_title('Number of pairs in bins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up bins for difference in prefered orientation\n",
    "n_bins = 20\n",
    "lower_bin_bound = 0\n",
    "upper_bin_bound = np.pi\n",
    "rad2deg = 180/np.pi\n",
    "ori_edges = np.linspace(lower_bin_bound, upper_bin_bound, n_bins+1)\n",
    "oe = list(['{:.0f}'.format(ee) for ee in [np.round(e * rad2deg) for e in ori_edges]])\n",
    "ori_labels = list(zip(oe[:-1], oe[1:]))\n",
    "ori_centers = np.round((ori_edges[1:] + ori_edges[:-1])/2 * rad2deg, decimals=2) \n",
    "print(\"ori_centers = \" + str(ori_centers))\n",
    "\n",
    "bin_centers = ori_centers\n",
    "ori_bin_edges=ori_edges\n",
    "binned_ori_preferences = bin_centers[(np.digitize(orientation_preference, ori_bin_edges))-1]\n",
    "raw_orientation_degrees = (np.array(orientation_preference)*rad2deg).astype(\"int\")\n",
    "\n",
    "#np.vstack([binned_ori_preferences.T,raw_orientation_degrees.T]).T\n",
    "#cdf['bdori'] = bin_centers[(np.digitize(np.abs(cdf[\"dori\"]), ori_bin_edges))-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For the whole volume: Gets all the bins of the orientation and how many neurons in each group\n",
    "\"\"\"\n",
    "\n",
    "from collections import Counter\n",
    "my_counter = Counter(binned_ori_preferences)\n",
    "#print(my_counter)\n",
    "binned_angles = np.array(list(my_counter.keys()))\n",
    "binned_angles_histogram = np.array(list(my_counter.values()))\n",
    "print(binned_angles,binned_angles_histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot as distribution of the orientations in the whole volume\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(binned_angles,binned_angles_histogram,width=rad2deg*(ori_edges[1]-ori_edges[0])-1)\n",
    "#plot as radians\n",
    "plt.figure()\n",
    "plt.bar(binned_angles/rad2deg,binned_angles_histogram,width=ori_edges[1]-ori_edges[0]-0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to get circular plots of the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visuallize the distribution of the orientation preferences in the volume on a circular plot\n",
    "https://stackoverflow.com/questions/22562364/circular-histogram-for-python\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_circular_distribution(theta,\n",
    "                               radii,\n",
    "                               width=-1,\n",
    "                               bottom = 8,\n",
    "                               max_height = 4):\n",
    "    N = len(radii)\n",
    "    #theta = np.linspace(0.0, 2 * np.pi, N, endpoint=False)\n",
    "    #radii = max_height*np.random.rand(N)\n",
    "    if width == -1:\n",
    "        width = (2*np.pi) / N\n",
    "\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "    bars = ax.bar(theta, radii, width=width, bottom=bottom)\n",
    "\n",
    "    # Use custom colors and opacity\n",
    "    for r, bar in zip(radii, bars):\n",
    "        bar.set_facecolor(plt.cm.jet(r / 10.))\n",
    "        bar.set_alpha(0.8)\n",
    "    #ax.set_yticks([0,45,90,135,180])\n",
    "    \"\"\"\n",
    "    ax.set_xticks(np.pi/180. * np.linspace(0,  180, 8, endpoint=False))\n",
    "    ax.set_thetalim(0,np.pi)\n",
    "    \"\"\"\n",
    "    ax.set_xticklabels(np.linspace(0,  180, 8, endpoint=False))\n",
    "    plt.show()\n",
    "\n",
    "#function will bin the data\n",
    "plot_circular_distribution(binned_angles/rad2deg*2,binned_angles_histogram,width=(ori_edges[1]-ori_edges[0])*2-0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the von misses fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from scipy.stats import vonmises\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "# kappa = 3.99\n",
    "# mean, var, skew, kurt = vonmises.stats(kappa, moments='mvsk')\n",
    "\n",
    "# x = np.linspace(vonmises.ppf(0.01, kappa),\n",
    "#                 vonmises.ppf(0.99, kappa), 100)\n",
    "# ax.plot(x, vonmises.pdf(x, kappa),\n",
    "#        'r-', lw=5, alpha=0.6, label='vonmises pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Step 2: Get distribution stats of the circular data --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"practices getting the circular statistics for orientation that only ranges from 0 - 180\"\"\"\n",
    "\n",
    "binned_ori_preferences \n",
    "doubled_orientation_preference = np.array(orientation_preference)*2\n",
    "np.max(doubled_orientation_preference),np.min(doubled_orientation_preference)\n",
    "\n",
    "\"\"\"mean\n",
    "pairwise_cdiff\n",
    "cdiff: Difference between pairs\n",
    "(angle + np.pi) % (2*np.pi) - np.pi\n",
    "median\n",
    "\"\"\"\n",
    "print(\"mean = \" + str(pycs.mean(doubled_orientation_preference)/2))\n",
    "print(\"variance = \" + str(pycs.var(doubled_orientation_preference)/4))\n",
    "print(\"std deviation = \" + str(pycs.std(doubled_orientation_preference)/2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding vector between soma ceneters and finding true distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Turns the downloaded table of soma data into a dictionary with the segment_id as the key\"\"\"\n",
    "soma_cell_data\n",
    "soma_cell_location_dict = dict([(k[\"segment_id\"],dict(location=np.array([k[\"soma_x\"],k[\"soma_y\"],k[\"soma_z\"]]),x_loc=k[\"soma_x\"],y_loc=k[\"soma_y\"],z_loc=k[\"soma_z\"])) for k in soma_cell_data])\n",
    "#soma_cell_location_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Demonstrates how to get the distance between the two somas\"\"\"\n",
    "seg_1 = 648518346341371119\n",
    "seg_2 = 648518346349470171\n",
    "location_1 = soma_cell_location_dict[seg_1][\"location\"]\n",
    "location_2 = soma_cell_location_dict[seg_2][\"location\"]\n",
    "print(location_1,location_2)\n",
    "print(np.linalg.norm(location_1-location_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"create a 2D array that has the distances between each cell pair\n",
    "Includes the:\n",
    "1) overall distance \n",
    "2) Distance along each axis\n",
    "\"\"\"\n",
    "from tqdm import tqdm\n",
    "\n",
    "soma_distance_array = dict()\n",
    "\n",
    "for seg_1 in tqdm(soma_cell_location_dict.keys()):\n",
    "    for seg_2 in soma_cell_location_dict.keys():\n",
    "        location_1 = soma_cell_location_dict[seg_1][\"location\"]\n",
    "        location_2 = soma_cell_location_dict[seg_2][\"location\"]\n",
    "        if seg_1 not in soma_distance_array.keys():\n",
    "            soma_distance_array[seg_1] = dict()\n",
    "        soma_distance_array[seg_1][seg_2] = dict(distance=np.linalg.norm(location_1-location_2),\n",
    "                                                 x_distance = location_1[0] - location_2[0], \n",
    "                                                 y_distance = location_1[1] - location_2[1], \n",
    "                                                 z_distance = location_1[2] - location_2[2])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Demonstrates how to get a subgroup that is either \n",
    "1) within a certian radius of target neuron\n",
    "2) within a specified column with the target neuron\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "target_neuron = 648518346341371119\n",
    "target_neuron_orientation_preferene = seg_id_to_orientation[target_neuron]\n",
    "\n",
    "\"\"\"\n",
    "Example of how to find neurons within a certain radius\n",
    "\"\"\"\n",
    "total_neurons_list = list(soma_cell_location_dict.keys())\n",
    "total_neurons_list.remove(target_neuron)\n",
    "\n",
    "circular_radius = 15000\n",
    "circular_radius_neurons = [k for k in total_neurons_list if abs(soma_distance_array[target_neuron][k][\"distance\"]) < circular_radius ]\n",
    "print(\"len(circular_radius_neurons) = \" + str(len(circular_radius_neurons)))\n",
    "\n",
    "\"\"\"\n",
    "Example of how to find neurons within z column\n",
    "\"\"\"\n",
    "\n",
    "box_width = 10000\n",
    "box_height = 2000\n",
    "width_axis = \"x_distance\"\n",
    "height_axis = \"y_distance\"\n",
    "\n",
    "column_neurons = [k for k in total_neurons_list if ((abs(soma_distance_array[target_neuron][k][width_axis]) < box_width)\n",
    "                                                                      and (abs(soma_distance_array[target_neuron][k][height_axis]) < box_height))]\n",
    "\n",
    "print(\"len(column_neurons) = \" + str(len(column_neurons)))\n",
    "print(column_neurons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get the orientation distribution and difference in orientation distributions for a target neuron and it's restricted neighbors\n",
    "\"\"\"\n",
    "global_neuron_group = total_neurons_list = list(soma_cell_location_dict.keys())\n",
    "print(\"global_neuron_group = \" + str(len(global_neuron_group)))\n",
    "restricted_neuron_group = circular_radius_neurons\n",
    "print(\"restricted_neuron_group = \" + str(len(restricted_neuron_group)))\n",
    "\n",
    "#get the orientations of these groups\n",
    "restricted_neuron_group_orientations = [seg_id_to_orientation[k] for k in restricted_neuron_group]\n",
    "\n",
    "global_neuron_group_orientations = [seg_id_to_orientation[k] for k in global_neuron_group]\n",
    "\n",
    "\n",
    "#send these orientations to be function that will display the linear and/or circular distribution and/or total distribution\n",
    "# Also want to compute and print out stats:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_orientation_data(orientation_preference,\n",
    "                         n_bins = 20,\n",
    "                        lower_bin_bound = 0,\n",
    "                         upper_bin_bound = np.pi):\n",
    "    \"\"\"\n",
    "    Functions that will do binning of data\n",
    "    Bases on the number of bins, lower bound and upper bound specified\n",
    "    \"\"\"\n",
    "    \n",
    "    rad2deg = 180/np.pi\n",
    "    ori_edges = np.linspace(lower_bin_bound, upper_bin_bound, n_bins+1)\n",
    "    oe = list(['{:.0f}'.format(ee) for ee in [np.round(e * rad2deg) for e in ori_edges]])\n",
    "    ori_labels = list(zip(oe[:-1], oe[1:]))\n",
    "    ori_centers = np.round((ori_edges[1:] + ori_edges[:-1])/2 * rad2deg, decimals=2) \n",
    "\n",
    "    bin_centers = ori_centers\n",
    "    ori_bin_edges=ori_edges\n",
    "    binned_ori_preferences = bin_centers[(np.digitize(orientation_preference, ori_bin_edges))-1]\n",
    "    raw_orientation_degrees = (np.array(orientation_preference)*rad2deg).astype(\"int\")\n",
    "    \n",
    "    from collections import Counter\n",
    "    my_counter = Counter(binned_ori_preferences)\n",
    "    #print(my_counter)\n",
    "    binned_angles = np.array(list(my_counter.keys()))\n",
    "    binned_angles_histogram = np.array(list(my_counter.values()))\n",
    "    \n",
    "    return binned_angles,binned_angles_histogram\n",
    "\n",
    "def plot_circular_distribution_lite(theta,\n",
    "                               radii,\n",
    "                                    ax,\n",
    "                                    n_bins,\n",
    "                               width=-1,\n",
    "                               bottom = 8):\n",
    "    \n",
    "    \"\"\"\n",
    "    will plot the circulation distribution given the \n",
    "    1) theta (x values)\n",
    "    2) radii (y values)\n",
    "    \n",
    "    Other parameters passed: \n",
    "    0) axis to plot it on\n",
    "    1) number of bins that could possibly be plotted\n",
    "    \n",
    "    optional\n",
    "    1) Width of each of the bins (else it is calculated)\n",
    "    2) bottom: The offset where the histogram starts\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    N = n_bins\n",
    "    \n",
    "    if width == -1:\n",
    "        width = (2*np.pi) / N\n",
    "\n",
    "    #ax = plt.subplot(111, polar=True)\n",
    "    bars = ax.bar(theta, radii, width=width, bottom=bottom)\n",
    "\n",
    "    # Use custom colors and opacity\n",
    "    for r, bar in zip(radii, bars):\n",
    "        bar.set_facecolor(plt.cm.jet(r / 10.))\n",
    "        bar.set_alpha(0.8)\n",
    "    #ax.set_yticks([0,45,90,135,180])\n",
    "    \"\"\"\n",
    "    ax.set_xticks(np.pi/180. * np.linspace(0,  180, 8, endpoint=False))\n",
    "    ax.set_thetalim(0,np.pi)\n",
    "    \"\"\"\n",
    "    ax.set_xticklabels(np.linspace(0,  180, 8, endpoint=False))\n",
    "    #plt.show()\n",
    "\n",
    "def graph_binned_orientation_data(binned_angles,\n",
    "                                binned_angles_histogram,\n",
    "                                  neuron_id,\n",
    "                                  title,\n",
    "                                  n_bins,\n",
    "                                  global_binned_angles = [],\n",
    "                                global_binned_angles_histogram= [],\n",
    "                                 graphs_to_plot=[],\n",
    "                                  figure_size = (20,20),\n",
    "                                 circular_flag = True,\n",
    "                                 target_neuron_orientation = -1,\n",
    "                                 target_color=\"y\"):\n",
    "    \"\"\"\n",
    "    Will graph the linear/circular or both of the distribution of a certain group\n",
    "    1) Will graph just the local group or global group alone if only\n",
    "    \"local\" or \"global\" sent in graph to plot\n",
    "    \n",
    "    And then highlight the target neuron's orientation \n",
    "    \"\"\"\n",
    "    \n",
    "    axis_label_size=20\n",
    "    tick_label_size = 20\n",
    "    title_size=30\n",
    "    \n",
    "    # if circular plots were also requested then adjust overall size\n",
    "    if circular_flag:\n",
    "        n_subplot = 2*len(graphs_to_plot)\n",
    "    else:\n",
    "        n_subplot = len(graphs_to_plot)\n",
    "    \n",
    "    width_size = 5\n",
    "    #print(\"n_subplot = \" + str(n_subplot))\n",
    "    currnet_subplot = 1\n",
    "    fig = plt.figure(figsize=(figure_size[0],figure_size[1]*len(graphs_to_plot)))\n",
    "    fig.tight_layout()\n",
    "    #fig.set_size_inches(20, 12)\n",
    "    if \"local\" in graphs_to_plot:\n",
    "        \n",
    "        if circular_flag:\n",
    "            ax = plt.subplot(n_subplot,2,currnet_subplot)\n",
    "            #graphing the linear graph\n",
    "            plt.bar(binned_angles,binned_angles_histogram,width=width_size)\n",
    "            if target_neuron_orientation != -1:\n",
    "                plt.bar(target_neuron_orientation,[0.5],width=width_size,color=target_color)\n",
    "#                 print(\" target_neuron_orientation[0] = \" + str( target_neuron_orientation[0]))\n",
    "#                 print(\"binned_angles = \" + str(binned_angles))\n",
    "#                 angle_index = np.where(binned_angles == target_neuron_orientation[0])[0]\n",
    "#                 if len(angle_index) == 0:\n",
    "#                     target_neuron_height = 0.5\n",
    "#                 else:\n",
    "#                     target_neuron_height = binned_angles_histogram[angle_index]\n",
    "#                 print(\"angle_index = \" + str(angle_index))\n",
    "#                 print(\"target_neuron_orientation/rad2deg = \" + str(target_neuron_orientation/rad2deg))\n",
    "#                 print(\"[target_neuron_height] =  \" + str([target_neuron_height]))\n",
    "#                 plt.bar(target_neuron_orientation/rad2deg,[target_neuron_height],width=width_size,color=target_color)\n",
    "                #             ax.set(\n",
    "#                    title=title + \"_linear\",\n",
    "#                    ylabel='Number of Neurons',\n",
    "#                    xlabel='Radians',\n",
    "#                     titlesize=20,\n",
    "#                     labelsize=20)\n",
    "            ax.set_title(title+\"_linear\",fontsize=title_size)\n",
    "            ax.set_xlabel(\"Degrees\",fontsize=axis_label_size)\n",
    "            ax.set_ylabel('Number of Neurons',fontsize=axis_label_size)\n",
    "            ax.tick_params(axis=\"both\",which=\"major\",labelsize=tick_label_size)\n",
    "            \n",
    "            #graphing the circular graph\n",
    "            ax = plt.subplot(n_subplot,2,currnet_subplot+1,polar=True)\n",
    "            plot_circular_distribution_lite(binned_angles/rad2deg*2,\n",
    "                                            binned_angles_histogram,\n",
    "                                            ax,\n",
    "                                           n_bins)\n",
    "            \n",
    "#             ax.set(\n",
    "#                    title=title + \"_circular\",\n",
    "#                    ylabel='Number of Neurons',\n",
    "#                    xlabel='Degrees',\n",
    "#                     titlesize=20,\n",
    "#                     labelsize=20)\n",
    "            ax.set_title(title+\"_circular\",fontsize=title_size)\n",
    "            ax.set_xlabel(\"Degrees\",fontsize=axis_label_size)\n",
    "            ax.set_ylabel('Number of Neurons',fontsize=axis_label_size)\n",
    "            ax.tick_params(axis=\"both\",which=\"major\",labelsize=tick_label_size)\n",
    "#             ax.set_xticklabels(ax.get_xticklabels(),fontsize=tick_label_size)\n",
    "#             ax.set_yticklabels(ax.get_yticklabels(),fontsize=tick_label_size)\n",
    "            \n",
    "            #increment the current_subplot\n",
    "            currnet_subplot += 2\n",
    "        else:\n",
    "            ax = plt.subplot(n_subplot,1,currnet_subplot)\n",
    "            #graphing the linear graph\n",
    "            plt.bar(binned_angles,binned_angles_histogram,width=width_size)\n",
    "            if target_neuron_orientation != -1:\n",
    "                plt.bar(target_neuron_orientation,[0.5],width=width_size,color=target_color)\n",
    "#             ax.set(\n",
    "#                    title=title + \"_linear\",\n",
    "#                    ylabel='Number of Neurons',\n",
    "#                    xlabel='Radians',\n",
    "#                     titlesize=20,\n",
    "#                     labelsize=20)\n",
    "            ax.set_title(title+\"_linear\",fontsize=title_size)\n",
    "            ax.set_xlabel(\"Degrees\",fontsize=axis_label_size)\n",
    "            ax.set_ylabel('Number of Neurons',fontsize=axis_label_size)\n",
    "            ax.tick_params(axis=\"both\",which=\"major\",labelsize=tick_label_size)\n",
    "            #increment the current_subplot\n",
    "            currnet_subplot += 1\n",
    "    \n",
    "    print(\"\\n\\n\\n\")\n",
    "    if \"global\" in graphs_to_plot:\n",
    "        binned_angles = global_binned_angles\n",
    "        binned_angles_histogram =  global_binned_angles_histogram\n",
    "        if circular_flag:\n",
    "            ax = plt.subplot(n_subplot,2,currnet_subplot)\n",
    "            #graphing the linear graph\n",
    "            plt.bar(binned_angles,binned_angles_histogram,width=width_size)\n",
    "            \n",
    "#             ax.set(\n",
    "#                    title=title + \"_linear\",\n",
    "#                    ylabel='Number of Neurons',\n",
    "#                    xlabel='Radians',\n",
    "#                     titlesize=20,\n",
    "#                     labelsize=20)\n",
    "            ax.set_title(title+\"_global_linear\",fontsize=title_size)\n",
    "            ax.set_xlabel(\"Degrees\",fontsize=axis_label_size)\n",
    "            ax.set_ylabel('Number of Neurons',fontsize=axis_label_size)\n",
    "            ax.tick_params(axis=\"both\",which=\"major\",labelsize=tick_label_size)\n",
    "            \n",
    "            #graphing the circular graph\n",
    "            ax = plt.subplot(n_subplot,2,currnet_subplot+1,polar=True)\n",
    "            plot_circular_distribution_lite(binned_angles/rad2deg*2,\n",
    "                                            binned_angles_histogram,\n",
    "                                            ax,n_bins)\n",
    "            \n",
    "#             ax.set(\n",
    "#                    title=title + \"_circular\",\n",
    "#                    ylabel='Number of Neurons',\n",
    "#                    xlabel='Degrees',\n",
    "#                     titlesize=20,\n",
    "#                     labelsize=20)\n",
    "            ax.set_title(title+\"_global_circular\",fontsize=title_size)\n",
    "            ax.set_xlabel(\"Degrees\",fontsize=axis_label_size)\n",
    "            ax.set_ylabel('Number of Neurons',fontsize=axis_label_size)\n",
    "            ax.tick_params(axis=\"both\",which=\"major\",labelsize=tick_label_size)\n",
    "#             ax.set_xticklabels(ax.get_xticklabels(),fontsize=tick_label_size)\n",
    "#             ax.set_yticklabels(ax.get_yticklabels(),fontsize=tick_label_size)\n",
    "            \n",
    "            #increment the current_subplot\n",
    "            currnet_subplot += 2\n",
    "        else:\n",
    "            ax = plt.subplot(n_subplot,1,currnet_subplot)\n",
    "            #graphing the linear graph\n",
    "            plt.bar(binned_angles,binned_angles_histogram,width=width_size)\n",
    "            \n",
    "#             ax.set(\n",
    "#                    title=title + \"_linear\",\n",
    "#                    ylabel='Number of Neurons',\n",
    "#                    xlabel='Radians',\n",
    "#                     titlesize=20,\n",
    "#                     labelsize=20)\n",
    "            ax.set_title(title+\"_global\",fontsize=title_size)\n",
    "            ax.set_xlabel(\"Degrees\",fontsize=axis_label_size)\n",
    "            ax.set_ylabel('Number of Neurons',fontsize=axis_label_size)\n",
    "            ax.tick_params(axis=\"both\",which=\"major\",labelsize=tick_label_size)\n",
    "            #increment the current_subplot\n",
    "            currnet_subplot += 1\n",
    "    left = 0.125\n",
    "    right = 0.9\n",
    "    bottom = 0.1\n",
    "    top = 0.9\n",
    "    wspace = 0.2\n",
    "    hspace = 0.5\n",
    "    fig.subplots_adjust(left=left,bottom=bottom,right=right,\n",
    "                       top=top,wspace=wspace,hspace=hspace)\n",
    "\n",
    "binned_angles,binned_angles_histogram = bin_orientation_data(orientation_preference,\n",
    "                                                         n_bins = 20,\n",
    "                                                        lower_bin_bound = 0,\n",
    "                                                         upper_bin_bound = np.pi)\n",
    "\n",
    "# graph_binned_orientation_data(binned_angles,\n",
    "#                                 binned_angles_histogram,\n",
    "#                                   neuron_id=45,\n",
    "#                               n_bins=20,\n",
    "#                                   title=\"example_type\",\n",
    "#                               global_binned_angles = binned_angles,\n",
    "#                                 global_binned_angles_histogram= binned_angles_histogram,\n",
    "#                                  graphs_to_plot=[\"local\",\"global\"],\n",
    "#                                  figure_size = (20,20),\n",
    "#                                  circular_flag = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_n_bins = 20\n",
    "current_lower_bin_bound = 0\n",
    "current_upper_bin_bound = np.pi\n",
    "\n",
    "binned_angles,binned_angles_histogram = bin_orientation_data(restricted_neuron_group_orientations,\n",
    "                                                         n_bins = current_n_bins,\n",
    "                                                        lower_bin_bound = current_lower_bin_bound,\n",
    "                                                         upper_bin_bound = current_upper_bin_bound)\n",
    "\n",
    "global_binned_angles,global_binned_angles_histogram = bin_orientation_data(global_neuron_group_orientations,\n",
    "                                                         n_bins = current_n_bins,\n",
    "                                                        lower_bin_bound = current_lower_bin_bound,\n",
    "                                                         upper_bin_bound = current_upper_bin_bound)\n",
    "\n",
    "#for getting the binning of the target neuron\n",
    "interest_binned_angles,interest_binned_angles_histogram = bin_orientation_data([target_neuron_orientation_preferene],\n",
    "                                                        n_bins = current_n_bins,\n",
    "                                                        lower_bin_bound = current_lower_bin_bound,\n",
    "                                                         upper_bin_bound = current_upper_bin_bound)\n",
    "\n",
    "print(interest_binned_angles)\n",
    "\n",
    "#gets the plots of the both the global and the subgroup while highlighting the neuron of interest\n",
    "# plots both linear and circular\n",
    "\n",
    "graph_binned_orientation_data(binned_angles,\n",
    "                                binned_angles_histogram,\n",
    "                                  neuron_id=45,\n",
    "                                  title=\"example_type\",\n",
    "                              n_bins=current_n_bins,\n",
    "                              global_binned_angles = global_binned_angles,\n",
    "                                global_binned_angles_histogram= global_binned_angles_histogram,\n",
    "                                 graphs_to_plot=[\"local\",\"global\"],\n",
    "                                 figure_size = (20,20),\n",
    "                                 circular_flag = True,\n",
    "                                 target_neuron_orientation = interest_binned_angles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find good column and radius "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circular_radius = 1000\n",
    "\n",
    "box_width = 1000\n",
    "\n",
    "suitable_number_threshold = 10\n",
    "total_neurons_in_cluster = []\n",
    "\n",
    "suitable_number = False\n",
    "while suitable_number == False:\n",
    "    for target_neuron in list(soma_cell_location_dict.keys()):\n",
    "        target_neuron_orientation_preferene = seg_id_to_orientation[target_neuron]\n",
    "        \"\"\"\n",
    "        Example of how to find neurons within a certain radius\n",
    "        \"\"\"\n",
    "        total_neurons_list = list(soma_cell_location_dict.keys())\n",
    "        total_neurons_list.remove(target_neuron)\n",
    "\n",
    "        circular_radius_neurons = [k for k in total_neurons_list if soma_distance_array[target_neuron][k][\"distance\"] < circular_radius ]\n",
    "        #print(\"len(circular_radius_neurons) = \" + str(len(circular_radius_neurons)))\n",
    "        total_neurons_in_cluster.append(len(circular_radius_neurons))\n",
    "\n",
    "        \"\"\"\n",
    "        Example of how to find neurons within x column\n",
    "        \"\"\"\n",
    "    # evaluate if enough neurons in each cluster (if 90 percent have 10 or more)\n",
    "    percentage_above_threshold = np.sum(np.array(total_neurons_in_cluster) >= suitable_number_threshold)/len(total_neurons_in_cluster)\n",
    "    if percentage_above_threshold >= 0.9:\n",
    "        suitable_number = True\n",
    "    else:\n",
    "        circular_radius += 100\n",
    "        total_neurons_in_cluster = []\n",
    "        \n",
    "    \n",
    "print(\"total_neurons_in_cluster = \" + str(total_neurons_in_cluster))\n",
    "print(\"Final circular_radius for circular  = \" + str(circular_radius))\n",
    "\n",
    "\"\"\"\n",
    "Final size: suitable number would be 15000\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "suitable_number_threshold = 10\n",
    "box_width = 1000\n",
    "width_axis = \"x_distance\"\n",
    "height_axis = \"y_distance\"\n",
    "\n",
    "total_neurons_in_cluster = []\n",
    "\n",
    "suitable_number = False\n",
    "while suitable_number == False:\n",
    "    for target_neuron in list(soma_cell_location_dict.keys()):\n",
    "        target_neuron_orientation_preferene = seg_id_to_orientation[target_neuron]\n",
    "        \"\"\"\n",
    "        Example of how to find neurons within a certain radius\n",
    "        \"\"\"\n",
    "        total_neurons_list = list(soma_cell_location_dict.keys())\n",
    "        total_neurons_list.remove(target_neuron)\n",
    "\n",
    "        column_neurons = [k for k in total_neurons_list if ((abs(soma_distance_array[target_neuron][k][width_axis]) < box_width)\n",
    "                                                                      and (abs(soma_distance_array[target_neuron][k][height_axis]) < box_width))]\n",
    "        #print(\"len(circular_radius_neurons) = \" + str(len(circular_radius_neurons)))\n",
    "        total_neurons_in_cluster.append(len(column_neurons))\n",
    "\n",
    "        \"\"\"\n",
    "        Example of how to find neurons within x column\n",
    "        \"\"\"\n",
    "    # evaluate if enough neurons in each cluster (if 90 percent have 10 or more)\n",
    "    percentage_above_threshold = np.sum(np.array(total_neurons_in_cluster) >= suitable_number_threshold)/len(total_neurons_in_cluster)\n",
    "    if percentage_above_threshold >= 0.9:\n",
    "        suitable_number = True\n",
    "    else:\n",
    "        box_width += 50\n",
    "        total_neurons_in_cluster = []\n",
    "\n",
    "#print the suitable threshold\n",
    "print(\"total_neurons_in_cluster Z AXIS = \" + str(total_neurons_in_cluster))\n",
    "print(\"Final box_width for circular  Z AXIS = \" + str(box_width))\n",
    "\n",
    "suitable_number_threshold = 10\n",
    "box_width = 1000\n",
    "width_axis = \"y_distance\"\n",
    "height_axis = \"z_distance\"\n",
    "\n",
    "total_neurons_in_cluster = []\n",
    "\n",
    "suitable_number = False\n",
    "while suitable_number == False:\n",
    "    for target_neuron in list(soma_cell_location_dict.keys()):\n",
    "        target_neuron_orientation_preferene = seg_id_to_orientation[target_neuron]\n",
    "        \"\"\"\n",
    "        Example of how to find neurons within a certain radius\n",
    "        \"\"\"\n",
    "        total_neurons_list = list(soma_cell_location_dict.keys())\n",
    "        total_neurons_list.remove(target_neuron)\n",
    "\n",
    "        column_neurons = [k for k in total_neurons_list if ((abs(soma_distance_array[target_neuron][k][width_axis]) < box_width)\n",
    "                                                                      and (abs(soma_distance_array[target_neuron][k][height_axis]) < box_width))]\n",
    "        #print(\"len(circular_radius_neurons) = \" + str(len(circular_radius_neurons)))\n",
    "        total_neurons_in_cluster.append(len(column_neurons))\n",
    "\n",
    "        \"\"\"\n",
    "        Example of how to find neurons within x column\n",
    "        \"\"\"\n",
    "    # evaluate if enough neurons in each cluster (if 90 percent have 10 or more)\n",
    "    percentage_above_threshold = np.sum(np.array(total_neurons_in_cluster) >= suitable_number_threshold)/len(total_neurons_in_cluster)\n",
    "    if percentage_above_threshold >= 0.9:\n",
    "        suitable_number = True\n",
    "    else:\n",
    "        box_width += 50\n",
    "        total_neurons_in_cluster = []\n",
    "\n",
    "#print the suitable threshold\n",
    "print(\"total_neurons_in_cluster X AXIS = \" + str(total_neurons_in_cluster))\n",
    "print(\"Final box_width for circular  X AXIS = \" + str(box_width))\n",
    "\n",
    "suitable_number_threshold = 10\n",
    "box_width = 1000\n",
    "width_axis = \"x_distance\"\n",
    "height_axis = \"z_distance\"\n",
    "\n",
    "total_neurons_in_cluster = []\n",
    "\n",
    "suitable_number = False\n",
    "while suitable_number == False:\n",
    "    for target_neuron in list(soma_cell_location_dict.keys()):\n",
    "        target_neuron_orientation_preferene = seg_id_to_orientation[target_neuron]\n",
    "        \"\"\"\n",
    "        Example of how to find neurons within a certain radius\n",
    "        \"\"\"\n",
    "        total_neurons_list = list(soma_cell_location_dict.keys())\n",
    "        total_neurons_list.remove(target_neuron)\n",
    "\n",
    "        column_neurons = [k for k in total_neurons_list if ((abs(soma_distance_array[target_neuron][k][width_axis]) < box_width)\n",
    "                                                                      and (abs(soma_distance_array[target_neuron][k][height_axis]) < box_width))]\n",
    "        #print(\"len(circular_radius_neurons) = \" + str(len(circular_radius_neurons)))\n",
    "        total_neurons_in_cluster.append(len(column_neurons))\n",
    "\n",
    "        \"\"\"\n",
    "        Example of how to find neurons within x column\n",
    "        \"\"\"\n",
    "    # evaluate if enough neurons in each cluster (if 90 percent have 10 or more)\n",
    "    percentage_above_threshold = np.sum(np.array(total_neurons_in_cluster) >= suitable_number_threshold)/len(total_neurons_in_cluster)\n",
    "    if percentage_above_threshold >= 0.9:\n",
    "        suitable_number = True\n",
    "    else:\n",
    "        box_width += 50\n",
    "        total_neurons_in_cluster = []\n",
    "\n",
    "#print the suitable threshold\n",
    "print(\"total_neurons_in_cluster Y AXIS = \" + str(total_neurons_in_cluster))\n",
    "print(\"Final box_width for circular  Y AXIS = \" + str(box_width))\n",
    "\n",
    "\n",
    "\n",
    "# column_neurons = [k for k in total_neurons_list if ((abs(soma_distance_array[target_neuron][k][width_axis]) < box_width)\n",
    "#                                                                       and (abs(soma_distance_array[target_neuron][k][height_axis]) < box_width))]\n",
    "\n",
    "# # print(\"len(column_neurons) = \" + str(len(column_neurons)))\n",
    "# # print(column_neurons)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the average size of the somas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_neurons = pinky.ProofreadLabel & [dict(segment_id=k) for k in list(soma_cell_location_dict.keys())]\n",
    "labels_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinky.PymeshfixDecimatedExcitatoryStitchedMesh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#current_id = 648518346349470171\n",
    "search_dict = dict(segment_id=current_id,segmentation=3)\n",
    "\n",
    "from tqdm import tqdm\n",
    "soma_bounding_box_widths_total = []\n",
    "\n",
    "for current_id in tqdm(list(soma_cell_location_dict.keys())):\n",
    "    search_dict = dict(segment_id=current_id,segmentation=3)\n",
    "    #getting the face labels so can find soma submesh\n",
    "    faces_labels = (labels_neurons & search_dict).fetch1(\"triangles\")\n",
    "    #print(len(faces_labels))\n",
    "    soma_faces = np.where(faces_labels==5)[0]\n",
    "    if len(soma_faces)>0:\n",
    "        #getting the mesh to use for submesh\n",
    "        verts,faces = (pinky.PymeshfixDecimatedExcitatoryStitchedMesh & search_dict).fetch1(\"vertices\",\"triangles\")\n",
    "        #print(\"len(faces) = \" + str(len(faces)))\n",
    "        #print(\"len(verts) = \" + str(len(verts)))\n",
    "\n",
    "        #build the mesh and get the soma submesh:\n",
    "        import trimesh\n",
    "        current_neuron_mesh = trimesh.Trimesh(vertices=verts,faces=faces)\n",
    "        soma_mesh = current_neuron_mesh.submesh([soma_faces],append=True)\n",
    "\n",
    "        #soma_mesh.show()\n",
    "        #get the bounding box dimensions of the soma:\n",
    "        soma_bounding_box_corners = np.stack([np.min(soma_mesh.bounding_box.vertices,axis=0),\n",
    "                    np.max(soma_mesh.bounding_box.vertices,axis=0)])\n",
    "\n",
    "        soma_bounding_box_widths = soma_bounding_box_corners[1]-soma_bounding_box_corners[0]\n",
    "        #print(\"soma_bounding_box_widths = \" + str(soma_bounding_box_widths))\n",
    "        soma_bounding_box_widths_total.append(soma_bounding_box_widths)\n",
    "\n",
    "soma_bounding_box_widths_total = np.array(soma_bounding_box_widths_total)\n",
    "print(soma_bounding_box_widths_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average x, y, z width for somas = \" + str(np.mean(soma_bounding_box_widths_total,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Result: \" + str(\"Average x, y, z width for somas = [16921.20080236 16743.62922297 13732.73280046]\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Start Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Final conclusion\n",
    "going to use 13000 as the width size: which is about the area of 4 somas arranged in square\n",
    "--- because the width is an absolute value ---\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_binned_angles,target_neuron_orientation_preferene*rad2deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions that will find the subgroup:\n",
    "\n",
    "def find_column_subgroup(width_axis ,\n",
    "                         height_axis,\n",
    "                        target_neuron,\n",
    "                        total_neurons_list,\n",
    "                        box_width=13000,\n",
    "                         box_height=13000,):\n",
    "    \"\"\"\n",
    "    Returns the list of ids for neurons in a column\n",
    "    Speicifed by the parameters\n",
    "    \"\"\"\n",
    "    column_neurons = [k for k in total_neurons_list if ((abs(soma_distance_array[target_neuron][k][width_axis]) < box_width))]\n",
    "    return column_neurons\n",
    "\n",
    "def find_radius_subgroup(target_neuron,\n",
    "                        total_neurons_list,\n",
    "                        circular_radius=15000):\n",
    "    \"\"\"\n",
    "    Returns the list of ids for neurons in a column\n",
    "    Speicifed by the parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    circular_radius_neurons = [k for k in total_neurons_list if soma_distance_array[target_neuron][k][\"distance\"] < circular_radius ]\n",
    "    return circular_radius_neurons\n",
    "                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Shows whole process of where start with a \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#\n",
    "target_neuron = 648518346341371119\n",
    "target_neuron_orientation_preferene = seg_id_to_orientation[target_neuron]\n",
    "\n",
    "\"\"\"\n",
    "Example of how to find neurons within a certain radius\n",
    "\"\"\"\n",
    "total_neurons_list = list(soma_cell_location_dict.keys())\n",
    "total_neurons_list.remove(target_neuron)\n",
    "\n",
    "circular_radius = 15000 #test 1\n",
    "circular_radius_neurons = [k for k in total_neurons_list if soma_distance_array[target_neuron][k][\"distance\"] < circular_radius ]\n",
    "print(\"len(circular_radius_neurons) = \" + str(len(circular_radius_neurons)))\n",
    "\n",
    "\"\"\"\n",
    "Example of how to find neurons within x column\n",
    "\"\"\"\n",
    "\n",
    "box_width = 13000\n",
    "box_height = 13000\n",
    "width_axis = \"x_distance\"\n",
    "height_axis = \"z_distance\"\n",
    "\n",
    "column_neurons = [k for k in total_neurons_list if ((abs(soma_distance_array[target_neuron][k][width_axis]) < box_width)\n",
    "                                                                      and (abs(soma_distance_array[target_neuron][k][height_axis]) < box_height))]\n",
    "\n",
    "print(\"len(column_neurons) = \" + str(len(column_neurons)))\n",
    "print(column_neurons)\n",
    "\n",
    "\"\"\"\n",
    "Get the orientation distribution and difference in orientation distributions for a target neuron and it's restricted neighbors\n",
    "\n",
    "This example shows the circular_radius_neurons\n",
    "\"\"\"\n",
    "global_neuron_group = total_neurons_list = list(soma_cell_location_dict.keys())\n",
    "print(\"global_neuron_group = \" + str(len(global_neuron_group)))\n",
    "restricted_neuron_group = circular_radius_neurons\n",
    "print(\"restricted_neuron_group = \" + str(len(restricted_neuron_group)))\n",
    "\n",
    "#get the orientations of these groups\n",
    "restricted_neuron_group_orientations = [seg_id_to_orientation[k] for k in restricted_neuron_group] #NOT INCLUDE TARGET NEURON\n",
    "\n",
    "global_neuron_group_orientations = [seg_id_to_orientation[k] for k in global_neuron_group] # DOES INCLUDE TARGET NEURON\n",
    "\n",
    "\n",
    "current_n_bins = 20\n",
    "current_lower_bin_bound = 0\n",
    "current_upper_bin_bound = np.pi\n",
    "\n",
    "binned_angles,binned_angles_histogram = bin_orientation_data(restricted_neuron_group_orientations,\n",
    "                                                         n_bins = current_n_bins,\n",
    "                                                        lower_bin_bound = current_lower_bin_bound,\n",
    "                                                         upper_bin_bound = current_upper_bin_bound)\n",
    "\n",
    "global_binned_angles,global_binned_angles_histogram = bin_orientation_data(global_neuron_group_orientations,\n",
    "                                                         n_bins = current_n_bins,\n",
    "                                                        lower_bin_bound = current_lower_bin_bound,\n",
    "                                                         upper_bin_bound = current_upper_bin_bound)\n",
    "\n",
    "interest_binned_angles,interest_binned_angles_histogram = bin_orientation_data([target_neuron_orientation_preferene],\n",
    "                                                        n_bins = current_n_bins,\n",
    "                                                        lower_bin_bound = current_lower_bin_bound,\n",
    "                                                         upper_bin_bound = current_upper_bin_bound)\n",
    "\n",
    "#print(interest_binned_angles)\n",
    "\n",
    "graph_binned_orientation_data(binned_angles,\n",
    "                                binned_angles_histogram,\n",
    "                                  neuron_id=target_neuron,\n",
    "                                  title=\"y_column_\"+str(box_width),\n",
    "                              n_bins=current_n_bins,\n",
    "                              global_binned_angles = global_binned_angles,\n",
    "                                global_binned_angles_histogram= global_binned_angles_histogram,\n",
    "                                 graphs_to_plot=[\"local\",\"global\"],\n",
    "                                 figure_size = (20,20),\n",
    "                                 circular_flag = True,\n",
    "                                 target_neuron_orientation = interest_binned_angles)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original volume dimensions\n",
    "x_box = 250000\n",
    "y_box = 140000\n",
    "z_box = 90000\n",
    "\n",
    "\n",
    "# test 2 (more strict to try and keep around 10 neurons for at least 90 %)\n",
    "y_width = y_height = 6600\n",
    "z_width = z_height = 11900\n",
    "x_width = x_height = 2850\n",
    "circular_radius = 13700\n",
    "\n",
    "# calculate the total volume for certain parameters\n",
    "y_col_volume = (2*y_width) * (2*y_height) * y_box\n",
    "x_col_volume = (2*x_width) * (2*x_height) * x_box\n",
    "z_col_volume = (2*z_width) * (2*z_height) * z_box\n",
    "sphere_volume = 4.0/3.0*np.pi*(circular_radius**3)\n",
    "\n",
    "print(f\"y_col_volume = {y_col_volume} \\\n",
    "\\nx_col_volume = {x_col_volume}\\\n",
    "\\nz_col_volume = {z_col_volume}\\\n",
    "\\nsphere_volume = {sphere_volume}\")\n",
    "\n",
    "\n",
    "print(\"\\n\\nThe relative scaling\")\n",
    "print(f\"y_col_volume = {y_col_volume/sphere_volume} \\\n",
    "\\nx_col_volume = {x_col_volume/sphere_volume}\\\n",
    "\\nz_col_volume = {z_col_volume/sphere_volume}\\\n",
    "\\nsphere_volume = {sphere_volume/sphere_volume}\")\n",
    "\n",
    "# find scaling factors to make everyone the same volume\n",
    "def get_extra_width(final_volume,current_height,current_width):\n",
    "    extra_width = np.sqrt((final_volume)/current_height)/2 - current_width\n",
    "    return extra_width\n",
    "#     if extra_width < 0:\n",
    "#         return - np.sqrt(np.abs(extra_width))\n",
    "#     else:\n",
    "#         return np.sqrt(np.abs(extra_width))\n",
    "    \n",
    "\n",
    "y_extra_width = get_extra_width(sphere_volume,y_box,y_width)\n",
    "#check that the height will now be the same\n",
    "y_new_width = y_width + y_extra_width\n",
    "\n",
    "\n",
    "x_extra_width = get_extra_width(sphere_volume,x_box,x_width)\n",
    "#check that the height will now be the same\n",
    "x_new_width = x_width + x_extra_width\n",
    "\n",
    "z_extra_width = get_extra_width(sphere_volume,z_box,z_width)\n",
    "#check that the height will now be the same\n",
    "z_new_width = z_width + z_extra_width\n",
    "\n",
    "\"\"\"\n",
    "4*w*h*box + 8*extra*h*ybox + 4*extra^2*y_box = new_volume\n",
    "8*extra*width + 4*extra**2 = (new_volum - current_volume)/y_box\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n New volume scales\")\n",
    "y_col_volume_new = (2*y_new_width) * (2*y_new_width) * y_box\n",
    "z_col_volume_new = (2*z_new_width) * (2*z_new_width) * z_box\n",
    "x_col_volume_new = (2*x_new_width) * (2*x_new_width) * x_box\n",
    "print(y_col_volume_new/sphere_volume,z_col_volume_new/sphere_volume,x_col_volume_new/sphere_volume)\n",
    "\n",
    "print(\"\\n New widths for exact same volume\")\n",
    "print(\"y_new_width = \" + str(y_new_width))\n",
    "print(\"z_new_width = \" + str(z_new_width))\n",
    "print(\"x_new_width = \" + str(x_new_width))\n",
    "\n",
    "# How could we add different scaling to make sure holds true\n",
    "scale_factor = 2\n",
    "circular_radius_scaled = (scale_factor**(1/3))*circular_radius\n",
    "y_new_width_scaled = (scale_factor**(1/2))*y_new_width\n",
    "z_new_width_scaled = (scale_factor**(1/2))*z_new_width\n",
    "x_new_width_scaled = (scale_factor**(1/2))*x_new_width\n",
    "\n",
    "y_col_volume_scaled = (2*y_new_width_scaled) * (2*y_new_width_scaled) * y_box\n",
    "z_col_volume_scaled = (2*z_new_width_scaled) * (2*z_new_width_scaled) * z_box\n",
    "x_col_volume_scaled = (2*x_new_width_scaled) * (2*x_new_width_scaled) * x_box\n",
    "sphere_volume_scaled = (4.0/3.0)*np.pi*(circular_radius_scaled**3)\n",
    "\n",
    "print(\"\\n New widths and radius SCALED by factor of \" + str(scale_factor))\n",
    "print(\"y_new_width_scaled = \" + str(y_new_width_scaled))\n",
    "print(\"z_new_width_scaled = \" + str(z_new_width_scaled))\n",
    "print(\"x_new_width_scaled = \" + str(x_new_width_scaled))\n",
    "print(\"circular_radius_scaled = \" + str(circular_radius_scaled))\n",
    "\n",
    "print(y_col_volume_scaled/sphere_volume_scaled,z_col_volume_scaled/sphere_volume_scaled,x_col_volume_scaled/sphere_volume_scaled)\n",
    "\n",
    "scale_factor = 0.5\n",
    "circular_radius_scaled = (scale_factor**(1/3))*circular_radius\n",
    "y_new_width_scaled = (scale_factor**(1/2))*y_new_width\n",
    "z_new_width_scaled = (scale_factor**(1/2))*z_new_width\n",
    "x_new_width_scaled = (scale_factor**(1/2))*x_new_width\n",
    "\n",
    "print(\"\\n New widths and radius SCALED by factor of \" + str(scale_factor))\n",
    "print(\"y_new_width_scaled = \" + str(y_new_width_scaled))\n",
    "print(\"z_new_width_scaled = \" + str(z_new_width_scaled))\n",
    "print(\"x_new_width_scaled = \" + str(x_new_width_scaled))\n",
    "print(\"circular_radius_scaled = \" + str(circular_radius_scaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Steps for analysis: For each neuron\n",
    "    1) Get the subgroup (from columns or spheres), can adjust for the same number of neurons or same distance\n",
    "    2) Calculate the average mse of the orientations of the subgroup from the neuron of interest (aka get the variance)\n",
    "    3) Calculate the same thing as step 2 but with a random shuffle of neurons from outside the volume (repeat for lots of shuffles so get the distribution)\n",
    "    4) Compare Step 2 and compute the probability of getting that from the distribution gotten in step 3\n",
    "    Repeat 1- 4 for all neurons\n",
    "\n",
    "Look at what the average probability is for all neurons and see if there is instane wher\n",
    "    \n",
    "    \n",
    "mse from the columns\n",
    "\n",
    "keep the column heights and sphere volume the same\"\"\"\n",
    "import time\n",
    "def calc_mse(restricted_neuron_group,\n",
    "             target_scaled\n",
    "            ):\n",
    "    \n",
    "    restricted_neuron_group_orientation_preference = np.array([seg_id_to_orientation[k] for k in restricted_neuron_group])\n",
    "\n",
    "    #now to get the total list shifted by subtracting off the target neuron\n",
    "    total_neurons_scaled = restricted_neuron_group_orientation_preference*2\n",
    "\n",
    "    differences = pycs.pairwise_cdiff(total_neurons_scaled,target_scaled)/2\n",
    "    squared_difference = np.mean(differences**2)\n",
    "    \n",
    "    return squared_difference\n",
    "\n",
    "mse_data = dict()\n",
    "#target_neuron = 648518346341371119\n",
    "start_time = time.time()\n",
    "for target_neuron in soma_cell_location_dict.keys():\n",
    "    \n",
    "\n",
    "    mse_data[target_neuron] = dict()\n",
    "\n",
    "    target_neuron_orientation_preferene = seg_id_to_orientation[target_neuron]\n",
    "\n",
    "\n",
    "    target_scaled = target_neuron_orientation_preferene*2\n",
    "    \"\"\"\n",
    "    Example of how to find neurons within a certain radius\n",
    "    \"\"\"\n",
    "    total_neurons_list = list(soma_cell_location_dict.keys())\n",
    "    total_neurons_list.remove(target_neuron)\n",
    "\n",
    "    \"\"\"\n",
    "    Example of how to find neurons within x column\n",
    "    \"\"\"\n",
    "\n",
    "    # test 1\n",
    "    y_width = y_height = 11000\n",
    "    z_width = z_height = 11000\n",
    "    x_width = x_height = 11000\n",
    "    circular_radius = 13000\n",
    "    \n",
    "    # test 2 (more strict to try and keep around 10 neurons for at least 90 %)\n",
    "    y_width = y_height = 6600\n",
    "    z_width = z_height = 11900\n",
    "    x_width = x_height = 2850\n",
    "    circular_radius = 13700\n",
    "    \n",
    "    #test 3 (with equal volume) \n",
    "    y_new_width = 4385.621445508057\n",
    "    z_new_width = 5469.83095905981\n",
    "    x_new_width = 3281.8985754358864\n",
    "    \n",
    "    y_width = y_height = y_new_width\n",
    "    z_width = z_height = z_new_width\n",
    "    x_width = x_height = x_new_width\n",
    "    \n",
    "    #test 4 (scaled by 2 with equal volume)\n",
    "    y_new_width_scaled = 6202.2053276717925\n",
    "    z_new_width_scaled = 7735.509126190617\n",
    "    x_new_width_scaled = 4641.305475714371\n",
    "    circular_radius_scaled = 17260.91838355976\n",
    "    \n",
    "    y_width = y_height = y_new_width_scaled\n",
    "    z_width = z_height = z_new_width_scaled\n",
    "    x_width = x_height = x_new_width_scaled\n",
    "    circular_radius = circular_radius_scaled\n",
    "    \n",
    "    # test 5\n",
    "    #New widths and radius SCALED by factor of 0.5\n",
    "    y_new_width_scaled = 3101.1026638358962\n",
    "    z_new_width_scaled = 3867.7545630953086\n",
    "    x_new_width_scaled = 2320.6527378571855\n",
    "    circular_radius_scaled = 10873.697205982167\n",
    "    \n",
    "    y_width = y_height = y_new_width_scaled\n",
    "    z_width = z_height = z_new_width_scaled\n",
    "    x_width = x_height = x_new_width_scaled\n",
    "    circular_radius = circular_radius_scaled\n",
    "    \n",
    "    width_axis = \"x_distance\"; height_axis = \"z_distance\"\n",
    "    y_column_subgroup = find_column_subgroup(width_axis,height_axis,target_neuron,total_neurons_list,y_width,y_height)\n",
    "\n",
    "    \n",
    "    width_axis = \"x_distance\"; height_axis = \"y_distance\"\n",
    "    z_column_subgroup = find_column_subgroup(width_axis,height_axis,target_neuron,total_neurons_list,z_width,z_height)\n",
    "\n",
    "    \n",
    "    width_axis = \"y_distance\"; height_axis = \"z_distance\"\n",
    "    x_column_subgroup = find_column_subgroup(width_axis,height_axis,target_neuron,total_neurons_list,x_width,x_height)\n",
    "\n",
    "    \n",
    "    circular_subgroup = find_radius_subgroup(target_neuron,total_neurons_list,circular_radius)\n",
    "\n",
    "\n",
    "    subgroups_list = dict(y_column_subgroup=y_column_subgroup,\n",
    "                         z_column_subgroup=z_column_subgroup,\n",
    "                         x_column_subgroup=x_column_subgroup,\n",
    "                         circular_subgroup=circular_subgroup)\n",
    "\n",
    "    n_random_shuffles = 1000\n",
    "\n",
    "\n",
    "    \n",
    "    for subgroup_name,restricted_neuron_group in subgroups_list.items():\n",
    "        #get the mse of that subgroup\n",
    "        restricted_neuron_group_mse = calc_mse(restricted_neuron_group,\n",
    "                                              target_scaled)\n",
    "        outside_neurons = [k for k in total_neurons_list if \n",
    "                       ((k not in restricted_neuron_group) and \n",
    "                        k != target_neuron)]\n",
    "#         print(\"len(restricted_neuron_group) = \" + str(len(restricted_neuron_group)))\n",
    "#         print(\"len(outside_neurons) = \" + str(len(outside_neurons)))\n",
    "        \n",
    "        random_shuffles_mse = []\n",
    "        for i in range(0,n_random_shuffles):\n",
    "            #get a random list from outside the subgroup\n",
    "            if len(restricted_neuron_group) < len(outside_neurons):\n",
    "                outside_neurons_rand = random.sample(outside_neurons,len(restricted_neuron_group))\n",
    "            else:\n",
    "                if i == 1:\n",
    "                    print(\"not using sampling\")\n",
    "                outside_neurons_rand = outside_neurons\n",
    "            \n",
    "            if len(restricted_neuron_group) < len(outside_neurons_rand):\n",
    "                print(\"RESTRICTED GROUP NUMBER IS LESS\")\n",
    "            random_shuffles_mse.append(calc_mse(outside_neurons_rand,\n",
    "                                              target_scaled))\n",
    "\n",
    "        #save the random shuffles\n",
    "        mse_data[target_neuron][subgroup_name] = dict() \n",
    "        mse_data[target_neuron][subgroup_name][\"shuffles\"] = random_shuffles_mse\n",
    "        mse_data[target_neuron][subgroup_name][\"real_group\"] = restricted_neuron_group_mse\n",
    "        mse_data[target_neuron][subgroup_name][\"real_group_len\"] = len(restricted_neuron_group)\n",
    "        \n",
    "        probability_less_than = np.sum(random_shuffles_mse<restricted_neuron_group_mse)/len(random_shuffles_mse)\n",
    "        mse_data[target_neuron][subgroup_name][\"probability\"] = probability_less_than\n",
    "print(f\"Total time for neurons = \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_parameter_string = f\"x_width = {x_width}, x_height = {x_height}\"\n",
    "y_parameter_string = f\"y_width = {y_width}, y_height = {y_height}\"\n",
    "z_parameter_string = f\"z_width = {z_width}, z_height = {z_height}\"\n",
    "sphere_parameter_string = f\"circular_radius = {circular_radius}\"\n",
    "\n",
    "\n",
    "whole_parameters_string = \"\\n\"+x_parameter_string+ \\\n",
    "                            \"\\n\"+y_parameter_string+ \\\n",
    "                            \"\\n\"+z_parameter_string+ \\\n",
    "                            \"\\n\"+sphere_parameter_string\n",
    "\n",
    "parameter_strings = [y_parameter_string,z_parameter_string,x_parameter_string,\n",
    "                    sphere_parameter_string]\n",
    "\n",
    "whole_parameters_string\n",
    "\n",
    "#get all of the probabilities for each group\n",
    "\n",
    "column_sphere_names = subgroups_list.keys()\n",
    "total_probabilities = []\n",
    "total_group_number = []\n",
    "column_sphere_subgroup_number = dict()\n",
    "column_sphere_probabilities = dict()\n",
    "for volume_name,param in zip(column_sphere_names,parameter_strings):\n",
    "    column_sphere_probabilities[volume_name] = []\n",
    "    column_sphere_subgroup_number[volume_name] = []\n",
    "    for a in mse_data.keys():\n",
    "            column_sphere_probabilities[volume_name].append(mse_data[a][volume_name][\"probability\"])\n",
    "            column_sphere_subgroup_number[volume_name].append(mse_data[a][volume_name][\"real_group_len\"])\n",
    "    plt.figure()\n",
    "    plt.hist(column_sphere_probabilities[volume_name],bins=100)\n",
    "    mean_group_number = np.mean(column_sphere_subgroup_number[volume_name])\n",
    "    std_dev_group_number = np.std(column_sphere_subgroup_number[volume_name])\n",
    "    plt.title(volume_name  + \" probability distributions\\n\" + param \n",
    "                           + \"\\nmean subgroup number = \" + str(np.round(mean_group_number,3))\n",
    "                           + \"\\nstd dev subgroup number = \" + str(np.round(std_dev_group_number,3))\n",
    "                            + \"\\n Mean probability = \" + str(np.round(np.mean(column_sphere_probabilities[volume_name]),3)))\n",
    "    total_group_number += column_sphere_subgroup_number[volume_name]\n",
    "    total_probabilities += column_sphere_probabilities[volume_name]\n",
    "    \n",
    "    \n",
    "mean_group_number = np.mean(total_group_number)\n",
    "std_dev_group_number = np.std(total_group_number)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(total_probabilities,bins=100)\n",
    "plt.title(\"Total probability distributions\" + whole_parameters_string\n",
    "         + \"\\nmean subgroup number = \" + str(np.round(mean_group_number,3))\n",
    "         + \"\\nstd dev subgroup number = \" + str(np.round(std_dev_group_number,3))\n",
    "         + \"\\n Mean probability = \" + str(np.round(np.mean(total_probabilities),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the same probability analysis for only neurons with orientations with certain preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_radian_subgroup = dict()\n",
    "window_size_degrees = 180/16/2\n",
    "window_size_radians = window_size_degrees/rad2deg*4\n",
    "\n",
    "#how the radians will move when graphing them\n",
    "n_window_samples = 50\n",
    "window_radians_stepsize = np.pi/n_window_samples\n",
    "\n",
    "total_center_radians = np.linspace(0,np.pi,n_window_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#-------------------starting loop through all middle orientations-----------------------#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for middle_orientation in tqdm(total_center_radians):\n",
    "    mse_radian_subgroup[middle_orientation] = dict()\n",
    "\n",
    "    #print(f\"Radians range = {(middle_orientation - window_size_radians,middle_orientation + window_size_radians)}\")\n",
    "\n",
    "    #get the orientation differences of all\n",
    "    target_neurons_to_iterate_through = [k for k in soma_cell_location_dict.keys() if \n",
    "                                         np.abs(pycs.cdiff(seg_id_to_orientation[k]*2,middle_orientation*2)/2) < window_size_radians]\n",
    "\n",
    "    #print(\"len(target_neurons_to_iterate_through) = \" + str(len(target_neurons_to_iterate_through)))\n",
    "    mse_radian_subgroup[middle_orientation][\"neuron_number\"] = len(target_neurons_to_iterate_through)\n",
    "\n",
    "    #checking that correctly getting the subgroup\n",
    "    orientations_neurons_to_iterate_through = [seg_id_to_orientation[k] for k in target_neurons_to_iterate_through]\n",
    "    x = plt.hist(orientations_neurons_to_iterate_through,bins=20)\n",
    "    plt.xlim([0,np.pi])\n",
    "    print((min(x[1]),max(x[1])))\n",
    "\n",
    "\n",
    "    plotting = False\n",
    "\n",
    "    mse_data = dict()\n",
    "    #target_neuron = 648518346341371119\n",
    "    start_time = time.time()\n",
    "\n",
    "    for target_neuron in target_neurons_to_iterate_through:\n",
    "\n",
    "\n",
    "        mse_data[target_neuron] = dict()\n",
    "\n",
    "        target_neuron_orientation_preferene = seg_id_to_orientation[target_neuron]\n",
    "\n",
    "\n",
    "        target_scaled = target_neuron_orientation_preferene*2\n",
    "        \"\"\"\n",
    "        Example of how to find neurons within a certain radius\n",
    "        \"\"\"\n",
    "        total_neurons_list = list(soma_cell_location_dict.keys())\n",
    "        total_neurons_list.remove(target_neuron)\n",
    "\n",
    "        \"\"\"\n",
    "        Example of how to find neurons within x column\n",
    "        \"\"\"\n",
    "\n",
    "        # test 1\n",
    "        y_width = y_height = 11000\n",
    "        z_width = z_height = 11000\n",
    "        x_width = x_height = 11000\n",
    "        circular_radius = 13000\n",
    "\n",
    "        # test 2 (more strict to try and keep around 10 neurons for at least 90 %)\n",
    "        y_width = y_height = 6600\n",
    "        z_width = z_height = 11900\n",
    "        x_width = x_height = 2850\n",
    "        circular_radius = 13700\n",
    "\n",
    "        #test 3 (with equal volume) \n",
    "        y_new_width = 4385.621445508057\n",
    "        z_new_width = 5469.83095905981\n",
    "        x_new_width = 3281.8985754358864\n",
    "\n",
    "        y_width = y_height = y_new_width\n",
    "        z_width = z_height = z_new_width\n",
    "        x_width = x_height = x_new_width\n",
    "\n",
    "    #     #test 4 (scaled by 2 with equal volume)\n",
    "    #     y_new_width_scaled = 6202.2053276717925\n",
    "    #     z_new_width_scaled = 7735.509126190617\n",
    "    #     x_new_width_scaled = 4641.305475714371\n",
    "    #     circular_radius_scaled = 17260.91838355976\n",
    "\n",
    "    #     y_width = y_height = y_new_width_scaled\n",
    "    #     z_width = z_height = z_new_width_scaled\n",
    "    #     x_width = x_height = x_new_width_scaled\n",
    "    #     circular_radius = circular_radius_scaled\n",
    "\n",
    "    #     # test 5\n",
    "    #     #New widths and radius SCALED by factor of 0.5\n",
    "    #     y_new_width_scaled = 3101.1026638358962\n",
    "    #     z_new_width_scaled = 3867.7545630953086\n",
    "    #     x_new_width_scaled = 2320.6527378571855\n",
    "    #     circular_radius_scaled = 10873.697205982167\n",
    "\n",
    "    #     y_width = y_height = y_new_width_scaled\n",
    "    #     z_width = z_height = z_new_width_scaled\n",
    "    #     x_width = x_height = x_new_width_scaled\n",
    "    #     circular_radius = circular_radius_scaled\n",
    "\n",
    "        width_axis = \"x_distance\"; height_axis = \"z_distance\"\n",
    "        y_column_subgroup = find_column_subgroup(width_axis,height_axis,target_neuron,total_neurons_list,y_width,y_height)\n",
    "\n",
    "\n",
    "        width_axis = \"x_distance\"; height_axis = \"y_distance\"\n",
    "        z_column_subgroup = find_column_subgroup(width_axis,height_axis,target_neuron,total_neurons_list,z_width,z_height)\n",
    "\n",
    "\n",
    "        width_axis = \"y_distance\"; height_axis = \"z_distance\"\n",
    "        x_column_subgroup = find_column_subgroup(width_axis,height_axis,target_neuron,total_neurons_list,x_width,x_height)\n",
    "\n",
    "\n",
    "        circular_subgroup = find_radius_subgroup(target_neuron,total_neurons_list,circular_radius)\n",
    "\n",
    "\n",
    "        subgroups_list = dict(y_column_subgroup=y_column_subgroup,\n",
    "                             z_column_subgroup=z_column_subgroup,\n",
    "                             x_column_subgroup=x_column_subgroup,\n",
    "                             circular_subgroup=circular_subgroup)\n",
    "\n",
    "        n_random_shuffles = 1000\n",
    "\n",
    "\n",
    "\n",
    "        for subgroup_name,restricted_neuron_group in subgroups_list.items():\n",
    "            #get the mse of that subgroup\n",
    "            restricted_neuron_group_mse = calc_mse(restricted_neuron_group,\n",
    "                                                  target_scaled)\n",
    "            outside_neurons = [k for k in total_neurons_list if \n",
    "                           ((k not in restricted_neuron_group) and \n",
    "                            k != target_neuron)]\n",
    "    #         print(\"len(restricted_neuron_group) = \" + str(len(restricted_neuron_group)))\n",
    "    #         print(\"len(outside_neurons) = \" + str(len(outside_neurons)))\n",
    "\n",
    "            random_shuffles_mse = []\n",
    "            for i in range(0,n_random_shuffles):\n",
    "                #get a random list from outside the subgroup\n",
    "                if len(restricted_neuron_group) < len(outside_neurons):\n",
    "                    outside_neurons_rand = random.sample(outside_neurons,len(restricted_neuron_group))\n",
    "                else:\n",
    "                    if i == 1:\n",
    "                        print(\"not using sampling\")\n",
    "                    outside_neurons_rand = outside_neurons\n",
    "\n",
    "                if len(restricted_neuron_group) < len(outside_neurons_rand):\n",
    "                    print(\"RESTRICTED GROUP NUMBER IS LESS\")\n",
    "                random_shuffles_mse.append(calc_mse(outside_neurons_rand,\n",
    "                                                  target_scaled))\n",
    "\n",
    "            #save the random shuffles\n",
    "            mse_data[target_neuron][subgroup_name] = dict() \n",
    "            mse_data[target_neuron][subgroup_name][\"shuffles\"] = random_shuffles_mse\n",
    "            mse_data[target_neuron][subgroup_name][\"real_group\"] = restricted_neuron_group_mse\n",
    "            mse_data[target_neuron][subgroup_name][\"real_group_len\"] = len(restricted_neuron_group)\n",
    "\n",
    "            probability_less_than = np.sum(random_shuffles_mse<restricted_neuron_group_mse)/len(random_shuffles_mse)\n",
    "            mse_data[target_neuron][subgroup_name][\"probability\"] = probability_less_than\n",
    "    print(f\"Total time for neurons = \" + str(time.time() - start_time))\n",
    "\n",
    "\n",
    "    x_parameter_string = f\"x_width = {x_width}, x_height = {x_height}\"\n",
    "    y_parameter_string = f\"y_width = {y_width}, y_height = {y_height}\"\n",
    "    z_parameter_string = f\"z_width = {z_width}, z_height = {z_height}\"\n",
    "    sphere_parameter_string = f\"circular_radius = {circular_radius}\"\n",
    "\n",
    "\n",
    "    whole_parameters_string = \"\\n\"+x_parameter_string+ \\\n",
    "                                \"\\n\"+y_parameter_string+ \\\n",
    "                                \"\\n\"+z_parameter_string+ \\\n",
    "                                \"\\n\"+sphere_parameter_string\n",
    "\n",
    "    parameter_strings = [y_parameter_string,z_parameter_string,x_parameter_string,\n",
    "                        sphere_parameter_string]\n",
    "\n",
    "    whole_parameters_string\n",
    "\n",
    "    #get all of the probabilities for each group\n",
    "\n",
    "    column_sphere_names = subgroups_list.keys()\n",
    "    total_probabilities = []\n",
    "    total_group_number = []\n",
    "    column_sphere_subgroup_number = dict()\n",
    "    column_sphere_probabilities = dict()\n",
    "    for volume_name,param in zip(column_sphere_names,parameter_strings):\n",
    "        column_sphere_probabilities[volume_name] = []\n",
    "        column_sphere_subgroup_number[volume_name] = []\n",
    "        for a in mse_data.keys():\n",
    "                column_sphere_probabilities[volume_name].append(mse_data[a][volume_name][\"probability\"])\n",
    "                column_sphere_subgroup_number[volume_name].append(mse_data[a][volume_name][\"real_group_len\"])\n",
    "        mean_group_number = np.mean(column_sphere_subgroup_number[volume_name])\n",
    "        std_dev_group_number = np.std(column_sphere_subgroup_number[volume_name])\n",
    "        mean_probability = np.mean(column_sphere_probabilities[volume_name])\n",
    "        if plotting:\n",
    "            plt.figure()\n",
    "            plt.hist(column_sphere_probabilities[volume_name],bins=100)\n",
    "\n",
    "            plt.title(volume_name  + \" probability distributions\\n\" + param \n",
    "                                   + \"\\nmean subgroup number = \" + str(np.round(mean_group_number,3))\n",
    "                                   + \"\\nstd dev subgroup number = \" + str(np.round(std_dev_group_number,3))\n",
    "                                    + \"\\n Mean probability = \" + str(np.round(mean_probability,3)))\n",
    "\n",
    "        #store the mean probability, subgroup number and std deviation in the largest dictionary so \n",
    "        # can compare as iterate over the radians\n",
    "        mse_radian_subgroup[middle_orientation][volume_name] = dict(mean_group_number=mean_group_number,\n",
    "                                                                   std_dev_group_number=std_dev_group_number,\n",
    "                                                                   mean_probability=mean_probability)\n",
    "\n",
    "\n",
    "        total_group_number += column_sphere_subgroup_number[volume_name]\n",
    "        total_probabilities += column_sphere_probabilities[volume_name]\n",
    "\n",
    "\n",
    "    mean_group_number = np.mean(total_group_number)\n",
    "    std_dev_group_number = np.std(total_group_number)\n",
    "    mean_probability = np.mean(total_probabilities)\n",
    "\n",
    "    mse_radian_subgroup[middle_orientation][\"total\"] = dict(mean_group_number=mean_group_number,\n",
    "                                                                   std_dev_group_number=std_dev_group_number,\n",
    "                                                                   mean_probability=mean_probability)\n",
    "    if plotting:\n",
    "        plt.figure()\n",
    "        plt.hist(total_probabilities,bins=100)\n",
    "        plt.title(\"Total probability distributions\" + whole_parameters_string\n",
    "                 + \"\\nmean subgroup number = \" + str(np.round(mean_group_number,3))\n",
    "                 + \"\\nstd dev subgroup number = \" + str(np.round(std_dev_group_number,3))\n",
    "                 + \"\\n Mean probability = \" + str(np.round(mean_probability,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graphs want to do \n",
    "1) The mean probability of each group vs. center\n",
    "2) The mean group number of each group vs. center\n",
    "3) The std dev group number of each group vs. center\n",
    "4) Number neurons that were tested in each radian group vs. center\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "x = list(mse_radian_subgroup.keys())\n",
    "column_type = list(mse_radian_subgroup[list(x)[0]].keys())\n",
    "if \"neuron_number\" in column_type:\n",
    "    column_type.remove(\"neuron_number\")\n",
    "\n",
    "#get the data for each column type\n",
    "probability_data = dict()\n",
    "std_dev_group_data = dict()\n",
    "mean_group_data = dict()\n",
    "for t in column_type:\n",
    "    probability_data[t] = [v[t][\"mean_probability\"] for k,v in mse_radian_subgroup.items()]\n",
    "    std_dev_group_data[t] = [v[t][\"mean_group_number\"] for k,v in mse_radian_subgroup.items()]\n",
    "    mean_group_data[t] = [v[t][\"std_dev_group_number\"] for k,v in mse_radian_subgroup.items()]\n",
    "    \n",
    "#get the neuron number for each radian group\n",
    "neuron_number_data = [mse_radian_subgroup[k][\"neuron_number\"] for k in mse_radian_subgroup.keys()]\n",
    "\n",
    "window_size_radians_rounded = np.round(window_size_radians,3)\n",
    "plt.figure()\n",
    "plt.title(\" Mean Probabilty vs. Radian center with window size +/- \" + str(window_size_radians_rounded) + \" radians\")\n",
    "for t,y in probability_data.items():\n",
    "    plt.plot(x,y,label=t)\n",
    "plt.legend()\n",
    "ax = plt.gca()\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0,box.y0,box.width*0.8,box.height])\n",
    "ax.legend(loc='center left',bbox_to_anchor=(1,0.5))\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\" Mean group number vs. Radian center with window size +/- \" + str(window_size_radians_rounded) + \" radians\")\n",
    "for t,y in mean_group_data.items():\n",
    "    plt.plot(x,y,label=t)\n",
    "plt.legend()\n",
    "ax = plt.gca()\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0,box.y0,box.width*0.8,box.height])\n",
    "ax.legend(loc='center left',bbox_to_anchor=(1,0.5))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\" Std dev group number vs. Radian center with window size +/- \" + str(window_size_radians_rounded) + \" radians\")\n",
    "for t,y in std_dev_group_data.items():\n",
    "    plt.plot(x,y,label=t)\n",
    "plt.legend()\n",
    "ax = plt.gca()\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0,box.y0,box.width*0.8,box.height])\n",
    "ax.legend(loc='center left',bbox_to_anchor=(1,0.5))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\" n_neurons in radian range vs. Radian center with window size +/- \" + str(window_size_radians_rounded) + \" radians\")\n",
    "plt.plot(x,neuron_number_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over differing the scale and seeing how that changes:\n",
    "mse_scale_subgroup = dict()\n",
    "n_window_samples = 20\n",
    "total_scalings = np.linspace(0.25,4,n_window_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#-------------------starting loop through all middle orientations-----------------------#\n",
    "for scale_facotr in tqdm(total_scalings):\n",
    "    mse_scale_subgroup[scale_facotr] = dict()\n",
    "\n",
    "\n",
    "    plotting = False\n",
    "\n",
    "    mse_data = dict()\n",
    "    #target_neuron = 648518346341371119\n",
    "    start_time = time.time()\n",
    "\n",
    "    for target_neuron in soma_cell_location_dict.keys():\n",
    "\n",
    "\n",
    "        mse_data[target_neuron] = dict()\n",
    "\n",
    "        target_neuron_orientation_preferene = seg_id_to_orientation[target_neuron]\n",
    "\n",
    "\n",
    "        target_scaled = target_neuron_orientation_preferene*2\n",
    "        \"\"\"\n",
    "        Example of how to find neurons within a certain radius\n",
    "        \"\"\"\n",
    "        total_neurons_list = list(soma_cell_location_dict.keys())\n",
    "        total_neurons_list.remove(target_neuron)\n",
    "\n",
    "        \"\"\"\n",
    "        Example of how to find neurons within x column\n",
    "        \"\"\"\n",
    "\n",
    "        # test 1\n",
    "        y_width = y_height = 11000\n",
    "        z_width = z_height = 11000\n",
    "        x_width = x_height = 11000\n",
    "        circular_radius = 13000\n",
    "\n",
    "        # test 2 (more strict to try and keep around 10 neurons for at least 90 %)\n",
    "        y_width = y_height = 6600\n",
    "        z_width = z_height = 11900\n",
    "        x_width = x_height = 2850\n",
    "        circular_radius = 13700\n",
    "\n",
    "        #test 3 (with equal volume) \n",
    "        y_new_width = 4385.621445508057\n",
    "        z_new_width = 5469.83095905981\n",
    "        x_new_width = 3281.8985754358864\n",
    "\n",
    "        y_width = y_height = y_new_width\n",
    "        z_width = z_height = z_new_width\n",
    "        x_width = x_height = x_new_width\n",
    "\n",
    "        \n",
    "        circular_radius_scaled = (scale_factor**(1/3))*circular_radius\n",
    "        y_new_width_scaled = (scale_factor**(1/2))*y_new_width\n",
    "        z_new_width_scaled = (scale_factor**(1/2))*z_new_width\n",
    "        x_new_width_scaled = (scale_factor**(1/2))*x_new_width\n",
    "\n",
    "#         print(\"\\n New widths and radius SCALED by factor of \" + str(scale_factor))\n",
    "#         print(\"y_new_width_scaled = \" + str(y_new_width_scaled))\n",
    "#         print(\"z_new_width_scaled = \" + str(z_new_width_scaled))\n",
    "#         print(\"x_new_width_scaled = \" + str(x_new_width_scaled))\n",
    "#         print(\"circular_radius_scaled = \" + str(circular_radius_scaled))\n",
    "        \n",
    "        y_width = y_height = y_new_width_scaled\n",
    "        z_width = z_height = z_new_width_scaled\n",
    "        x_width = x_height = x_new_width_scaled\n",
    "        circular_radius = circular_radius_scaled\n",
    "        \n",
    "\n",
    "        width_axis = \"x_distance\"; height_axis = \"z_distance\"\n",
    "        y_column_subgroup = find_column_subgroup(width_axis,height_axis,target_neuron,total_neurons_list,y_width,y_height)\n",
    "\n",
    "\n",
    "        width_axis = \"x_distance\"; height_axis = \"y_distance\"\n",
    "        z_column_subgroup = find_column_subgroup(width_axis,height_axis,target_neuron,total_neurons_list,z_width,z_height)\n",
    "\n",
    "\n",
    "        width_axis = \"y_distance\"; height_axis = \"z_distance\"\n",
    "        x_column_subgroup = find_column_subgroup(width_axis,height_axis,target_neuron,total_neurons_list,x_width,x_height)\n",
    "\n",
    "\n",
    "        circular_subgroup = find_radius_subgroup(target_neuron,total_neurons_list,circular_radius)\n",
    "\n",
    "\n",
    "        subgroups_list = dict(y_column_subgroup=y_column_subgroup,\n",
    "                             z_column_subgroup=z_column_subgroup,\n",
    "                             x_column_subgroup=x_column_subgroup,\n",
    "                             circular_subgroup=circular_subgroup)\n",
    "\n",
    "        n_random_shuffles = 1000\n",
    "\n",
    "\n",
    "\n",
    "        for subgroup_name,restricted_neuron_group in subgroups_list.items():\n",
    "            #get the mse of that subgroup\n",
    "            restricted_neuron_group_mse = calc_mse(restricted_neuron_group,\n",
    "                                                  target_scaled)\n",
    "            outside_neurons = [k for k in total_neurons_list if \n",
    "                           ((k not in restricted_neuron_group) and \n",
    "                            k != target_neuron)]\n",
    "    #         print(\"len(restricted_neuron_group) = \" + str(len(restricted_neuron_group)))\n",
    "    #         print(\"len(outside_neurons) = \" + str(len(outside_neurons)))\n",
    "\n",
    "            random_shuffles_mse = []\n",
    "            for i in range(0,n_random_shuffles):\n",
    "                #get a random list from outside the subgroup\n",
    "                if len(restricted_neuron_group) < len(outside_neurons):\n",
    "                    outside_neurons_rand = random.sample(outside_neurons,len(restricted_neuron_group))\n",
    "                else:\n",
    "                    if i == 1:\n",
    "                        print(\"not using sampling\")\n",
    "                    outside_neurons_rand = outside_neurons\n",
    "\n",
    "                if len(restricted_neuron_group) < len(outside_neurons_rand):\n",
    "                    print(\"RESTRICTED GROUP NUMBER IS LESS\")\n",
    "                random_shuffles_mse.append(calc_mse(outside_neurons_rand,\n",
    "                                                  target_scaled))\n",
    "\n",
    "            #save the random shuffles\n",
    "            mse_data[target_neuron][subgroup_name] = dict() \n",
    "            mse_data[target_neuron][subgroup_name][\"shuffles\"] = random_shuffles_mse\n",
    "            mse_data[target_neuron][subgroup_name][\"real_group\"] = restricted_neuron_group_mse\n",
    "            mse_data[target_neuron][subgroup_name][\"real_group_len\"] = len(restricted_neuron_group)\n",
    "\n",
    "            probability_less_than = np.sum(random_shuffles_mse<restricted_neuron_group_mse)/len(random_shuffles_mse)\n",
    "            mse_data[target_neuron][subgroup_name][\"probability\"] = probability_less_than\n",
    "    print(f\"Total time for neurons = \" + str(time.time() - start_time))\n",
    "\n",
    "\n",
    "    x_parameter_string = f\"x_width = {x_width}, x_height = {x_height}\"\n",
    "    y_parameter_string = f\"y_width = {y_width}, y_height = {y_height}\"\n",
    "    z_parameter_string = f\"z_width = {z_width}, z_height = {z_height}\"\n",
    "    sphere_parameter_string = f\"circular_radius = {circular_radius}\"\n",
    "\n",
    "\n",
    "    whole_parameters_string = \"\\n\"+x_parameter_string+ \\\n",
    "                                \"\\n\"+y_parameter_string+ \\\n",
    "                                \"\\n\"+z_parameter_string+ \\\n",
    "                                \"\\n\"+sphere_parameter_string\n",
    "\n",
    "    parameter_strings = [y_parameter_string,z_parameter_string,x_parameter_string,\n",
    "                        sphere_parameter_string]\n",
    "\n",
    "    whole_parameters_string\n",
    "\n",
    "    #get all of the probabilities for each group\n",
    "\n",
    "    column_sphere_names = subgroups_list.keys()\n",
    "    total_probabilities = []\n",
    "    total_group_number = []\n",
    "    column_sphere_subgroup_number = dict()\n",
    "    column_sphere_probabilities = dict()\n",
    "    for volume_name,param in zip(column_sphere_names,parameter_strings):\n",
    "        column_sphere_probabilities[volume_name] = []\n",
    "        column_sphere_subgroup_number[volume_name] = []\n",
    "        for a in mse_data.keys():\n",
    "                column_sphere_probabilities[volume_name].append(mse_data[a][volume_name][\"probability\"])\n",
    "                column_sphere_subgroup_number[volume_name].append(mse_data[a][volume_name][\"real_group_len\"])\n",
    "        mean_group_number = np.mean(column_sphere_subgroup_number[volume_name])\n",
    "        std_dev_group_number = np.std(column_sphere_subgroup_number[volume_name])\n",
    "        mean_probability = np.mean(column_sphere_probabilities[volume_name])\n",
    "        if plotting:\n",
    "            plt.figure()\n",
    "            plt.hist(column_sphere_probabilities[volume_name],bins=100)\n",
    "\n",
    "            plt.title(volume_name  + \" probability distributions\\n\" + param \n",
    "                                   + \"\\nmean subgroup number = \" + str(np.round(mean_group_number,3))\n",
    "                                   + \"\\nstd dev subgroup number = \" + str(np.round(std_dev_group_number,3))\n",
    "                                    + \"\\n Mean probability = \" + str(np.round(mean_probability,3)))\n",
    "\n",
    "        #store the mean probability, subgroup number and std deviation in the largest dictionary so \n",
    "        # can compare as iterate over the radians\n",
    "        mse_scale_subgroup[scale_facotr][volume_name] = dict(mean_group_number=mean_group_number,\n",
    "                                                                   std_dev_group_number=std_dev_group_number,\n",
    "                                                                   mean_probability=mean_probability)\n",
    "\n",
    "\n",
    "        total_group_number += column_sphere_subgroup_number[volume_name]\n",
    "        total_probabilities += column_sphere_probabilities[volume_name]\n",
    "\n",
    "\n",
    "    mean_group_number = np.mean(total_group_number)\n",
    "    std_dev_group_number = np.std(total_group_number)\n",
    "    mean_probability = np.mean(total_probabilities)\n",
    "\n",
    "    mse_scale_subgroup[scale_facotr][\"total\"] = dict(mean_group_number=mean_group_number,\n",
    "                                                                   std_dev_group_number=std_dev_group_number,\n",
    "                                                                   mean_probability=mean_probability)\n",
    "    if plotting:\n",
    "        plt.figure()\n",
    "        plt.hist(total_probabilities,bins=100)\n",
    "        plt.title(\"Total probability distributions\" + whole_parameters_string\n",
    "                 + \"\\nmean subgroup number = \" + str(np.round(mean_group_number,3))\n",
    "                 + \"\\nstd dev subgroup number = \" + str(np.round(std_dev_group_number,3))\n",
    "                 + \"\\n Mean probability = \" + str(np.round(mean_probability,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_scale_subgroup.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graphs want to do \n",
    "1) The mean probability of each group vs. center\n",
    "2) The mean group number of each group vs. center\n",
    "3) The std dev group number of each group vs. center\n",
    "4) Number neurons that were tested in each radian group vs. center\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "x = list(mse_scale_subgroup.keys())\n",
    "column_type = list(mse_scale_subgroup[list(x)[0]].keys())\n",
    "\n",
    "#get the data for each column type\n",
    "probability_data = dict()\n",
    "std_dev_group_data = dict()\n",
    "mean_group_data = dict()\n",
    "for t in column_type:\n",
    "    probability_data[t] = [v[t][\"mean_probability\"] for k,v in mse_scale_subgroup.items()]\n",
    "    std_dev_group_data[t] = [v[t][\"mean_group_number\"] for k,v in mse_scale_subgroup.items()]\n",
    "    mean_group_data[t] = [v[t][\"std_dev_group_number\"] for k,v in mse_scale_subgroup.items()]\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.title(\" Mean Probabilty vs. Scale\")\n",
    "for t,y in probability_data.items():\n",
    "    plt.plot(x,y,label=t)\n",
    "plt.legend()\n",
    "ax = plt.gca()\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0,box.y0,box.width*0.8,box.height])\n",
    "ax.legend(loc='center left',bbox_to_anchor=(1,0.5))\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\" Mean group number vs. Scale\")\n",
    "for t,y in mean_group_data.items():\n",
    "    plt.plot(x,y,label=t)\n",
    "plt.legend()\n",
    "ax = plt.gca()\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0,box.y0,box.width*0.8,box.height])\n",
    "ax.legend(loc='center left',bbox_to_anchor=(1,0.5))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\" Std dev group number vs. Scale\")\n",
    "for t,y in std_dev_group_data.items():\n",
    "    plt.plot(x,y,label=t)\n",
    "plt.legend()\n",
    "ax = plt.gca()\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0,box.y0,box.width*0.8,box.height])\n",
    "ax.legend(loc='center left',bbox_to_anchor=(1,0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heat map of the highest probabilites: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Steps for analysis: For each neuron\n",
    "    1) Get the subgroup (from columns or spheres), can adjust for the same number of neurons or same distance\n",
    "    2) Calculate the average mse of the orientations of the subgroup from the neuron of interest (aka get the variance)\n",
    "    3) Calculate the same thing as step 2 but with a random shuffle of neurons from outside the volume (repeat for lots of shuffles so get the distribution)\n",
    "    4) Compare Step 2 and compute the probability of getting that from the distribution gotten in step 3\n",
    "    Repeat 1- 4 for all neurons\n",
    "\n",
    "Look at what the average probability is for all neurons and see if there is instane wher\n",
    "    \n",
    "    \n",
    "mse from the columns\n",
    "\n",
    "keep the column heights and sphere volume the same\"\"\"\n",
    "import time\n",
    "def calc_mse(restricted_neuron_group,\n",
    "             target_scaled\n",
    "            ):\n",
    "    \n",
    "    restricted_neuron_group_orientation_preference = np.array([seg_id_to_orientation[k] for k in restricted_neuron_group])\n",
    "\n",
    "    #now to get the total list shifted by subtracting off the target neuron\n",
    "    total_neurons_scaled = restricted_neuron_group_orientation_preference*2\n",
    "\n",
    "    differences = pycs.pairwise_cdiff(total_neurons_scaled,target_scaled)/2\n",
    "    squared_difference = np.mean(differences**2)\n",
    "    \n",
    "    return squared_difference\n",
    "\n",
    "mse_data = dict()\n",
    "\n",
    "start_time = time.time()\n",
    "for target_neuron in soma_cell_location_dict.keys():\n",
    "    \n",
    "\n",
    "    mse_data[target_neuron] = dict()\n",
    "\n",
    "    target_neuron_orientation_preferene = seg_id_to_orientation[target_neuron]\n",
    "\n",
    "\n",
    "    target_scaled = target_neuron_orientation_preferene*2\n",
    "    \"\"\"\n",
    "    Example of how to find neurons within a certain radius\n",
    "    \"\"\"\n",
    "    total_neurons_list = list(soma_cell_location_dict.keys())\n",
    "    total_neurons_list.remove(target_neuron)\n",
    "\n",
    "    \"\"\"\n",
    "    Example of how to find neurons within x column\n",
    "    \"\"\"\n",
    "\n",
    "    # test 1\n",
    "    y_width = y_height = 11000\n",
    "    z_width = z_height = 11000\n",
    "    x_width = x_height = 11000\n",
    "    circular_radius = 13000\n",
    "    \n",
    "    # test 2 (more strict to try and keep around 10 neurons for at least 90 %)\n",
    "    y_width = y_height = 6600\n",
    "    z_width = z_height = 11900\n",
    "    x_width = x_height = 2850\n",
    "    circular_radius = 13700\n",
    "    \n",
    "    #test 3 (with equal volume) \n",
    "    y_new_width = 4385.621445508057\n",
    "    z_new_width = 5469.83095905981\n",
    "    x_new_width = 3281.8985754358864\n",
    "    \n",
    "    y_width = y_height = y_new_width\n",
    "    z_width = z_height = z_new_width\n",
    "    x_width = x_height = x_new_width\n",
    "    \n",
    "    \n",
    "    width_axis = \"x_distance\"; height_axis = \"z_distance\"\n",
    "    y_column_subgroup = find_column_subgroup(width_axis,height_axis,target_neuron,total_neurons_list,y_width,y_height)\n",
    "\n",
    "    \n",
    "    width_axis = \"x_distance\"; height_axis = \"y_distance\"\n",
    "    z_column_subgroup = find_column_subgroup(width_axis,height_axis,target_neuron,total_neurons_list,z_width,z_height)\n",
    "\n",
    "    \n",
    "    width_axis = \"y_distance\"; height_axis = \"z_distance\"\n",
    "    x_column_subgroup = find_column_subgroup(width_axis,height_axis,target_neuron,total_neurons_list,x_width,x_height)\n",
    "\n",
    "    \n",
    "    circular_subgroup = find_radius_subgroup(target_neuron,total_neurons_list,circular_radius)\n",
    "\n",
    "\n",
    "    subgroups_list = dict(y_column_subgroup=y_column_subgroup,\n",
    "                         z_column_subgroup=z_column_subgroup,\n",
    "                         x_column_subgroup=x_column_subgroup,\n",
    "                         circular_subgroup=circular_subgroup)\n",
    "\n",
    "    n_random_shuffles = 1000\n",
    "\n",
    "\n",
    "    \n",
    "    for subgroup_name,restricted_neuron_group in subgroups_list.items():\n",
    "        #get the mse of that subgroup\n",
    "        restricted_neuron_group_mse = calc_mse(restricted_neuron_group,\n",
    "                                              target_scaled)\n",
    "        outside_neurons = [k for k in total_neurons_list if \n",
    "                       ((k not in restricted_neuron_group) and \n",
    "                        k != target_neuron)]\n",
    "#         print(\"len(restricted_neuron_group) = \" + str(len(restricted_neuron_group)))\n",
    "#         print(\"len(outside_neurons) = \" + str(len(outside_neurons)))\n",
    "        \n",
    "        random_shuffles_mse = []\n",
    "        for i in range(0,n_random_shuffles):\n",
    "            #get a random list from outside the subgroup\n",
    "            if len(restricted_neuron_group) < len(outside_neurons):\n",
    "                outside_neurons_rand = random.sample(outside_neurons,len(restricted_neuron_group))\n",
    "            else:\n",
    "                if i == 1:\n",
    "                    print(\"not using sampling\")\n",
    "                outside_neurons_rand = outside_neurons\n",
    "            \n",
    "            if len(restricted_neuron_group) < len(outside_neurons_rand):\n",
    "                print(\"RESTRICTED GROUP NUMBER IS LESS\")\n",
    "            random_shuffles_mse.append(calc_mse(outside_neurons_rand,\n",
    "                                              target_scaled))\n",
    "\n",
    "        #save the random shuffles\n",
    "        mse_data[target_neuron][subgroup_name] = dict() \n",
    "        mse_data[target_neuron][subgroup_name][\"shuffles\"] = random_shuffles_mse\n",
    "        mse_data[target_neuron][subgroup_name][\"real_group\"] = restricted_neuron_group_mse\n",
    "        mse_data[target_neuron][subgroup_name][\"real_group_len\"] = len(restricted_neuron_group)\n",
    "        \n",
    "        probability_less_than = np.sum(random_shuffles_mse<restricted_neuron_group_mse)/len(random_shuffles_mse)\n",
    "        mse_data[target_neuron][subgroup_name][\"probability\"] = probability_less_than\n",
    "print(f\"Total time for neurons = \" + str(time.time() - start_time))\n",
    "\n",
    "\n",
    "x_parameter_string = f\"x_width = {x_width}, x_height = {x_height}\"\n",
    "y_parameter_string = f\"y_width = {y_width}, y_height = {y_height}\"\n",
    "z_parameter_string = f\"z_width = {z_width}, z_height = {z_height}\"\n",
    "sphere_parameter_string = f\"circular_radius = {circular_radius}\"\n",
    "\n",
    "\n",
    "whole_parameters_string = \"\\n\"+x_parameter_string+ \\\n",
    "                            \"\\n\"+y_parameter_string+ \\\n",
    "                            \"\\n\"+z_parameter_string+ \\\n",
    "                            \"\\n\"+sphere_parameter_string\n",
    "\n",
    "parameter_strings = [y_parameter_string,z_parameter_string,x_parameter_string,\n",
    "                    sphere_parameter_string]\n",
    "\n",
    "whole_parameters_string\n",
    "\n",
    "#get all of the probabilities for each group\n",
    "\n",
    "column_sphere_names = subgroups_list.keys()\n",
    "total_probabilities = []\n",
    "total_group_number = []\n",
    "column_sphere_subgroup_number = dict()\n",
    "column_sphere_probabilities = dict()\n",
    "for volume_name,param in zip(column_sphere_names,parameter_strings):\n",
    "    column_sphere_probabilities[volume_name] = []\n",
    "    column_sphere_subgroup_number[volume_name] = []\n",
    "    for a in mse_data.keys():\n",
    "            column_sphere_probabilities[volume_name].append(mse_data[a][volume_name][\"probability\"])\n",
    "            column_sphere_subgroup_number[volume_name].append(mse_data[a][volume_name][\"real_group_len\"])\n",
    "    plt.figure()\n",
    "    plt.hist(column_sphere_probabilities[volume_name],bins=100)\n",
    "    mean_group_number = np.mean(column_sphere_subgroup_number[volume_name])\n",
    "    std_dev_group_number = np.std(column_sphere_subgroup_number[volume_name])\n",
    "    plt.title(volume_name  + \" probability distributions\\n\" + param \n",
    "                           + \"\\nmean subgroup number = \" + str(np.round(mean_group_number,3))\n",
    "                           + \"\\nstd dev subgroup number = \" + str(np.round(std_dev_group_number,3))\n",
    "                            + \"\\n Mean probability = \" + str(np.round(np.mean(column_sphere_probabilities[volume_name]),3)))\n",
    "    total_group_number += column_sphere_subgroup_number[volume_name]\n",
    "    total_probabilities += column_sphere_probabilities[volume_name]\n",
    "    \n",
    "    \n",
    "mean_group_number = np.mean(total_group_number)\n",
    "std_dev_group_number = np.std(total_group_number)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(total_probabilities,bins=100)\n",
    "plt.title(\"Total probability distributions\" + whole_parameters_string\n",
    "         + \"\\nmean subgroup number = \" + str(np.round(mean_group_number,3))\n",
    "         + \"\\nstd dev subgroup number = \" + str(np.round(std_dev_group_number,3))\n",
    "         + \"\\n Mean probability = \" + str(np.round(np.mean(total_probabilities),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----- 2nd Part: Start graphing the heat maps according to the locations in the volume --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radius Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shows clustering of the circular subgroups\n",
    "\n",
    "y_col_values = [mse_data[a][\"circular_subgroup\"][\"probability\"] for a in soma_cell_location_dict.keys()]\n",
    "soma_centers_list =  np.array([soma_cell_location_dict[a][\"location\"] for a in soma_cell_location_dict.keys()])\n",
    "\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "fig.tight_layout()\n",
    "ax = plt.subplot(1,3,1)\n",
    "sc = ax.scatter(soma_centers_list[:,0],\n",
    "           soma_centers_list[:,1], \n",
    "           c=y_col_values, \n",
    "           marker='o')\n",
    "\n",
    "ax.set_xlabel('x axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "plt.colorbar(sc)\n",
    "\n",
    "ax = plt.subplot(1,3,2)\n",
    "\n",
    "sc = ax.scatter(soma_centers_list[:,0],\n",
    "           soma_centers_list[:,2], \n",
    "           c=y_col_values, \n",
    "           marker='o')\n",
    "\n",
    "ax.set_xlabel('x axis')\n",
    "ax.set_ylabel('z axis')\n",
    "plt.colorbar(sc)\n",
    "\n",
    "ax = plt.subplot(1,3,3)\n",
    "sc = ax.scatter(soma_centers_list[:,1],\n",
    "           soma_centers_list[:,2], \n",
    "           c=y_col_values, \n",
    "           marker='o')\n",
    "\n",
    "ax.set_xlabel('y axis')\n",
    "ax.set_ylabel('z axis')\n",
    "plt.colorbar(sc)\n",
    "\n",
    "\n",
    "#soma_cell_location_dict\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "\n",
    "\n",
    "fig = pyplot.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "sc = ax.scatter(soma_centers_list[:,0], soma_centers_list[:,1], soma_centers_list[:,2],c=y_col_values)\n",
    "ax.set_xlabel(\"X axis\")\n",
    "ax.set_xlabel(\"Y axis\")\n",
    "ax.set_xlabel(\"Z axis\")\n",
    "plt.colorbar(sc)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y Column Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total groups = ['y_column_subgroup', 'z_column_subgroup', 'x_column_subgroup', 'circular_subgroup']\n",
    "y_col_values = [mse_data[a][\"y_column_subgroup\"][\"probability\"] for a in soma_cell_location_dict.keys()]\n",
    "soma_centers_list =  np.array([soma_cell_location_dict[a][\"location\"] for a in soma_cell_location_dict.keys()])\n",
    "\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "fig.tight_layout()\n",
    "ax = plt.subplot(1,3,1)\n",
    "sc = ax.scatter(soma_centers_list[:,0],\n",
    "           soma_centers_list[:,1], \n",
    "           c=y_col_values, \n",
    "           marker='o')\n",
    "\n",
    "ax.set_xlabel('x axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "\n",
    "\n",
    "ax = plt.subplot(1,3,2)\n",
    "\n",
    "sc = ax.scatter(soma_centers_list[:,0],\n",
    "           soma_centers_list[:,2], \n",
    "           c=y_col_values, \n",
    "           marker='o')\n",
    "\n",
    "ax.set_xlabel('x axis')\n",
    "ax.set_ylabel('z axis')\n",
    "\n",
    "\n",
    "ax = plt.subplot(1,3,3)\n",
    "sc = ax.scatter(soma_centers_list[:,1],\n",
    "           soma_centers_list[:,2], \n",
    "           c=y_col_values, \n",
    "           marker='o')\n",
    "\n",
    "ax.set_xlabel('y axis')\n",
    "ax.set_ylabel('z axis')\n",
    "plt.colorbar(sc)\n",
    "\n",
    "\n",
    "#soma_cell_location_dict\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "\n",
    "\n",
    "fig = pyplot.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "sc = ax.scatter(soma_centers_list[:,0], soma_centers_list[:,1], soma_centers_list[:,2],c=y_col_values)\n",
    "ax.set_xlabel(\"X axis\")\n",
    "ax.set_xlabel(\"Y axis\")\n",
    "ax.set_xlabel(\"Z axis\")\n",
    "plt.colorbar(sc)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z Column Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total groups = ['y_column_subgroup', 'z_column_subgroup', 'x_column_subgroup', 'circular_subgroup']\n",
    "y_col_values = [mse_data[a][\"z_column_subgroup\"][\"probability\"] for a in soma_cell_location_dict.keys()]\n",
    "soma_centers_list =  np.array([soma_cell_location_dict[a][\"location\"] for a in soma_cell_location_dict.keys()])\n",
    "\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "fig.tight_layout()\n",
    "ax = plt.subplot(1,3,1)\n",
    "sc = ax.scatter(soma_centers_list[:,0],\n",
    "           soma_centers_list[:,1], \n",
    "           c=y_col_values, \n",
    "           marker='o')\n",
    "\n",
    "ax.set_xlabel('x axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "\n",
    "\n",
    "ax = plt.subplot(1,3,2)\n",
    "\n",
    "sc = ax.scatter(soma_centers_list[:,0],\n",
    "           soma_centers_list[:,2], \n",
    "           c=y_col_values, \n",
    "           marker='o')\n",
    "\n",
    "ax.set_xlabel('x axis')\n",
    "ax.set_ylabel('z axis')\n",
    "\n",
    "\n",
    "ax = plt.subplot(1,3,3)\n",
    "sc = ax.scatter(soma_centers_list[:,1],\n",
    "           soma_centers_list[:,2], \n",
    "           c=y_col_values, \n",
    "           marker='o')\n",
    "\n",
    "ax.set_xlabel('y axis')\n",
    "ax.set_ylabel('z axis')\n",
    "plt.colorbar(sc)\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "\n",
    "\n",
    "fig = pyplot.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "sc = ax.scatter(soma_centers_list[:,0], soma_centers_list[:,1], soma_centers_list[:,2],c=y_col_values)\n",
    "ax.set_xlabel(\"X axis\")\n",
    "ax.set_xlabel(\"Y axis\")\n",
    "ax.set_xlabel(\"Z axis\")\n",
    "plt.colorbar(sc)\n",
    "pyplot.show()\n",
    "\n",
    "#soma_cell_location_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X column clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total groups = ['y_column_subgroup', 'z_column_subgroup', 'x_column_subgroup', 'circular_subgroup']\n",
    "y_col_values = [mse_data[a][\"x_column_subgroup\"][\"probability\"] for a in soma_cell_location_dict.keys()]\n",
    "soma_centers_list =  np.array([soma_cell_location_dict[a][\"location\"] for a in soma_cell_location_dict.keys()])\n",
    "\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "fig.tight_layout()\n",
    "ax = plt.subplot(1,3,1)\n",
    "sc = ax.scatter(soma_centers_list[:,0],\n",
    "           soma_centers_list[:,1], \n",
    "           c=y_col_values, \n",
    "           marker='o')\n",
    "\n",
    "ax.set_xlabel('x axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "\n",
    "\n",
    "ax = plt.subplot(1,3,2)\n",
    "\n",
    "sc = ax.scatter(soma_centers_list[:,0],\n",
    "           soma_centers_list[:,2], \n",
    "           c=y_col_values, \n",
    "           marker='o')\n",
    "\n",
    "ax.set_xlabel('x axis')\n",
    "ax.set_ylabel('z axis')\n",
    "\n",
    "\n",
    "ax = plt.subplot(1,3,3)\n",
    "sc = ax.scatter(soma_centers_list[:,1],\n",
    "           soma_centers_list[:,2], \n",
    "           c=y_col_values, \n",
    "           marker='o')\n",
    "\n",
    "ax.set_xlabel('y axis')\n",
    "ax.set_ylabel('z axis')\n",
    "plt.colorbar(sc)\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "\n",
    "\n",
    "fig = pyplot.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "sc = ax.scatter(soma_centers_list[:,0], soma_centers_list[:,1], soma_centers_list[:,2],c=y_col_values)\n",
    "ax.set_xlabel(\"X axis\")\n",
    "ax.set_xlabel(\"Y axis\")\n",
    "ax.set_xlabel(\"Z axis\")\n",
    "plt.colorbar(sc)\n",
    "pyplot.show()\n",
    "\n",
    "#soma_cell_location_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circular_subgroup\n",
    "\n",
    "mse_data[a][volume_name][\"probability\"]\n",
    "volume_name\n",
    "\n",
    "plt.scatter(x=x, y=y, c=value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find what a distribution looks like where subgroup has probability of 1 (put on hold for right now):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get the distributions from one of the shuffles\n",
    "target_neuron = 648518346341371119\n",
    "print(target_neuron)\n",
    "currnet_subgroup = \"circular_subgroup\"\n",
    "mse_current_target_shuffles = mse_data[target_neuron][currnet_subgroup][\"shuffles\"]\n",
    "\n",
    "mse_current_target_real  = mse_data[target_neuron][currnet_subgroup][\"real_group\"]\n",
    "probability_less_than = np.sum(mse_current_target_shuffles<mse_current_target_real)/len(mse_current_target_shuffles)\n",
    "plt.figure()\n",
    "plt.hist(mse_current_target_shuffles,bins= 40)\n",
    "print(\"mse_current_target_real = \" + str(mse_current_target_real))\n",
    "print(\"probability_less_than = \" + str(probability_less_than))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding how all of the probabilities change as you scale the volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffling for validation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "outside_neurons = [k for k in total_neurons_list if \n",
    "                   ((k not in restricted_neuron_group) and \n",
    "                    k != target_neuron)]\n",
    "#checking that correct\n",
    "#print(np.sum([len(outside_neurons),len(restricted_neuron_group),1]))\n",
    "\n",
    "# get a random shuffling of the outside neurons\n",
    "outside_neurons_rand = random.sample(outside_neurons,len(restricted_neuron_group))\n",
    "print(len(outside_neurons_rand))\n",
    "outside_neurons_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Need to shift the neurons so we can get the \n",
    "get the list of global neurons that are not the specific neuron or subset\n",
    "\"\"\"\n",
    "\n",
    "target_neuron = 648518346341371119\n",
    "target_neuron_orientation_preferene = seg_id_to_orientation[target_neuron]\n",
    "\n",
    "\"\"\"\n",
    "Example of how to find neurons within a certain radius\n",
    "\"\"\"\n",
    "total_neurons_list = list(soma_cell_location_dict.keys())\n",
    "total_neurons_list.remove(target_neuron)\n",
    "\n",
    "#get total list of orientations without the target neuron\n",
    "total_neurons_list_orientation_preference = np.array([seg_id_to_orientation[k] for k in total_neurons_list])\n",
    "len(total_neurons_list_orientation_preference)\n",
    "\n",
    "#now to get the total list shifted by subtracting off the target neuron\n",
    "target_scaled = target_neuron_orientation_preferene*2\n",
    "total_neurons_scaled = total_neurons_list_orientation_preference*2\n",
    "\n",
    "differences = pycs.pairwise_cdiff(total_neurons_scaled,target_scaled)/2\n",
    "squared_difference = np.sum(differences**2)\n",
    "\n",
    "#store this as an outcome in the overall probability distribution\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"    just making sure computation was equivalent   \"\"\"\n",
    "# differences_check = np.array([cdiff(k,target_scaled) for k in total_neurons_scaled])/2\n",
    "# print((len(differences_check),np.min(differences_check),np.max(differences_check)))\n",
    "\n",
    "# for d,cd in zip(differences,differences_check):\n",
    "#     if abs(d-cd) > 0.0001:\n",
    "#         print(\"not equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
