{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import time\n",
    "import pymeshfix\n",
    "import os\n",
    "import datetime\n",
    "import calcification_Module as cm\n",
    "\n",
    "#for supressing the output\n",
    "import os, contextlib\n",
    "import pathlib\n",
    "import subprocess\n",
    "\n",
    "#for error counting\n",
    "from collections import Counter\n",
    "\n",
    "#for reading in the new raw_skeleton files\n",
    "import csv\n",
    "\n",
    "from meshparty import trimesh_io\n",
    "\n",
    "#for filtering\n",
    "import math\n",
    "from pykdtree.kdtree import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@10.28.0.34:3306\n"
     ]
    }
   ],
   "source": [
    "#setting the address and the username\n",
    "dj.config['database.host'] = '10.28.0.34'\n",
    "dj.config['database.user'] = 'celiib'\n",
    "dj.config['database.password'] = 'newceliipass'\n",
    "dj.config['safemode']=True\n",
    "dj.config[\"display.limit\"] = 20\n",
    "\n",
    "schema = dj.schema('microns_pinky')\n",
    "pinky = dj.create_virtual_module('pinky', 'microns_pinky')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ta3p100.FilteredSkeleton.describe()\n",
    "#ta3p100.FilteredSkeletonMinusSoma.describe()\n",
    "#ta3p100.FilteredSkeletonMinusSoma.drop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that takes in a 3x3 array of coordinates for faces and returns triangles and vertices\n",
    "def index_unique_rows(full_coordinate_array):\n",
    "    \"\"\"\n",
    "    Separates an array of nested coordinate rows into an array of unique rows and and index array.\n",
    "    \"\"\"\n",
    "    vertices, flat_idx = np.unique(full_coordinate_array.reshape(-1, full_coordinate_array.shape[-1]), axis=0, return_inverse=True)\n",
    "    return vertices, flat_idx.reshape(-1, full_coordinate_array.shape[-2])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will take in and populate the soma table based on the key it gets\n",
    "def soma_verts_faces(query_key):\n",
    "    \n",
    "    table=\"\"\n",
    "    vertices_soma,triangles_soma = (pinky.CompartmentFinal.ComponentFinal() & query_key\n",
    "                                    & \"compartment_type='Soma'\").fetch(\"vertex_indices\",\"triangle_indices\")\n",
    "\n",
    "    if len(vertices_soma) > 0:\n",
    "        print(\"Soma found in Exhitatory\")\n",
    "        #get the regular mesh from CleansedMesh\n",
    "        vertices_mesh,triangles_mesh = (pinky.PymeshfixDecimatedExcitatoryStitchedMesh & query_key).fetch(\"vertices\",\"triangles\")\n",
    "    else:\n",
    "        vertices_soma,triangles_soma = (pinky.CompartmentOrphan.ComponentOrphan() & query_key & \"compartment_type='Soma'\").fetch(\"vertex_indices\",\"triangle_indices\")\n",
    "        if len(vertices_soma) > 0:\n",
    "            print(\"Soma found in Orphans\")\n",
    "            vertices_mesh,triangles_mesh = (pinky.Decimation35OrphanStitched & query_key).fetch(\"vertices\",\"triangles\")\n",
    "        else:\n",
    "            print(\"No Soma exists for \" + str(query_key[\"segment_id\"]))\n",
    "            return np.array([]),np.array([])\n",
    "            \n",
    "    ts_flatten = np.hstack(triangles_soma).astype(\"int64\")\n",
    "\n",
    "    vertices_real = vertices_mesh[0]\n",
    "    triangles_real = triangles_mesh[0]\n",
    "\n",
    "    ts_stack_whole = vertices_real[triangles_real[ts_flatten]]\n",
    "\n",
    "    vertices_whole, triangles_whole = index_unique_rows(ts_stack_whole)\n",
    "    return vertices_whole, triangles_whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_edges_by_bounding_box(edges,max_bb_zone,min_bb_zone):\n",
    "    #can just use bounding box function to get rid of any inside edges\n",
    "    filtered_remaining = list()\n",
    "\n",
    "    for i,e in enumerate(edges):\n",
    "        #print(e)\n",
    "        if min(e[0][0],e[1][0])>max_bb_zone[0]:\n",
    "            #print(\"minx>maxx\")\n",
    "            filtered_remaining.append(e)\n",
    "            \n",
    "            continue\n",
    "\n",
    "        if max(e[0][0],e[1][0])<min_bb_zone[0]:\n",
    "            #print(\"maxx<minx\")\n",
    "            filtered_remaining.append(e)\n",
    "            continue\n",
    "\n",
    "        if min(e[0][1],e[1][1])>max_bb_zone[1]:\n",
    "            #print(\"miny>maxy\")\n",
    "            filtered_remaining.append(e)\n",
    "            continue\n",
    "\n",
    "        if max(e[0][1],e[1][1])<min_bb_zone[1]:\n",
    "            #print(\"maxy<miny\")\n",
    "            filtered_remaining.append(e)\n",
    "            continue\n",
    "\n",
    "        if min(e[0][2],e[1][2])>max_bb_zone[2]:\n",
    "            #print(\"minz>maxz\")\n",
    "            filtered_remaining.append(e)\n",
    "            continue\n",
    "\n",
    "        if max(e[0][2],e[1][2])<min_bb_zone[2]:\n",
    "            #print(\"maxz<minz\")\n",
    "            filtered_remaining.append(e)\n",
    "            continue\n",
    "\n",
    "        #filtered_edges.append(e)\n",
    "\n",
    "    return np.array(filtered_remaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exhitatory_with_somas = dj.U(\"segment_id\",\"segmentation\") & ((pinky.CompartmentFinal.ComponentFinal() & \"compartment_type='Soma'\").proj(\"segment_id\"))\n",
    "#exhitatory_with_somas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "orphans_with_somas = dj.U(\"segment_id\",\"segmentation\") & ((pinky.CompartmentOrphan.ComponentOrphan() & \"compartment_type='Soma'\").proj(\"segment_id\"))\n",
    "#orphans_with_somas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_soma = ((dj.U(\"segment_id\",\"segmentation\") & ((pinky.CompartmentOrphan.ComponentOrphan() & \"compartment_type='Soma'\").proj(\"segment_id\")).proj()) + \n",
    "(dj.U(\"segment_id\",\"segmentation\") & ((pinky.CompartmentFinal.ComponentFinal() & \"compartment_type='Soma'\").proj(\"segment_id\"))\n",
    ".proj()))\n",
    "    \n",
    "#total_soma\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(ta3p100.FilteredSkeleton & total_soma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(332, 353)\n"
     ]
    }
   ],
   "source": [
    "total_neurons_with_somas = exhitatory_with_somas.proj() + orphans_with_somas.proj()\n",
    "print((len(total_neurons_with_somas),35 +318))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class FilteredSkeletonMinusSoma(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> pinky.FilteredNeuronSkeleton\n",
    "    ---\n",
    "    vertices              :longblob #vertex coordinates of soma mesh\n",
    "    triangles             :longblob #faces for soma mesh\n",
    "    edges                  :longblob #edges of skeelton after soma edges removed\n",
    "    n_edges               :int unsigned #number of edges of skeelton after soma edges removed\n",
    "    soma_bounding_corners :blob #bounding box corners for the soma mesh\n",
    "    \"\"\"\n",
    "    \n",
    "    key_source = pinky.FilteredNeuronSkeleton & ((dj.U(\"segment_id\",\"segmentation\") & ((pinky.CompartmentOrphan.ComponentOrphan() & \"compartment_type='Soma'\").proj(\"segment_id\")).proj()) + \n",
    "                (dj.U(\"segment_id\",\"segmentation\") & ((pinky.CompartmentFinal.ComponentFinal() & \"compartment_type='Soma'\").proj(\"segment_id\")).proj()))\n",
    "    #how you get the date and time  datetime.datetime.now()\n",
    "    \n",
    "    def make(self, key):\n",
    "        print()\n",
    "        print()\n",
    "        print(str(key[\"segment_id\"])+ \":\")\n",
    "        global_start_time = time.time()\n",
    "        #create return key\n",
    "        return_key = key.copy()\n",
    "\n",
    "        #pull down the skeleton for the mesh\n",
    "        skeleton_data = (pinky.FilteredNeuronSkeleton() & key).fetch(as_dict=True)[0]\n",
    "        \n",
    "        #get the vertices and triangles for the Soma\n",
    "        start_time = time.time()\n",
    "        vertices_whole, triangles_whole = soma_verts_faces(key)\n",
    "        print(f\"Step 1: extracted Soma Mesh = {time.time()-start_time}\")\n",
    "\n",
    "        #if no soma portion was found then just write regular skeleton\n",
    "        if not vertices_whole.any():\n",
    "            \n",
    "            print(\"No Soma Found\")\n",
    "\n",
    "            #return_key[\"soma_exist\"] = False\n",
    "            return_key[\"vertices\"] = vertices_whole\n",
    "            return_key[\"triangles\"] = triangles_whole\n",
    "            return_key[\"edges\"] = skeleton_data[\"edges\"]\n",
    "            return_key[\"n_edges\"] = skeleton_data[\"n_edges\"]\n",
    "            return_key[\"soma_bounding_corners\"] = np.array([])\n",
    "\n",
    "            self.insert(return_key,skip_duplicates=True)\n",
    "\n",
    "        #just need to strip the portions of the skeleton that are inside of the mesh\n",
    "\n",
    "        #find the bounding box\n",
    "        start_time = time.time()\n",
    "        mesh = trimesh_io.Mesh(vertices=vertices_whole, faces=triangles_whole)\n",
    "        min_bb = np.array(mesh.bounding_box.vertices).min(0)\n",
    "        max_bb = np.array(mesh.bounding_box.vertices).max(0)\n",
    "        print(f\"Step 2: Calculated Bounding Box = {time.time()-start_time}\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        #get the filtered edges according to bounding box:\n",
    "        filtered_edges_postsyn = filter_edges_by_bounding_box(skeleton_data[\"edges\"],max_bb,min_bb)\n",
    "\n",
    "        print(f\"Step 3: filtering edges = {time.time()-start_time}\")\n",
    "\n",
    "        \n",
    "\n",
    "        #write off the new data to the table\n",
    "        #return_key[\"soma_exist\"] = True\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        return_key[\"vertices\"] = vertices_whole\n",
    "        return_key[\"triangles\"] = triangles_whole\n",
    "        return_key[\"edges\"] = filtered_edges_postsyn\n",
    "        return_key[\"n_edges\"] = filtered_edges_postsyn.shape[0]\n",
    "        return_key[\"soma_bounding_corners\"] = np.array((min_bb,max_bb))\n",
    "        \n",
    "#         print(return_key)\n",
    "#         print(return_key.keys())\n",
    "#         print(\"len(return_key.keys()) = \" + str(len(return_key.keys())))\n",
    "        \n",
    "#         for k in return_key.keys():\n",
    "#             print(\"type(return_key[\"+k+\"])=\" + str(type(return_key[k])))\n",
    "        \n",
    "        self.insert1(return_key,skip_duplicates=True,ignore_extra_fields=True)\n",
    "        print(f\"Step 4: Inserted Key = {time.time()-start_time}\")\n",
    "        print(f\"Total time = {time.time()-global_start_time}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire Notebook = 0.025814056396484375\n"
     ]
    }
   ],
   "source": [
    "notebook_start_time = time.time()\n",
    "FilteredSkeletonMinusSoma.populate(reserve_jobs=True)\n",
    "print(f\"Entire Notebook = {time.time()-notebook_start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(schema.jobs & \"table_name='__filtered_skeleton_minus_soma'\").delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FilteredSkeletonMinusSoma.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire Notebook = 0.025708675384521484\n"
     ]
    }
   ],
   "source": [
    "notebook_start_time = time.time()\n",
    "FilteredSkeletonMinusSoma.populate(reserve_jobs=True)\n",
    "print(f\"Entire Notebook = {time.time()-notebook_start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ta3p100.CleansedMeshOrphan & (FilteredSkeletonMinusSoma() & \"n_edges=0\").proj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #investigating the error: arrays used as indices must be of integer (or boolean) type\n",
    "# query_key = dict(segmentation=2,segment_id=648518346341378749)\n",
    "\n",
    "# table=\"\"\n",
    "# vertices_soma,triangles_soma = (ta3p100.CompartmentFinal.ComponentFinal() & query_key\n",
    "#                                 & \"compartment_type='Soma'\").fetch(\"vertex_indices\",\"triangle_indices\")\n",
    "\n",
    "# if len(vertices_soma) > 0:\n",
    "#     print(\"Soma found in Exhitatory\")\n",
    "#     #get the regular mesh from CleansedMesh\n",
    "#     vertices_mesh,triangles_mesh = (ta3p100.CleansedMesh & query_key).fetch(\"vertices\",\"triangles\")\n",
    "# else:\n",
    "#     vertices_soma,triangles_soma = (ta3p100.CompartmentOrphan.ComponentOrphan() & query_key).fetch(\"vertex_indices\",\"triangle_indices\")\n",
    "#     if len(vertices_soma) > 0:\n",
    "#         print(\"Soma found in Orphans\")\n",
    "#         vertices_mesh,triangles_mesh = (ta3p100.CleansedMeshOrphan & query_key).fetch(\"vertices\",\"triangles\")\n",
    "#     else:\n",
    "#         print(\"No Soma exists for \" + str(query_key[\"segment_id\"]))\n",
    "#         #return np.array([]),np.array([])\n",
    "\n",
    "# ts_flatten = np.hstack(triangles_soma).astype(\"int64\")\n",
    "# type(ts_flatten[0])\n",
    "\n",
    "# vertices_real = vertices_mesh[0]\n",
    "# triangles_real = triangles_mesh[0]\n",
    "\n",
    "# ts_stack_whole = vertices_real[triangles_real[ts_flatten]]\n",
    "\n",
    "# vertices_whole, triangles_whole = index_unique_rows(ts_stack_whole)\n",
    "# #return vertices_whole, triangles_whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
