{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWill generate the skeletons for all of the\\nExhitatory Neurons and Orphan Neurons\\n\\nProcess: \\n1) Check which table the neuron is in\\n2) Filter away any error labels \\n3) Run pymeshfix on neuron\\n4) Run skeletonization\\n5) Write to datajoint as array\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Will generate the skeletons for all of the\n",
    "Exhitatory Neurons and Orphan Neurons\n",
    "\n",
    "Process: \n",
    "1) Check which table the neuron is in\n",
    "2) Filter away any error labels \n",
    "3) Run pymeshfix on neuron\n",
    "4) Run skeletonization\n",
    "5) Write to datajoint as array\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import time\n",
    "import pymeshfix\n",
    "import os\n",
    "import datetime\n",
    "import calcification_Module as cm\n",
    "\n",
    "#for supressing the output\n",
    "import os, contextlib\n",
    "import pathlib\n",
    "import subprocess\n",
    "\n",
    "#for error counting\n",
    "from collections import Counter\n",
    "\n",
    "#for reading in the new raw_skeleton files\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@10.28.0.34:3306\n"
     ]
    }
   ],
   "source": [
    "#setting the address and the username\n",
    "dj.config['database.host'] = '10.28.0.34'\n",
    "dj.config['database.user'] = 'celiib'\n",
    "dj.config['database.password'] = 'newceliipass'\n",
    "dj.config['safemode']=True\n",
    "dj.config[\"display.limit\"] = 20\n",
    "\n",
    "schema = dj.schema('microns_pinky')\n",
    "pinky = dj.create_virtual_module('pinky', 'microns_pinky')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(schema.jobs & \"table_name='__neuron_skeleton'\").delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ta3p100.CoarseLabelFinal() #ta3p100.CoarseLabelOrphan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that will filter out error triangles\n",
    "def generate_neighborhood(triangles, num_vertices):\n",
    "    neighborhood = dict()\n",
    "    for i in range(num_vertices):\n",
    "        neighborhood[i] = set()\n",
    "    for node1, node2, node3 in triangles:\n",
    "        neighborhood[node1].update([node2, node3])\n",
    "        neighborhood[node2].update([node1, node3])\n",
    "        neighborhood[node3].update([node1, node2])\n",
    "    return neighborhood\n",
    "\n",
    "def set_search_first(starting_node, neighborhood):\n",
    "    \"\"\"\n",
    "    Modified Depth-First-Search utilizing sets to reduce duplicate checks:\n",
    "\n",
    "    Neighborhood must be a dict with the keys being the vertex indices!\n",
    "    \"\"\"    \n",
    "    visited_nodes = set()\n",
    "    temp_stack = set()\n",
    "    temp_stack.add(starting_node)\n",
    "    while len(temp_stack) > 0:\n",
    "        starting_node = temp_stack.pop()\n",
    "        if starting_node not in visited_nodes:\n",
    "            visited_nodes.add(starting_node)\n",
    "            temp_stack.update(neighborhood[starting_node])\n",
    "    return list(visited_nodes)\n",
    "def get_connected_portions(neighborhood):\n",
    "    neighborhood_copy = neighborhood.copy()\n",
    "    portions = []\n",
    "    while len(neighborhood_copy) > 0:\n",
    "        starting_node = next(iter(neighborhood_copy))\n",
    "        portion = set_search_first(starting_node, neighborhood_copy)\n",
    "        for node in portion:\n",
    "            neighborhood_copy.pop(node)\n",
    "        portions.append(portion)\n",
    "    return portions\n",
    "\n",
    "def get_largest_portion_index(portions):\n",
    "    portion_lengths = [len(portion) for portion in portions]\n",
    "    return portion_lengths.index(max(portion_lengths))\n",
    "\n",
    "def get_largest_portion(portions):\n",
    "    return portions[get_largest_portion_index(portions)]\n",
    "\n",
    "def remove_floating_artifacts(mesh,key,mesh_labels):    \n",
    "    mesh_copy = mesh.copy()\n",
    "    \n",
    "#     #get the labels for the mesh\n",
    "#     #find out if in Orphan Table or Regular Neuron Table\n",
    "#     if len(ta3p100.CoarseLabelFinal() & key) > 0:\n",
    "#         mesh_labels = (ta3p100.CoarseLabelFinal & key).fetch1()\n",
    "#     elif len(ta3p100.CoarseLabelOrphan() & key) > 0:\n",
    "#         mesh_labels = (ta3p100.CoarseLabelOrphan & key).fetch1()\n",
    "#     else:\n",
    "#         raise Exception('neuron' + str(key[\"segment_id\"]) + \n",
    "#                         'not present in any labels!')\n",
    "\n",
    "    \n",
    "    #look for errors\n",
    "    not_errors = [i for i,k in enumerate(mesh_labels[\"triangles\"]) if k != 10]\n",
    "    original_triangles = mesh[\"triangles\"]\n",
    "    \"\"\"\n",
    "    print(type(not_errors))\n",
    "    print(len(not_errors))\n",
    "    print(\"not_errors = \"+ str(not_errors[:100]))\n",
    "    print(type(original_triangles))\n",
    "    print(len(original_triangles))\n",
    "    #print(original_triangles)\n",
    "    print(\"not_errors = \" + str(original_triangles[not_errors]))\n",
    "    \"\"\"\n",
    "    \n",
    "    mesh_copy['triangles'] = np.array(original_triangles[not_errors])\n",
    "    \n",
    "    return mesh_copy\n",
    "\n",
    "\n",
    "def remove_isolated_vertices(mesh):\n",
    "    mesh_copy = mesh.copy()\n",
    "\n",
    "    neighborhood = generate_neighborhood(mesh_copy['triangles'], len(mesh_copy['vertices']))\n",
    "    isolated_nodes = [portion.pop() for portion in get_connected_portions(neighborhood) if len(portion) == 1]\n",
    "\n",
    "    vertices = mesh_copy['vertices']\n",
    "    triangles = mesh_copy['triangles']\n",
    "    vertex_list = list(vertices)\n",
    "\n",
    "    if len(isolated_nodes) > 0:\n",
    "        num_isolated_nodes_passed = 0\n",
    "        isolated_nodes_set = set(isolated_nodes)\n",
    "        count_to_decrement = np.zeros(len(vertices))\n",
    "        for i in range(len(vertices)):\n",
    "            if i in isolated_nodes_set:\n",
    "                num_isolated_nodes_passed += 1\n",
    "            else:\n",
    "                count_to_decrement[i] = num_isolated_nodes_passed\n",
    "\n",
    "        for i, triangle in enumerate(triangles):\n",
    "            start = time.time()\n",
    "            node1, node2, node3 = triangle\n",
    "            triangles[i][0] -= count_to_decrement[node1]\n",
    "            triangles[i][1] -= count_to_decrement[node2]\n",
    "            triangles[i][2] -= count_to_decrement[node3]\n",
    "        for i, isolated_node in enumerate(isolated_nodes):\n",
    "            vertex_list.pop(isolated_node - i)\n",
    "\n",
    "    mesh_copy['vertices'] = np.array(vertex_list)\n",
    "\n",
    "    return mesh_copy\n",
    "\n",
    "\n",
    "def remove_error_segments(key):\n",
    "\n",
    "    full_start = time.time()\n",
    "\n",
    "    print(str(key['segment_id']) +  \":\")\n",
    "    start = time.time()\n",
    "\n",
    "    #find out if in Orphan Table or Regular Neuron Table\n",
    "    if len(pinky.CoarseLabelFinal() & key) > 0:\n",
    "        mesh = (pinky.PymeshfixDecimatedExcitatoryStitchedMesh & key).fetch1()\n",
    "        mesh_labels = (pinky.CoarseLabelFinal & key).fetch1()\n",
    "    elif len(pinky.CoarseLabelOrphan() & key) > 0:\n",
    "        mesh = (pinky.Decimation35OrphanStitched & key).fetch1()\n",
    "        mesh_labels = (pinky.CoarseLabelOrphan & key).fetch1()\n",
    "    else:\n",
    "        raise Exception('neuron' + str(key[\"segment_id\"]) + \n",
    "                        'not present in any labels!')\n",
    "    \n",
    "    print(key['segment_id'], \"mesh fetched.\", time.time() - start)\n",
    "    start = time.time()\n",
    "    \n",
    "    #print(mesh['triangles'])\n",
    "    myCounter = Counter(mesh_labels['triangles'])#.tolist())\n",
    "    print(myCounter)\n",
    "    \n",
    "    keys = list(myCounter.keys())\n",
    "    #print(len(keys))\n",
    "    \n",
    "    if len(keys) < 2 and keys[0] == 10:\n",
    "        print(\"only error segments\")\n",
    "        key['n_vertices'] = 0\n",
    "        key['n_triangles'] = 0\n",
    "        key['vertices'] = np.ndarray([])\n",
    "        key['triangles'] = np.ndarray([])\n",
    "        \n",
    "        print(\"This took \", time.time() - full_start, \"seconds.\")\n",
    "        print()\n",
    "        return key\n",
    "    \n",
    "    neighborhood = generate_neighborhood(mesh['triangles'], len(mesh['vertices']))\n",
    "    print(key['segment_id'] , \"neighborhood generated.\", time.time() - start)\n",
    "    start = time.time()\n",
    "    \n",
    "    mesh = remove_floating_artifacts(mesh,key,mesh_labels)\n",
    "    print(key['segment_id'], \"floating artifacts removed.\", time.time() - start)\n",
    "    start = time.time()\n",
    "\n",
    "    mesh = remove_isolated_vertices(mesh)\n",
    "    print(key['segment_id'], \"isolated nodes removed.\", time.time() - start)\n",
    "    start = time.time()\n",
    "\n",
    "    key['n_vertices'] = len(mesh['vertices'])\n",
    "    key['n_triangles'] = len(mesh['triangles'])\n",
    "    key['vertices'] = mesh['vertices']\n",
    "    key['triangles'] = mesh['triangles']\n",
    "\n",
    "    #self.insert1(key, skip_duplicates=True)\n",
    "    print(key['segment_id'], \"key successfully filtered.\", time.time() - start)\n",
    "    start = time.time()\n",
    "\n",
    "    print(\"This took \", time.time() - full_start, \"seconds.\")\n",
    "    print()\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output for the skeleton edges to be stored by datajoint\n",
    "\"\"\" OLD WAY THAT DATAJOINT WAS GETTING MAD AT \n",
    "def read_skeleton(file_path):\n",
    "    with open(file_path) as f:\n",
    "        bones = list()\n",
    "        for line in f.readlines():\n",
    "            bones.append(np.array(line.split()[1:], float).reshape(-1, 3))\n",
    "    return np.array(bones)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" NEW FLAT LIST WAY, this is outdated for one below\"\"\"\n",
    "#\n",
    "def read_skeleton_flat(file_path):\n",
    "    with open(file_path) as f:\n",
    "        bones = list()\n",
    "        for line in f.readlines():\n",
    "            for r in (np.array(line.split()[1:], float).reshape(-1, 3)):\n",
    "                bones.append(r)\n",
    "            bones.append([np.nan,np.nan,np.nan])\n",
    "    return np.array(bones).astype(float)\n",
    "\n",
    "\n",
    "\"\"\" New read function: for adjusted 2 vert skeleton output\"\"\"\n",
    "# def read_raw_skeleton(file_path):\n",
    "#     edges = list()\n",
    "#     with open(file_path) as f:\n",
    "#         reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONE)\n",
    "#         for i,row in enumerate(reader):\n",
    "#             v1 = (float(row[1]),float(row[2]),float(row[3]))\n",
    "#             v2 = (float(row[4]),float(row[5]),float(row[6]))\n",
    "#             edges.append((v1,v2))\n",
    "#     return np.array(edges).astype(float)\n",
    "\n",
    "\n",
    "def read_skeleton_revised(file_path):\n",
    "    with open(file_path) as f:\n",
    "        bones = np.array([])\n",
    "        for line in f.readlines():\n",
    "            #print(line)\n",
    "            line = (np.array(line.split()[1:], float).reshape(-1, 3))\n",
    "            #print(line[:-1])\n",
    "            #print(line[1:])\n",
    "\n",
    "            #print(bones.size)\n",
    "            if bones.size <= 0:\n",
    "                bones = np.stack((line[:-1],line[1:]),axis=1)\n",
    "            else:\n",
    "                bones = np.vstack((bones,(np.stack((line[:-1],line[1:]),axis=1))))\n",
    "            #print(bones)\n",
    "\n",
    "\n",
    "    return np.array(bones).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure there is a temp file in the directory, if not then make one\n",
    "#if temp folder doesn't exist then create it\n",
    "if (os.path.isdir(os.getcwd() + \"/pymesh_neurons\")) == False:\n",
    "    os.mkdir(\"pymesh_neurons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326\n"
     ]
    }
   ],
   "source": [
    "#keysource for neuron table\n",
    "pinky.CoarseLabelFinal()\n",
    "print(len(pinky.CoarseLabelFinal()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840\n"
     ]
    }
   ],
   "source": [
    "pinky.CoarseLabelOrphan()\n",
    "print(len(pinky.CoarseLabelOrphan()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        \n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">segmentation</p>\n",
       "                                <span class=\"djtooltiptext\">segmentation id</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">segment_id</p>\n",
       "                                <span class=\"djtooltiptext\">segment id unique within each Segmentation</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr> <td>3</td>\n",
       "<td>648518346341371119</td></tr><tr><td>3</td>\n",
       "<td>648518346349386137</td></tr><tr><td>3</td>\n",
       "<td>648518346349470171</td></tr><tr><td>3</td>\n",
       "<td>648518346349471156</td></tr><tr><td>3</td>\n",
       "<td>648518346349471500</td></tr><tr><td>3</td>\n",
       "<td>648518346349471562</td></tr><tr><td>3</td>\n",
       "<td>648518346349471565</td></tr><tr><td>3</td>\n",
       "<td>648518346349471910</td></tr><tr><td>3</td>\n",
       "<td>648518346349472574</td></tr><tr><td>3</td>\n",
       "<td>648518346349472601</td></tr><tr><td>3</td>\n",
       "<td>648518346349473044</td></tr><tr><td>3</td>\n",
       "<td>648518346349473160</td></tr><tr><td>3</td>\n",
       "<td>648518346349473583</td></tr><tr><td>3</td>\n",
       "<td>648518346349473597</td></tr><tr><td>3</td>\n",
       "<td>648518346349473804</td></tr><tr><td>3</td>\n",
       "<td>648518346349473811</td></tr><tr><td>3</td>\n",
       "<td>648518346349473813</td></tr><tr><td>3</td>\n",
       "<td>648518346349473821</td></tr><tr><td>3</td>\n",
       "<td>648518346349473830</td></tr><tr><td>3</td>\n",
       "<td>648518346349473833</td> </tr> </tbody>\n",
       "            </table>\n",
       "            <p>...</p>\n",
       "            <p>1166 tuples</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*segmentation  *segment_id   \n",
       "+------------+ +------------+\n",
       "3              64851834634137\n",
       "3              64851834634938\n",
       "3              64851834634947\n",
       "3              64851834634947\n",
       "3              64851834634947\n",
       "3              64851834634947\n",
       "3              64851834634947\n",
       "3              64851834634947\n",
       "3              64851834634947\n",
       "3              64851834634947\n",
       "3              64851834634947\n",
       "3              64851834634947\n",
       "3              64851834634947\n",
       "3              64851834634947\n",
       "3              64851834634947\n",
       "3              64851834634947\n",
       "3              64851834634947\n",
       "3              64851834634947\n",
       "3              64851834634947\n",
       "3              64851834634947\n",
       "   ...\n",
       " (1166 tuples)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns_table = ((dj.U(\"segmentation\",\"segment_id\") & pinky.CoarseLabelFinal.proj()) \n",
    "     + (dj.U(\"segmentation\",\"segment_id\") & pinky.CoarseLabelOrphan.proj()))\n",
    "print(len(ns_table))\n",
    "ns_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the output file\n",
    "##write the OFF file for the neuron\n",
    "import pathlib\n",
    "def write_Whole_Neuron_Off_file(neuron_ID,\n",
    "                                vertices=[], \n",
    "                                triangles=[],\n",
    "                                folder=\"pymesh_neurons\"):\n",
    "    #primary_key = dict(segmentation=1, segment_id=segment_id, decimation_ratio=0.35)\n",
    "    #vertices, triangles = (mesh_Table_35 & primary_key).fetch1('vertices', 'triangles')\n",
    "    \n",
    "    num_vertices = (len(vertices))\n",
    "    num_faces = len(triangles)\n",
    "    \n",
    "    #get the current file location\n",
    "    file_loc = pathlib.Path.cwd() / folder\n",
    "    filename = \"neuron_\" + str(neuron_ID)\n",
    "    path_and_filename = file_loc / filename\n",
    "    \n",
    "    #print(file_loc)\n",
    "    #print(path_and_filename)\n",
    "    \n",
    "    #open the file and start writing to it    \n",
    "    f = open(str(path_and_filename) + \".off\", \"w\")\n",
    "    f.write(\"OFF\\n\")\n",
    "    f.write(str(num_vertices) + \" \" + str(num_faces) + \" 0\\n\" )\n",
    "    \n",
    "    \n",
    "    #iterate through and write all of the vertices in the file\n",
    "    for verts in vertices:\n",
    "        f.write(str(verts[0]) + \" \" + str(verts[1]) + \" \" + str(verts[2])+\"\\n\")\n",
    "    \n",
    "    #print(\"Done writing verts\")\n",
    "        \n",
    "    for faces in triangles:\n",
    "        f.write(\"3 \" + str(faces[0]) + \" \" + str(faces[1]) + \" \" + str(faces[2])+\"\\n\")\n",
    "    \n",
    "    print(\"Done writing OFF file\")\n",
    "    #f.write(\"end\")\n",
    "    \n",
    "    return str(path_and_filename),str(filename),str(file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meshlab_fix_manifold(key,folder=\"pymesh_neurons\"):\n",
    "    \n",
    "    file_loc = pathlib.Path.cwd() / folder\n",
    "    filename = \"neuron_\" + str(key[\"segment_id\"])\n",
    "    path_and_filename = str(file_loc / filename)\n",
    "    \n",
    "    \n",
    "    input_mesh = path_and_filename + \".off\"\n",
    "    mid_mesh = path_and_filename + \"_pre_vert.off\"\n",
    "    output_mesh = path_and_filename+\"_mls.off\"\n",
    "    \n",
    "    meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"remeshing_fixing_seg_fault.mls\"\n",
    "    \n",
    "    print(\"starting remeshing_fixing_seg_fault\")\n",
    "    subprocess_result_1 = run_meshlab_script(meshlab_script,\n",
    "                      input_mesh,\n",
    "                      mid_mesh)\n",
    "    #print(\"Poisson subprocess_result= \"+ str(subprocess_result_1))\n",
    "    \n",
    "    if str(subprocess_result_1)[-13:] != \"returncode=0)\":\n",
    "        raise Exception('neuron' + str(key[\"segment_id\"]) + \n",
    "                         ' did not fix the manifold edges')\n",
    "    \n",
    "    meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"removing_duplicate_vertices.mls\"\n",
    "    \n",
    "    print(\"starting removing_duplicate_vertices\")\n",
    "    subprocess_result_1 = run_meshlab_script(meshlab_script,\n",
    "                      mid_mesh,\n",
    "                      output_mesh)\n",
    "    #print(\"Poisson subprocess_result= \"+ str(subprocess_result_1))\n",
    "    \n",
    "    if str(subprocess_result_1)[-13:] != \"returncode=0)\":\n",
    "        raise Exception('neuron' + str(key[\"segment_id\"]) + \n",
    "                         ' did not make it through vertex removal')\n",
    "    \n",
    "    return output_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_meshlab_script(mlx_script,input_mesh_file,output_mesh_file):\n",
    "    \n",
    "    \n",
    "    script_command = (\" -i \" + str(input_mesh_file) + \" -o \" + \n",
    "                                    str(output_mesh_file) + \" -s \" + str(mlx_script))\n",
    "    #return script_command\n",
    "    subprocess_result = subprocess.run('xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@ ' + \n",
    "                   script_command,shell=True)\n",
    "    \n",
    "    return subprocess_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location = \"./pymesh_neurons/\"\n",
    "# input_file =  \"neuron_648518346349499624.off\"\n",
    "# run_meshlab_script(location + \"remeshing_fixing_seg_fault.mls\",\n",
    "#                   location + \"neuron_648518346349499624.off\",\n",
    "#                   location + input_file[:-4] + \"_pinky_fix.off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location = \"./pymesh_neurons/\"\n",
    "# input_file =  \"neuron_648518346349499624_pinky_fix.off\"\n",
    "# run_meshlab_script(location + \"removing_duplicate_vertices.mls\",\n",
    "#                   location + input_file,\n",
    "#                   location + input_file[:-4] + \"_vert_dupl.off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class NeuronSkeleton(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> pinky.Mesh\n",
    "    ---\n",
    "    n_edges   :int unsigned #number of edges stored\n",
    "    edges     :longblob #array storing edges on each row\n",
    "    n_vertices   :int unsigned #number of vertices in mesh filtered of error segments\n",
    "    n_triangles  :int unsigned #number of faces in mesh filtered of error segments\n",
    "    vertices     :longblob #mesh data for vertices in mesh filtered of error segments\n",
    "    triangles    :longblob #mesh data for faces in mesh filtered of error segments\n",
    "     \n",
    "    \"\"\"\n",
    "    \n",
    "    key_source = ((dj.U(\"segmentation\",\"segment_id\") & pinky.CoarseLabelFinal.proj()) \n",
    "     + (dj.U(\"segmentation\",\"segment_id\") & pinky.CoarseLabelOrphan.proj()))\n",
    "    \n",
    "    #how you get the date and time  datetime.datetime.now()\n",
    "    \n",
    "    def make(self, key):\n",
    "        global_time = time.time()\n",
    "        #get the mesh with the error segments filtered away\n",
    "        start_time = time.time()\n",
    "        new_key = remove_error_segments(key)\n",
    "        print(f\"Step 1: Retrieving Mesh and removing error segments: {time.time() - start_time}\")\n",
    "        \n",
    "        #where i deal with the error segments\n",
    "        if new_key[\"vertices\"].size<2:\n",
    "            start_time = time.time()\n",
    "            print(\"All faces were error segments, inserting dummy entry\")\n",
    "            #create the key with None\n",
    "            new_key[\"n_vertices\"] = 0\n",
    "            new_key[\"n_triangles\"] = 0\n",
    "            new_key[\"vertices\"] = np.array([]).astype(float)\n",
    "            new_key[\"triangles\"] = np.array([]).astype(float)\n",
    "            new_key[\"n_edges\"] = 0\n",
    "            new_key[\"edges\"] = np.array([]).astype(float)\n",
    "            self.insert1(new_key,skip_duplicates=True)\n",
    "            \n",
    "            #insert dummy dictionary into correspondence table\n",
    "#             new_correspondence_dict = dict(segmentation=key[\"segmentation\"],\n",
    "#                                            segment_id=key[\"segment_id\"],\n",
    "#                                            time_updated=str(datetime.datetime.now()),\n",
    "#                                            n_correspondence = 0,\n",
    "#                                            correspondence=np.array([]).astype(float))\n",
    "            \n",
    "#             #if all goes well then write to correspondence database\n",
    "#             ta3p100.NeuronRawSkeletonCorrespondence.insert1(new_correspondence_dict,skip_duplicates=True)\n",
    "            \n",
    "            \n",
    "            print(f\"Step 2: Inserting dummy dictionary: {time.time() - start_time}\")\n",
    "            print(f\"Total time: {time.time() - global_time}\")\n",
    "            print(\"\\n\\n\")\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            #print(\"Step 2: Remove all error semgents\")\n",
    "            start_time = time.time()\n",
    "            #pass the vertices and faces to pymeshfix to become watertight\n",
    "            meshfix = pymeshfix.MeshFix(new_key[\"vertices\"],new_key[\"triangles\"])\n",
    "            meshfix.repair(verbose=False,joincomp=True,remove_smallest_components=False)\n",
    "            print(f\"Step 2: Pymesh shrinkwrapping: {time.time() - start_time}\")\n",
    "\n",
    "            #print(\"Step 2: Writing Off File\")\n",
    "            start_time = time.time()\n",
    "            #write the new mesh to off file\n",
    "            path_and_filename,filename,file_loc = write_Whole_Neuron_Off_file(str(new_key[\"segment_id\"]),meshfix.v,meshfix.f)\n",
    "            print(f\"Step 3: Writing shrinkwrap off file: {time.time() - start_time}\")\n",
    "\n",
    "            #Run the meshlabserver scripts\n",
    "            start_time = time.time()\n",
    "            output_mesh = meshlab_fix_manifold(key)\n",
    "            print(f\"Step 4: Meshlab fixing non-manifolds: {time.time() - start_time}\")\n",
    "\n",
    "            print(output_mesh[:-4])\n",
    "\n",
    "            #send to be skeletonized\n",
    "            start_time = time.time()\n",
    "            return_value = cm.calcification(output_mesh[:-4])\n",
    "            if return_value > 0:\n",
    "                raise Exception('skeletonization for neuron ' + str(new_key[\"segment_id\"]) + \n",
    "                                ' did not finish... exited with error code: ' + str(return_value))\n",
    "            #print(f\"Step 5: Generating Skeleton: {time.time() - start_time}\")\n",
    "\n",
    "\n",
    "\n",
    "            #read in the skeleton files into an array\n",
    "            #start_time = time.time()\n",
    "            \n",
    "            ##****** this needs to be changed for reading them in******\n",
    "            bone_array = read_skeleton_revised(output_mesh[:-4]+\"_skeleton.cgal\")\n",
    "            #correspondence_array = read_skeleton_revised(output_mesh[:-4]+\"_correspondance.cgal\")\n",
    "            #print(bone_array)\n",
    "            if len(bone_array) <= 0:\n",
    "                raise Exception('No skeleton generated for ' + str(new_key[\"segment_id\"]))\n",
    "            \n",
    "#             if len(correspondence_array) <= 0:\n",
    "#                 raise Exception('No CORRESPONDENCE generated for ' + str(new_key[\"segment_id\"]))\n",
    "                \n",
    "            print(f\"Step 5: Generating and reading Skeleton: {time.time() - start_time}\")\n",
    "\n",
    "\n",
    "            start_time = time.time()\n",
    "            \n",
    "            new_key[\"n_edges\"] = bone_array.shape[0]\n",
    "            new_key[\"edges\"] = bone_array\n",
    "            #new_key[\"branches\"] = []\n",
    "\n",
    "            #print(key)\n",
    "            #if all goes well then write to database\n",
    "            self.insert1(new_key,skip_duplicates=True)\n",
    "            \n",
    "            #create a new dictionary key to be inserted into correspondence table\n",
    "            \"\"\"\n",
    "            time_updated      :timestamp    # the time at which the component labels were updated\n",
    "            ---\n",
    "            n_correspondence   :int unsigned #number of mappings from skeleton vert to original surface vert \n",
    "            correspondence     :longblob #array storing mapping of every skeleton vert to original surface vert  \n",
    "            \"\"\"\n",
    "#             #insert dummy dictionary into correspondence table\n",
    "#             new_correspondence_dict = dict(segmentation=key[\"segmentation\"],\n",
    "#                                            segment_id=key[\"segment_id\"],\n",
    "#                                            time_updated=str(datetime.datetime.now()),\n",
    "#                                            n_correspondence = correspondence_array.shape[0],\n",
    "#                                            correspondence=correspondence_array)\n",
    "            \n",
    "#             #if all goes well then write to correspondence database\n",
    "#             ta3p100.NeuronRawSkeletonCorrespondence.insert1(new_correspondence_dict,skip_duplicates=True)\n",
    "            \n",
    "            \n",
    "            os.system(\"rm \"+str(path_and_filename)+\"*\")\n",
    "            print(f\"Step 6: Inserting both dictionaries: {time.time() - start_time}\")\n",
    "            print(f\"Total time: {time.time() - global_time}\")\n",
    "            print(\"\\n\\n\")\n",
    "          \n",
    "                         \n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pinky.NeuronSkeleton()#.delete()\n",
    "#(schema.jobs & \"table_name='__neuron_skeleton'\").delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648518346349503588:\n",
      "648518346349503588 mesh fetched. 0.18071722984313965\n",
      "Counter({3: 444852, 4: 174617, 2: 120248, 5: 61071, 6: 6915})\n",
      "648518346349503588 neighborhood generated. 6.098029613494873\n",
      "648518346349503588 floating artifacts removed. 1.136986494064331\n",
      "648518346349503588 isolated nodes removed. 8.86164927482605\n",
      "648518346349503588 key successfully filtered. 7.3909759521484375e-06\n",
      "This took  16.278417587280273 seconds.\n",
      "\n",
      "Step 1: Retrieving Mesh and removing error segments: 16.52729368209839\n",
      "Step 2: Pymesh shrinkwrapping: 46.60325765609741\n",
      "Done writing OFF file\n",
      "Step 3: Writing shrinkwrap off file: 4.570465087890625\n",
      "starting remeshing_fixing_seg_fault\n",
      "starting removing_duplicate_vertices\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "NeuronSkeleton.populate(reserve_jobs=True)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinky.NeuronSkeleton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
