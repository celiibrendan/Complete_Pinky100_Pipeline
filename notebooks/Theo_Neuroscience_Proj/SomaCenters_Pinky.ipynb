{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: To use the soma extraction algorithm to extract soma centers, meshes and bounding\n",
    "boxes for the pinky data set (to be used for theoretical neuroscience project)\n",
    "\n",
    "Thing have to do to make sure meshlab is there: export PATH=$PATH:/meshlab/src/distrib\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@10.28.0.34:3306\n"
     ]
    }
   ],
   "source": [
    "import cgal_Segmentation_Module as csm\n",
    "from whole_neuron_classifier_datajoint_adapted import extract_branches_whole_neuron\n",
    "import time\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import datajoint as dj\n",
    "\n",
    "dj.config['database.host'] = '10.28.0.34'\n",
    "dj.config['database.user'] = 'celiib'\n",
    "dj.config['database.password'] = 'newceliipass'\n",
    "pinky = dj.create_virtual_module('pinky', 'microns_pinky')\n",
    "schema = dj.schema(\"microns_pinky\")\n",
    "\n",
    "dj.config[\"display.limit\"] = 40\n",
    "dj.config[\"enable_python_native_blobs\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinky.SomaCenters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(schema.jobs & \"table_name='__soma_centers'\")#.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_meshlab_script(mlx_script,input_mesh_file,output_mesh_file):\n",
    "    script_command = (\" -i \" + str(input_mesh_file) + \" -o \" + \n",
    "                                    str(output_mesh_file) + \" -s \" + str(mlx_script))\n",
    "    #return script_command\n",
    "    command_to_run = 'xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@ ' + script_command\n",
    "    #command_to_run = 'meshlabserver ' + script_command\n",
    "    \n",
    "    print(command_to_run)\n",
    "    subprocess_result = subprocess.run(command_to_run,shell=True)\n",
    "    \n",
    "    return subprocess_result\n",
    "\n",
    "import os, contextlib\n",
    "import pathlib\n",
    "import subprocess\n",
    "def meshlab_fix_manifold_path_specific_mls(input_path_and_filename,\n",
    "                                           output_path_and_filename=\"\",\n",
    "                                           segment_id=-1,meshlab_script=\"\"):\n",
    "    #fix the path if it comes with the extension\n",
    "    if input_path_and_filename[-4:] == \".off\":\n",
    "        path_and_filename = input_path_and_filename[:-4]\n",
    "        input_mesh = input_path_and_filename\n",
    "    else:\n",
    "        raise Exception(\"Not passed off file\")\n",
    "    \n",
    "    \n",
    "    if output_path_and_filename == \"\":\n",
    "        output_mesh = path_and_filename+\"_mls.off\"\n",
    "    else:\n",
    "        output_mesh = output_path_and_filename\n",
    "    \n",
    "    if meshlab_script == \"\":\n",
    "        meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"remeshing_remove_non_man_edges.mls\"\n",
    "    \n",
    "    #print(\"meshlab_script = \" + str(meshlab_script))\n",
    "    #print(\"starting meshlabserver fixing non-manifolds\")\n",
    "    subprocess_result_1 = run_meshlab_script(meshlab_script,\n",
    "                      input_mesh,\n",
    "                      output_mesh)\n",
    "    #print(\"Poisson subprocess_result= \"+ str(subprocess_result_1))\n",
    "    \n",
    "    if str(subprocess_result_1)[-13:] != \"returncode=0)\":\n",
    "        raise Exception('neuron' + str(segment_id) + \n",
    "                         ' did not fix the manifold edges')\n",
    "    \n",
    "    return output_mesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soma_mesh = trimesh.load_mesh(\"../Platinum_Blender/soma_test.off\")\n",
    "# soma_mesh.show()\n",
    "# soma_mesh.bounding_box.vertices\n",
    "# soma_bounding_box_corners = np.stack([np.min(soma_mesh.bounding_box.vertices,axis=0),\n",
    "# np.max(soma_mesh.bounding_box.vertices,axis=0)])\n",
    "# soma_bounding_box_corners[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinky.PymeshfixDecimatedExcitatoryStitchedMesh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class SomaCenters(dj.Computed):\n",
    "    \n",
    "    definition=\"\"\"\n",
    "    -> pinky.PymeshfixDecimatedExcitatoryStitchedMesh\n",
    "    ---\n",
    "    soma_center             : longblob                 # the xyz coordinates of the soma (with the [4,4,40] adjustment already applied)\n",
    "    vertices            : longblob                     # vertices for soma mesh\n",
    "    faces                : longblob                    # faces array for soma mesh\n",
    "    bounding_box         : longblob                    # upper and lower corners for soma bounding box\n",
    "    bbox_x_min           : int unsigned                # minimum x value for the soma bounding box\n",
    "    bbox_x_max           : int unsigned                # maximum x value for the soma bounding box\n",
    "    bbox_y_min           : int unsigned                # minimum y value for the soma bounding box\n",
    "    bbox_y_max           : int unsigned                # maximum y value for the soma bounding box\n",
    "    bbox_z_min           : int unsigned                # minimum z value for the soma bounding box\n",
    "    bbox_z_max           : int unsigned                # maximum z value for the soma bounding box\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def make(self,key):\n",
    "        \n",
    "        segment_id = key[\"segment_id\"]\n",
    "        segmentation = key[\"segmentation\"]\n",
    "        print(\"\\n\\n******Working on neuron: \" + str(segment_id) + \"********\")\n",
    "        \n",
    "        \n",
    "        verts,faces = (pinky.PymeshfixDecimatedExcitatoryStitchedMesh & key).fetch(\"vertices\",\"triangles\")\n",
    "        new_mesh_vertices = verts[0]\n",
    "        new_mesh_faces = faces[0] \n",
    "        \"\"\"\n",
    "        .[************ retrieve the vertices and faces array of the mesh .[************\n",
    "        new_mesh_vertices, new_mesh_faces =\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        start MLS remeshing\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # make sure temp folder exists, if not then create one\n",
    "        import os\n",
    "        directory = \"./temp\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        \n",
    "        original_main = trimesh.Trimesh(new_mesh_vertices,new_mesh_faces)\n",
    "        output_mesh_name = \"temp/\" + str(segment_id) + \"_original.off\"\n",
    "        original_main.export(\"./\" + output_mesh_name)\n",
    "        \n",
    "        import pathlib\n",
    "        # run the meshlab server script\n",
    "        script_name = \"poisson_working_meshlab.mls\"\n",
    "        meshlab_script_path_and_name = str(pathlib.Path.cwd()) + \"/\" + script_name\n",
    "        input_path =str(pathlib.Path.cwd()) + \"/\" +  output_mesh_name\n",
    "\n",
    "        indices = [i for i, a in enumerate(input_path) if a == \"_\"]\n",
    "        stripped_ending = input_path[:-(len(input_path)-indices[-1])]\n",
    "\n",
    "        output_path = stripped_ending + \"_mls.off\"\n",
    "        print(meshlab_script_path_and_name)\n",
    "        print(input_path)\n",
    "        print(output_path)\n",
    "        print(\"Running the mls function\")\n",
    "        meshlab_fix_manifold_path_specific_mls(input_path_and_filename=input_path,\n",
    "                                                   output_path_and_filename=output_path,\n",
    "                                                   segment_id=segment_id,\n",
    "                                                   meshlab_script=meshlab_script_path_and_name)\n",
    "        \n",
    "        \"\"\"\n",
    "        start the CGAL segmentation:\n",
    "        \"\"\"\n",
    "        new_mesh = trimesh.load_mesh(output_path)\n",
    "        \n",
    "        mesh_splits = new_mesh.split(only_watertight=True)\n",
    "\n",
    "        len(\"Total mesh splits = \" + str(mesh_splits))\n",
    "        #get the largest mesh\n",
    "        mesh_lengths = np.array([len(split.faces) for split in mesh_splits])\n",
    "\n",
    "        # import matplotlib.pyplot as plt\n",
    "        # import seaborn as sns\n",
    "        # sns.set()\n",
    "        # sns.distplot(mesh_lengths)\n",
    "\n",
    "        largest_index = np.where(mesh_lengths == np.max(mesh_lengths))\n",
    "        largest_mesh = mesh_splits[largest_index][0]\n",
    "\n",
    "\n",
    "        indices = [i for i, a in enumerate(output_path) if a == \"_\"]\n",
    "        stripped_ending = output_path[:-(len(output_path)-indices[-1])]\n",
    "        largest_mesh_path = stripped_ending + \"_largest_piece.off\"\n",
    "\n",
    "        largest_mesh.export(largest_mesh_path)\n",
    "        print(\"done exporting\")\n",
    "        \n",
    "        \n",
    "        faces = np.array(largest_mesh.faces)\n",
    "        verts = np.array(largest_mesh.vertices)\n",
    "        #run the whole algorithm on the neuron to test\n",
    "        verts_labels, faces_labels = extract_branches_whole_neuron(import_Off_Flag=False,segment_id=segment_id,vertices=verts,\n",
    "                             triangles=faces,pymeshfix_Flag=False,\n",
    "                             import_CGAL_Flag=False,\n",
    "                             return_Only_Labels=True,\n",
    "                             clusters=3,\n",
    "                             smoothness=0.2)\n",
    "        \n",
    "        soma_faces = np.where(faces_labels == 5.0)[0]\n",
    "        soma_mesh = largest_mesh.submesh([soma_faces],append=True)\n",
    "        \n",
    "        soma_center = soma_mesh.vertices.mean(axis=0).astype(\"float\")\n",
    "        soma_center = soma_center/np.array([4,4,40])\n",
    "        print(\"Poor man's center from just averagin vertices = \" + str(soma_center))\n",
    "        \n",
    "        soma_bounding_box_corners = np.stack([np.min(soma_mesh.bounding_box.vertices,axis=0),\n",
    "            np.max(soma_mesh.bounding_box.vertices,axis=0)])\n",
    "\n",
    "        \n",
    "        insert_key = dict(key)\n",
    "        insert_key[\"soma_center\"] = soma_center\n",
    "        insert_key[\"vertices\"] = soma_mesh.vertices\n",
    "        insert_key[\"faces\"] = soma_mesh.faces\n",
    "        insert_key[\"bounding_box\"] = soma_bounding_box_corners\n",
    "        insert_key[\"bbox_x_min\"] = int(soma_bounding_box_corners[0,0])\n",
    "        insert_key[\"bbox_x_max\"] = int(soma_bounding_box_corners[1,0])\n",
    "        insert_key[\"bbox_y_min\"] = int(soma_bounding_box_corners[0,1])\n",
    "        insert_key[\"bbox_y_max\"] = int(soma_bounding_box_corners[1,1])\n",
    "        insert_key[\"bbox_z_min\"] = int(soma_bounding_box_corners[0,2])\n",
    "        insert_key[\"bbox_z_max\"] = int(soma_bounding_box_corners[1,2])\n",
    "        \n",
    "        #4) Insert the key into the table\n",
    "        self.insert1(insert_key,skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(schema.jobs & \"table_name='__soma_centers'\").delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(schema.jobs & \"table_name='__whole_auto_annotations_label_clusters3'\")#.delete()\n",
    "import time\n",
    "start_time = time.time()\n",
    "SomaCenters.populate(reserve_jobs=True)\n",
    "print(f\"Total time for SomaCenters populate = {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
