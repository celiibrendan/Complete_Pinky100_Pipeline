{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPurpose: To create a table that can be autopopulated to find the soma centeres\\n\\nWhat table will save: \\n- soma center\\n- soma mesh (vertices and triangles)\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose: To create a table that can be autopopulated to find the soma centeres\n",
    "- table will be a dj.Computed that will populate from whichever table created\n",
    "    by Christos and Stelios that has version numbers and ids of the postsynaptic targets\n",
    "\n",
    "What table will save: \n",
    "- soma center\n",
    "- soma mesh (vertices and triangles)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cgal_Segmentation_Module as csm\n",
    "from whole_neuron_classifier_datajoint_adapted import extract_branches_whole_neuron\n",
    "import time\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import datajoint as dj\n",
    "\n",
    "m65 = dj.create_virtual_module('m65', 'microns_minnie65_01')\n",
    "schema = dj.schema(\"microns_minnie65_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mesh stitching functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all the meshes into one mesh\n",
    "def add_mesh_piece(main_mesh_vertices,main_mesh_faces,sub_mesh_vertices,sub_mesh_faces):\n",
    "    \"\"\"\n",
    "    Purpose: Takes in a large mesh piece and an array of other meshes and \n",
    "    returns a large mesh with all meshes appended\n",
    "    \n",
    "    Parameters:\n",
    "    main_mesh_vertices (np.array) : np array store the vertices as rows and the elements as the coordinates\n",
    "    main_mesh_faces (np.array) : np array store the faces as rows and the elements as the referenced vertices\n",
    "    sub_mesh_vertices(list of np.arrays) : list of np arrays with the vertices arrays for all subsegments to be added\n",
    "    sub_mesh_faces(list of np.arrays) : list of np arrays with the faces arrays for all subsegments to be added\n",
    "    \n",
    "    Returns:\n",
    "    mesh_vertices (np.array) : np array store the vertices as rows and the elements as the coordinates for NEW CONCATENATED MESH\n",
    "    mesh_faces (np.array) : np array store the faces as rows and the elements as the referenced vertices for NEW CONCATENATED MESH\n",
    "    \n",
    "    \n",
    "    Pseudocode: \n",
    "    - Checks: \n",
    "    a. Make sure there sub_mesh arrays are greater than 0 and of the same length\n",
    "\n",
    "    1) Count the number of vertices and faces in the main mesh\n",
    "    2) Iterate through the submesh vertices and faces. In loop:\n",
    "    a. Count the number of vertices in the submesh and concate the vertices arrays to the main mesh array\n",
    "    b. Add the vertices_count and add that to every number in the faces array\n",
    "    c. Concatenate the submesh faces onto the larger mesh face\n",
    "    d. Save this new vertices and faces as the main_mesh verts and faces\n",
    "    e. Print out how many new vertices and faces added\n",
    "    3) Print out number of segments added, total faces/vertices for new mesh\n",
    "    4) Return the main mesh vertices and faces\n",
    "    \n",
    "    \"\"\"\n",
    "    #a. Make sure there sub_mesh arrays are greater than 0 and of the same length\n",
    "    if len(sub_mesh_vertices) <= 0:\n",
    "        print(\"There were no vertices in submesh to add, returning main mesh\")\n",
    "        return main_mesh_vertices, main_mesh_faces\n",
    "    if len(sub_mesh_faces) <= 0:\n",
    "        print(\"There were no face in submesh to add, returning main mesh\")\n",
    "        return main_mesh_vertices, main_mesh_faces\n",
    "    if len(sub_mesh_faces) != len(sub_mesh_vertices):\n",
    "        raise Exception(\"The sub_mesh_faces and sub_mesh_vertices length did not match\")\n",
    "        \n",
    "    \n",
    "    #1) Count the number of vertices and faces in the main mesh\n",
    "    n_main_vertices = len(main_mesh_vertices)\n",
    "    n_main_faces = len(main_mesh_faces)\n",
    "    \n",
    "    \n",
    "    #2) Iterate through the submesh vertices and faces. In loop:\n",
    "    for i,(sub_verts, sub_faces) in enumerate(zip(sub_mesh_vertices,sub_mesh_faces)):\n",
    "        #a. Count the number of vertices in the submesh and concate the vertices arrays to the main mesh array\n",
    "        n_sub_verts = len(sub_verts)\n",
    "        n_sub_faces = len(sub_faces)\n",
    "        \n",
    "        main_mesh_vertices = np.vstack([main_mesh_vertices,sub_verts])\n",
    "\n",
    "        \n",
    "        #b. Add the vertices_count of main to every number in the faces array\n",
    "        sub_faces = sub_faces + n_main_vertices\n",
    "        \n",
    "        #c. Concatenate the submesh faces onto the larger mesh face\n",
    "        main_mesh_faces = np.vstack([main_mesh_faces,sub_faces])\n",
    "        \n",
    "        #d. Save this new vertices and faces as the main_mesh verts and faces (DONE)\n",
    "        \n",
    "        #e. Print out how many new vertices and faces added\n",
    "        #print(f\"Added subsegment {i} with {n_sub_verts} vertices and {n_sub_faces} faces\")\n",
    "        \n",
    "        n_main_vertices = len(main_mesh_vertices)\n",
    "        n_main_faces = len(main_mesh_faces)\n",
    "    \n",
    "    #3) Print out number of segments added, total faces/vertices for new mesh  \n",
    "    print(f\"Added {len(sub_mesh_vertices)} subsegements \\n  --> final mesh: {len(main_mesh_vertices)} vertices and {len(main_mesh_faces)} faces\")\n",
    "        \n",
    "    return main_mesh_vertices,main_mesh_faces "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# meshlab functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_meshlab_script(mlx_script,input_mesh_file,output_mesh_file):\n",
    "    script_command = (\" -i \" + str(input_mesh_file) + \" -o \" + \n",
    "                                    str(output_mesh_file) + \" -s \" + str(mlx_script))\n",
    "    #return script_command\n",
    "    command_to_run = 'xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@ ' + script_command\n",
    "    #command_to_run = 'meshlabserver ' + script_command\n",
    "    \n",
    "    print(command_to_run)\n",
    "    subprocess_result = subprocess.run(command_to_run,shell=True)\n",
    "    \n",
    "    return subprocess_result\n",
    "\n",
    "import os, contextlib\n",
    "import pathlib\n",
    "import subprocess\n",
    "def meshlab_fix_manifold_path_specific_mls(input_path_and_filename,\n",
    "                                           output_path_and_filename=\"\",\n",
    "                                           segment_id=-1,meshlab_script=\"\"):\n",
    "    #fix the path if it comes with the extension\n",
    "    if input_path_and_filename[-4:] == \".off\":\n",
    "        path_and_filename = input_path_and_filename[:-4]\n",
    "        input_mesh = input_path_and_filename\n",
    "    else:\n",
    "        raise Exception(\"Not passed off file\")\n",
    "    \n",
    "    \n",
    "    if output_path_and_filename == \"\":\n",
    "        output_mesh = path_and_filename+\"_mls.off\"\n",
    "    else:\n",
    "        output_mesh = output_path_and_filename\n",
    "    \n",
    "    if meshlab_script == \"\":\n",
    "        meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"remeshing_remove_non_man_edges.mls\"\n",
    "    \n",
    "    #print(\"meshlab_script = \" + str(meshlab_script))\n",
    "    #print(\"starting meshlabserver fixing non-manifolds\")\n",
    "    subprocess_result_1 = run_meshlab_script(meshlab_script,\n",
    "                      input_mesh,\n",
    "                      output_mesh)\n",
    "    #print(\"Poisson subprocess_result= \"+ str(subprocess_result_1))\n",
    "    \n",
    "    if str(subprocess_result_1)[-13:] != \"returncode=0)\":\n",
    "        raise Exception('neuron' + str(segment_id) + \n",
    "                         ' did not fix the manifold edges')\n",
    "    \n",
    "    return output_mesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "def SomaCenters(dj.Computed):\n",
    "    \n",
    "    definition=\"\"\"\n",
    "    -> m65.[************TABLE TO BE FILLED IN***********************]\n",
    "    ---\n",
    "    soma_center             : longblob                 # the xyz coordinates of the soma (with the [4,4,40] adjustment already applied)\n",
    "    vertices            : longblob                     # vertices for soma mesh\n",
    "    faces                : longblob                    # faces array for soma mesh\n",
    "    \"\"\"\n",
    "    \n",
    "    def make(self,key):\n",
    "        segment_id = key[\"segment_id\"]\n",
    "        version = key[\"version\"]\n",
    "        \n",
    "        \"\"\"\n",
    "        .[************ retrieve the vertices and faces array of the mesh .[************\n",
    "        new_mesh_vertices, new_mesh_faces =\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        start MLS remeshing\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # make sure temp folder exists, if not then create one\n",
    "        import os\n",
    "        directory = \"./temp\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        \n",
    "        original_main = trimesh.Trimesh(new_mesh_vertices,new_mesh_faces)\n",
    "        output_mesh_name = \"temp/\" + str(segment_id) + \"_original.off\"\n",
    "        original_main.export(\"./\" + output_mesh_name)\n",
    "        \n",
    "        import pathlib\n",
    "        # run the meshlab server script\n",
    "        script_name = \"poisson_working_meshlab.mls\"\n",
    "        meshlab_script_path_and_name = str(pathlib.Path.cwd()) + \"/\" + script_name\n",
    "        input_path =str(pathlib.Path.cwd()) + \"/\" +  output_mesh_name\n",
    "\n",
    "        indices = [i for i, a in enumerate(input_path) if a == \"_\"]\n",
    "        stripped_ending = input_path[:-(len(input_path)-indices[-1])]\n",
    "\n",
    "        output_path = stripped_ending + \"_mls.off\"\n",
    "        print(meshlab_script_path_and_name)\n",
    "        print(input_path)\n",
    "        print(output_path)\n",
    "        print(\"Running the mls function\")\n",
    "        meshlab_fix_manifold_path_specific_mls(input_path_and_filename=input_path,\n",
    "                                                   output_path_and_filename=output_path,\n",
    "                                                   segment_id=segment_id,\n",
    "                                                   meshlab_script=meshlab_script_path_and_name)\n",
    "        \n",
    "        \"\"\"\n",
    "        start the CGAL segmentation:\n",
    "        \"\"\"\n",
    "        new_mesh = trimesh.load_mesh(output_path)\n",
    "        \n",
    "        mesh_splits = new_mesh.split(only_watertight=True)\n",
    "\n",
    "        len(\"Total mesh splits = \" + str(mesh_splits))\n",
    "        #get the largest mesh\n",
    "        mesh_lengths = np.array([len(split.faces) for split in mesh_splits])\n",
    "\n",
    "        # import matplotlib.pyplot as plt\n",
    "        # import seaborn as sns\n",
    "        # sns.set()\n",
    "        # sns.distplot(mesh_lengths)\n",
    "\n",
    "        largest_index = np.where(mesh_lengths == np.max(mesh_lengths))\n",
    "        largest_mesh = mesh_splits[largest_index][0]\n",
    "\n",
    "\n",
    "        indices = [i for i, a in enumerate(output_path) if a == \"_\"]\n",
    "        stripped_ending = output_path[:-(len(output_path)-indices[-1])]\n",
    "        largest_mesh_path = stripped_ending + \"_largest_piece.off\"\n",
    "\n",
    "        largest_mesh.export(largest_mesh_path)\n",
    "        print(\"done exporting\")\n",
    "        \n",
    "        \n",
    "        faces = np.array(largest_mesh.faces)\n",
    "        verts = np.array(largest_mesh.vertices)\n",
    "        #run the whole algorithm on the neuron to test\n",
    "        verts_labels, faces_labels = extract_branches_whole_neuron(import_Off_Flag=False,segment_id=segment_id,vertices=verts,\n",
    "                             triangles=faces,pymeshfix_Flag=False,\n",
    "                             import_CGAL_Flag=False,\n",
    "                             return_Only_Labels=True,\n",
    "                             clusters=3,\n",
    "                             smoothness=0.2)\n",
    "        \n",
    "        soma_faces = np.where(faces_labels == 5.0)[0]\n",
    "        soma_mesh = largest_mesh.submesh([soma_faces],append=True)\n",
    "        \n",
    "        soma_center = soma_mesh.vertices.mean(axis=0).astype(\"float\")\n",
    "        soma_center = soma_center/np.array([4,4,40])\n",
    "        print(\"Poor man's center from just averagin vertices = \" + str(soma_center))\n",
    "        \n",
    "        \n",
    "        \n",
    "        insert_key = dict(key)\n",
    "        insert_key[\"soma_center\"] = soma_center\n",
    "        insert_key[\"vertices\"] = soma_mesh.vertices\n",
    "        insert_key[\"faces\"] = soma_mesh.faces\n",
    "        \n",
    "        #4) Insert the key into the table\n",
    "        self.insert1(insert_key,skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(schema.jobs & \"table_name='__whole_auto_annotations_label_clusters3'\")#.delete()\n",
    "import time\n",
    "start_time = time.time()\n",
    "SomaCenters.populate(reserve_jobs=True)\n",
    "print(f\"Total time for SomaCenters populate = {time.time() - start_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
