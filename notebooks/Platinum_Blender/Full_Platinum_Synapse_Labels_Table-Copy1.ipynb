{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPurpose: \\nWill populate the SynapseCompartmentLabels table\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose: \n",
    "Will populate the SynapseCompartmentLabels table\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "import numpy as np\n",
    "\n",
    "import datajoint as dj\n",
    "import numpy as np\n",
    "from pykdtree.kdtree import KDTree\n",
    "import time\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "m65 = dj.create_virtual_module('m65', 'microns_minnie65_01')\n",
    "schema = dj.schema(\"microns_minnie65_01\")\n",
    "pinky = dj.create_virtual_module(\"pinky\",\"microns_pinky\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all the meshes into one mesh\n",
    "def add_mesh_piece(main_mesh_vertices,main_mesh_faces,sub_mesh_vertices,sub_mesh_faces):\n",
    "    \"\"\"\n",
    "    Purpose: Takes in a large mesh piece and an array of other meshes and \n",
    "    returns a large mesh with all meshes appended\n",
    "    \n",
    "    Parameters:\n",
    "    main_mesh_vertices (np.array) : np array store the vertices as rows and the elements as the coordinates\n",
    "    main_mesh_faces (np.array) : np array store the faces as rows and the elements as the referenced vertices\n",
    "    sub_mesh_vertices(list of np.arrays) : list of np arrays with the vertices arrays for all subsegments to be added\n",
    "    sub_mesh_faces(list of np.arrays) : list of np arrays with the faces arrays for all subsegments to be added\n",
    "    \n",
    "    Returns:\n",
    "    mesh_vertices (np.array) : np array store the vertices as rows and the elements as the coordinates for NEW CONCATENATED MESH\n",
    "    mesh_faces (np.array) : np array store the faces as rows and the elements as the referenced vertices for NEW CONCATENATED MESH\n",
    "    \n",
    "    \n",
    "    Pseudocode: \n",
    "    - Checks: \n",
    "    a. Make sure there sub_mesh arrays are greater than 0 and of the same length\n",
    "\n",
    "    1) Count the number of vertices and faces in the main mesh\n",
    "    2) Iterate through the submesh vertices and faces. In loop:\n",
    "    a. Count the number of vertices in the submesh and concate the vertices arrays to the main mesh array\n",
    "    b. Add the vertices_count and add that to every number in the faces array\n",
    "    c. Concatenate the submesh faces onto the larger mesh face\n",
    "    d. Save this new vertices and faces as the main_mesh verts and faces\n",
    "    e. Print out how many new vertices and faces added\n",
    "    3) Print out number of segments added, total faces/vertices for new mesh\n",
    "    4) Return the main mesh vertices and faces\n",
    "    \n",
    "    \"\"\"\n",
    "    #a. Make sure there sub_mesh arrays are greater than 0 and of the same length\n",
    "    if len(sub_mesh_vertices) <= 0:\n",
    "        print(\"There were no vertices in submesh to add, returning main mesh\")\n",
    "        return main_mesh_vertices, main_mesh_faces\n",
    "    if len(sub_mesh_faces) <= 0:\n",
    "        print(\"There were no face in submesh to add, returning main mesh\")\n",
    "        return main_mesh_vertices, main_mesh_faces\n",
    "    if len(sub_mesh_faces) != len(sub_mesh_vertices):\n",
    "        raise Exception(\"The sub_mesh_faces and sub_mesh_vertices length did not match\")\n",
    "        \n",
    "    \n",
    "    #1) Count the number of vertices and faces in the main mesh\n",
    "    n_main_vertices = len(main_mesh_vertices)\n",
    "    n_main_faces = len(main_mesh_faces)\n",
    "    \n",
    "    \n",
    "    #2) Iterate through the submesh vertices and faces. In loop:\n",
    "    for i,(sub_verts, sub_faces) in enumerate(zip(sub_mesh_vertices,sub_mesh_faces)):\n",
    "        #a. Count the number of vertices in the submesh and concate the vertices arrays to the main mesh array\n",
    "        n_sub_verts = len(sub_verts)\n",
    "        n_sub_faces = len(sub_faces)\n",
    "        \n",
    "        main_mesh_vertices = np.vstack([main_mesh_vertices,sub_verts])\n",
    "\n",
    "        \n",
    "        #b. Add the vertices_count of main to every number in the faces array\n",
    "        sub_faces = sub_faces + n_main_vertices\n",
    "        \n",
    "        #c. Concatenate the submesh faces onto the larger mesh face\n",
    "        main_mesh_faces = np.vstack([main_mesh_faces,sub_faces])\n",
    "        \n",
    "        #d. Save this new vertices and faces as the main_mesh verts and faces (DONE)\n",
    "        \n",
    "        #e. Print out how many new vertices and faces added\n",
    "        #print(f\"Added subsegment {i} with {n_sub_verts} vertices and {n_sub_faces} faces\")\n",
    "        \n",
    "        n_main_vertices = len(main_mesh_vertices)\n",
    "        n_main_faces = len(main_mesh_faces)\n",
    "    \n",
    "    #3) Print out number of segments added, total faces/vertices for new mesh  \n",
    "    print(f\"Added {len(sub_mesh_vertices)} subsegements \\n  --> final mesh: {len(main_mesh_vertices)} vertices and {len(main_mesh_faces)} faces\")\n",
    "        \n",
    "    return main_mesh_vertices,main_mesh_faces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_synapse_labels_to_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class SynapseCompartmentLabel(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    -> m65.FromNeuromancer\n",
    "    decimation_ratio     : decimal(3,2)                 # percentage that the faces are decimated\n",
    "    -> m65.Synapse\n",
    "    ---\n",
    "    (presynaptic_label)->m65.LabelKey\n",
    "    \"\"\" # (postsynaptic_label)->pinky.LabelKey : tinyint unsigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_proofread_key = dict(version = 0,\n",
    "                    decimation_ratio = 1.00,\n",
    "                    author = \"celiib\",\n",
    "                    status=\"complete\")\n",
    "\n",
    "write_synapse_labels_to_database(complete_proofread_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/datajoint/connection.py:215: UserWarning: MySQL server has gone away. Reconnecting to the server.\n",
      "  warnings.warn(\"MySQL server has gone away. Reconnecting to the server.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 46 subsegements \n",
      "  --> final mesh: 1252162 vertices and 2390205 faces\n"
     ]
    }
   ],
   "source": [
    "#get all the neurons for that user that have complete status (aka have been proofread)\n",
    "proofread_segment_ids = (m65.ProofreadLabel & complete_proofread_key).fetch(\"segment_id\")\n",
    "proofread_segment_ids\n",
    "\n",
    "\n",
    "meshes = dict()\n",
    "labels = dict()\n",
    "kdtrees = dict()\n",
    "mesh_synapses = dict()\n",
    "\n",
    "version = complete_proofread_key[\"version\"]\n",
    "decimation_ratio = complete_proofread_key[\"decimation_ratio\"]\n",
    "author = complete_proofread_key[\"author\"]\n",
    "criteria_id=1 # ******* RIGHT NOW SET TO A CELII TEST ******\n",
    "\n",
    "    \n",
    "for segment_id in proofread_segment_ids:\n",
    "    # Practicing how to get the mesh and the full subsegments list\n",
    "\n",
    "    version = complete_proofread_key[\"version\"]\n",
    "    decimation_ratio = complete_proofread_key[\"decimation_ratio\"]\n",
    "    author = complete_proofread_key[\"author\"]\n",
    "\n",
    "    key = dict(segment_id=segment_id, version = version)\n",
    "    n = (m65.FromNeuromancer & key).fetch1()\n",
    "\n",
    "    #get all of the segments and their data=\n",
    "    subsegments = (m65.FromNeuromancer.Subsegment & key).fetch(as_dict=True)\n",
    "    subsegment_dicts = dict([(k[\"subsegment_id\"],dict(vertices=k[\"vertices\"],faces=k[\"faces\"])) for k in subsegments])\n",
    "\n",
    "    subsegment_ordered_list = np.sort(np.array(list(subsegment_dicts.keys())))\n",
    "    subsegments_vertices = [subsegment_dicts[k][\"vertices\"] for k in subsegment_ordered_list]\n",
    "    subsegments_faces = [subsegment_dicts[k][\"faces\"] for k in subsegment_ordered_list]\n",
    "\n",
    "    # creating the entire mesh from the main mesh and all of its sub meshes: \n",
    "    new_mesh_vertices, new_mesh_faces = add_mesh_piece(main_mesh_vertices=n[\"vertices\"],\n",
    "                       main_mesh_faces=n[\"faces\"],\n",
    "                       sub_mesh_vertices = subsegments_vertices,\n",
    "                       sub_mesh_faces=subsegments_faces)\n",
    "\n",
    "    #get the segment labels\n",
    "\n",
    "\n",
    "    #find the synapses for neuron and all subsegments\n",
    "    lookup_key = dict(segment_id=segment_id,version = version)\n",
    "    subsegment_ids = list((m65.FromNeuromancer.Subsegment & lookup_key).fetch(\"subsegment_id\"))\n",
    "    subsegment_ids.append(segment_id)\n",
    "    segment_synapses = np.array((m65.Synapse() & [dict(presyn=k) for k in subsegment_ids]).fetch('synapse_id', 'centroid_x', 'centroid_y', 'centroid_z')).T\n",
    "\n",
    "    #\n",
    "    labels_search_key = dict(complete_proofread_key,\n",
    "                            segment_id=segment_id)\n",
    "\n",
    "    segment_vert_labels, segment_tri_labels = (m65.ProofreadLabel() & labels_search_key).fetch1(\"vertices\",\"triangles\")\n",
    "    len(segment_vert_labels)\n",
    "\n",
    "    if len(segment_vert_labels) <= 0:\n",
    "        print(f\"Skipping the mesh {segment_id} because it has no labels\")\n",
    "        \n",
    "    #Add the data to the corresponding lists\n",
    "    meshes[segment_id] = (new_mesh_vertices, new_mesh_faces)\n",
    "    labels[segment_id] = (segment_vert_labels, segment_tri_labels)\n",
    "    kdtrees[segment_id] = KDTree(meshes[segment_id][0])\n",
    "    mesh_synapses[segment_id]  = segment_synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "201it [00:00, 189621.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 37.86it/s]\n"
     ]
    }
   ],
   "source": [
    "matched_synapses = dict()\n",
    "synapses_to_exclude = []\n",
    "for segment_id in tqdm(proofread_segment_ids):\n",
    "    synapses = mesh_synapses[segment_id]\n",
    "    synapse_ids, postsyn_coords = synapses.T[0], synapses.T[1:].T\n",
    "    kdtree = kdtrees[segment_id]\n",
    "    distances, nearest_nodes = kdtree.query(postsyn_coords * [4, 4, 40])\n",
    "    vertex_labels = labels[segment_id][0]\n",
    "    synapse_labels = dict()\n",
    "    \n",
    "    for synapse_id, nearest_node, distance_node in tqdm(zip(synapse_ids, nearest_nodes,distances)):\n",
    "        if distance_node > 5000:\n",
    "            synapses_to_exclude.append(dict(version=version,synapse_id=synapse_id,\n",
    "                                           criteria_id=criteria_id))\n",
    "        else:\n",
    "            synapse_labels[synapse_id] = vertex_labels[nearest_node]\n",
    "    matched_synapses[segment_id] = synapse_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add to synapse exclude\n",
    "m65.SynapseExclude.insert(synapses_to_exclude,skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1418.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06125974655151367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_synapse_labels = list()\n",
    "for segment_id,labeled_synapses in tqdm(matched_synapses.items()):\n",
    "    version_array = np.array([version] * len(labeled_synapses))\n",
    "    decimation_ratio_array = np.array([decimation_ratio] * len(labeled_synapses))\n",
    "    segment_id_array = np.array([segment_id] * len(labeled_synapses))\n",
    "    synapse_to_label = np.array(list(labeled_synapses.items())).T\n",
    "    proper_label_array = np.array((segment_id_array,\n",
    "                                   version_array,\n",
    "                                   decimation_ratio_array,\n",
    "                                    *synapse_to_label)).T\n",
    "    all_synapse_labels.extend(proper_label_array)\n",
    "all_synapse_labels_array = np.array(all_synapse_labels)\n",
    "\n",
    "all_synapse_labels_array = [ [int(k[0]), int(k[1]), float(k[2]), int(k[3]), int(k[4])] for k in   all_synapse_labels_array]\n",
    "\n",
    "start = time.time()\n",
    "SynapseCompartmentLabel.insert(all_synapse_labels_array, skip_duplicates=True)\n",
    "print(f\"Fininshed inserting synapse labels: Took {time.time() - start} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
