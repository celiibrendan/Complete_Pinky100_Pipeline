{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import contextlib\n",
    "\n",
    "def print_trimesh(current_mesh,file_name):\n",
    "    with open(os.devnull, \"w\") as f, contextlib.redirect_stdout(f):\n",
    "        current_mesh.export(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinky = dj.create_virtual_module(\"pinky\",\"microns_pinky\")\n",
    "ta3p100 = dj.create_virtual_module(\"ta3p100\",\"microns_ta3p100\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_id == None\n",
    "mesh_index = 2\n",
    "\n",
    "if segment_id == None:\n",
    "    #gets the possible segment ids\n",
    "    segment_ids = (pinky.AllenSoma() & \"cell_class='excitatory'\").fetch(\"segment_id\")\n",
    "    neuron_id = segment_ids[mesh_index]\n",
    "else:\n",
    "    neuron_id = segment_id\n",
    "\n",
    "print(neuron_id)\n",
    "key = dict(segment_id=segment_ids[mesh_index],segmentation=3)\n",
    "vertices,triangles = (pinky.Mesh & key).fetch(\"vertices\",\"triangles\")\n",
    "\n",
    "unfiltered_mesh = trimesh.Trimesh()\n",
    "unfiltered_mesh.vertices = vertices[0]\n",
    "unfiltered_mesh.faces = triangles[0]\n",
    "#new_mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_mesh_significant_outside_pieces(unfiltered_mesh,significance_threshold=2000,n_sample_points=1000):\n",
    "    \"\"\"\n",
    "    Purpose; will take in a full, unfiltered mesh and find the biggest mesh piece, and then return a list of that mesh \n",
    "    with all of the other mesh fragments that are both above the significance_threshold AND outside of the biggest mesh piece\n",
    "\n",
    "    Pseudocode: \n",
    "    1) split the meshes to unconnected pieces\n",
    "    2) Filter the meshes for only those above the significance_threshold\n",
    "    3) find the biggest mesh piece\n",
    "    4) Iterate through all of the remaining pieces:\n",
    "        a. Determine if mesh inside or outside main mesh\n",
    "        b. If outside add to final list to return\n",
    "\n",
    "    Returns: \n",
    "    1) list of significant mesh pieces, including the main one that are not inside of main mesh\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    mesh_pieces = unfiltered_mesh.split(only_watertight=False)\n",
    "    \n",
    "    print(f\"There were {len(mesh_pieces)} pieces after mesh split\")\n",
    "\n",
    "    significant_pieces = [m for m in mesh_pieces if len(m.faces) > significance_threshold]\n",
    "\n",
    "    print(f\"There were {len(significant_pieces)} pieces found after size threshold\")\n",
    "    if len(significant_pieces) <=0:\n",
    "        print(\"THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\")\n",
    "        return []\n",
    "\n",
    "    #find piece with largest size\n",
    "    max_index = 0\n",
    "    max_face_len = len(significant_pieces[max_index].faces)\n",
    "\n",
    "    for i in range(1,len(significant_pieces)):\n",
    "        if max_face_len < len(significant_pieces[i].faces):\n",
    "            max_index = i\n",
    "            max_face_len = len(significant_pieces[i].faces)\n",
    "\n",
    "    print(\"max_index = \" + str(max_index))\n",
    "    print(\"max_face_len = \" + str(max_face_len))\n",
    "\n",
    "    final_mesh_pieces = []\n",
    "\n",
    "    main_mesh = significant_pieces[max_index]\n",
    "\n",
    "    #final_mesh_pieces.append(main_mesh)\n",
    "    for i,mesh in enumerate(significant_pieces):\n",
    "        if i != max_index:\n",
    "            #get a random sample of points\n",
    "            # points = np.array(mesh.vertices[:n_sample_points,:]) # OLD WAY OF DOING THIS\n",
    "            idx = np.random.randint(len(mesh.vertices), size=n_sample_points)\n",
    "            points = mesh.vertices[idx,:]\n",
    "            \n",
    "            \n",
    "            start_time = time.time()\n",
    "            signed_distance = trimesh.proximity.signed_distance(main_mesh,points)\n",
    "            print(f\"Total time = {time.time() - start_time}\")\n",
    "\n",
    "            outside_percentage = sum(signed_distance < 0)/n_sample_points\n",
    "            if outside_percentage > 0.9:\n",
    "                final_mesh_pieces.append(mesh)\n",
    "                print(f\"Mesh piece {i} OUTSIDE mesh\")\n",
    "            else:\n",
    "                print(f\"Mesh piece {i} inside mesh :( \")\n",
    "                \n",
    "    return main_mesh,final_mesh_pieces\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs the filtering function for inside and outside meshes\n",
    "global_timer = time.time()\n",
    "\n",
    "\n",
    "#setting thresholds\n",
    "significance_threshold=10 #number of faces needed for pieces to be considered to be kept\n",
    "n_sample_points = 3 #number of points sampled on the mesh for determination of inside or outside\n",
    "start_time = time.time()\n",
    "\n",
    "#the main mesh is the first mesh in the piece\n",
    "main_mesh,child_meshes = filter_mesh_significant_outside_pieces(unfiltered_mesh,\n",
    "                            significance_threshold=significance_threshold,\n",
    "                                n_sample_points=n_sample_points)\n",
    "print(f\"Total time for Mesh Cleansing: {time.time() - start_time}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOW TO SAVE AND LOAD OF THE MESHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
