{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFirst attempt to combine all functionality in one function\\nthat can be run from top to bottom\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "First attempt to combine all functionality in one function\n",
    "that can be run from top to bottom\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gets parts that are outside of the main mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 4 pieces after mesh split\n",
      "There were 4 pieces found after size threshold\n",
      "max_index = 1\n",
      "max_face_len = 12664\n",
      "Total time = 0.2384178638458252\n",
      "Mesh piece 0 OUTSIDE mesh\n",
      "Total time = 0.004962444305419922\n",
      "Mesh piece 2 OUTSIDE mesh\n",
      "Total time = 0.05995750427246094\n",
      "Mesh piece 3 OUTSIDE mesh\n",
      "Total time for Mesh Cleansing: 0.3820939064025879\n"
     ]
    }
   ],
   "source": [
    "def filter_mesh_significant_outside_pieces(unfiltered_mesh,significance_threshold=2000,n_sample_points=1000):\n",
    "    \"\"\"\n",
    "    Purpose; will take in a full, unfiltered mesh and find the biggest mesh piece, and then return a list of that mesh \n",
    "    with all of the other mesh fragments that are both above the significance_threshold AND outside of the biggest mesh piece\n",
    "\n",
    "    Pseudocode: \n",
    "    1) split the meshes to unconnected pieces\n",
    "    2) Filter the meshes for only those above the significance_threshold\n",
    "    3) find the biggest mesh piece\n",
    "    4) Iterate through all of the remaining pieces:\n",
    "        a. Determine if mesh inside or outside main mesh\n",
    "        b. If outside add to final list to return\n",
    "\n",
    "    Returns: \n",
    "    1) list of significant mesh pieces, including the main one that are not inside of main mesh\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    mesh_pieces = unfiltered_mesh.split(only_watertight=False)\n",
    "    \n",
    "    print(f\"There were {len(mesh_pieces)} pieces after mesh split\")\n",
    "\n",
    "    significant_pieces = [m for m in mesh_pieces if len(m.faces) > significance_threshold]\n",
    "\n",
    "    print(f\"There were {len(significant_pieces)} pieces found after size threshold\")\n",
    "    if len(significant_pieces) <=0:\n",
    "        print(\"THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\")\n",
    "        return []\n",
    "\n",
    "    #find piece with largest size\n",
    "    max_index = 0\n",
    "    max_face_len = len(significant_pieces[max_index].faces)\n",
    "\n",
    "    for i in range(1,len(significant_pieces)):\n",
    "        if max_face_len < len(significant_pieces[i].faces):\n",
    "            max_index = i\n",
    "            max_face_len = len(significant_pieces[i].faces)\n",
    "\n",
    "    print(\"max_index = \" + str(max_index))\n",
    "    print(\"max_face_len = \" + str(max_face_len))\n",
    "\n",
    "    final_mesh_pieces = []\n",
    "\n",
    "    main_mesh = significant_pieces[max_index]\n",
    "\n",
    "    #final_mesh_pieces.append(main_mesh)\n",
    "    for i,mesh in enumerate(significant_pieces):\n",
    "        if i != max_index:\n",
    "            #get a random sample of points\n",
    "            # points = np.array(mesh.vertices[:n_sample_points,:]) # OLD WAY OF DOING THIS\n",
    "            idx = np.random.randint(len(mesh.vertices), size=n_sample_points)\n",
    "            points = mesh.vertices[idx,:]\n",
    "            \n",
    "            \n",
    "            start_time = time.time()\n",
    "            signed_distance = trimesh.proximity.signed_distance(main_mesh,points)\n",
    "            print(f\"Total time = {time.time() - start_time}\")\n",
    "\n",
    "            outside_percentage = sum(signed_distance < 0)/n_sample_points\n",
    "            if outside_percentage > 0.9:\n",
    "                final_mesh_pieces.append(mesh)\n",
    "                print(f\"Mesh piece {i} OUTSIDE mesh\")\n",
    "            else:\n",
    "                print(f\"Mesh piece {i} inside mesh :( \")\n",
    "                \n",
    "    return main_mesh,final_mesh_pieces\n",
    "\n",
    "file_location = \"./test_meshes/\"\n",
    "file_name =\"example_neuron_gap_2.off\"\n",
    "unfiltered_mesh = trimesh.load_mesh(file_location + file_name)\n",
    "\n",
    "#setting thresholds\n",
    "significance_threshold=1 #number of faces needed for pieces to be considered to be kept\n",
    "n_sample_points = 5 #number of points sampled on the mesh for determination of inside or outside\n",
    "start_time = time.time()\n",
    "\n",
    "#the main mesh is the first mesh in the piece\n",
    "main_mesh,child_meshes = filter_mesh_significant_outside_pieces(unfiltered_mesh,\n",
    "                            significance_threshold=significance_threshold,\n",
    "                                n_sample_points=n_sample_points)\n",
    "print(f\"Total time for Mesh Cleansing: {time.time() - start_time}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculates the facets for all the children and the main mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need a way of finding the neighbors that have to share adjacent faces\n",
    "def create_neighbors_lookup(mesh):\n",
    "    start_time = time.time()\n",
    "    neighbors_lookup = dict([(i,[]) for i in range(0,len(mesh.faces))])\n",
    "    print(f\"Creating empty dictionary : {time.time() - start_time}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for adj in mesh.face_adjacency:\n",
    "        neighbors_lookup[adj[0]].append(adj[1])\n",
    "        neighbors_lookup[adj[1]].append(adj[0])\n",
    "    print(f\"Filling in neighbors lookup : {time.time() - start_time}\")\n",
    "    \n",
    "    return neighbors_lookup\n",
    "\n",
    "def filter_and_expand_facets(new_mesh,\n",
    "                             first_pass_size_threshold=2000,\n",
    "                             normal_closeness=0.985):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #filter the facets that are below a size threshold\n",
    "    new_facets = new_mesh.facets[np.where(new_mesh.facets_area > first_pass_size_threshold)[0]]\n",
    "\n",
    "    neighbors_lookup = create_neighbors_lookup(new_mesh)\n",
    "    \n",
    "    #generate a normals lookup table and see if works faster than regular lookup\n",
    "    normal_lookup = {}\n",
    "\n",
    "    for i in range(0,len(new_mesh.faces)):\n",
    "        normal_lookup[i] = new_mesh.face_normals[i]\n",
    "    \n",
    "    global_start_time = time.time()\n",
    "    final_facets= [0]*len(new_facets)\n",
    "    \n",
    "    for i,facet in enumerate(new_facets):\n",
    "    #     mini_global_start_time = time.time()\n",
    "    #     print(facet)\n",
    "    #     print(type(facet))\n",
    "    #     start_time = time.time()\n",
    "    #     print([find_neighbors(k) for k in facet])\n",
    "        total_neighbors = list(set(np.hstack([neighbors_lookup[k] for k in facet])).difference(set(facet)))\n",
    "    #     print(total_neighbors)\n",
    "    #     print(f\"time initial neighbors: {(time.time() - start_time)}\")\n",
    "        neighbors_to_add = []\n",
    "        neighbors_checked = []\n",
    "        #print(total_neighbors)\n",
    "\n",
    "        #just get the normal from one of the faces already in the facet\n",
    "    #     start_time = time.time()\n",
    "        facet_normal = normal_lookup[facet[0]]\n",
    "\n",
    "    #     total_dot_time = 0\n",
    "        while len(total_neighbors) > 0:\n",
    "            current_neighbor = total_neighbors.pop()\n",
    "            neighbors_checked.append(current_neighbor)\n",
    "\n",
    "    #         print(\"--------------\")\n",
    "    # #         #check to see if neighbor has same normal face\n",
    "    # #         start_dot_time = time.time()\n",
    "    # #         dot_result = np.dot(new_mesh.face_normals[current_neighbor],facet_normal) #> normal_closeness\n",
    "    # #         print(dot_result)\n",
    "    # #         print((time.time() - start_dot_time) * 1000)\n",
    "\n",
    "    #         start_dot_time = time.time()\n",
    "    #         print(current_neighbor)\n",
    "    #         #a = new_mesh.face_normals[current_neighbor]\n",
    "\n",
    "    #         print((time.time() - start_dot_time) * 1000)\n",
    "    #         dot_result = a[0]*facet_normal[0] + a[1]*facet_normal[1] + a[2]*facet_normal[2]  > normal_closeness\n",
    "    #         print(dot_result)\n",
    "    #         print((time.time() - start_dot_time) * 1000)\n",
    "    #         print(\"--------------\")\n",
    "\n",
    "    #         total_dot_time += (time.time() - start_dot_time)*1000\n",
    "\n",
    "            a = normal_lookup[current_neighbor]\n",
    "            if a[0]*facet_normal[0] + a[1]*facet_normal[1] + a[2]*facet_normal[2]  > normal_closeness:\n",
    "\n",
    "                neighbors_to_add.append(current_neighbor)\n",
    "                #get the neighbors of this current face\n",
    "                for neigh in neighbors_lookup[current_neighbor]:\n",
    "                    #only add those neighbors that havent already been checked, in original facet group, or already in list to check\n",
    "                    if neigh not in neighbors_checked and neigh not in facet and neigh not in total_neighbors:\n",
    "                        total_neighbors.append(neigh)\n",
    "    #     print(f\"Total dot time: {total_dot_time}\")\n",
    "    #     print(f\"time loop: {(time.time() - start_time)}\")\n",
    "    #     print(\"neighbors_to_add = \" + str(neighbors_to_add))abs\n",
    "    #     print(\"neighbors_checked = \" + str(neighbors_checked))\n",
    "    #     print(\"adding list = \" + str(list(facet) + neighbors_to_add))\n",
    "    #     start_time = time.time()\n",
    "        final_facets[i] = list(facet) + neighbors_to_add\n",
    "    #     print(f\"Appending to list: {(time.time() - start_time)}\")\n",
    "\n",
    "    #     print(f\"Total time: {(time.time() - mini_global_start_time)}\")\n",
    "    #     print(\"------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    print(f\"Total Facet building time: {(time.time() - global_start_time)}\")\n",
    "    return final_facets\n",
    "\n",
    "def filter_final_facets(gap_mesh):\n",
    "    \"\"\"\n",
    "    Gets the facets faces list and the center points of these facets from mesh\n",
    "    Filters:\n",
    "    1) Only lets facets greater than first_pass_size_threshold exist\n",
    "      **** might need to look at this because area is that of facets before expansion\n",
    "    2) Has to have a high convex border\n",
    "    \n",
    "    Expansions:\n",
    "    1) Expands the facet group to neighbors that are within the normal_closeness\n",
    "    for their normals when doing the dot product\n",
    "    \n",
    "    Order:\n",
    "    1) Size filtering\n",
    "    2) Expansion\n",
    "    3) Convex Border filtering\n",
    "    \"\"\"\n",
    "    \n",
    "    final_facets = filter_and_expand_facets(gap_mesh,\n",
    "                                 first_pass_size_threshold=2000,\n",
    "                                 normal_closeness=0.985)\n",
    "\n",
    "    # after computing final faces, filter for convexity\n",
    "    edges = gap_mesh.edges_sorted.reshape((-1, 6)) #groups all the edges belonging to the corresponding face in one row\n",
    "    final_facets_mean = np.zeros(len(final_facets))\n",
    "    \n",
    "    \n",
    "    #make lookup table for face number to spot in the adjacency edges\n",
    "    face_adjacency_index_lookup = [[] for i in gap_mesh.faces]\n",
    "    for i,faces in enumerate(gap_mesh.face_adjacency):\n",
    "        for f in faces:\n",
    "            face_adjacency_index_lookup[f].append(i)\n",
    "\n",
    "\n",
    "    for j,facet in tqdm(enumerate(final_facets)):\n",
    "        # get the edges for each facet\n",
    "        edges_facet = [edges[i].reshape((-1, 2)) for i in [facet]][0] #stores all the edges belonging to that face\n",
    "\n",
    "        #get the indexes of the boundary edges:\n",
    "        indexes = trimesh.grouping.group_rows(edges_facet, require_count=1)\n",
    "        edge_0 = edges_facet[indexes]\n",
    "\n",
    "        #find the faces that correspond to the boundary edges\n",
    "        edge_0_faces = [facet[int(k/3)] for k in indexes]\n",
    "\n",
    "\n",
    "        #2) Find the indexes of the edges int he face_adajacency_edges and store the projections\n",
    "        adjacency_values = []\n",
    "        for edge,edge_face in zip(edge_0,edge_0_faces):\n",
    "            possible_adj_indexes = face_adjacency_index_lookup[edge_face]\n",
    "\n",
    "            for index in possible_adj_indexes:\n",
    "                if len(set(edge).intersection(set(gap_mesh.face_adjacency_edges[index]))) >= 2:\n",
    "                    #print(f\"adj edge = {e} and boundary edge = {edge}\")\n",
    "                    adjacency_values.append(gap_mesh.face_adjacency_angles[index]) # the metric we actually want to measure\n",
    "                    break\n",
    "\n",
    "\n",
    "        final_facets_mean[j] = np.mean(adjacency_values)\n",
    "        \n",
    "        \n",
    "\n",
    "    #filter the final facets and output them so they can be plotted\n",
    "    adjacency_threshold =  0.8\n",
    "    final_facets_mean_filtered = np.array(final_facets)[final_facets_mean > adjacency_threshold]\n",
    "\n",
    "    #Compute the centers\n",
    "    final_facets_centers = []\n",
    "    \n",
    "    for filt in final_facets_mean_filtered: \n",
    "        #print(\"filt = \" + str(filt))\n",
    "        unique_vertices = gap_mesh.vertices[np.unique(gap_mesh.faces[filt].ravel())].astype(\"float\")\n",
    "        final_facets_centers.append((np.mean(unique_vertices[:,0]),\n",
    "                          np.mean(unique_vertices[:,1]),\n",
    "                          np.mean(unique_vertices[:,2])))\n",
    "    \n",
    "    return final_facets_mean_filtered,final_facets_centers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating empty dictionary : 0.004793643951416016\n",
      "Filling in neighbors lookup : 0.03212690353393555\n",
      "Total Facet building time: 0.053343772888183594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "368it [00:00, 2916.15it/s]\n",
      "151it [00:00, 2468.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating empty dictionary : 0.003015756607055664\n",
      "Filling in neighbors lookup : 0.028903484344482422\n",
      "Total Facet building time: 0.05066490173339844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating empty dictionary : 0.0022394657135009766\n",
      "Filling in neighbors lookup : 0.019341230392456055\n",
      "Total Facet building time: 0.04440140724182129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "270it [00:00, 2881.36it/s]\n",
      "31it [00:00, 2522.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating empty dictionary : 9.608268737792969e-05\n",
      "Filling in neighbors lookup : 0.0013284683227539062\n",
      "Total Facet building time: 0.003468751907348633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main_mesh_facets,main_mesh_facets_centers = filter_final_facets(main_mesh)\n",
    "child_meshes_facets = [filter_final_facets(gap_mesh) for gap_mesh in child_meshes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check that facet extraction for each piece worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download the facets list and see if the process worked:\n",
    "# index = 2\n",
    "# facets_group = np.zeros(len(child_meshes[index].faces)).astype(int)\n",
    "\n",
    "# for i,facet_group in enumerate(child_meshes_facets[index][0]):\n",
    "#     for face in facet_group:\n",
    "#         facets_group[face] = i + 1 #so that you reserve the label 0 for blenders none\n",
    "\n",
    "# np.savez(\"./test_meshes/\" + file_name[:-4] + \"_facet_piece_\" + str(index) + \".npz\",\n",
    "#          facets_group=facets_group,\n",
    "#         facets_group_centers=child_meshes_facets[index][1])\n",
    "\n",
    "# from print_trimesh import print_trimesh\n",
    "# print_trimesh(child_meshes[index],\"./test_meshes/piece_\" + str(index) + \".off\")\n",
    "\n",
    "\n",
    "# len(facets_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START ITERATIVE PROCESS THAT CONNECTS THE MESHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_bbox_filter(child,min_bb_zone,max_bb_zone):\n",
    "    \"\"\"\n",
    "    Determines if child is withing the bounding box zone\n",
    "    designated by the bounding box corners\n",
    "    \n",
    "    \"\"\"\n",
    "    #get the min and max of the bounding box for the mesh\n",
    "    min_bb = np.array(child.bounding_box.vertices).min(0)\n",
    "    max_bb = np.array(child.bounding_box.vertices).max(0)\n",
    "    \n",
    "    #print(min_bb,max_bb)\n",
    "    #print(min_bb_zone,max_bb_zone)\n",
    "    \n",
    "    #if fails any of these checks then return false, else return True\n",
    "    if min(min_bb[0],max_bb[0])>max_bb_zone[0]:\n",
    "        print(\"returning x greater max\")\n",
    "        return False\n",
    "    \n",
    "    if max(min_bb[0],max_bb[0])<min_bb_zone[0]:\n",
    "        print(\"returning x less min\")\n",
    "        return False\n",
    "    \n",
    "    if min(min_bb[1],max_bb[1])>max_bb_zone[1]:\n",
    "        print(\"returning y greater max\")\n",
    "        return False\n",
    "    \n",
    "    if max(min_bb[1],max_bb[1])<min_bb_zone[1]:\n",
    "        print(\"returning y less min\")\n",
    "        return False\n",
    "        \n",
    "    if min(min_bb[2],max_bb[2])>max_bb_zone[2]:\n",
    "        print(\"returning z greater max\")\n",
    "        return False\n",
    "    \n",
    "    if max(min_bb[2],max_bb[2])<min_bb_zone[2]:\n",
    "        print(\"returning z less mim\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "import math\n",
    "def area(vertices):\n",
    "    \"\"\"\n",
    "    Calculates the area of a 3D triangle from it's coordinates\n",
    "    \"\"\"\n",
    "    side_a = np.linalg.norm(vertices[0]-vertices[1])\n",
    "    side_b = np.linalg.norm(vertices[1]-vertices[2])\n",
    "    side_c = np.linalg.norm(vertices[2]-vertices[0])\n",
    "    s = 0.5 * ( side_a + side_b + side_c)\n",
    "    return math.sqrt(s * (s - side_a) * (s - side_b) * (s - side_c))\n",
    "\n",
    "def find_polygon_area(mesh,list_of_faces):\n",
    "    \"Calculates the area of a 3D polygon that is created from connected traingles\"\n",
    "    return(sum([area(mesh.vertices[mesh.faces[r]]) for r in list_of_faces]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restitching functions\n",
    "import trimesh\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import time\n",
    "import math\n",
    "\n",
    "#gets the projection of point p onto line a\n",
    "def ClosestPointOnLine(a, b, p):\n",
    "    ap = p-a\n",
    "    ab = b-a\n",
    "    #base_vector = ab\n",
    "    result = np.dot(ap,ab)/np.dot(ab,ab) # * ab\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#now have the mesh and the facet faces, can send to function\n",
    "def stitch_mesh_piece_vp3(new_mesh,facet_1,facet_2,\n",
    "                          delete_facets=False,\n",
    "                         return_added_mesh = True):\n",
    "    \"\"\"\n",
    "    Changed since last version: \n",
    "    1) parameter for deleting facets at end or not\n",
    "    2) parameter for returning added mesh or not \n",
    "    3) Changed normals check to print statement and not exception\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    #how to find the normals of facet groups:\n",
    "    facet_group_1_normal = new_mesh.face_normals[facet_1[0]]\n",
    "    facet_group_2_normal = new_mesh.face_normals[facet_2[0]]\n",
    "\n",
    "\n",
    "    #get the correct version of the normals:\n",
    "    if np.dot(facet_group_1_normal,facet_group_2_normal) > 0.8:\n",
    "        pass\n",
    "    elif np.dot(facet_group_1_normal,facet_group_2_normal) < -0.8:\n",
    "        print(\"opposite normals\")\n",
    "        facet_group_2_normal = facet_group_2_normal*-1\n",
    "    else:\n",
    "        print(\"Not correct normals\")\n",
    "        #raise Exception(\"Not correct normals\")\n",
    "\n",
    "    print(facet_group_1_normal,facet_group_2_normal)\n",
    "\n",
    "    # make each row correspond to a single face\n",
    "    edges = new_mesh.edges_sorted.reshape((-1, 6))\n",
    "    # get the edges for each facet\n",
    "    edges_facet = [edges[i].reshape((-1, 2)) for i in [facet_1,facet_2]]\n",
    "    edges_boundary = np.array([i[trimesh.grouping.group_rows(i, require_count=1)]\n",
    "                               for i in edges_facet])\n",
    "\n",
    "    edge_0 = edges_boundary[0]\n",
    "    edge_1 = edges_boundary[1]\n",
    "\n",
    "    #gets the unique number of points\n",
    "    edge_0_points = np.unique(np.hstack(edge_0))\n",
    "    edge_1_points = np.unique(np.hstack(edge_1))\n",
    "\n",
    "    \"\"\"\n",
    "    get the dot product of all the points\n",
    "    \"\"\"\n",
    "\n",
    "    #get any 2 points on the triangle and make that the reference traingle\n",
    "    edge_0_anchor_points = new_mesh.vertices[[edge_0_points[0],edge_0_points[1]]]\n",
    "\n",
    "    #gets the starting index for the 1st facet\n",
    "    max_index = edge_0_points[0]\n",
    "    max_magnitude = ClosestPointOnLine(edge_0_anchor_points[0],edge_0_anchor_points[1],new_mesh.vertices[max_index])\n",
    "\n",
    "    for i in range(1,len(edge_0_points)):\n",
    "        current_magnitude = ClosestPointOnLine(edge_0_anchor_points[0],edge_0_anchor_points[1],new_mesh.vertices[edge_0_points[i]])\n",
    "\n",
    "        if current_magnitude > max_magnitude:\n",
    "            max_index = i\n",
    "            max_magnitude = current_magnitude\n",
    "\n",
    "    edge_0_starting_point = edge_0_points[max_index]\n",
    "\n",
    "    #gets the starting index for the 2nd facet\n",
    "    max_index = edge_1_points[0]\n",
    "    max_magnitude = ClosestPointOnLine(edge_0_anchor_points[0],edge_0_anchor_points[1],new_mesh.vertices[max_index])\n",
    "\n",
    "    for i in range(1,len(edge_1_points)):\n",
    "        current_magnitude = ClosestPointOnLine(edge_0_anchor_points[0],edge_0_anchor_points[1],new_mesh.vertices[edge_1_points[i]])\n",
    "        if current_magnitude > max_magnitude:\n",
    "            max_index = i\n",
    "            max_magnitude = current_magnitude\n",
    "\n",
    "    edge_1_starting_point = edge_1_points[max_index]\n",
    "\n",
    "    print(f\"starting edge 1st facet = {edge_0_starting_point}, starting edge 2nd facet= {edge_1_starting_point}, \")\n",
    "    print(new_mesh.vertices[edge_0_starting_point],new_mesh.vertices[edge_1_starting_point])\n",
    "\n",
    "    \"\"\"\n",
    "    Need to order the points for restitching\n",
    "\n",
    "    Pseudocode: \n",
    "    1) Get starting piont\n",
    "    2) Find the two edges corresponding to that point\n",
    "    3) Need to decide which direction to start....\n",
    "    - go in direction that make the cross of the (1st and last) point in the same direction of the \n",
    "    normal of the first facet\n",
    "    4) loop through and record the orders of the vertices as you traverse along the edges \n",
    "    until you arrive back at the start\n",
    "    5) Error if:\n",
    "        a. You arrive back at the start and haven't processed all the edges\n",
    "        b. Processsed all the edges but haven't arrived back at start\n",
    "\n",
    "    6) Repeat steps 1 through 5 for 2nd facet group\n",
    "    \"\"\"\n",
    "    start_point_list = [edge_0_starting_point,edge_1_starting_point]\n",
    "    edge_list = [edge_0,edge_1]\n",
    "    edge_order_list = []\n",
    "\n",
    "\n",
    "    for i,start_point in enumerate(start_point_list):\n",
    "        print(f\"start_point = {start_point}\")\n",
    "        edge_order = [start_point]\n",
    "        processed_edges = []\n",
    "\n",
    "        #find the matching edges\n",
    "        starting_edges_indices = np.where(np.logical_or(edge_list[i][:,0] == start_point,edge_list[i][:,1] == start_point) == True)[0]\n",
    "        print(starting_edges_indices)\n",
    "        starting_edges = edge_list[i][starting_edges_indices]\n",
    "        print(f\"starting edges = {starting_edges}\") #the list of the two possible edges\n",
    "\n",
    "        if starting_edges.size < 4:\n",
    "            raise Exception(\"Not enough edges for 1st facet start point\")\n",
    "\n",
    "        if starting_edges.size > 4:\n",
    "            raise Exception(\"Too many edges for 1st facet start point\") \n",
    "\n",
    "        #np.where(starting_edges[1,:] != start_point)[0][0]\n",
    "        #gets the vectors that will be used for the cross product\n",
    "        print(\"np.where(starting_edges[0,:] != start_point)[0][0] = \" + str(np.where(starting_edges[0,:] != start_point)[0][0]))\n",
    "        print(\"np.where(starting_edges[1,:] != start_point)[0][0] = \" + str(np.where(starting_edges[1,:] != start_point)[0][0]))\n",
    "\n",
    "\n",
    "        #gets the possible starting vectors\n",
    "        possible_starting_vector_1 = new_mesh.vertices[starting_edges[0,:][np.where(starting_edges[0,:] != start_point)[0][0]]] - new_mesh.vertices[start_point]\n",
    "        possible_starting_vector_2 = new_mesh.vertices[starting_edges[1,:][np.where(starting_edges[1,:] != start_point)[0][0]]] - new_mesh.vertices[start_point]\n",
    "        \n",
    "\n",
    "        #find the cross product of the starting vectors\n",
    "        starting_edges_cross = np.cross(possible_starting_vector_1,possible_starting_vector_2)\n",
    "\n",
    "        #make sure that the order of the vectors goes so that the cross product is in line with the starting normal\n",
    "        if np.dot(starting_edges_cross,facet_group_1_normal) > 0:\n",
    "            print(\"group 1 picked\")\n",
    "            processed_edges.append(starting_edges_indices[0])\n",
    "            current_vertex = starting_edges[0][np.where(starting_edges[0,:] != start_point)[0][0]]\n",
    "        else:\n",
    "            print(\"group 2 picked\")\n",
    "            processed_edges.append(starting_edges_indices[1])\n",
    "            #print(\"np.where(starting_edges[1,:] != start_point) = \" + str(np.where(starting_edges[1,:] != start_point)))\n",
    "            current_vertex = starting_edges[1][np.where(starting_edges[1,:] != start_point)[0][0]]\n",
    "\n",
    "        #print(f\"current_vertex = {current_vertex}\" )\n",
    "        #print(\"edge_list = \" + str(edge_list))\n",
    "\n",
    "        #now iterate through number of \n",
    "        for z in range(1,edge_list[i][:,0].size):\n",
    "            #print(\"edge_order_temp = \" + str(edge_order))\n",
    "            if current_vertex == start_point:\n",
    "                print(\"Start vertex reached before processed all of edges\")\n",
    "                \n",
    "                \"\"\"\n",
    "                \n",
    "                These should be ok because the extra loops are created from holes inside and this process should always get the outside loop\n",
    "                \n",
    "                \n",
    "                \"\"\"\n",
    "                break\n",
    "\n",
    "            #get the next edge\n",
    "            counter = 0\n",
    "            next_vertex = -1\n",
    "            for j,edg in enumerate(edge_list[i]):\n",
    "                #print(\"edg = \" + str(edg))\n",
    "                #print(\"processed_edges = \" + str(processed_edges))\n",
    "                if current_vertex in edg and j not in processed_edges:\n",
    "                    current_edge_index = j\n",
    "                    if edg[0] != current_vertex:\n",
    "                        next_vertex = edg[0]\n",
    "                    else:\n",
    "                        next_vertex = edg[1]\n",
    "\n",
    "\n",
    "                    counter += 1\n",
    "                    if counter >= 2:\n",
    "                        raise Exception(f\"More than 2 edges possibilities for {current_vertex}\")\n",
    "\n",
    "            #make sure the next vertex was found\n",
    "            if next_vertex <= -1:\n",
    "                raise Exception(f\"No next vertex was found for {current_vertex} \")\n",
    "\n",
    "            #if found next vertex\n",
    "            processed_edges.append(current_edge_index)\n",
    "            edge_order.append(current_vertex)\n",
    "\n",
    "            current_vertex = next_vertex\n",
    "\n",
    "\n",
    "        edge_order_list.append(edge_order)\n",
    "        print(f\"edge_{i}_order = {edge_order}\")\n",
    "\n",
    "    lengths_of_boundaries = [len(x) for x in edge_order_list]\n",
    "    bigger = lengths_of_boundaries.index(max(lengths_of_boundaries))\n",
    "    smaller = 1-bigger\n",
    "\n",
    "    print(f\"index of bigger facets = {bigger}\\nindex of smaller facets = {smaller}\",)\n",
    "\n",
    "    dividend = int(lengths_of_boundaries[bigger]/lengths_of_boundaries[smaller])\n",
    "    remainder = lengths_of_boundaries[bigger] - int(lengths_of_boundaries[bigger]/lengths_of_boundaries[smaller])*lengths_of_boundaries[smaller]\n",
    "\n",
    "    print(f\"dividend = {dividend}, remainder = {remainder}\")\n",
    "\n",
    "\n",
    "    new_faces = []\n",
    "    current_bigger = 0\n",
    "    for i,current_smaller in enumerate(edge_order_list[smaller]):\n",
    "        #print(\"current_smaller =\" + str(current_smaller))\n",
    "        #print(\"current_bigger=\" + str(current_bigger))\n",
    "        if i == 0:\n",
    "            new_faces.append([current_smaller,edge_order_list[smaller][-1],edge_order_list[bigger][current_bigger]])\n",
    "        else:\n",
    "            new_faces.append([current_smaller,edge_order_list[smaller][i-1],edge_order_list[bigger][current_bigger]])\n",
    "\n",
    "        for j in range(0,dividend + int(i<remainder)):\n",
    "            if current_bigger > len(edge_order_list[bigger]):\n",
    "                raise Exception(\"Somehow rapped around too much\")\n",
    "\n",
    "            if current_bigger >= len(edge_order_list[bigger])-1:\n",
    "                next_bigger = 0\n",
    "            else:\n",
    "                next_bigger = current_bigger+1\n",
    "\n",
    "            new_faces.append([current_smaller,edge_order_list[bigger][current_bigger],\n",
    "                                edge_order_list[bigger][next_bigger]])\n",
    "\n",
    "            current_bigger += 1\n",
    "\n",
    "    print(\"new_faces = \" + str(new_faces))\n",
    "\n",
    "    stitch_mesh = trimesh.Trimesh()\n",
    "\n",
    "    stitch_mesh.vertices = new_mesh.vertices\n",
    "    stitch_mesh.faces = new_mesh.faces\n",
    "    stitch_mesh.faces = np.vstack([stitch_mesh.faces, new_faces])\n",
    "\n",
    "\n",
    "\n",
    "    if delete_facets == True:\n",
    "        #now take away the original facet faces:\n",
    "        total_faces = np.linspace(0,len(stitch_mesh.faces)-1,len(stitch_mesh.faces)).astype(\"int\")\n",
    "        facet_faces = np.hstack([facet_1 ,facet_2])\n",
    "        faces_to_keep = set(total_faces).difference(set(facet_faces))\n",
    "        faces_to_keep\n",
    "\n",
    "        stitch_mesh = stitch_mesh.submesh([list(faces_to_keep)])[0]\n",
    "\n",
    "    trimesh.repair.fix_inversion(stitch_mesh)\n",
    "    trimesh.repair.fix_winding(stitch_mesh)\n",
    "    trimesh.repair.fix_normals(stitch_mesh)\n",
    "\n",
    "    if return_added_mesh == True:\n",
    "        added_mesh = trimesh.Trimesh()\n",
    "        added_mesh.vertices = new_mesh.vertices\n",
    "        added_mesh.faces = new_faces\n",
    "        trimesh.repair.fix_inversion(added_mesh)\n",
    "        trimesh.repair.fix_winding(added_mesh)\n",
    "        trimesh.repair.fix_normals(added_mesh)\n",
    "\n",
    "        return stitch_mesh,added_mesh\n",
    "    \n",
    "    else:\n",
    "        return stitch_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #sets \n",
    "# initial_parameters = dict(bounding_box_threshold=4000,\n",
    "#                          stitch_distance_threshold=3000,\n",
    "#                          size_ratio_threshold=0.30)\n",
    "# main_mesh = main_mesh\n",
    "# bounding_box_threshold = initial_parameters[\"bounding_box_threshold\"]\n",
    "# stitch_distance_threshold = initial_parameters[\"stitch_distance_threshold\"]\n",
    "# size_ratio_threshold = initial_parameters[\"size_ratio_threshold\"]\n",
    "\n",
    "# no_new_children_multiplier = 0\n",
    "# bbox_expansion_percentage = 0.10\n",
    "# stitch_expansion_percentage = 1\n",
    "# size_expansion_percentage = 0.10\n",
    "# no_new_children_limit = 4\n",
    "# consider_same_direction_normals = True\n",
    "\n",
    "# children_processed = []\n",
    "\n",
    "# while len(children_processed) < len(child_meshes):\n",
    "#     if no_new_children_multiplier >= no_new_children_limit:\n",
    "#         print(\"The number of times expanding the thresholds has exceed the limit /n Just returning main mesh\")\n",
    "        \n",
    "    \n",
    "#     #update the thresholds\n",
    "#     bounding_box_threshold = initial_parameters[\"bounding_box_threshold\"]*(1 + bbox_expansion_percentage*no_new_children_multiplier)\n",
    "#     stitch_distance_threshold = initial_parameters[\"stitch_distance_threshold\"]*(1 + stitch_expansion_percentage*no_new_children_multiplier)\n",
    "#     #reduces the \n",
    "#     size_ratio_threshold = initial_parameters[\"size_ratio_threshold\"]*(1 - size_expansion_percentage*no_new_children_multiplier)\n",
    "    \n",
    "#     #print thresholds\n",
    "#     print(f\"bounding_box_threshold = {bounding_box_threshold}\")\n",
    "#     print(f\"stitch_distance_threshold = {stitch_distance_threshold}\" )\n",
    "#     print(f\"size_ratio_threshold = {size_ratio_threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounding_box_threshold = 4000.0\n",
      "stitch_distance_threshold = 2000\n",
      "size_ratio_threshold = 0.3\n",
      "returning y greater max\n",
      "skipped\n",
      "Child Index 1\n",
      "Total pairwise : 0.06117129325866699\n",
      "pair = [ 0 13]\n",
      "ratio = 0.8941142486615555\n",
      "Total size  = 22160.29558590948\n",
      "pair = [4 4]\n",
      "ratio = 0.9238600477781631\n",
      "Total size  = 2145344.802921111\n",
      "pair = [ 4 11]\n",
      "ratio = 0.31461487997077864\n",
      "Total size  = 1465960.1689037592\n",
      "pair = [ 4 12]\n",
      "ratio = 0.923860047778163\n",
      "Total size  = 2145344.802921111\n",
      "pair = [ 4 14]\n",
      "ratio = 0.1956040720052912\n",
      "Total size  = 1333248.2189596533\n",
      "pair = [ 4 19]\n",
      "ratio = 0.020996582379876595\n",
      "Total size  = 1138539.0087696516\n",
      "pair = [ 4 33]\n",
      "ratio = 0.9238600477781629\n",
      "Total size  = 2145344.8029211108\n",
      "pair = [ 4 34]\n",
      "ratio = 0.013950776717942223\n",
      "Total size  = 1130682.053386291\n",
      "pair = [ 4 35]\n",
      "ratio = 0.3146148799707786\n",
      "Total size  = 1465960.1689037592\n",
      "pair = [ 4 36]\n",
      "ratio = 0.9324446406441476\n",
      "Total size  = 2154917.698679045\n",
      "pair = [5 4]\n",
      "ratio = 0.04369100795756481\n",
      "Total size  = 1075230.9453543646\n",
      "pair = [ 5 11]\n",
      "ratio = 0.12829773564079666\n",
      "Total size  = 395846.3113370127\n",
      "pair = [ 5 12]\n",
      "ratio = 0.04369100795756482\n",
      "Total size  = 1075230.9453543643\n",
      "pair = [ 5 14]\n",
      "ratio = 0.20635754810901918\n",
      "Total size  = 263134.3613929067\n",
      "pair = [ 5 19]\n",
      "ratio = 0.5201760586165013\n",
      "Total size  = 68425.15120290499\n",
      "pair = [ 5 33]\n",
      "ratio = 0.04369100795756483\n",
      "Total size  = 1075230.9453543643\n",
      "pair = [ 5 34]\n",
      "ratio = 0.34562101186205935\n",
      "Total size  = 60568.19581954438\n",
      "pair = [ 5 35]\n",
      "ratio = 0.1282977356407967\n",
      "Total size  = 395846.3113370126\n",
      "pair = [ 5 36]\n",
      "ratio = 0.04328876475848216\n",
      "Total size  = 1084803.8411122982\n",
      "pair = [17  4]\n",
      "ratio = 0.005929340516644542\n",
      "Total size  = 1036328.1349717071\n",
      "pair = [17 11]\n",
      "ratio = 0.017411385035281897\n",
      "Total size  = 356943.5009543552\n",
      "pair = [17 12]\n",
      "ratio = 0.005929340516644544\n",
      "Total size  = 1036328.1349717069\n",
      "pair = [17 14]\n",
      "ratio = 0.028004942621296994\n",
      "Total size  = 224231.55101024918\n",
      "pair = [17 33]\n",
      "ratio = 0.005929340516644545\n",
      "Total size  = 1036328.1349717068\n",
      "pair = [17 34]\n",
      "ratio = 0.3926577654959579\n",
      "Total size  = 21665.38543688687\n",
      "pair = [17 35]\n",
      "ratio = 0.0174113850352819\n",
      "Total size  = 356943.5009543551\n",
      "pair = [17 36]\n",
      "ratio = 0.005874751780669808\n",
      "Total size  = 1045901.0307296406\n",
      "pair = [20  4]\n",
      "ratio = 0.9238600477781636\n",
      "Total size  = 2145344.8029211108\n",
      "pair = [20 11]\n",
      "ratio = 0.3146148799707788\n",
      "Total size  = 1465960.1689037587\n",
      "pair = [20 12]\n",
      "ratio = 0.9238600477781633\n",
      "Total size  = 2145344.8029211108\n",
      "pair = [20 14]\n",
      "ratio = 0.19560407200529129\n",
      "Total size  = 1333248.2189596528\n",
      "pair = [20 19]\n",
      "ratio = 0.020996582379876602\n",
      "Total size  = 1138539.0087696512\n",
      "pair = [20 33]\n",
      "ratio = 0.9238600477781632\n",
      "Total size  = 2145344.8029211108\n",
      "pair = [20 34]\n",
      "ratio = 0.013950776717942228\n",
      "Total size  = 1130682.0533862906\n",
      "pair = [20 35]\n",
      "ratio = 0.31461487997077875\n",
      "Total size  = 1465960.1689037587\n",
      "pair = [20 36]\n",
      "ratio = 0.932444640644148\n",
      "Total size  = 2154917.6986790444\n",
      "pair = [25  4]\n",
      "ratio = 0.9238600477781626\n",
      "Total size  = 2145344.802921112\n",
      "pair = [25 11]\n",
      "ratio = 0.31461487997077847\n",
      "Total size  = 1465960.1689037601\n",
      "pair = [25 12]\n",
      "ratio = 0.9238600477781623\n",
      "Total size  = 2145344.8029211117\n",
      "pair = [25 14]\n",
      "ratio = 0.1956040720052911\n",
      "Total size  = 1333248.218959654\n",
      "pair = [25 19]\n",
      "ratio = 0.02099658237987658\n",
      "Total size  = 1138539.0087696523\n",
      "pair = [25 33]\n",
      "ratio = 0.9238600477781622\n",
      "Total size  = 2145344.8029211117\n",
      "pair = [25 34]\n",
      "ratio = 0.013950776717942214\n",
      "Total size  = 1130682.0533862917\n",
      "pair = [25 35]\n",
      "ratio = 0.3146148799707784\n",
      "Total size  = 1465960.16890376\n",
      "pair = [25 36]\n",
      "ratio = 0.932444640644147\n",
      "Total size  = 2154917.698679046\n",
      "pair = [26  4]\n",
      "ratio = 0.9188579182886314\n",
      "Total size  = 2151415.3830299396\n",
      "pair = [26 11]\n",
      "ratio = 0.3129114354147205\n",
      "Total size  = 1472030.7490125876\n",
      "pair = [26 12]\n",
      "ratio = 0.9188579182886312\n",
      "Total size  = 2151415.3830299396\n",
      "pair = [26 14]\n",
      "ratio = 0.1945449972036443\n",
      "Total size  = 1339318.7990684817\n",
      "pair = [26 19]\n",
      "ratio = 0.020882898901351518\n",
      "Total size  = 1144609.58887848\n",
      "pair = [26 33]\n",
      "ratio = 0.9188579182886311\n",
      "Total size  = 2151415.3830299396\n",
      "pair = [26 34]\n",
      "ratio = 0.013875241909623021\n",
      "Total size  = 1136752.6334951194\n",
      "pair = [26 35]\n",
      "ratio = 0.31291143541472044\n",
      "Total size  = 1472030.7490125876\n",
      "pair = [26 36]\n",
      "ratio = 0.9273960309055415\n",
      "Total size  = 2160988.278787873\n",
      "pair = [30  4]\n",
      "ratio = 0.31726094237133096\n",
      "Total size  = 1357068.0570641602\n",
      "pair = [30 12]\n",
      "ratio = 0.31726094237133107\n",
      "Total size  = 1357068.05706416\n",
      "pair = [30 33]\n",
      "ratio = 0.31726094237133107\n",
      "Total size  = 1357068.0570641598\n",
      "pair = [30 34]\n",
      "ratio = 0.04759656283783195\n",
      "Total size  = 342405.3075293399\n",
      "pair = [39  4]\n",
      "ratio = 0.31726094237133096\n",
      "Total size  = 1357068.0570641602\n",
      "pair = [39 12]\n",
      "ratio = 0.31726094237133107\n",
      "Total size  = 1357068.05706416\n",
      "pair = [39 33]\n",
      "ratio = 0.31726094237133107\n",
      "Total size  = 1357068.0570641598\n",
      "pair = [39 34]\n",
      "ratio = 0.04759656283783195\n",
      "Total size  = 342405.3075293399\n",
      "pair = [46  4]\n",
      "ratio = 0.31726094237133096\n",
      "Total size  = 1357068.0570641602\n",
      "pair = [46 12]\n",
      "ratio = 0.31726094237133107\n",
      "Total size  = 1357068.05706416\n",
      "pair = [46 33]\n",
      "ratio = 0.31726094237133107\n",
      "Total size  = 1357068.0570641598\n",
      "pair = [46 34]\n",
      "ratio = 0.04759656283783195\n",
      "Total size  = 342405.3075293399\n",
      "best_stitch_pair = [26 36]\n",
      "best_stitch_pair_size = 2160988.278787873\n",
      "best_stitch_pair_size_ratio = 0.9273960309055415\n",
      "Child Index 2\n",
      "Total pairwise : 0.04547476768493652\n",
      "There was no possible stitch found after stitch distance and face normal filters\n",
      "repeat_main_facets = []\n",
      "child_meshes_stitch_facets = {1: [26, 36]}\n",
      "opposite normals\n",
      "[-0.09544989  0.99543424  0.        ] [ 0.03722231  0.99930701 -0.        ]\n",
      "starting edge 1st facet = 4811, starting edge 2nd facet= 9574, \n",
      "[ 425443.6875       11419.42480469 -170083.234375  ] [ 425632.71875     11544.3828125 -170136.34375  ]\n",
      "start_point = 4811\n",
      "[20 27]\n",
      "starting edges = [[2799 4811]\n",
      " [4811 5843]]\n",
      "np.where(starting_edges[0,:] != start_point)[0][0] = 0\n",
      "np.where(starting_edges[1,:] != start_point)[0][0] = 1\n",
      "group 1 picked\n",
      "edge_0_order = [4811, 2799, 6349, 5007, 3460, 3412, 4148, 4802, 72, 70, 68, 67, 66, 65, 64, 63, 73, 71, 2455, 2690, 2324, 4159, 2703, 5718, 1961, 2751, 5183, 771, 4501, 5843]\n",
      "start_point = 9574\n",
      "[13 18]\n",
      "starting edges = [[8037 9574]\n",
      " [9574 9866]]\n",
      "np.where(starting_edges[0,:] != start_point)[0][0] = 0\n",
      "np.where(starting_edges[1,:] != start_point)[0][0] = 1\n",
      "group 2 picked\n",
      "edge_1_order = [9574, 9866, 9301, 7426, 7820, 10153, 7321, 6588, 10048, 9381, 9882, 7409, 9028, 9661, 6587, 8027, 10190, 9333, 7911, 10086, 10267, 10125, 7403, 8348, 9459, 9859, 10172, 8751, 9361, 7411, 7953, 9517, 10293, 8378, 10104, 8527, 8037]\n",
      "index of bigger facets = 1\n",
      "index of smaller facets = 0\n",
      "dividend = 1, remainder = 7\n",
      "new_faces = [[4811, 5843, 9574], [4811, 9574, 9866], [4811, 9866, 9301], [2799, 4811, 9301], [2799, 9301, 7426], [2799, 7426, 7820], [6349, 2799, 7820], [6349, 7820, 10153], [6349, 10153, 7321], [5007, 6349, 7321], [5007, 7321, 6588], [5007, 6588, 10048], [3460, 5007, 10048], [3460, 10048, 9381], [3460, 9381, 9882], [3412, 3460, 9882], [3412, 9882, 7409], [3412, 7409, 9028], [4148, 3412, 9028], [4148, 9028, 9661], [4148, 9661, 6587], [4802, 4148, 6587], [4802, 6587, 8027], [72, 4802, 8027], [72, 8027, 10190], [70, 72, 10190], [70, 10190, 9333], [68, 70, 9333], [68, 9333, 7911], [67, 68, 7911], [67, 7911, 10086], [66, 67, 10086], [66, 10086, 10267], [65, 66, 10267], [65, 10267, 10125], [64, 65, 10125], [64, 10125, 7403], [63, 64, 7403], [63, 7403, 8348], [73, 63, 8348], [73, 8348, 9459], [71, 73, 9459], [71, 9459, 9859], [2455, 71, 9859], [2455, 9859, 10172], [2690, 2455, 10172], [2690, 10172, 8751], [2324, 2690, 8751], [2324, 8751, 9361], [4159, 2324, 9361], [4159, 9361, 7411], [2703, 4159, 7411], [2703, 7411, 7953], [5718, 2703, 7953], [5718, 7953, 9517], [1961, 5718, 9517], [1961, 9517, 10293], [2751, 1961, 10293], [2751, 10293, 8378], [5183, 2751, 8378], [5183, 8378, 10104], [771, 5183, 10104], [771, 10104, 8527], [4501, 771, 8527], [4501, 8527, 8037], [5843, 4501, 8037], [5843, 8037, 9574]]\n",
      "Creating empty dictionary : 0.008191823959350586\n",
      "Filling in neighbors lookup : 0.04979276657104492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "286it [00:00, 2853.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Facet building time: 0.09438800811767578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "630it [00:00, 3048.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounding_box_threshold = 4000.0\n",
      "stitch_distance_threshold = 2000\n",
      "size_ratio_threshold = 0.3\n",
      "Child Index 0\n",
      "Total pairwise : 0.03062129020690918\n",
      "pair = [ 1 85]\n",
      "ratio = 0.9200545031133976\n",
      "Total size  = 508095.9063347269\n",
      "pair = [ 1 86]\n",
      "ratio = 0.2131299712417774\n",
      "Total size  = 1506242.6651805325\n",
      "pair = [ 1 96]\n",
      "ratio = 0.2131299712417774\n",
      "Total size  = 1506242.6651805325\n",
      "pair = [ 1 98]\n",
      "ratio = 0.21289676428837173\n",
      "Total size  = 1507602.731378729\n",
      "pair = [  1 121]\n",
      "ratio = 0.2131299712417774\n",
      "Total size  = 1506242.6651805325\n",
      "pair = [ 2 85]\n",
      "ratio = 0.9200545031133976\n",
      "Total size  = 508095.9063347269\n",
      "pair = [ 2 86]\n",
      "ratio = 0.2131299712417774\n",
      "Total size  = 1506242.6651805325\n",
      "pair = [ 2 96]\n",
      "ratio = 0.2131299712417774\n",
      "Total size  = 1506242.6651805325\n",
      "pair = [ 2 98]\n",
      "ratio = 0.21289676428837173\n",
      "Total size  = 1507602.731378729\n",
      "pair = [  2 121]\n",
      "ratio = 0.2131299712417774\n",
      "Total size  = 1506242.6651805325\n",
      "pair = [ 5 85]\n",
      "ratio = 0.14832896921075053\n",
      "Total size  = 1884890.114077766\n",
      "pair = [ 5 86]\n",
      "ratio = 0.7564285237395648\n",
      "Total size  = 2883036.8729235716\n",
      "pair = [ 5 87]\n",
      "ratio = 0.03953547999079723\n",
      "Total size  = 1706314.307140093\n",
      "pair = [ 5 95]\n",
      "ratio = 0.054619397723146154\n",
      "Total size  = 1731073.3510879332\n",
      "pair = [ 5 96]\n",
      "ratio = 0.7564285237395648\n",
      "Total size  = 2883036.8729235716\n",
      "pair = [ 5 98]\n",
      "ratio = 0.7572571149681827\n",
      "Total size  = 2884396.939121768\n",
      "pair = [  5 121]\n",
      "ratio = 0.7564285237395648\n",
      "Total size  = 2883036.8729235716\n",
      "pair = [ 7 85]\n",
      "ratio = 0.008411712655034945\n",
      "Total size  = 245518.13453231016\n",
      "pair = [10 85]\n",
      "ratio = 0.14832896921075056\n",
      "Total size  = 1884890.1140777657\n",
      "pair = [10 86]\n",
      "ratio = 0.7564285237395649\n",
      "Total size  = 2883036.8729235716\n",
      "pair = [10 87]\n",
      "ratio = 0.039535479990797234\n",
      "Total size  = 1706314.3071400928\n",
      "pair = [10 95]\n",
      "ratio = 0.05461939772314616\n",
      "Total size  = 1731073.351087933\n",
      "pair = [10 96]\n",
      "ratio = 0.7564285237395649\n",
      "Total size  = 2883036.8729235716\n",
      "pair = [10 98]\n",
      "ratio = 0.7572571149681828\n",
      "Total size  = 2884396.939121768\n",
      "pair = [ 10 121]\n",
      "ratio = 0.7564285237395649\n",
      "Total size  = 2883036.8729235716\n",
      "pair = [11 85]\n",
      "ratio = 0.04471669276696601\n",
      "Total size  = 254357.31289512946\n",
      "pair = [11 86]\n",
      "ratio = 0.008768549488122595\n",
      "Total size  = 1252504.071740935\n",
      "pair = [11 96]\n",
      "ratio = 0.008768549488122595\n",
      "Total size  = 1252504.071740935\n",
      "pair = [11 98]\n",
      "ratio = 0.00875895493555921\n",
      "Total size  = 1253864.1379391316\n",
      "pair = [ 11 121]\n",
      "ratio = 0.008768549488122595\n",
      "Total size  = 1252504.071740935\n",
      "pair = [12 85]\n",
      "ratio = 0.14832896921075056\n",
      "Total size  = 1884890.1140777657\n",
      "pair = [12 86]\n",
      "ratio = 0.7564285237395649\n",
      "Total size  = 2883036.8729235716\n",
      "pair = [12 87]\n",
      "ratio = 0.039535479990797234\n",
      "Total size  = 1706314.3071400928\n",
      "pair = [12 95]\n",
      "ratio = 0.05461939772314616\n",
      "Total size  = 1731073.351087933\n",
      "pair = [12 96]\n",
      "ratio = 0.7564285237395649\n",
      "Total size  = 2883036.8729235716\n",
      "pair = [12 98]\n",
      "ratio = 0.7572571149681828\n",
      "Total size  = 2884396.939121768\n",
      "pair = [ 12 121]\n",
      "ratio = 0.7564285237395649\n",
      "Total size  = 2883036.8729235716\n",
      "pair = [13 85]\n",
      "ratio = 0.9200545031133979\n",
      "Total size  = 508095.90633472684\n",
      "pair = [13 86]\n",
      "ratio = 0.21312997124177738\n",
      "Total size  = 1506242.6651805325\n",
      "pair = [13 96]\n",
      "ratio = 0.21312997124177738\n",
      "Total size  = 1506242.6651805325\n",
      "pair = [13 98]\n",
      "ratio = 0.21289676428837168\n",
      "Total size  = 1507602.731378729\n",
      "pair = [ 13 121]\n",
      "ratio = 0.21312997124177738\n",
      "Total size  = 1506242.6651805325\n",
      "pair = [16 85]\n",
      "ratio = 0.14832896921075067\n",
      "Total size  = 1884890.1140777646\n",
      "pair = [16 86]\n",
      "ratio = 0.7564285237395655\n",
      "Total size  = 2883036.87292357\n",
      "pair = [16 87]\n",
      "ratio = 0.03953547999079726\n",
      "Total size  = 1706314.3071400917\n",
      "pair = [16 95]\n",
      "ratio = 0.054619397723146196\n",
      "Total size  = 1731073.3510879318\n",
      "pair = [16 96]\n",
      "ratio = 0.7564285237395655\n",
      "Total size  = 2883036.87292357\n",
      "pair = [16 98]\n",
      "ratio = 0.7572571149681834\n",
      "Total size  = 2884396.939121767\n",
      "pair = [ 16 121]\n",
      "ratio = 0.7564285237395655\n",
      "Total size  = 2883036.87292357\n",
      "pair = [20 85]\n",
      "ratio = 0.14832896921075056\n",
      "Total size  = 1884890.1140777657\n",
      "pair = [20 86]\n",
      "ratio = 0.7564285237395649\n",
      "Total size  = 2883036.8729235716\n",
      "pair = [20 87]\n",
      "ratio = 0.039535479990797234\n",
      "Total size  = 1706314.3071400928\n",
      "pair = [20 95]\n",
      "ratio = 0.05461939772314616\n",
      "Total size  = 1731073.351087933\n",
      "pair = [20 96]\n",
      "ratio = 0.7564285237395649\n",
      "Total size  = 2883036.8729235716\n",
      "pair = [20 98]\n",
      "ratio = 0.7572571149681828\n",
      "Total size  = 2884396.939121768\n",
      "pair = [ 20 121]\n",
      "ratio = 0.7564285237395649\n",
      "Total size  = 2883036.8729235716\n",
      "pair = [21 85]\n",
      "ratio = 0.1483289692107506\n",
      "Total size  = 1884890.1140777653\n",
      "pair = [21 86]\n",
      "ratio = 0.7564285237395652\n",
      "Total size  = 2883036.8729235707\n",
      "pair = [21 87]\n",
      "ratio = 0.03953547999079724\n",
      "Total size  = 1706314.3071400924\n",
      "pair = [21 95]\n",
      "ratio = 0.054619397723146175\n",
      "Total size  = 1731073.3510879325\n",
      "pair = [21 96]\n",
      "ratio = 0.7564285237395652\n",
      "Total size  = 2883036.8729235707\n",
      "pair = [21 98]\n",
      "ratio = 0.757257114968183\n",
      "Total size  = 2884396.9391217674\n",
      "pair = [ 21 121]\n",
      "ratio = 0.7564285237395652\n",
      "Total size  = 2883036.8729235707\n",
      "pair = [22 85]\n",
      "ratio = 0.9200545031133974\n",
      "Total size  = 508095.90633472695\n",
      "pair = [22 86]\n",
      "ratio = 0.21312997124177746\n",
      "Total size  = 1506242.6651805325\n",
      "pair = [22 96]\n",
      "ratio = 0.21312997124177746\n",
      "Total size  = 1506242.6651805325\n",
      "pair = [22 98]\n",
      "ratio = 0.21289676428837176\n",
      "Total size  = 1507602.731378729\n",
      "pair = [ 22 121]\n",
      "ratio = 0.21312997124177746\n",
      "Total size  = 1506242.6651805325\n",
      "pair = [24 85]\n",
      "ratio = 0.9200545031133976\n",
      "Total size  = 508095.9063347269\n",
      "pair = [24 86]\n",
      "ratio = 0.2131299712417774\n",
      "Total size  = 1506242.6651805325\n",
      "pair = [24 96]\n",
      "ratio = 0.2131299712417774\n",
      "Total size  = 1506242.6651805325\n",
      "pair = [24 98]\n",
      "ratio = 0.21289676428837173\n",
      "Total size  = 1507602.731378729\n",
      "pair = [ 24 121]\n",
      "ratio = 0.2131299712417774\n",
      "Total size  = 1506242.6651805325\n",
      "best_stitch_pair = [ 5 98]\n",
      "best_stitch_pair_size = 2884396.939121768\n",
      "best_stitch_pair_size_ratio = 0.7572571149681827\n",
      "Child 1 already processed\n",
      "Child Index 2\n",
      "Total pairwise : 0.049483537673950195\n",
      "There was no possible stitch found after stitch distance and face normal filters\n",
      "repeat_main_facets = []\n",
      "child_meshes_stitch_facets = {0: [5, 98]}\n",
      "opposite normals\n",
      "[-0.07095509  0.99735877  0.01551953] [-0.  1.  0.]\n",
      "starting edge 1st facet = 6887, starting edge 2nd facet= 12218, \n",
      "[ 425760.           15220.00195312 -171680.        ] [ 426035.71875      15542.84863281 -171908.828125  ]\n",
      "start_point = 6887\n",
      "[ 6 17]\n",
      "starting edges = [[6887 8833]\n",
      " [6887 9741]]\n",
      "np.where(starting_edges[0,:] != start_point)[0][0] = 1\n",
      "np.where(starting_edges[1,:] != start_point)[0][0] = 1\n",
      "group 2 picked\n",
      "edge_0_order = [6887, 9741, 8106, 6747, 9467, 10233, 8640, 7591, 7125, 8864, 10115, 9992, 7321, 6746, 8228, 9049, 9144, 7048, 7367, 10351, 9503, 9062, 8235, 10012, 8858, 7149, 9286, 8833]\n",
      "start_point = 12218\n",
      "[22 23]\n",
      "starting edges = [[10457 12218]\n",
      " [11561 12218]]\n",
      "np.where(starting_edges[0,:] != start_point)[0][0] = 0\n",
      "np.where(starting_edges[1,:] != start_point)[0][0] = 0\n",
      "group 2 picked\n",
      "edge_1_order = [12218, 11561, 11787, 11359, 10787, 10812, 10838, 10862, 10386, 11861, 11525, 10877, 11748, 12470, 12432, 11011, 11659, 11615, 11948, 12270, 10475, 11260, 11820, 11445, 12599, 10985, 10914, 10743, 12443, 12515, 11131, 10655, 10689, 12559, 11618, 10457]\n",
      "index of bigger facets = 1\n",
      "index of smaller facets = 0\n",
      "dividend = 1, remainder = 8\n",
      "new_faces = [[6887, 8833, 12218], [6887, 12218, 11561], [6887, 11561, 11787], [9741, 6887, 11787], [9741, 11787, 11359], [9741, 11359, 10787], [8106, 9741, 10787], [8106, 10787, 10812], [8106, 10812, 10838], [6747, 8106, 10838], [6747, 10838, 10862], [6747, 10862, 10386], [9467, 6747, 10386], [9467, 10386, 11861], [9467, 11861, 11525], [10233, 9467, 11525], [10233, 11525, 10877], [10233, 10877, 11748], [8640, 10233, 11748], [8640, 11748, 12470], [8640, 12470, 12432], [7591, 8640, 12432], [7591, 12432, 11011], [7591, 11011, 11659], [7125, 7591, 11659], [7125, 11659, 11615], [8864, 7125, 11615], [8864, 11615, 11948], [10115, 8864, 11948], [10115, 11948, 12270], [9992, 10115, 12270], [9992, 12270, 10475], [7321, 9992, 10475], [7321, 10475, 11260], [6746, 7321, 11260], [6746, 11260, 11820], [8228, 6746, 11820], [8228, 11820, 11445], [9049, 8228, 11445], [9049, 11445, 12599], [9144, 9049, 12599], [9144, 12599, 10985], [7048, 9144, 10985], [7048, 10985, 10914], [7367, 7048, 10914], [7367, 10914, 10743], [10351, 7367, 10743], [10351, 10743, 12443], [9503, 10351, 12443], [9503, 12443, 12515], [9062, 9503, 12515], [9062, 12515, 11131], [8235, 9062, 11131], [8235, 11131, 10655], [10012, 8235, 10655], [10012, 10655, 10689], [8858, 10012, 10689], [8858, 10689, 12559], [7149, 8858, 12559], [7149, 12559, 11618], [9286, 7149, 11618], [9286, 11618, 10457], [8833, 9286, 10457], [8833, 10457, 12218]]\n",
      "Creating empty dictionary : 0.0469670295715332\n",
      "Filling in neighbors lookup : 0.0745546817779541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "188it [00:00, 1873.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Facet building time: 0.09720611572265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "776it [00:00, 2170.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounding_box_threshold = 4000.0\n",
      "stitch_distance_threshold = 2000\n",
      "size_ratio_threshold = 0.3\n",
      "Child 0 already processed\n",
      "Child 1 already processed\n",
      "Child Index 2\n",
      "Total pairwise : 0.04990673065185547\n",
      "**********1.0**********\n",
      "**********True**********\n",
      "pair = [  0 140]\n",
      "ratio = 0.5166944204861496\n",
      "Total size  = 7826.387863329249\n",
      "pair = [  1 123]\n",
      "ratio = 0.5696087999389912\n",
      "Total size  = 23081.50607331565\n",
      "pair = [  1 134]\n",
      "ratio = 0.569608799938991\n",
      "Total size  = 23081.506073315653\n",
      "pair = [  5 138]\n",
      "ratio = 0.07909109011715439\n",
      "Total size  = 37127.091568559146\n",
      "pair = [  6 123]\n",
      "ratio = 0.5708717908671189\n",
      "Total size  = 23100.078683751613\n",
      "pair = [  6 134]\n",
      "ratio = 0.5708717908671188\n",
      "Total size  = 23100.078683751613\n",
      "pair = [  7 138]\n",
      "ratio = 0.2269765350027875\n",
      "Total size  = 42215.222222413315\n",
      "pair = [  8 123]\n",
      "ratio = 0.17279770403891845\n",
      "Total size  = 17246.29559263246\n",
      "pair = [  8 134]\n",
      "ratio = 0.17279770403891842\n",
      "Total size  = 17246.29559263246\n",
      "pair = [  9 138]\n",
      "ratio = 0.34700499544738755\n",
      "Total size  = 46344.90847649594\n",
      "pair = [ 10 138]\n",
      "ratio = 0.34700499544738744\n",
      "Total size  = 46344.90847649593\n",
      "pair = [ 11 124]\n",
      "ratio = 0.6865252307629388\n",
      "Total size  = 650082.5056590659\n",
      "pair = [ 11 125]\n",
      "ratio = 0.6865252307629387\n",
      "Total size  = 650082.5056590658\n",
      "pair = [ 11 129]\n",
      "ratio = 0.005313179481347012\n",
      "Total size  = 387504.7338566491\n",
      "pair = [ 11 132]\n",
      "ratio = 0.028244879993722882\n",
      "Total size  = 396343.9122194684\n",
      "pair = [ 11 133]\n",
      "ratio = 0.6865252307629385\n",
      "Total size  = 650082.5056590657\n",
      "pair = [ 11 139]\n",
      "ratio = 0.6865252307629388\n",
      "Total size  = 650082.5056590659\n",
      "pair = [ 11 141]\n",
      "ratio = 0.6865252307629387\n",
      "Total size  = 650082.5056590658\n",
      "pair = [ 12 124]\n",
      "ratio = 0.6865252307629388\n",
      "Total size  = 650082.5056590659\n",
      "pair = [ 12 125]\n",
      "ratio = 0.6865252307629387\n",
      "Total size  = 650082.5056590658\n",
      "pair = [ 12 129]\n",
      "ratio = 0.005313179481347012\n",
      "Total size  = 387504.7338566491\n",
      "pair = [ 12 132]\n",
      "ratio = 0.028244879993722882\n",
      "Total size  = 396343.9122194684\n",
      "pair = [ 12 133]\n",
      "ratio = 0.6865252307629385\n",
      "Total size  = 650082.5056590657\n",
      "pair = [ 12 139]\n",
      "ratio = 0.6865252307629388\n",
      "Total size  = 650082.5056590659\n",
      "pair = [ 12 141]\n",
      "ratio = 0.6865252307629387\n",
      "Total size  = 650082.5056590658\n",
      "pair = [ 13 123]\n",
      "ratio = 0.2651798293672194\n",
      "Total size  = 18604.798798599368\n",
      "pair = [ 13 134]\n",
      "ratio = 0.2651798293672194\n",
      "Total size  = 18604.798798599368\n",
      "pair = [ 14 123]\n",
      "ratio = 0.8774878602525352\n",
      "Total size  = 27608.947815965155\n",
      "pair = [ 14 134]\n",
      "ratio = 0.8774878602525351\n",
      "Total size  = 27608.94781596516\n",
      "pair = [ 15 123]\n",
      "ratio = 0.5232997296067536\n",
      "Total size  = 22400.519136847986\n",
      "pair = [ 15 134]\n",
      "ratio = 0.5232997296067536\n",
      "Total size  = 22400.51913684799\n",
      "best_stitch_pair = [ 11 124]\n",
      "best_stitch_pair_size = 650082.5056590659\n",
      "best_stitch_pair_size_ratio = 0.6865252307629388\n",
      "repeat_main_facets = []\n",
      "child_meshes_stitch_facets = {2: [11, 124]}\n",
      "[ 0.00101376  0.99999345 -0.00347333] [1.34086098e-03 9.99998974e-01 5.04458504e-04]\n",
      "starting edge 1st facet = 12167, starting edge 2nd facet= 12700, \n",
      "[ 426248.78125      15541.30761719 -173784.375     ] [ 425714.03125      15417.83300781 -174118.234375  ]\n",
      "start_point = 12167\n",
      "[17 18]\n",
      "starting edges = [[11384 12167]\n",
      " [11957 12167]]\n",
      "np.where(starting_edges[0,:] != start_point)[0][0] = 0\n",
      "np.where(starting_edges[1,:] != start_point)[0][0] = 0\n",
      "group 1 picked\n",
      "Start vertex reached before processed all of edges\n",
      "edge_0_order = [12167, 11384, 10882, 12009, 12214, 11766, 10345, 12424, 12478, 12228, 10971, 11965, 10809, 11266, 11474, 11519, 10933, 12264, 11924, 10974, 10348, 11552, 11957]\n",
      "start_point = 12700\n",
      "[ 3 15]\n",
      "starting edges = [[12700 12730]\n",
      " [12700 12837]]\n",
      "np.where(starting_edges[0,:] != start_point)[0][0] = 1\n",
      "np.where(starting_edges[1,:] != start_point)[0][0] = 1\n",
      "group 1 picked\n",
      "edge_1_order = [12700, 12730, 12570, 12785, 12732, 12741, 12799, 12640, 12713, 12746, 12847, 12839, 12809, 12592, 12593, 12804, 12676, 12794, 12787, 12837]\n",
      "index of bigger facets = 0\n",
      "index of smaller facets = 1\n",
      "dividend = 1, remainder = 3\n",
      "new_faces = [[12700, 12837, 12167], [12700, 12167, 11384], [12700, 11384, 10882], [12730, 12700, 10882], [12730, 10882, 12009], [12730, 12009, 12214], [12570, 12730, 12214], [12570, 12214, 11766], [12570, 11766, 10345], [12785, 12570, 10345], [12785, 10345, 12424], [12732, 12785, 12424], [12732, 12424, 12478], [12741, 12732, 12478], [12741, 12478, 12228], [12799, 12741, 12228], [12799, 12228, 10971], [12640, 12799, 10971], [12640, 10971, 11965], [12713, 12640, 11965], [12713, 11965, 10809], [12746, 12713, 10809], [12746, 10809, 11266], [12847, 12746, 11266], [12847, 11266, 11474], [12839, 12847, 11474], [12839, 11474, 11519], [12809, 12839, 11519], [12809, 11519, 10933], [12592, 12809, 10933], [12592, 10933, 12264], [12593, 12592, 12264], [12593, 12264, 11924], [12804, 12593, 11924], [12804, 11924, 10974], [12676, 12804, 10974], [12676, 10974, 10348], [12794, 12676, 10348], [12794, 10348, 11552], [12787, 12794, 11552], [12787, 11552, 11957], [12837, 12787, 11957], [12837, 11957, 12167]]\n",
      "Creating empty dictionary : 0.044111013412475586\n",
      "Filling in neighbors lookup : 0.08204889297485352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192it [00:00, 1919.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Facet building time: 0.07064199447631836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "802it [00:00, 2229.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All children have been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Pseudocode for loop at the end that will keep everything going:\n",
    "1) When process a child, will add that index to a list\n",
    "2) Have no_new_children_processed counter set at end of loop \n",
    "    if no children were added to main mesh\n",
    "    --> this will prompt the expansion of the initial parameters\n",
    "3) If this gets too high\n",
    "\n",
    "\n",
    "\n",
    "Things that still need to add:\n",
    "1) Better way of making sure that the normals are good\n",
    "- Can sample one of the neighboring points and flip normals if the dot product is negative\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#sets \n",
    "initial_parameters = dict(bounding_box_threshold=4000,\n",
    "                         stitch_distance_threshold=2000,\n",
    "                         size_ratio_threshold=0.30)\n",
    "main_mesh = main_mesh\n",
    "bounding_box_threshold = initial_parameters[\"bounding_box_threshold\"]\n",
    "stitch_distance_threshold = initial_parameters[\"stitch_distance_threshold\"]\n",
    "size_ratio_threshold = initial_parameters[\"size_ratio_threshold\"]\n",
    "\n",
    "no_new_children_multiplier = 0\n",
    "bbox_expansion_percentage = 0.10\n",
    "stitch_expansion_percentage = 1\n",
    "size_ratio_expansion_percentage = 0.10\n",
    "\n",
    "no_new_children_limit = 4\n",
    "\n",
    "consider_same_direction_normals = True\n",
    "children_processed = []\n",
    "\n",
    "while len(children_processed) < len(child_meshes):\n",
    "    if no_new_children_multiplier >= no_new_children_limit:\n",
    "        print(\"The number of times expanding the thresholds has exceed the limit /n Just returning main mesh\")\n",
    "        \n",
    "    \n",
    "    #update the thresholds\n",
    "    bounding_box_threshold = initial_parameters[\"bounding_box_threshold\"]*(1 + bbox_expansion_percentage*no_new_children_multiplier)\n",
    "    stitch_distance_threshold = initial_parameters[\"stitch_distance_threshold\"]*(1 + stitch_expansion_percentage*no_new_children_multiplier)\n",
    "    #reduces the \n",
    "    size_ratio_threshold = initial_parameters[\"size_ratio_threshold\"]*(1 - size_ratio_expansion_percentage*no_new_children_multiplier)\n",
    "    \n",
    "    #print thresholds\n",
    "    print(f\"bounding_box_threshold = {bounding_box_threshold}\")\n",
    "    print(f\"stitch_distance_threshold = {stitch_distance_threshold}\" )\n",
    "    print(f\"size_ratio_threshold = {size_ratio_threshold}\")\n",
    "\n",
    "    #get the main mesh facets normals\n",
    "    main_mesh_normals = [main_mesh.face_normals[fac[0]] for fac in main_mesh_facets]\n",
    "    hit_indexes_list= []\n",
    "    \n",
    "    \n",
    "    #dictionary to save the stitch points\n",
    "    child_meshes_stitch_facets = dict()\n",
    "    child_meshes_stitch_face_ratios = dict()\n",
    "    for i,child in enumerate(child_meshes):\n",
    "        \n",
    "        if i in children_processed:\n",
    "            print(f\"Child {i} already processed\")\n",
    "            continue\n",
    "\n",
    "        #initialize the stitch index\n",
    "        #child_meshes_stitch_facets[i] = [-1,-1]\n",
    "\n",
    "        #two highest points for the bounding box\n",
    "        min_bb = np.array(main_mesh.bounding_box.vertices).min(0)\n",
    "        max_bb = np.array(main_mesh.bounding_box.vertices).max(0)\n",
    "\n",
    "        min_bb_zone = min_bb - bounding_box_threshold\n",
    "        max_bb_zone = max_bb + bounding_box_threshold\n",
    "\n",
    "\n",
    "\n",
    "        #then send mesh to function that decides if with\n",
    "        pass_bbox_filter = apply_bbox_filter(child,min_bb_zone,max_bb_zone)\n",
    "\n",
    "        if not pass_bbox_filter:\n",
    "            print(\"skipped\")\n",
    "            continue\n",
    "\n",
    "        #### used for validation to make sure that bounding box was correctly filtering\n",
    "    #     #add the following to main mesh just to visualize\n",
    "    #     final_mesh = final_mesh + child\n",
    "    #     print(\"just added\")\n",
    "\n",
    "        #\n",
    "        \"\"\"\n",
    "\n",
    "        Do pairwise calculation of distances between centers of facets on child piece and main piece\n",
    "            Filter the pairs for stitch distance threshold\n",
    "            Filter the pairs for matching or opposite normals\n",
    "            Filter for those that are reasonable in size matching (within 50% of each other)\n",
    "\n",
    "        If there are still ties after this point then pitch the best matching size\n",
    "\n",
    "        If None remaining then keep going (might loosen up the parameters later), BUT WITH GLOBAL CHECK SO DOESN’T KEEP ITERATING\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        child_facets,child_facets_centers = child_meshes_facets[i]\n",
    "\n",
    "\n",
    "        main_mesh_facets,main_mesh_facets_centers\n",
    "\n",
    "        facet_distances = np.zeros((len(child_facets_centers),len(main_mesh_facets_centers)))\n",
    "        facet_normals = np.zeros((len(child_facets_centers),len(main_mesh_facets_centers)))\n",
    "\n",
    "        start_time = time.time()\n",
    "        #do the pairwise comparison\n",
    "        for cc,child_center in enumerate(child_facets_centers):\n",
    "\n",
    "            #get the normal of the child\n",
    "            child_normal = child.face_normals[child_facets[cc][0]]\n",
    "            for mm, main_center in enumerate(main_mesh_facets_centers):\n",
    "                #get the euclidean distance\n",
    "    #             facet_distances[cc,mm] = math.sqrt((child_center[0] - main_center[0])**2 + \n",
    "    #                                                  (child_center[1] - main_center[1])**2 + \n",
    "    #                                                  (child_center[2] - main_center[2])**2 )\n",
    "\n",
    "\n",
    "\n",
    "                facet_distances[cc,mm] = np.linalg.norm(np.array(child_center) - np.array(main_center))\n",
    "\n",
    "                main_normal = main_mesh_normals[mm]\n",
    "    #             print(\"main_normal = \" + str(main_normal))\n",
    "    #             print(\"child_normal = \" + str(child_normal))\n",
    "                #get whether the normals are line up (or possibly opposite)\n",
    "                normals_dot = np.dot(child_normal,main_normal)\n",
    "                #print(normals_dot)\n",
    "                if consider_same_direction_normals == True:\n",
    "                    facet_normals[cc,mm] =  normals_dot < -0.95  or normals_dot > 0.95\n",
    "                else:\n",
    "                    facet_normals[cc,mm] =  normals_dot < -0.95 # or normals_dot > 0.95\n",
    "\n",
    "\n",
    "        print(f\"Child Index {i}\")\n",
    "        print(f\"Total pairwise : {time.time() - start_time}\")\n",
    "\n",
    "    #     if i == 1:\n",
    "    #         4,12\n",
    "    #         print(\"4,12 facet distance = \" + str(facet_distances[4,12]))\n",
    "\n",
    "        #apply the filters\n",
    "        #stitch_distance_booleans = facet_distances < stitch_distance_threshold\n",
    "\n",
    "        #get the indexes that make it through \n",
    "        main_facet_bebug = 124\n",
    "        piece_facet_debug = 11\n",
    "        \n",
    "        if i == 2 and (0 in children_processed):\n",
    "            print(\"**********\" + str(facet_normals[piece_facet_debug,main_facet_bebug]) + \"**********\")\n",
    "            print(\"**********\" + str((facet_distances < stitch_distance_threshold)[piece_facet_debug,main_facet_bebug]) + \"**********\")\n",
    "        \n",
    "        hit_indexes = np.where(np.logical_and(facet_distances < stitch_distance_threshold,facet_normals)== True) \n",
    "\n",
    "        possible_stitch_pairs = np.vstack(hit_indexes).T\n",
    "        \n",
    "        #print(\"possible_stitch_pairs = \" + str(possible_stitch_pairs))\n",
    "            \n",
    "\n",
    "        face_0_unique_facets = np.unique(hit_indexes[0])\n",
    "        face_1_unique_facets = np.unique(hit_indexes[1])\n",
    "        #get the sizes of all the unique ones\n",
    "\n",
    "        ####need to fix this up********************************* to find the area of the child facets and the main facets\n",
    "        if len(hit_indexes[0]) <= 0:\n",
    "            print(\"There was no possible stitch found after stitch distance and face normal filters\")\n",
    "            continue\n",
    "\n",
    "        if len(hit_indexes[0]) > 0:\n",
    "            face_0_facet_sizes = dict([(u,find_polygon_area(child,child_facets[u])) for u in face_0_unique_facets])\n",
    "            face_1_facet_sizes = dict([(u,find_polygon_area(main_mesh,main_mesh_facets[u])) for u in face_1_unique_facets])\n",
    "\n",
    "    #     print(\"possible_stitch_pairs = \" + str(possible_stitch_pairs))\n",
    "    #     print(\"len(hit_indexes) = \" + str(len(hit_indexes)))\n",
    "    #     print(\"hit_indexes[0].any() = \" + str(hit_indexes[0].any()))\n",
    "    #     print(\"hit_indexes = \" + str(hit_indexes))\n",
    "    #     print(\"hit_indexes[0] = \" + str(hit_indexes[0]))\n",
    "    #     print(\"len(hit_indexes[0]) = \" + str(len(hit_indexes[0])))\n",
    "\n",
    "        #find the sizes of all of them\n",
    "        face_pair_sizes = np.zeros(len(possible_stitch_pairs[:,0]))\n",
    "        face_size_ratios = np.zeros(len(possible_stitch_pairs[:,0]))\n",
    "\n",
    "        #print(\"possible_stitch_pairs = \" + str(possible_stitch_pairs))\n",
    "        for numba,pair in enumerate(possible_stitch_pairs):\n",
    "            print(\"pair = \" + str(pair))\n",
    "            sizes = [face_0_facet_sizes[pair[0]],face_1_facet_sizes[pair[1]]]\n",
    "            min_area = min(sizes)\n",
    "            max_area = max(sizes)\n",
    "\n",
    "            ratio = min_area/max_area\n",
    "\n",
    "            print(f\"ratio = {ratio}\")\n",
    "            print(f\"Total size  = {min_area + max_area}\")\n",
    "            if ratio >= size_ratio_threshold:\n",
    "                face_pair_sizes[numba] = min_area + max_area\n",
    "                face_size_ratios[numba] = ratio\n",
    "            \n",
    "                #print(f\"face_pair_sizes[numba] = {face_pair_sizes[numba]}, face_size_ratios[numba] = {face_size_ratios[numba]}\")\n",
    "\n",
    "\n",
    "        #check that made it past stitch ratio threshold\n",
    "\n",
    "        #best possible stitch pair is just the maximum sized matching ones\n",
    "        best_index = np.where(face_pair_sizes == max(face_pair_sizes))\n",
    "        best_stitch_pair = possible_stitch_pairs[best_index][0]\n",
    "        best_stitch_pair_size = face_pair_sizes[best_index][0]\n",
    "        best_stitch_pair_size_ratio = face_size_ratios[best_index][0]\n",
    "        \n",
    "        print(\"best_stitch_pair = \" + str(best_stitch_pair))\n",
    "        print(\"best_stitch_pair_size = \" + str(best_stitch_pair_size))\n",
    "        print(\"best_stitch_pair_size_ratio = \" + str(best_stitch_pair_size_ratio))\n",
    "\n",
    "        child_meshes_stitch_facets[i] = [best_stitch_pair[0],best_stitch_pair[1]]\n",
    "        child_meshes_stitch_face_ratios[i] = best_stitch_pair_size_ratio\n",
    "\n",
    "    \n",
    "#     if 0 in child_meshes_stitch_facets.keys():\n",
    "#         print(\"Just processed piece 1\")\n",
    "#         break\n",
    "    \n",
    "    \n",
    "    # makes sure that no two child branches try to connect to the same main branch\n",
    "    from collections import Counter\n",
    "    mesh_stitch_counter = Counter(np.array([val for val in child_meshes_stitch_facets.values()])[:,1])\n",
    "\n",
    "    repeat_main_facets = [key for key,val in mesh_stitch_counter.items() if (key != -1 and val > 1)] #gets the main mesh facet with multiples\n",
    "    print(\"repeat_main_facets = \" + str(repeat_main_facets))\n",
    "\n",
    "\n",
    "    if len(repeat_main_facets)>0:\n",
    "\n",
    "        child_mesh_double_indexes = [key for key,val in child_meshes_stitch_facets.items() if val[1] in repeat_main_facets]\n",
    "        print(\"child_mesh_double_indexes = \" + str(child_mesh_double_indexes))\n",
    "\n",
    "\n",
    "        #decide which one to ditch --> pick the best matching area:\n",
    "        max_ratio = -1\n",
    "        max_child = -1\n",
    "\n",
    "\n",
    "        for child_index in child_mesh_double_indexes:\n",
    "            current_ratio = child_meshes_stitch_face_ratios[child_index]\n",
    "\n",
    "            if current_ratio > max_ratio:\n",
    "                max_child = child_index\n",
    "                max_ratio = current_ratio\n",
    "\n",
    "        print(f\"max_child = {max_child}, max_ratio = {max_ratio}\")\n",
    "\n",
    "        #remove the others from the stitch facets\n",
    "        for double_index in child_mesh_double_indexes:\n",
    "            if double_index != max_child:\n",
    "                del child_meshes_stitch_facets[double_index]\n",
    "    \n",
    "    \"\"\"\n",
    "    Pseudocode for stitching:\n",
    "    1) For each pair in the child_meshes_stitch_facets:\n",
    "    a. Get the child mesh for that pair\n",
    "    b. Get the list of faces for the child facet (from the facet number)\n",
    "    c. Get the list of faces for the main facet (from the main number)\n",
    "\n",
    "    d. Get the original number of faces and vertices in the main mesh\n",
    "    d2. Use the orignal number of faces and add to list of faces for child facet to offset them correctly\n",
    "        - Save this number list in a dictionary (to use for later and creating the submesh)\n",
    "    e. Add the two meshes together to get big mesh\n",
    "    f. Send the two meshes and the two facet lists to the restitching function to get a main mesh that is stitched up\n",
    "     - but send it to function that doesnt delete the original facet faces \n",
    "         (because this would remove meshes from original and screw up facet number)\n",
    "    g. reassign the main_mesh to this newly stitched up mesh\n",
    "    h. recompute the facets for the main mesh\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    child_faces_to_remove = []\n",
    "    current_main_mesh = main_mesh.copy()\n",
    "\n",
    "    #current_main_mesh.show() #checked that could make a copy of the mesh\n",
    "\n",
    "    main_faces_to_remove = []\n",
    "    if len(child_meshes_stitch_facets.keys()) == 0:\n",
    "        #increment the no children flag multiplier\n",
    "        \n",
    "        no_new_children_multiplier += 1\n",
    "        print(f\"no stitch points found --> relaxing the parameters time {no_new_children_multiplier}\")\n",
    "        continue\n",
    "    else:\n",
    "        print(\"child_meshes_stitch_facets = \" + str(child_meshes_stitch_facets))\n",
    "        for child_key,pair in child_meshes_stitch_facets.items():\n",
    "            current_child_mesh = child_meshes[child_key]\n",
    "            current_child_facet_faces = child_meshes_facets[child_key][0][pair[0]]\n",
    "\n",
    "\n",
    "            current_main_mesh_facet_faces = main_mesh_facets[pair[1]]\n",
    "\n",
    "            #Get the original number of faces and vertices in the main mesh\n",
    "            original_mesh_faces_len = len(current_main_mesh.faces)\n",
    "            current_child_facet_faces_adjusted = [k + original_mesh_faces_len \n",
    "                                                              for k in current_child_facet_faces]\n",
    "\n",
    "            #Save the faces number for deletion later\n",
    "            child_faces_to_remove += current_child_facet_faces_adjusted\n",
    "            main_faces_to_remove += current_main_mesh_facet_faces\n",
    "\n",
    "            combined_mesh = main_mesh + current_child_mesh\n",
    "\n",
    "            #how to stitch up the mesh\n",
    "            stitch_mesh,added_mesh = stitch_mesh_piece_vp3(new_mesh=combined_mesh,\n",
    "                                                           facet_1=current_main_mesh_facet_faces,\n",
    "                                                           facet_2=current_child_facet_faces_adjusted,\n",
    "                                                          delete_facets=False,\n",
    "                                                          return_added_mesh=True)\n",
    "\n",
    "            #reassign the main mesh\n",
    "            current_main_mesh = stitch_mesh\n",
    "\n",
    "            #add the child to processed child\n",
    "            children_processed.append(child_key)\n",
    "\n",
    "        #remove all of the processed facets from the main mesh\n",
    "        #now take away the original facet faces:\n",
    "        total_faces = np.linspace(0,len(current_main_mesh.faces)-1,len(current_main_mesh.faces)).astype(\"int\")\n",
    "        facet_faces = np.hstack([child_faces_to_remove ,main_faces_to_remove])\n",
    "        faces_to_keep = set(total_faces).difference(set(facet_faces))\n",
    "\n",
    "\n",
    "        main_mesh = current_main_mesh.submesh([list(faces_to_keep)])[0]\n",
    "\n",
    "\n",
    "        #reset the no_new_children_multiplier\n",
    "        no_new_children_multiplier = 0\n",
    "        #recompute the main mesh facets\n",
    "        main_mesh_facets,main_mesh_facets_centers = filter_final_facets(main_mesh)\n",
    "        \n",
    "#         if 0 in children_processed and 1 in children_processed:\n",
    "#             print(\"Exiting before does piece 2\")\n",
    "#             break\n",
    "\n",
    "        if len(np.unique(children_processed)) == len(child_meshes):\n",
    "            print(\"All children have been processed\")\n",
    "            break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that stitching went well:\n",
    "from print_trimesh import print_trimesh\n",
    "print_trimesh(main_mesh,\"./test_meshes/debug_5.off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the wrong Facet Picking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from print_trimesh import print_trimesh\n",
    "print_trimesh(main_mesh,\"main_mesh_processed_1.off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in piece 0 that is being missed in the facet selection: 3166\n",
    "\n",
    "#possible facets that are being missed out: \n",
    "missing_facets = []\n",
    "\n",
    "for nn,facet_face_list in enumerate(child_meshes_facets[2][0]):\n",
    "    if 479 in facet_face_list:\n",
    "        missing_facets.append(nn)\n",
    "        print(len(facet_face_list))\n",
    "        print(facet_face_list)\n",
    "        \n",
    "\n",
    "missing_facets\n",
    "\n",
    "piece_facet = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the main mesh facets that was missed\n",
    "#possible facets that are being missed out: \n",
    "missing_facets_main = []\n",
    "\n",
    "main_mesh_facets,main_mesh_facets_centers = filter_final_facets(main_mesh)\n",
    "\n",
    "for nn,facet_face_list in enumerate(main_mesh_facets):\n",
    "    if 23523 in facet_face_list:\n",
    "        missing_facets_main.append(nn)\n",
    "        #print(len(facet_face_list))\n",
    "        print(facet_face_list)\n",
    "        \n",
    "missing_facets_main\n",
    "missing_facets_main[0]\n",
    "\n",
    "main_facet = 124"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_2 = trimesh.load(\"./test_meshes/piece_2.off\")\n",
    "main_mesh_debug = trimesh.load(\"./test_meshes/no_piece_2.off\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_main_mesh = main_mesh_debug.face_normals[21250]\n",
    "normal_piece_mesh = piece_2.face_normals[458]\n",
    "print(normal_main_mesh,normal_piece_mesh)\n",
    "\n",
    "np.dot(normal_main_mesh,normal_piece_mesh) #have normals that are in the same direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the normals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_trimesh(main_mesh,\"./test_meshes/main_mesh_pt2.off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facet_normals[cc,mm] =  normals_dot < -0.95  #or normals_dot > 0.95\n",
    "\n",
    "\n",
    "# print(f\"Child Index {i}\")\n",
    "# print(f\"Total pairwise : {time.time() - start_time}\")\n",
    "\n",
    "# #     if i == 1:\n",
    "# #         4,12\n",
    "# #         print(\"4,12 facet distance = \" + str(facet_distances[4,12]))\n",
    "\n",
    "# #apply the filters\n",
    "# #stitch_distance_booleans = facet_distances < stitch_distance_threshold\n",
    "\n",
    "# #get the indexes that make it through \n",
    "# #         missing_facets = [5, 10, 12, 16, 20, 21]\n",
    "# #         if i == 0:\n",
    "# #             print(facet_normals[])\n",
    "\n",
    "# hit_indexes = np.where(np.logical_and(facet_distances < stitch_distance_threshold,facet_normals)== True) \n",
    "\n",
    "# possible_stitch_pairs = np.vstack(hit_indexes).T\n",
    "\n",
    "\n",
    "main_facet_bebug = 86\n",
    "piece_facet_debug = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet_normals[5,86]\n",
    "facet_normals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the Edge Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from print_trimesh import print_trimesh\n",
    "print_trimesh(main_mesh,\"./test_meshes/main_mesh_debug_2.off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_child_facet_faces_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_mesh_facets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the facets generated for main mesh again:\n",
    "# download the facets list and see if the process worked:\n",
    "index = 2\n",
    "facets_group = np.zeros(len(main_mesh.faces)).astype(int)\n",
    "\n",
    "for i,facet_group in enumerate(main_mesh_facets):\n",
    "    for face in facet_group:\n",
    "        facets_group[face] = i + 1 #so that you reserve the label 0 for blenders none\n",
    "\n",
    "np.savez(\"./test_meshes/\" +\"main_facet\" + \".npz\",\n",
    "         facets_group=facets_group)\n",
    "        \n",
    "\n",
    "from print_trimesh import print_trimesh\n",
    "print_trimesh(main_mesh,\"./test_meshes/main_mesh.off\")\n",
    "\n",
    "\n",
    "len(facets_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from print_trimesh import print_trimesh\n",
    "print_trimesh(main_mesh,\"./test_meshes/main_mesh_debug.off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_meshes_stitch_facets = {0: [22, 85]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(child_meshes_facets[0][0][22])\n",
    "main_mesh_facets[85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check to see if there are any edges that repeat more than twice\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "new_array = np.array([[10462, 10467],\n",
    "       [10467, 10476],\n",
    "       [10456, 11122],\n",
    "       [10462, 11403],\n",
    "       [10476, 11403],\n",
    "       [10956, 11417],\n",
    "       [11029, 11537],\n",
    "       [11417, 11628],\n",
    "       [11080, 11673],\n",
    "       [11628, 11673],\n",
    "       [10456, 11706],\n",
    "       [10443, 11922],\n",
    "       [11122, 12081],\n",
    "       [11706, 12114],\n",
    "       [10956, 12122],\n",
    "       [11119, 12122],\n",
    "       [11029, 12166],\n",
    "       [11537, 12324],\n",
    "       [12114, 12324],\n",
    "       [11922, 12371],\n",
    "       [12166, 12371],\n",
    "       [11119, 12385],\n",
    "       [11080, 12421],\n",
    "       [12081, 12421],\n",
    "       [10443, 12582],\n",
    "       [12385, 12636],\n",
    "       [12582, 12636]])\n",
    "\n",
    "#Counter(np.hstack([new_array[:,1],new_array[:,0]]))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Shows that they all only occur twice\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "new_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loop_unique = np.unique(np.hstack([new_array[:,1],new_array[:,0]]))\n",
    "print(len(total_loop_unique))\n",
    "total_loop_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_piece= np.unique(np.array([11119, 12122, 10956, 11417, 11628, 11673, 11080, 12421, 12081, 11122, 10456, 11706, 12114, 12324, 11537, 11029, 12166, 12371, 11922, 10443, 12582, 12636, 12385]))\n",
    "print(len(new_piece))\n",
    "new_piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the difference between the two\n",
    "set(total_loop_unique).difference(set(new_piece))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Conclusion: There was a loop formed by the facet which is throwing things off\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
