{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import datajoint as dj\n",
    "from print_trimesh import print_trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import contextlib\n",
    "\n",
    "def print_trimesh(current_mesh,file_name):\n",
    "    with open(os.devnull, \"w\") as f, contextlib.redirect_stdout(f):\n",
    "        current_mesh.export(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinky = dj.create_virtual_module(\"pinky\",\"microns_pinky\")\n",
    "ta3p100 = dj.create_virtual_module(\"ta3p100\",\"microns_ta3p100\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648518346349471156\n"
     ]
    }
   ],
   "source": [
    "segment_id = None\n",
    "mesh_index = 3\n",
    "\n",
    "if segment_id == None:\n",
    "    #gets the possible segment ids\n",
    "    segment_ids = (pinky.AllenSoma() & \"cell_class='excitatory'\").fetch(\"segment_id\")\n",
    "    neuron_id = segment_ids[mesh_index]\n",
    "else:\n",
    "    neuron_id = segment_id\n",
    "\n",
    "print(neuron_id)\n",
    "key = dict(segment_id=segment_ids[mesh_index],segmentation=3)\n",
    "vertices,triangles = (pinky.Mesh & key).fetch(\"vertices\",\"triangles\")\n",
    "\n",
    "unfiltered_mesh = trimesh.Trimesh()\n",
    "unfiltered_mesh.vertices = vertices[0]\n",
    "unfiltered_mesh.faces = triangles[0]\n",
    "#new_mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download a version of the original mesh\n",
    "\n",
    "\n",
    "print_trimesh(unfiltered_mesh,\"./test_meshes/\" + \"original_\" + str(neuron_id) +\"entire_neuron_facets_optimized_v11.off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_mesh_significant_outside_pieces(unfiltered_mesh,significance_threshold=2000,n_sample_points=1000):\n",
    "    \"\"\"\n",
    "    Purpose; will take in a full, unfiltered mesh and find the biggest mesh piece, and then return a list of that mesh \n",
    "    with all of the other mesh fragments that are both above the significance_threshold AND outside of the biggest mesh piece\n",
    "\n",
    "    Pseudocode: \n",
    "    1) split the meshes to unconnected pieces\n",
    "    2) Filter the meshes for only those above the significance_threshold\n",
    "    3) find the biggest mesh piece\n",
    "    4) Iterate through all of the remaining pieces:\n",
    "        a. Determine if mesh inside or outside main mesh\n",
    "        b. If outside add to final list to return\n",
    "\n",
    "    Returns: \n",
    "    1) list of significant mesh pieces, including the main one that are not inside of main mesh\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    mesh_pieces = unfiltered_mesh.split(only_watertight=False)\n",
    "    \n",
    "    print(f\"There were {len(mesh_pieces)} pieces after mesh split\")\n",
    "\n",
    "    significant_pieces = [m for m in mesh_pieces if len(m.faces) > significance_threshold]\n",
    "\n",
    "    print(f\"There were {len(significant_pieces)} pieces found after size threshold\")\n",
    "    if len(significant_pieces) <=0:\n",
    "        print(\"THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\")\n",
    "        return []\n",
    "\n",
    "    #find piece with largest size\n",
    "    max_index = 0\n",
    "    max_face_len = len(significant_pieces[max_index].faces)\n",
    "\n",
    "    for i in range(1,len(significant_pieces)):\n",
    "        if max_face_len < len(significant_pieces[i].faces):\n",
    "            max_index = i\n",
    "            max_face_len = len(significant_pieces[i].faces)\n",
    "\n",
    "    print(\"max_index = \" + str(max_index))\n",
    "    print(\"max_face_len = \" + str(max_face_len))\n",
    "\n",
    "    final_mesh_pieces = []\n",
    "\n",
    "    main_mesh = significant_pieces[max_index]\n",
    "\n",
    "    #final_mesh_pieces.append(main_mesh)\n",
    "    for i,mesh in enumerate(significant_pieces):\n",
    "        if i != max_index:\n",
    "            #get a random sample of points\n",
    "            # points = np.array(mesh.vertices[:n_sample_points,:]) # OLD WAY OF DOING THIS\n",
    "            idx = np.random.randint(len(mesh.vertices), size=n_sample_points)\n",
    "            points = mesh.vertices[idx,:]\n",
    "            \n",
    "            \n",
    "            start_time = time.time()\n",
    "            signed_distance = trimesh.proximity.signed_distance(main_mesh,points)\n",
    "            print(f\"Total time = {time.time() - start_time}\")\n",
    "\n",
    "            outside_percentage = sum(signed_distance < 0)/n_sample_points\n",
    "            if outside_percentage > 0.9:\n",
    "                final_mesh_pieces.append(mesh)\n",
    "                print(f\"Mesh piece {i} OUTSIDE mesh\")\n",
    "            else:\n",
    "                print(f\"Mesh piece {i} inside mesh :( \")\n",
    "                \n",
    "    return main_mesh,final_mesh_pieces\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 2889 pieces after mesh split\n",
      "There were 269 pieces found after size threshold\n",
      "max_index = 0\n",
      "max_face_len = 1551161\n",
      "Total time = 28.830869674682617\n",
      "Mesh piece 1 OUTSIDE mesh\n",
      "Total time = 0.002494335174560547\n",
      "Mesh piece 2 OUTSIDE mesh\n",
      "Total time = 0.5465919971466064\n",
      "Mesh piece 3 OUTSIDE mesh\n",
      "Total time = 0.7535746097564697\n",
      "Mesh piece 4 OUTSIDE mesh\n",
      "Total time = 0.5596988201141357\n",
      "Mesh piece 5 OUTSIDE mesh\n",
      "Total time = 0.2354419231414795\n",
      "Mesh piece 6 inside mesh :( \n",
      "Total time = 0.3012547492980957\n",
      "Mesh piece 7 inside mesh :( \n",
      "Total time = 0.3359966278076172\n",
      "Mesh piece 8 inside mesh :( \n",
      "Total time = 0.26143789291381836\n",
      "Mesh piece 9 inside mesh :( \n",
      "Total time = 0.2334444522857666\n",
      "Mesh piece 10 inside mesh :( \n",
      "Total time = 0.5211236476898193\n",
      "Mesh piece 11 inside mesh :( \n",
      "Total time = 1.016357660293579\n",
      "Mesh piece 12 OUTSIDE mesh\n",
      "Total time = 1.0448899269104004\n",
      "Mesh piece 13 OUTSIDE mesh\n",
      "Total time = 0.5239486694335938\n",
      "Mesh piece 14 inside mesh :( \n",
      "Total time = 0.6726186275482178\n",
      "Mesh piece 15 inside mesh :( \n",
      "Total time = 0.5544326305389404\n",
      "Mesh piece 16 inside mesh :( \n",
      "Total time = 0.2723238468170166\n",
      "Mesh piece 17 inside mesh :( \n",
      "Total time = 0.33667922019958496\n",
      "Mesh piece 18 inside mesh :( \n",
      "Total time = 0.33151841163635254\n",
      "Mesh piece 19 inside mesh :( \n",
      "Total time = 0.2763688564300537\n",
      "Mesh piece 20 inside mesh :( \n",
      "Total time = 0.2552030086517334\n",
      "Mesh piece 21 inside mesh :( \n",
      "Total time = 0.4681861400604248\n",
      "Mesh piece 22 inside mesh :( \n",
      "Total time = 0.5948193073272705\n",
      "Mesh piece 23 OUTSIDE mesh\n",
      "Total time = 0.238539457321167\n",
      "Mesh piece 24 inside mesh :( \n",
      "Total time = 0.3899548053741455\n",
      "Mesh piece 25 inside mesh :( \n",
      "Total time = 0.19224977493286133\n",
      "Mesh piece 26 inside mesh :( \n",
      "Total time = 0.5369160175323486\n",
      "Mesh piece 27 inside mesh :( \n",
      "Total time = 0.5499634742736816\n",
      "Mesh piece 28 inside mesh :( \n",
      "Total time = 0.5180964469909668\n",
      "Mesh piece 29 inside mesh :( \n",
      "Total time = 0.6166555881500244\n",
      "Mesh piece 30 inside mesh :( \n",
      "Total time = 0.39202022552490234\n",
      "Mesh piece 31 inside mesh :( \n",
      "Total time = 0.3635115623474121\n",
      "Mesh piece 32 inside mesh :( \n",
      "Total time = 0.29667067527770996\n",
      "Mesh piece 33 inside mesh :( \n",
      "Total time = 0.5653703212738037\n",
      "Mesh piece 34 inside mesh :( \n",
      "Total time = 0.5111055374145508\n",
      "Mesh piece 35 inside mesh :( \n",
      "Total time = 0.39821934700012207\n",
      "Mesh piece 36 inside mesh :( \n",
      "Total time = 0.4795536994934082\n",
      "Mesh piece 37 inside mesh :( \n",
      "Total time = 0.336517333984375\n",
      "Mesh piece 38 inside mesh :( \n",
      "Total time = 0.7724685668945312\n",
      "Mesh piece 39 inside mesh :( \n",
      "Total time = 0.33777475357055664\n",
      "Mesh piece 40 inside mesh :( \n",
      "Total time = 0.8811445236206055\n",
      "Mesh piece 41 inside mesh :( \n",
      "Total time = 0.6380612850189209\n",
      "Mesh piece 42 inside mesh :( \n",
      "Total time = 0.6588079929351807\n",
      "Mesh piece 43 inside mesh :( \n",
      "Total time = 0.4623982906341553\n",
      "Mesh piece 44 inside mesh :( \n",
      "Total time = 0.55686354637146\n",
      "Mesh piece 45 inside mesh :( \n",
      "Total time = 0.7480924129486084\n",
      "Mesh piece 46 inside mesh :( \n",
      "Total time = 0.43162107467651367\n",
      "Mesh piece 47 inside mesh :( \n",
      "Total time = 0.3503286838531494\n",
      "Mesh piece 48 inside mesh :( \n",
      "Total time = 0.2101607322692871\n",
      "Mesh piece 49 inside mesh :( \n",
      "Total time = 0.5386462211608887\n",
      "Mesh piece 50 inside mesh :( \n",
      "Total time = 0.45885658264160156\n",
      "Mesh piece 51 inside mesh :( \n",
      "Total time = 0.2880833148956299\n",
      "Mesh piece 52 inside mesh :( \n",
      "Total time = 0.5616931915283203\n",
      "Mesh piece 53 inside mesh :( \n",
      "Total time = 0.21171307563781738\n",
      "Mesh piece 54 inside mesh :( \n",
      "Total time = 0.4448094367980957\n",
      "Mesh piece 55 inside mesh :( \n",
      "Total time = 0.4205796718597412\n",
      "Mesh piece 56 inside mesh :( \n",
      "Total time = 0.2610805034637451\n",
      "Mesh piece 57 inside mesh :( \n",
      "Total time = 0.2402935028076172\n",
      "Mesh piece 58 inside mesh :( \n",
      "Total time = 0.2998197078704834\n",
      "Mesh piece 59 inside mesh :( \n",
      "Total time = 0.4383854866027832\n",
      "Mesh piece 60 inside mesh :( \n",
      "Total time = 0.2651097774505615\n",
      "Mesh piece 61 inside mesh :( \n",
      "Total time = 0.3120746612548828\n",
      "Mesh piece 62 inside mesh :( \n",
      "Total time = 0.5469644069671631\n",
      "Mesh piece 63 inside mesh :( \n",
      "Total time = 0.4492659568786621\n",
      "Mesh piece 64 inside mesh :( \n",
      "Total time = 0.43470239639282227\n",
      "Mesh piece 65 inside mesh :( \n",
      "Total time = 0.4118046760559082\n",
      "Mesh piece 66 inside mesh :( \n",
      "Total time = 0.5387887954711914\n",
      "Mesh piece 67 inside mesh :( \n",
      "Total time = 0.35085058212280273\n",
      "Mesh piece 68 inside mesh :( \n",
      "Total time = 0.3813507556915283\n",
      "Mesh piece 69 inside mesh :( \n",
      "Total time = 0.11614227294921875\n",
      "Mesh piece 70 OUTSIDE mesh\n",
      "Total time = 0.8728353977203369\n",
      "Mesh piece 71 inside mesh :( \n",
      "Total time = 0.316023588180542\n",
      "Mesh piece 72 inside mesh :( \n",
      "Total time = 0.3269798755645752\n",
      "Mesh piece 73 inside mesh :( \n",
      "Total time = 0.3088371753692627\n",
      "Mesh piece 74 inside mesh :( \n",
      "Total time = 0.44976282119750977\n",
      "Mesh piece 75 inside mesh :( \n",
      "Total time = 0.45598340034484863\n",
      "Mesh piece 76 inside mesh :( \n",
      "Total time = 0.4469614028930664\n",
      "Mesh piece 77 inside mesh :( \n",
      "Total time = 0.5225331783294678\n",
      "Mesh piece 78 inside mesh :( \n",
      "Total time = 0.5460257530212402\n",
      "Mesh piece 79 inside mesh :( \n",
      "Total time = 0.4265918731689453\n",
      "Mesh piece 80 inside mesh :( \n",
      "Total time = 0.6033728122711182\n",
      "Mesh piece 81 inside mesh :( \n",
      "Total time = 0.4814577102661133\n",
      "Mesh piece 82 inside mesh :( \n",
      "Total time = 0.36508941650390625\n",
      "Mesh piece 83 inside mesh :( \n",
      "Total time = 0.5075817108154297\n",
      "Mesh piece 84 inside mesh :( \n",
      "Total time = 0.3256189823150635\n",
      "Mesh piece 85 inside mesh :( \n",
      "Total time = 0.33545470237731934\n",
      "Mesh piece 86 inside mesh :( \n",
      "Total time = 0.4509389400482178\n",
      "Mesh piece 87 inside mesh :( \n",
      "Total time = 0.37199926376342773\n",
      "Mesh piece 88 inside mesh :( \n",
      "Total time = 0.29072999954223633\n",
      "Mesh piece 89 inside mesh :( \n",
      "Total time = 0.45604634284973145\n",
      "Mesh piece 90 inside mesh :( \n",
      "Total time = 0.3828918933868408\n",
      "Mesh piece 91 inside mesh :( \n",
      "Total time = 0.6660158634185791\n",
      "Mesh piece 92 inside mesh :( \n",
      "Total time = 0.36920857429504395\n",
      "Mesh piece 93 inside mesh :( \n",
      "Total time = 0.5335965156555176\n",
      "Mesh piece 94 inside mesh :( \n",
      "Total time = 0.39485859870910645\n",
      "Mesh piece 95 inside mesh :( \n",
      "Total time = 0.4140584468841553\n",
      "Mesh piece 96 inside mesh :( \n",
      "Total time = 0.4397618770599365\n",
      "Mesh piece 97 inside mesh :( \n",
      "Total time = 0.4867575168609619\n",
      "Mesh piece 98 inside mesh :( \n",
      "Total time = 0.616473913192749\n",
      "Mesh piece 99 inside mesh :( \n",
      "Total time = 0.47071051597595215\n",
      "Mesh piece 100 inside mesh :( \n",
      "Total time = 0.4761040210723877\n",
      "Mesh piece 101 inside mesh :( \n",
      "Total time = 0.28218817710876465\n",
      "Mesh piece 102 inside mesh :( \n",
      "Total time = 0.4885430335998535\n",
      "Mesh piece 103 inside mesh :( \n",
      "Total time = 0.5011777877807617\n",
      "Mesh piece 104 inside mesh :( \n",
      "Total time = 0.33061957359313965\n",
      "Mesh piece 105 inside mesh :( \n",
      "Total time = 0.5055828094482422\n",
      "Mesh piece 106 inside mesh :( \n",
      "Total time = 0.19602108001708984\n",
      "Mesh piece 107 inside mesh :( \n",
      "Total time = 0.7038860321044922\n",
      "Mesh piece 108 inside mesh :( \n",
      "Total time = 0.6265623569488525\n",
      "Mesh piece 109 inside mesh :( \n",
      "Total time = 0.5657074451446533\n",
      "Mesh piece 110 inside mesh :( \n",
      "Total time = 0.6269896030426025\n",
      "Mesh piece 111 inside mesh :( \n",
      "Total time = 0.5978984832763672\n",
      "Mesh piece 112 inside mesh :( \n",
      "Total time = 0.5749881267547607\n",
      "Mesh piece 113 inside mesh :( \n",
      "Total time = 0.6486735343933105\n",
      "Mesh piece 114 inside mesh :( \n",
      "Total time = 0.39281535148620605\n",
      "Mesh piece 115 inside mesh :( \n",
      "Total time = 0.38907742500305176\n",
      "Mesh piece 116 inside mesh :( \n",
      "Total time = 0.658825159072876\n",
      "Mesh piece 117 inside mesh :( \n",
      "Total time = 0.3138093948364258\n",
      "Mesh piece 118 inside mesh :( \n",
      "Total time = 0.4235053062438965\n",
      "Mesh piece 119 inside mesh :( \n",
      "Total time = 0.38857269287109375\n",
      "Mesh piece 120 inside mesh :( \n",
      "Total time = 0.3643629550933838\n",
      "Mesh piece 121 inside mesh :( \n",
      "Total time = 0.4329183101654053\n",
      "Mesh piece 122 inside mesh :( \n",
      "Total time = 0.3423953056335449\n",
      "Mesh piece 123 inside mesh :( \n",
      "Total time = 0.3790628910064697\n",
      "Mesh piece 124 inside mesh :( \n",
      "Total time = 0.2606465816497803\n",
      "Mesh piece 125 inside mesh :( \n",
      "Total time = 0.24015212059020996\n",
      "Mesh piece 126 inside mesh :( \n",
      "Total time = 0.4507284164428711\n",
      "Mesh piece 127 inside mesh :( \n",
      "Total time = 0.46567392349243164\n",
      "Mesh piece 128 inside mesh :( \n",
      "Total time = 0.43205833435058594\n",
      "Mesh piece 129 inside mesh :( \n",
      "Total time = 0.5375699996948242\n",
      "Mesh piece 130 inside mesh :( \n",
      "Total time = 0.3713505268096924\n",
      "Mesh piece 131 inside mesh :( \n",
      "Total time = 0.37978482246398926\n",
      "Mesh piece 132 inside mesh :( \n",
      "Total time = 0.3585333824157715\n",
      "Mesh piece 133 inside mesh :( \n",
      "Total time = 0.5176208019256592\n",
      "Mesh piece 134 inside mesh :( \n",
      "Total time = 0.3038172721862793\n",
      "Mesh piece 135 inside mesh :( \n",
      "Total time = 0.3874204158782959\n",
      "Mesh piece 136 OUTSIDE mesh\n",
      "Total time = 0.5257766246795654\n",
      "Mesh piece 137 OUTSIDE mesh\n",
      "Total time = 0.3624410629272461\n",
      "Mesh piece 138 OUTSIDE mesh\n",
      "Total time = 0.0019490718841552734\n",
      "Mesh piece 139 OUTSIDE mesh\n",
      "Total time = 0.657853364944458\n",
      "Mesh piece 140 inside mesh :( \n",
      "Total time = 0.46810340881347656\n",
      "Mesh piece 141 inside mesh :( \n",
      "Total time = 0.37770986557006836\n",
      "Mesh piece 142 inside mesh :( \n",
      "Total time = 0.30267953872680664\n",
      "Mesh piece 143 inside mesh :( \n",
      "Total time = 0.4900202751159668\n",
      "Mesh piece 144 inside mesh :( \n",
      "Total time = 0.44220662117004395\n",
      "Mesh piece 145 inside mesh :( \n",
      "Total time = 0.4331855773925781\n",
      "Mesh piece 146 inside mesh :( \n",
      "Total time = 0.3287625312805176\n",
      "Mesh piece 147 inside mesh :( \n",
      "Total time = 0.37883734703063965\n",
      "Mesh piece 148 inside mesh :( \n",
      "Total time = 0.4332752227783203\n",
      "Mesh piece 149 inside mesh :( \n",
      "Total time = 0.28557276725769043\n",
      "Mesh piece 150 inside mesh :( \n",
      "Total time = 0.5035722255706787\n",
      "Mesh piece 151 inside mesh :( \n",
      "Total time = 0.36982011795043945\n",
      "Mesh piece 152 inside mesh :( \n",
      "Total time = 0.531785249710083\n",
      "Mesh piece 153 OUTSIDE mesh\n",
      "Total time = 0.18929004669189453\n",
      "Mesh piece 154 inside mesh :( \n",
      "Total time = 0.6131341457366943\n",
      "Mesh piece 155 inside mesh :( \n",
      "Total time = 0.43353772163391113\n",
      "Mesh piece 156 inside mesh :( \n",
      "Total time = 0.4489424228668213\n",
      "Mesh piece 157 inside mesh :( \n",
      "Total time = 0.4324190616607666\n",
      "Mesh piece 158 inside mesh :( \n",
      "Total time = 0.32452821731567383\n",
      "Mesh piece 159 inside mesh :( \n",
      "Total time = 0.5112223625183105\n",
      "Mesh piece 160 inside mesh :( \n",
      "Total time = 0.5441296100616455\n",
      "Mesh piece 161 inside mesh :( \n",
      "Total time = 0.6877036094665527\n",
      "Mesh piece 162 inside mesh :( \n",
      "Total time = 0.4239037036895752\n",
      "Mesh piece 163 inside mesh :( \n",
      "Total time = 0.35317492485046387\n",
      "Mesh piece 164 inside mesh :( \n",
      "Total time = 0.33852696418762207\n",
      "Mesh piece 165 inside mesh :( \n",
      "Total time = 0.46437788009643555\n",
      "Mesh piece 166 inside mesh :( \n",
      "Total time = 0.38190746307373047\n",
      "Mesh piece 167 inside mesh :( \n",
      "Total time = 0.3993065357208252\n",
      "Mesh piece 168 inside mesh :( \n",
      "Total time = 0.5282695293426514\n",
      "Mesh piece 169 inside mesh :( \n",
      "Total time = 0.6390407085418701\n",
      "Mesh piece 170 inside mesh :( \n",
      "Total time = 0.5967822074890137\n",
      "Mesh piece 171 inside mesh :( \n",
      "Total time = 0.4659738540649414\n",
      "Mesh piece 172 inside mesh :( \n",
      "Total time = 0.4223308563232422\n",
      "Mesh piece 173 inside mesh :( \n",
      "Total time = 0.25545835494995117\n",
      "Mesh piece 174 inside mesh :( \n",
      "Total time = 0.267362117767334\n",
      "Mesh piece 175 inside mesh :( \n",
      "Total time = 0.29379844665527344\n",
      "Mesh piece 176 inside mesh :( \n",
      "Total time = 0.24522805213928223\n",
      "Mesh piece 177 inside mesh :( \n",
      "Total time = 0.25678443908691406\n",
      "Mesh piece 178 inside mesh :( \n",
      "Total time = 0.21918582916259766\n",
      "Mesh piece 179 inside mesh :( \n",
      "Total time = 0.22621369361877441\n",
      "Mesh piece 180 inside mesh :( \n",
      "Total time = 0.2555510997772217\n",
      "Mesh piece 181 inside mesh :( \n",
      "Total time = 0.2962162494659424\n",
      "Mesh piece 182 inside mesh :( \n",
      "Total time = 0.27239489555358887\n",
      "Mesh piece 183 inside mesh :( \n",
      "Total time = 0.316817045211792\n",
      "Mesh piece 184 inside mesh :( \n",
      "Total time = 0.28698062896728516\n",
      "Mesh piece 185 inside mesh :( \n",
      "Total time = 0.2965519428253174\n",
      "Mesh piece 186 inside mesh :( \n",
      "Total time = 0.34118103981018066\n",
      "Mesh piece 187 inside mesh :( \n",
      "Total time = 0.392545223236084\n",
      "Mesh piece 188 inside mesh :( \n",
      "Total time = 0.3860769271850586\n",
      "Mesh piece 189 inside mesh :( \n",
      "Total time = 0.30403852462768555\n",
      "Mesh piece 190 inside mesh :( \n",
      "Total time = 0.37128567695617676\n",
      "Mesh piece 191 inside mesh :( \n",
      "Total time = 0.3061189651489258\n",
      "Mesh piece 192 inside mesh :( \n",
      "Total time = 0.28562331199645996\n",
      "Mesh piece 193 inside mesh :( \n",
      "Total time = 0.3226656913757324\n",
      "Mesh piece 194 inside mesh :( \n",
      "Total time = 0.3205912113189697\n",
      "Mesh piece 195 inside mesh :( \n",
      "Total time = 0.3311178684234619\n",
      "Mesh piece 196 inside mesh :( \n",
      "Total time = 0.38329291343688965\n",
      "Mesh piece 197 inside mesh :( \n",
      "Total time = 0.4019138813018799\n",
      "Mesh piece 198 inside mesh :( \n",
      "Total time = 0.32300829887390137\n",
      "Mesh piece 199 inside mesh :( \n",
      "Total time = 0.2673017978668213\n",
      "Mesh piece 200 inside mesh :( \n",
      "Total time = 0.3564755916595459\n",
      "Mesh piece 201 inside mesh :( \n",
      "Total time = 0.39936399459838867\n",
      "Mesh piece 202 inside mesh :( \n",
      "Total time = 0.6378288269042969\n",
      "Mesh piece 203 OUTSIDE mesh\n",
      "Total time = 0.5205743312835693\n",
      "Mesh piece 204 OUTSIDE mesh\n",
      "Total time = 0.6606454849243164\n",
      "Mesh piece 205 inside mesh :( \n",
      "Total time = 0.30497312545776367\n",
      "Mesh piece 206 inside mesh :( \n",
      "Total time = 0.4084789752960205\n",
      "Mesh piece 207 inside mesh :( \n",
      "Total time = 0.41997766494750977\n",
      "Mesh piece 208 inside mesh :( \n",
      "Total time = 0.2564690113067627\n",
      "Mesh piece 209 inside mesh :( \n",
      "Total time = 0.3521606922149658\n",
      "Mesh piece 210 inside mesh :( \n",
      "Total time = 0.3869771957397461\n",
      "Mesh piece 211 inside mesh :( \n",
      "Total time = 0.4390869140625\n",
      "Mesh piece 212 inside mesh :( \n",
      "Total time = 0.2831733226776123\n",
      "Mesh piece 213 inside mesh :( \n",
      "Total time = 0.36226844787597656\n",
      "Mesh piece 214 inside mesh :( \n",
      "Total time = 0.2784740924835205\n",
      "Mesh piece 215 inside mesh :( \n",
      "Total time = 0.3559293746948242\n",
      "Mesh piece 216 inside mesh :( \n",
      "Total time = 0.26799750328063965\n",
      "Mesh piece 217 inside mesh :( \n",
      "Total time = 0.2522306442260742\n",
      "Mesh piece 218 inside mesh :( \n",
      "Total time = 0.4591686725616455\n",
      "Mesh piece 219 inside mesh :( \n",
      "Total time = 0.38553810119628906\n",
      "Mesh piece 220 inside mesh :( \n",
      "Total time = 0.24344992637634277\n",
      "Mesh piece 221 inside mesh :( \n",
      "Total time = 0.4863550662994385\n",
      "Mesh piece 222 inside mesh :( \n",
      "Total time = 0.2906303405761719\n",
      "Mesh piece 223 inside mesh :( \n",
      "Total time = 0.31301259994506836\n",
      "Mesh piece 224 inside mesh :( \n",
      "Total time = 0.1580944061279297\n",
      "Mesh piece 225 inside mesh :( \n",
      "Total time = 0.3523838520050049\n",
      "Mesh piece 226 inside mesh :( \n",
      "Total time = 0.31845784187316895\n",
      "Mesh piece 227 inside mesh :( \n",
      "Total time = 0.4040544033050537\n",
      "Mesh piece 228 inside mesh :( \n",
      "Total time = 0.29924464225769043\n",
      "Mesh piece 229 inside mesh :( \n",
      "Total time = 0.4341003894805908\n",
      "Mesh piece 230 inside mesh :( \n",
      "Total time = 0.3467750549316406\n",
      "Mesh piece 231 inside mesh :( \n",
      "Total time = 0.3842198848724365\n",
      "Mesh piece 232 inside mesh :( \n",
      "Total time = 0.4077463150024414\n",
      "Mesh piece 233 inside mesh :( \n",
      "Total time = 0.2565131187438965\n",
      "Mesh piece 234 inside mesh :( \n",
      "Total time = 0.22239351272583008\n",
      "Mesh piece 235 inside mesh :( \n",
      "Total time = 0.2790486812591553\n",
      "Mesh piece 236 inside mesh :( \n",
      "Total time = 0.32930612564086914\n",
      "Mesh piece 237 inside mesh :( \n",
      "Total time = 0.6225070953369141\n",
      "Mesh piece 238 inside mesh :( \n",
      "Total time = 0.6276612281799316\n",
      "Mesh piece 239 inside mesh :( \n",
      "Total time = 0.7092211246490479\n",
      "Mesh piece 240 inside mesh :( \n",
      "Total time = 0.7065610885620117\n",
      "Mesh piece 241 inside mesh :( \n",
      "Total time = 0.6033153533935547\n",
      "Mesh piece 242 inside mesh :( \n",
      "Total time = 0.5584383010864258\n",
      "Mesh piece 243 inside mesh :( \n",
      "Total time = 0.6445133686065674\n",
      "Mesh piece 244 inside mesh :( \n",
      "Total time = 0.546762228012085\n",
      "Mesh piece 245 inside mesh :( \n",
      "Total time = 0.5204570293426514\n",
      "Mesh piece 246 inside mesh :( \n",
      "Total time = 0.583195686340332\n",
      "Mesh piece 247 inside mesh :( \n",
      "Total time = 0.4685065746307373\n",
      "Mesh piece 248 inside mesh :( \n",
      "Total time = 0.3565409183502197\n",
      "Mesh piece 249 inside mesh :( \n",
      "Total time = 0.3462352752685547\n",
      "Mesh piece 250 inside mesh :( \n",
      "Total time = 0.35582447052001953\n",
      "Mesh piece 251 inside mesh :( \n",
      "Total time = 0.5508248805999756\n",
      "Mesh piece 252 inside mesh :( \n",
      "Total time = 0.5631413459777832\n",
      "Mesh piece 253 inside mesh :( \n",
      "Total time = 0.36749267578125\n",
      "Mesh piece 254 inside mesh :( \n",
      "Total time = 0.6059200763702393\n",
      "Mesh piece 255 inside mesh :( \n",
      "Total time = 0.355424165725708\n",
      "Mesh piece 256 inside mesh :( \n",
      "Total time = 0.5082111358642578\n",
      "Mesh piece 257 inside mesh :( \n",
      "Total time = 0.5661196708679199\n",
      "Mesh piece 258 inside mesh :( \n",
      "Total time = 0.47222256660461426\n",
      "Mesh piece 259 inside mesh :( \n",
      "Total time = 0.626399040222168\n",
      "Mesh piece 260 inside mesh :( \n",
      "Total time = 0.43396782875061035\n",
      "Mesh piece 261 inside mesh :( \n",
      "Total time = 0.3103663921356201\n",
      "Mesh piece 262 inside mesh :( \n",
      "Total time = 0.35671019554138184\n",
      "Mesh piece 263 inside mesh :( \n",
      "Total time = 0.3340575695037842\n",
      "Mesh piece 264 inside mesh :( \n",
      "Total time = 0.5603268146514893\n",
      "Mesh piece 265 inside mesh :( \n",
      "Total time = 0.353740930557251\n",
      "Mesh piece 266 inside mesh :( \n",
      "Total time = 0.3755929470062256\n",
      "Mesh piece 267 inside mesh :( \n",
      "Total time = 0.4662446975708008\n",
      "Mesh piece 268 inside mesh :( \n",
      "Total time for Mesh Cleansing: 147.3182578086853\n"
     ]
    }
   ],
   "source": [
    "#Runs the filtering function for inside and outside meshes\n",
    "global_timer = time.time()\n",
    "\n",
    "\n",
    "#setting thresholds\n",
    "significance_threshold=30 #number of faces needed for pieces to be considered to be kept\n",
    "n_sample_points = 2 #number of points sampled on the mesh for determination of inside or outside\n",
    "start_time = time.time()\n",
    "\n",
    "#the main mesh is the first mesh in the piece\n",
    "main_mesh,child_meshes = filter_mesh_significant_outside_pieces(unfiltered_mesh,\n",
    "                            significance_threshold=significance_threshold,\n",
    "                                n_sample_points=n_sample_points)\n",
    "print(f\"Total time for Mesh Cleansing: {time.time() - start_time}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOW TO SAVE AND LOAD OF THE MESHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"./test_meshes/\" + str(neuron_id) + \"_main_and_child_meshes_array.npz\",main_mesh=[main_mesh],child_meshes=child_meshes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_meshes = np.load(\"./test_meshes/main_and_child_meshes_array.npz\")\n",
    "# loaded_meshes.files\n",
    "\n",
    "# main_mesh_loaded = loaded_meshes[\"main_mesh\"][0]\n",
    "# child_meshes_loaded = loaded_meshes[\"child_meshes\"]\n",
    "\n",
    "# print(len(child_meshes_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_mesh = main_mesh_loaded\n",
    "# child_meshes = child_meshes_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACET GENERATION AND FILTERING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def area(vertices):\n",
    "    \"\"\"\n",
    "    Calculates the area of a 3D triangle from it's coordinates\n",
    "    \"\"\"\n",
    "    side_a = np.linalg.norm(vertices[0]-vertices[1])\n",
    "    side_b = np.linalg.norm(vertices[1]-vertices[2])\n",
    "    side_c = np.linalg.norm(vertices[2]-vertices[0])\n",
    "    s = 0.5 * ( side_a + side_b + side_c)\n",
    "    return math.sqrt(s * (s - side_a) * (s - side_b) * (s - side_c))\n",
    "\n",
    "def find_polygon_area(mesh,list_of_faces):\n",
    "    \"Calculates the area of a 3D polygon that is created from connected traingles\"\n",
    "    return(sum([area(mesh.vertices[mesh.faces[r]]) for r in list_of_faces]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need a way of finding the neighbors that have to share adjacent faces\n",
    "def create_neighbors_lookup(mesh):\n",
    "    start_time = time.time()\n",
    "    neighbors_lookup = dict([(i,[]) for i in range(0,len(mesh.faces))])\n",
    "    #print(f\"Creating empty dictionary : {time.time() - start_time}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for adj in mesh.face_adjacency:\n",
    "        neighbors_lookup[adj[0]].append(adj[1])\n",
    "        neighbors_lookup[adj[1]].append(adj[0])\n",
    "    #print(f\"Filling in neighbors lookup : {time.time() - start_time}\")\n",
    "    \n",
    "    return neighbors_lookup\n",
    "\n",
    "# need a way of finding the neighbors that have to share adjacent faces\n",
    "def create_facet_lookup(mesh):\n",
    "    start_time = time.time()\n",
    "    facets_lookup = np.ones(len(main_mesh.faces))*-1\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for jj,facet in enumerate(mesh.facets):\n",
    "        for fac in facet:\n",
    "            facets_lookup[fac] = jj\n",
    "    \n",
    "    print(f\"Filling in facet lookup : {time.time() - start_time}\")\n",
    "    \n",
    "    return facets_lookup\n",
    "\n",
    "def filter_and_expand_facets(new_mesh,\n",
    "                             first_pass_size_threshold=2000,\n",
    "                             normal_closeness=0.985):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #filter the facets that are below a size threshold\n",
    "    new_facets = new_mesh.facets[np.where(new_mesh.facets_area > first_pass_size_threshold)[0]]\n",
    "\n",
    "    #is a fast lookup for the neighbors of a certain face\n",
    "    neighbors_lookup = create_neighbors_lookup(new_mesh)\n",
    "    \n",
    "    #generate a normals lookup table and see if works faster than regular lookup\n",
    "    normal_lookup = {}\n",
    "\n",
    "    for i in range(0,len(new_mesh.faces)):\n",
    "        normal_lookup[i] = new_mesh.face_normals[i]\n",
    "    \n",
    "    global_start_time = time.time()\n",
    "    final_facets= [0]*len(new_facets)\n",
    "    \n",
    "    #creates entire list of neighbors that have been added in expansion\n",
    "    #if a neighbor was already added that was already in the current facet\n",
    "    #then that facet has already been absorbed and need to delete that\n",
    "    \n",
    "\n",
    "    #these are facets that need to be deleted at the end\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Other way to optimize\n",
    "\n",
    "    1) Create lookup dictionary that maps the face back to the facet\n",
    "    2) when add a neighbor add the set of all their facets to the facet to delete\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Total number of facets = \" + str(len(new_facets)))\n",
    "    facet_lookup = create_facet_lookup(new_mesh)\n",
    "    facets_to_delete = set()\n",
    "    \n",
    "    for i,facet in enumerate(new_facets):\n",
    "#         mini_global_start_time = time.time()\n",
    "    #     print(facet)\n",
    "    #     print(type(facet))\n",
    "    #     start_time = time.time()\n",
    "    #     print([find_neighbors(k) for k in facet])\n",
    "    \n",
    "    \n",
    "\n",
    "#         new_time = time.time()\n",
    "#         # make sure that there are no repeats of facets by checking for common elements\n",
    "#         if not set(total_added_neighbors).isdisjoint(facet):\n",
    "#             facets_to_delete.append(i)\n",
    "#             #print(\"found overlapping neighbor\")\n",
    "#             continue\n",
    "#         print(f\"Time for check = {time.time() - new_time}\")\n",
    "            \n",
    "        if i in facets_to_delete:\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    #gets all of the neighbors\n",
    "        total_neighbors = list(set(np.hstack([neighbors_lookup[k] for k in facet])).difference(set(facet)))\n",
    "    #     print(total_neighbors)\n",
    "    #     print(f\"time initial neighbors: {(time.time() - start_time)}\")\n",
    "        neighbors_to_add = []\n",
    "        neighbors_checked = []\n",
    "        #print(total_neighbors)\n",
    "\n",
    "        #just get the normal from one of the faces already in the facet\n",
    "    #     start_time = time.time()\n",
    "        facet_normal = normal_lookup[facet[0]]\n",
    "\n",
    "    #     total_dot_time = 0\n",
    "        while len(total_neighbors) > 0:\n",
    "            current_neighbor = total_neighbors.pop()\n",
    "            neighbors_checked.append(current_neighbor)\n",
    "\n",
    "    #         print(\"--------------\")\n",
    "    # #         #check to see if neighbor has same normal face\n",
    "    # #         start_dot_time = time.time()\n",
    "    # #         dot_result = np.dot(new_mesh.face_normals[current_neighbor],facet_normal) #> normal_closeness\n",
    "    # #         print(dot_result)\n",
    "    # #         print((time.time() - start_dot_time) * 1000)\n",
    "\n",
    "    #         start_dot_time = time.time()\n",
    "    #         print(current_neighbor)\n",
    "    #         #a = new_mesh.face_normals[current_neighbor]\n",
    "\n",
    "    #         print((time.time() - start_dot_time) * 1000)\n",
    "    #         dot_result = a[0]*facet_normal[0] + a[1]*facet_normal[1] + a[2]*facet_normal[2]  > normal_closeness\n",
    "    #         print(dot_result)\n",
    "    #         print((time.time() - start_dot_time) * 1000)\n",
    "    #         print(\"--------------\")\n",
    "\n",
    "    #         total_dot_time += (time.time() - start_dot_time)*1000\n",
    "\n",
    "            a = normal_lookup[current_neighbor]\n",
    "            if a[0]*facet_normal[0] + a[1]*facet_normal[1] + a[2]*facet_normal[2]  > normal_closeness:\n",
    "\n",
    "                neighbors_to_add.append(current_neighbor)\n",
    "                #get the neighbors of this current face\n",
    "                for neigh in neighbors_lookup[current_neighbor]:\n",
    "                    #only add those neighbors that havent already been checked, in original facet group, or already in list to check\n",
    "                    if neigh not in neighbors_checked and neigh not in facet and neigh not in total_neighbors:\n",
    "                        total_neighbors.append(neigh)\n",
    "    #     print(f\"Total dot time: {total_dot_time}\")\n",
    "    #     print(f\"time loop: {(time.time() - start_time)}\")\n",
    "    #     print(\"neighbors_to_add = \" + str(neighbors_to_add))abs\n",
    "    #     print(\"neighbors_checked = \" + str(neighbors_checked))\n",
    "    #     print(\"adding list = \" + str(list(facet) + neighbors_to_add))\n",
    "    #     start_time = time.time()\n",
    "        \n",
    "        #get all the facets of the neighbors to add\n",
    "        neighbors_to_add_facets = facet_lookup[neighbors_to_add]\n",
    "        facets_to_delete = facets_to_delete.union(set(neighbors_to_add_facets))\n",
    "        \n",
    "        final_facets[i] = np.array(list(facet) + neighbors_to_add)\n",
    "    #     print(f\"Appending to list: {(time.time() - start_time)}\")\n",
    "\n",
    "#         print(f\"Total time: {(time.time() - mini_global_start_time)}\")\n",
    "    #     print(\"------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    print(f\"Total Facet building time: {(time.time() - global_start_time)}\")\n",
    "    print(f\"Found Total number of overlapping faces: {len(facets_to_delete)}\")\n",
    "    \n",
    "    #print(\"facets_to_delete = \" + str(facets_to_delete))\n",
    "    #delete the faces = \n",
    "    final_facets = np.delete(final_facets,list(facets_to_delete),axis=0)\n",
    "    return final_facets\n",
    "\n",
    "def filter_final_facets(gap_mesh):\n",
    "    \"\"\"\n",
    "    Gets the facets faces list and the center points of these facets from mesh\n",
    "    Filters:\n",
    "    1) Only lets facets greater than first_pass_size_threshold exist\n",
    "      **** might need to look at this because area is that of facets before expansion\n",
    "    2) Has to have a high convex border\n",
    "    \n",
    "    Expansions:\n",
    "    1) Expands the facet group to neighbors that are within the normal_closeness\n",
    "    for their normals when doing the dot product\n",
    "    \n",
    "    Order:\n",
    "    1) Size filtering\n",
    "    2) Expansion\n",
    "    3) Convex Border filtering\n",
    "    \"\"\"\n",
    "    \n",
    "    final_facets = filter_and_expand_facets(gap_mesh,\n",
    "                                 first_pass_size_threshold=2000,\n",
    "                                 normal_closeness=0.985)\n",
    "    \n",
    "    \n",
    "\n",
    "    # after computing final faces, filter for convexity\n",
    "    edges = gap_mesh.edges_sorted.reshape((-1, 6)) #groups all the edges belonging to the corresponding face in one row\n",
    "    final_facets_mean = np.zeros(len(final_facets))\n",
    "    \n",
    "    \n",
    "    #make lookup table for face number to spot in the adjacency edges\n",
    "    face_adjacency_index_lookup = [[] for i in gap_mesh.faces]\n",
    "    for i,faces in enumerate(gap_mesh.face_adjacency):\n",
    "        for f in faces:\n",
    "            face_adjacency_index_lookup[f].append(i)\n",
    "\n",
    "\n",
    "    for j,facet in enumerate(final_facets):\n",
    "        # get the edges for each facet\n",
    "        edges_facet = [edges[i].reshape((-1, 2)) for i in [facet]][0] #stores all the edges belonging to that face\n",
    "\n",
    "        #get the indexes of the boundary edges:\n",
    "        indexes = trimesh.grouping.group_rows(edges_facet, require_count=1)\n",
    "        edge_0 = edges_facet[indexes]\n",
    "\n",
    "        #find the faces that correspond to the boundary edges\n",
    "        edge_0_faces = [facet[int(k/3)] for k in indexes]\n",
    "\n",
    "\n",
    "        #2) Find the indexes of the edges int he face_adajacency_edges and store the projections\n",
    "        adjacency_values = []\n",
    "        for edge,edge_face in zip(edge_0,edge_0_faces):\n",
    "            possible_adj_indexes = face_adjacency_index_lookup[edge_face]\n",
    "\n",
    "            for index in possible_adj_indexes:\n",
    "                if len(set(edge).intersection(set(gap_mesh.face_adjacency_edges[index]))) >= 2:\n",
    "                    #print(f\"adj edge = {e} and boundary edge = {edge}\")\n",
    "                    adjacency_values.append(gap_mesh.face_adjacency_angles[index]) # the metric we actually want to measure\n",
    "                    break\n",
    "\n",
    "\n",
    "        final_facets_mean[j] = np.mean(adjacency_values)\n",
    "        \n",
    "        \n",
    "\n",
    "    #filter the final facets and output them so they can be plotted\n",
    "    adjacency_threshold =  0.8\n",
    "    final_facets_mean_filtered = np.array(final_facets)[final_facets_mean > adjacency_threshold]\n",
    "\n",
    "    #print(final_facets_mean_filtered)\n",
    "    #Compute the centers\n",
    "    final_facets_centers = []\n",
    "    \n",
    "    for filt in final_facets_mean_filtered: \n",
    "        #print(\"filt = \" + str(filt))\n",
    "        unique_vertices = gap_mesh.vertices[np.unique(gap_mesh.faces[filt].ravel())].astype(\"float\")\n",
    "        final_facets_centers.append((np.mean(unique_vertices[:,0]),\n",
    "                          np.mean(unique_vertices[:,1]),\n",
    "                          np.mean(unique_vertices[:,2])))\n",
    "    \n",
    "    return final_facets_mean_filtered,final_facets_centers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE OLDER FACET FILTERING METHOD THAT DOESN'T RETURN AS MANY FACETS BUT MISSES OUT ON THE \n",
    "#SMALL ONES\n",
    "\n",
    "def filter_final_facets_working(gap_mesh,final_facets):\n",
    "    \"\"\"\n",
    "    Gets the facets faces list and the center points of these facets from mesh\n",
    "    Filters:\n",
    "    1) Only lets facets greater than first_pass_size_threshold exist\n",
    "      **** might need to look at this because area is that of facets before expansion\n",
    "    2) Has to have a high convex border\n",
    "    \n",
    "    Expansions:\n",
    "    1) Expands the facet group to neighbors that are within the normal_closeness\n",
    "    for their normals when doing the dot product\n",
    "    \n",
    "    Order:\n",
    "    1) Size filtering\n",
    "    2) Expansion\n",
    "    3) Convex Border filtering\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # after computing final faces, filter for convexity\n",
    "    edges = gap_mesh.edges_sorted.reshape((-1, 6)) #groups all the edges belonging to the corresponding face in one row\n",
    "    final_facets_mean = np.zeros(len(final_facets))\n",
    "    \n",
    "    \n",
    "    #make lookup table for face number to spot in the adjacency edges\n",
    "    face_adjacency_index_lookup = [[] for i in gap_mesh.faces]\n",
    "    for i,faces in enumerate(gap_mesh.face_adjacency):\n",
    "        for f in faces:\n",
    "            face_adjacency_index_lookup[f].append(i)\n",
    "\n",
    "\n",
    "    for j,facet in enumerate(final_facets):\n",
    "        # get the edges for each facet\n",
    "        edges_facet = [edges[i].reshape((-1, 2)) for i in [facet]][0] #stores all the edges belonging to that face\n",
    "\n",
    "        #get the indexes of the boundary edges:\n",
    "        indexes = trimesh.grouping.group_rows(edges_facet, require_count=1)\n",
    "        edge_0 = edges_facet[indexes]\n",
    "\n",
    "        #find the faces that correspond to the boundary edges\n",
    "        edge_0_faces = [facet[int(k/3)] for k in indexes]\n",
    "\n",
    "\n",
    "        #2) Find the indexes of the edges int he face_adajacency_edges and store the projections\n",
    "        adjacency_values = []\n",
    "        for edge,edge_face in zip(edge_0,edge_0_faces):\n",
    "            possible_adj_indexes = face_adjacency_index_lookup[edge_face]\n",
    "\n",
    "            for index in possible_adj_indexes:\n",
    "                if len(set(edge).intersection(set(gap_mesh.face_adjacency_edges[index]))) >= 2:\n",
    "                    #print(f\"adj edge = {e} and boundary edge = {edge}\")\n",
    "                    adjacency_values.append(gap_mesh.face_adjacency_angles[index]) # the metric we actually want to measure\n",
    "                    break\n",
    "\n",
    "\n",
    "        final_facets_mean[j] = np.mean(adjacency_values)\n",
    "        \n",
    "        \n",
    "\n",
    "    #filter the final facets and output them so they can be plotted\n",
    "    adjacency_threshold =  0.8\n",
    "    \n",
    "#     #need to make sure they are array of arrays\n",
    "#     thresholld_boolean_results = final_facets_mean > adjacency_threshold\n",
    "#     for fa,individual_facet in  enumerate(final_facets):\n",
    "#         if thresholld_boolean_results[fa] == True:\n",
    "#             np\n",
    "    \n",
    "    final_facets_mean_filtered = np.array(final_facets)[final_facets_mean > adjacency_threshold]\n",
    "    \n",
    "    if len(final_facets_mean_filtered.shape) > 1:\n",
    "        total_array = np.empty(final_facets_mean_filtered.shape[0],object)\n",
    "        total_array[:] = [x for x in final_facets_mean_filtered]\n",
    "        final_facets_mean_filtered = total_array\n",
    "        print(\"Had to restructure the array because was 2D array\")\n",
    "\n",
    "    \n",
    "\n",
    "    #Compute the centers\n",
    "    final_facets_centers = []\n",
    "    \n",
    "    for filt in final_facets_mean_filtered: \n",
    "        #print(\"filt = \" + str(filt))\n",
    "        unique_vertices = gap_mesh.vertices[np.unique(gap_mesh.faces[filt].ravel())].astype(\"float\")\n",
    "        final_facets_centers.append((np.mean(unique_vertices[:,0]),\n",
    "                          np.mean(unique_vertices[:,1]),\n",
    "                          np.mean(unique_vertices[:,2])))\n",
    "    \n",
    "    return final_facets_mean_filtered,final_facets_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_final_facets_optimized_with_checks(example_mesh,\n",
    "                                  normal_closeness=0.99,\n",
    "                                  first_pass_size_threshold=6000):\n",
    "    \"\"\"\n",
    "    Way of computing facets that uses trimesh grouping function and normals threshold\n",
    "    instead of the pre-built trimesh.facets\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #get the facets for the child mesh\n",
    "    start_time_total = time.time()\n",
    "\n",
    "    #switch out with dot product\n",
    "    \n",
    "    \n",
    "    #Old way of computing the dot product manually\n",
    "    total_normals = example_mesh.face_normals[example_mesh.face_adjacency]\n",
    "    \n",
    "    #using manual method\n",
    "#     print(len(total_normals[:,0]*total_normals[:,1]))\n",
    "    start_normal = time.time()\n",
    "    total_normal_dots = np.sum(total_normals[:,0]*total_normals[:,1],axis=1)\n",
    "    print(f\"Total normals took {time.time() - start_normal}\")\n",
    "    ''' DONT HAVE TO DO DOT PRODUCT BECAUSE JUST WANT TO MULTIPLY THE ROWS OF EACH COLUMN'''\n",
    "#     print(\"About to do dot product\")\n",
    "#     dot_start = time.time()\n",
    "#     a = total_normals[:,0]\n",
    "#     b = total_normals[:,1].T\n",
    "#     #new way using the dot product\n",
    "#     total_normal_dots = np.dot(a,b)\n",
    "    \n",
    "    \n",
    "    #get the True/False value if face adjacency is within normal closeness\n",
    "    start_normal = time.time()\n",
    "    total_normal_dots_facet_mask = total_normal_dots > normal_closeness\n",
    "    print(f\"Boolean mask finished: {time.time() - start_normal}\")\n",
    "\n",
    "    #getting the grouping of the faces into facets within the threshold\n",
    "    start_normal = time.time()\n",
    "    components = trimesh.graph.connected_components(example_mesh.face_adjacency[total_normal_dots_facet_mask],\n",
    "                                          nodes=np.arange(len(example_mesh.faces)),\n",
    "                                          min_len=2,\n",
    "                                          engine=\"None\")\n",
    "    print(f\"Grouping took: {time.time() - start_normal}\")\n",
    "    \n",
    "    \n",
    "\n",
    "    #print(f\"Lenght of facets BEFORE filtering = {len(components)}\")\n",
    "    \n",
    "    #filter by the size\n",
    "    \n",
    "    start_normal = time.time()\n",
    "    size_filtered_components = [facet_list for facet_list in components \n",
    "                                    if find_polygon_area(example_mesh,facet_list) > first_pass_size_threshold]\n",
    "    print(f\"Filtering edges by size finished: {time.time() - start_normal}, facet # = {len(size_filtered_components)}\")\n",
    "\n",
    "#     if facet_index in checking_list:\n",
    "#         print(\"size_filtered_components = \" + str(size_filtered_components))\n",
    "\n",
    "    #filter by the convexity\n",
    "    #final_facets_mean_filtered,final_facets_centers = filter_final_facets(example_mesh,size_filtered_components)\n",
    "    \n",
    "    start_normal = time.time()\n",
    "    final_facets_mean_filtered,final_facets_centers = filter_final_facets_working(example_mesh,size_filtered_components)\n",
    "    print(f\"Filtering by convexity and getting centers took: {time.time() - start_normal}, facet # = {len(final_facets_mean_filtered)}\")\n",
    "\n",
    "#     if facet_index in checking_list:\n",
    "#         print(\"final_facets_mean_filtered = \" + str(final_facets_mean_filtered))\n",
    "    \n",
    "    print(f\"Total Time = {time.time() - start_time_total}\")\n",
    "\n",
    "    return final_facets_mean_filtered,final_facets_centers\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACTUALLY CALCULATING THE FACETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " face length 1551161 using unoptimized facets\n",
      "Total number of facets = 50336\n",
      "Filling in facet lookup : 0.19189023971557617\n",
      "Total Facet building time: 16.943564891815186\n",
      "Found Total number of overlapping faces: 14996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:162: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:162: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:162: FutureWarning: in the future negative indices will not be ignored by `numpy.delete`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 10472 facets for main mesh: 61.207746744155884\n",
      "Starting child 0\n",
      " face length 620 using OPTIMIZED facets\n",
      "Total normals took 0.00022983551025390625\n",
      "Boolean mask finished: 2.574920654296875e-05\n",
      "Grouping took: 0.0036613941192626953\n",
      "Filtering edges by size finished: 0.042807579040527344, facet # = 83\n",
      "Filtering by convexity and getting centers took: 0.041062355041503906, facet # = 30\n",
      "Total Time = 0.0908808708190918\n",
      "Finished facets for child 0 : 0.09101653099060059 with facet length = 30\n",
      "Starting child 1\n",
      " face length 962 using OPTIMIZED facets\n",
      "Total normals took 0.00013947486877441406\n",
      "Boolean mask finished: 1.4066696166992188e-05\n",
      "Grouping took: 0.002106189727783203\n",
      "Filtering edges by size finished: 0.042059898376464844, facet # = 129\n",
      "Filtering by convexity and getting centers took: 0.048055171966552734, facet # = 44\n",
      "Total Time = 0.0950465202331543\n",
      "Finished facets for child 1 : 0.09512925148010254 with facet length = 44\n",
      "Starting child 2\n",
      " face length 3986 using OPTIMIZED facets\n",
      "Total normals took 0.00026416778564453125\n",
      "Boolean mask finished: 1.4781951904296875e-05\n",
      "Grouping took: 0.0029137134552001953\n",
      "Filtering edges by size finished: 0.12924551963806152, facet # = 536\n",
      "Filtering by convexity and getting centers took: 0.23438477516174316, facet # = 161\n",
      "Total Time = 0.3708174228668213\n",
      "Finished facets for child 2 : 0.37103962898254395 with facet length = 161\n",
      "Starting child 3\n",
      " face length 2778 using OPTIMIZED facets\n",
      "Total normals took 0.00015592575073242188\n",
      "Boolean mask finished: 1.3113021850585938e-05\n",
      "Grouping took: 0.002431631088256836\n",
      "Filtering edges by size finished: 0.10505366325378418, facet # = 367\n",
      "Filtering by convexity and getting centers took: 0.19150733947753906, facet # = 105\n",
      "Total Time = 0.30276918411254883\n",
      "Finished facets for child 3 : 0.3029203414916992 with facet length = 105\n",
      "Starting child 4\n",
      " face length 4062 using OPTIMIZED facets\n",
      "Total normals took 0.00023102760314941406\n",
      "Boolean mask finished: 8.940696716308594e-05\n",
      "Grouping took: 0.0027513504028320312\n",
      "Filtering edges by size finished: 0.11931777000427246, facet # = 458\n",
      "Filtering by convexity and getting centers took: 0.2029895782470703, facet # = 157\n",
      "Total Time = 0.3290407657623291\n",
      "Finished facets for child 4 : 0.32923150062561035 with facet length = 157\n",
      "Starting child 5\n",
      " face length 82 using OPTIMIZED facets\n",
      "Total normals took 3.838539123535156e-05\n",
      "Boolean mask finished: 6.67572021484375e-06\n",
      "Grouping took: 0.0009396076202392578\n",
      "Filtering edges by size finished: 0.0020630359649658203, facet # = 10\n",
      "Filtering by convexity and getting centers took: 0.0043947696685791016, facet # = 6\n",
      "Total Time = 0.009060859680175781\n",
      "Finished facets for child 5 : 0.0091552734375 with facet length = 6\n",
      "Starting child 6\n",
      " face length 38 using OPTIMIZED facets\n",
      "Total normals took 3.0279159545898438e-05\n",
      "Boolean mask finished: 6.4373016357421875e-06\n",
      "Grouping took: 0.0010781288146972656\n",
      "Filtering edges by size finished: 0.0012810230255126953, facet # = 2\n",
      "Filtering by convexity and getting centers took: 0.0012748241424560547, facet # = 2\n",
      "Total Time = 0.004834651947021484\n",
      "Finished facets for child 6 : 0.004886627197265625 with facet length = 2\n",
      "Starting child 7\n",
      " face length 70 using OPTIMIZED facets\n",
      "Total normals took 3.218650817871094e-05\n",
      "Boolean mask finished: 6.9141387939453125e-06\n",
      "Grouping took: 0.0009036064147949219\n",
      "Filtering edges by size finished: 0.002321004867553711, facet # = 11\n",
      "Filtering by convexity and getting centers took: 0.004510402679443359, facet # = 4\n",
      "Total Time = 0.009072065353393555\n",
      "Finished facets for child 7 : 0.009163856506347656 with facet length = 4\n",
      "Starting child 8\n",
      " face length 854 using OPTIMIZED facets\n",
      "Total normals took 0.00019097328186035156\n",
      "Boolean mask finished: 1.2636184692382812e-05\n",
      "Grouping took: 0.002377748489379883\n",
      "Filtering edges by size finished: 0.02633500099182129, facet # = 123\n",
      "Filtering by convexity and getting centers took: 0.04438376426696777, facet # = 29\n",
      "Total Time = 0.07650065422058105\n",
      "Finished facets for child 8 : 0.07660603523254395 with facet length = 29\n",
      "Starting child 9\n",
      " face length 72 using OPTIMIZED facets\n",
      "Total normals took 3.1948089599609375e-05\n",
      "Boolean mask finished: 6.4373016357421875e-06\n",
      "Grouping took: 0.0009496212005615234\n",
      "Filtering edges by size finished: 0.0025763511657714844, facet # = 14\n",
      "Filtering by convexity and getting centers took: 0.006161928176879883, facet # = 11\n",
      "Total Time = 0.010997772216796875\n",
      "Finished facets for child 9 : 0.011079072952270508 with facet length = 11\n",
      "Starting child 10\n",
      " face length 114 using OPTIMIZED facets\n",
      "Total normals took 0.0001251697540283203\n",
      "Boolean mask finished: 7.62939453125e-06\n",
      "Grouping took: 0.0010485649108886719\n",
      "Filtering edges by size finished: 0.002925395965576172, facet # = 16\n",
      "Filtering by convexity and getting centers took: 0.00655055046081543, facet # = 7\n",
      "Total Time = 0.01213383674621582\n",
      "Finished facets for child 10 : 0.012190580368041992 with facet length = 7\n",
      "Starting child 11\n",
      " face length 32 using OPTIMIZED facets\n",
      "Total normals took 2.8133392333984375e-05\n",
      "Boolean mask finished: 6.198883056640625e-06\n",
      "Grouping took: 0.0009295940399169922\n",
      "Filtering edges by size finished: 0.0016782283782958984, facet # = 6\n",
      "Filtering by convexity and getting centers took: 0.003198862075805664, facet # = 6\n",
      "Total Time = 0.006913423538208008\n",
      "Finished facets for child 11 : 0.006986141204833984 with facet length = 6\n",
      "Starting child 12\n",
      " face length 50 using OPTIMIZED facets\n",
      "Total normals took 2.956390380859375e-05\n",
      "Boolean mask finished: 6.4373016357421875e-06\n",
      "Grouping took: 0.0009522438049316406\n",
      "Filtering edges by size finished: 0.003025054931640625, facet # = 12\n",
      "Filtering by convexity and getting centers took: 0.005914211273193359, facet # = 12\n",
      "Total Time = 0.011199235916137695\n",
      "Finished facets for child 12 : 0.011251211166381836 with facet length = 12\n",
      "Starting child 13\n",
      " face length 198 using OPTIMIZED facets\n",
      "Total normals took 0.00016498565673828125\n",
      "Boolean mask finished: 7.152557373046875e-06\n",
      "Grouping took: 0.0010540485382080078\n",
      "Filtering edges by size finished: 0.0053863525390625, facet # = 27\n",
      "Filtering by convexity and getting centers took: 0.010092020034790039, facet # = 8\n",
      "Total Time = 0.0188138484954834\n",
      "Finished facets for child 13 : 0.018929719924926758 with facet length = 8\n",
      "Starting child 14\n",
      " face length 72 using OPTIMIZED facets\n",
      "Total normals took 3.147125244140625e-05\n",
      "Boolean mask finished: 6.67572021484375e-06\n",
      "Grouping took: 0.0009005069732666016\n",
      "Filtering edges by size finished: 0.002214193344116211, facet # = 8\n",
      "Filtering by convexity and getting centers took: 0.003982067108154297, facet # = 7\n",
      "Total Time = 0.008296489715576172\n",
      "Finished facets for child 14 : 0.008379697799682617 with facet length = 7\n",
      "Starting child 15\n",
      " face length 32 using OPTIMIZED facets\n",
      "Total normals took 2.574920654296875e-05\n",
      "Boolean mask finished: 7.62939453125e-06\n",
      "Grouping took: 0.0008246898651123047\n",
      "Filtering edges by size finished: 0.0012753009796142578, facet # = 4\n",
      "Filtering by convexity and getting centers took: 0.00222015380859375, facet # = 4\n",
      "Total Time = 0.0056514739990234375\n",
      "Finished facets for child 15 : 0.005703449249267578 with facet length = 4\n",
      "Total time for facets: 62.574724435806274\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Rule: \n",
    "1) if mesh size is above a threshold --> run the unoptimized less careful version\n",
    "2) if mesh is below that size --> run optimized more generous (but with all the filters )\n",
    "\n",
    "\"\"\"\n",
    "facet_time = time.time()\n",
    "start_time = time.time()\n",
    "\n",
    "length_threshold = 60000\n",
    "\n",
    "if len(main_mesh.faces > length_threshold):\n",
    "    print(f\" face length {len(main_mesh.faces)} using unoptimized facets\")\n",
    "    main_mesh_facets,main_mesh_facets_centers = filter_final_facets(main_mesh)\n",
    "    \n",
    "else:\n",
    "    print(f\" face length {len(main_mesh.faces)} using OPTIMIZED facets\")\n",
    "    main_mesh_facets,main_mesh_facets_centers = filter_final_facets_optimized_with_checks(main_mesh)\n",
    "    \n",
    "\n",
    "print(f\"Finished { len(main_mesh_facets)} facets for main mesh: {time.time() - start_time}\")\n",
    "child_meshes_facets= []\n",
    "for jj,gap_mesh in enumerate(child_meshes):\n",
    "    print(\"Starting child \" + str(jj))\n",
    "    start_time = time.time()\n",
    "    if len(gap_mesh.faces) > length_threshold:\n",
    "        print(f\" face length {len(gap_mesh.faces)} using unoptimized facets\")\n",
    "        child_meshes_facets.append(filter_final_facets(gap_mesh))\n",
    "    else:\n",
    "        print(f\" face length {len(gap_mesh.faces)} using OPTIMIZED facets\")\n",
    "        child_meshes_facets.append(filter_final_facets_optimized_with_checks(gap_mesh))\n",
    "\n",
    "    \n",
    "    print(f\"Finished facets for child {jj} : {time.time() - start_time} with facet length = {len(child_meshes_facets[jj][0])}\")\n",
    "\n",
    "\n",
    "print(f\"Total time for facets: {time.time() - facet_time}\")\n",
    "#child_meshes_facets = [filter_final_facets(gap_mesh) for gap_mesh in child_meshes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of faces for child 0 = 30\n",
      "number of faces for child 1 = 44\n",
      "number of faces for child 2 = 161\n",
      "number of faces for child 3 = 105\n",
      "number of faces for child 4 = 157\n",
      "number of faces for child 5 = 6\n",
      "number of faces for child 6 = 2\n",
      "number of faces for child 7 = 4\n",
      "number of faces for child 8 = 29\n",
      "number of faces for child 9 = 11\n",
      "number of faces for child 10 = 7\n",
      "number of faces for child 11 = 6\n",
      "number of faces for child 12 = 12\n",
      "number of faces for child 13 = 8\n",
      "number of faces for child 14 = 7\n",
      "number of faces for child 15 = 4\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Check the ones that don't have any facets\n",
    "zero_faced = []\n",
    "\n",
    "for i,ch in enumerate(child_meshes_facets):\n",
    "    num_facets = len(ch[1])\n",
    "    print(f\"number of faces for child {i} = {num_facets}\")\n",
    "    if num_facets == 0:\n",
    "        zero_faced.append(i)\n",
    "    #print(f\"Child {i} has {num_facets} facets\")\n",
    "print(zero_faced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of faces for child 0 = 620\n",
      "number of faces for child 1 = 962\n",
      "number of faces for child 2 = 3986\n",
      "number of faces for child 3 = 2778\n",
      "number of faces for child 4 = 4062\n",
      "number of faces for child 5 = 82\n",
      "number of faces for child 6 = 38\n",
      "number of faces for child 7 = 70\n",
      "number of faces for child 8 = 854\n",
      "number of faces for child 9 = 72\n",
      "number of faces for child 10 = 114\n",
      "number of faces for child 11 = 32\n",
      "number of faces for child 12 = 50\n",
      "number of faces for child 13 = 198\n",
      "number of faces for child 14 = 72\n",
      "number of faces for child 15 = 32\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#print the sizes of the children\n",
    "# Check the ones that don't have any facets\n",
    "for i,ch in enumerate(child_meshes):\n",
    "    num_faces = len(ch.faces)\n",
    "    print(f\"number of faces for child {i} = {num_faces}\")\n",
    "print(zero_faced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the child meshes\n",
    "for child_id in range(0,len(child_meshes)):\n",
    "    print_trimesh(child_meshes[child_id],\"./test_meshes/chld_\" + str(child_id) + \".off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Results on the newurons facets reviewed\n",
    "A lot of the bigger faces weren't restitched because didn't look like clean cuts\n",
    "The big ones weren't being added\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START ITERATIVE PROCESS THAT CONNECTS THE MESHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_bbox_filter(child,min_bb_zone,max_bb_zone):\n",
    "    \"\"\"\n",
    "    Determines if child is withing the bounding box zone\n",
    "    designated by the bounding box corners\n",
    "    \n",
    "    \"\"\"\n",
    "    #get the min and max of the bounding box for the mesh\n",
    "    min_bb = np.array(child.bounding_box.vertices).min(0)\n",
    "    max_bb = np.array(child.bounding_box.vertices).max(0)\n",
    "    \n",
    "    #print(min_bb,max_bb)\n",
    "    #print(min_bb_zone,max_bb_zone)\n",
    "    \n",
    "    #if fails any of these checks then return false, else return True\n",
    "    if min(min_bb[0],max_bb[0])>max_bb_zone[0]:\n",
    "        print(\"returning x greater max\")\n",
    "        return False\n",
    "    \n",
    "    if max(min_bb[0],max_bb[0])<min_bb_zone[0]:\n",
    "        print(\"returning x less min\")\n",
    "        return False\n",
    "    \n",
    "    if min(min_bb[1],max_bb[1])>max_bb_zone[1]:\n",
    "        print(\"returning y greater max\")\n",
    "        return False\n",
    "    \n",
    "    if max(min_bb[1],max_bb[1])<min_bb_zone[1]:\n",
    "        print(\"returning y less min\")\n",
    "        return False\n",
    "        \n",
    "    if min(min_bb[2],max_bb[2])>max_bb_zone[2]:\n",
    "        print(\"returning z greater max\")\n",
    "        return False\n",
    "    \n",
    "    if max(min_bb[2],max_bb[2])<min_bb_zone[2]:\n",
    "        print(\"returning z less mim\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "import math\n",
    "def area(vertices):\n",
    "    \"\"\"\n",
    "    Calculates the area of a 3D triangle from it's coordinates\n",
    "    \"\"\"\n",
    "    side_a = np.linalg.norm(vertices[0]-vertices[1])\n",
    "    side_b = np.linalg.norm(vertices[1]-vertices[2])\n",
    "    side_c = np.linalg.norm(vertices[2]-vertices[0])\n",
    "    s = 0.5 * ( side_a + side_b + side_c)\n",
    "    return math.sqrt(s * (s - side_a) * (s - side_b) * (s - side_c))\n",
    "\n",
    "def find_polygon_area(mesh,list_of_faces):\n",
    "    \"Calculates the area of a 3D polygon that is created from connected traingles\"\n",
    "    return(sum([area(mesh.vertices[mesh.faces[r]]) for r in list_of_faces]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restitching functions\n",
    "import trimesh\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import time\n",
    "import math\n",
    "\n",
    "#gets the projection of point p onto line a\n",
    "def ClosestPointOnLine(a, b, p):\n",
    "    ap = p-a\n",
    "    ab = b-a\n",
    "    #base_vector = ab\n",
    "    result = np.dot(ap,ab)/np.dot(ab,ab) # * ab\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "#now have the mesh and the facet faces, can send to function\n",
    "def stitch_mesh_piece_vp4(new_mesh,facet_1,facet_2,\n",
    "                          delete_facets=False,\n",
    "                         return_added_mesh = False,\n",
    "                         fix_normals = False):\n",
    "\n",
    "    \"\"\"\n",
    "    Changed since last version: \n",
    "    1) parameter for deleting facets at end or not\n",
    "    2) parameter for returning added mesh or not \n",
    "    3) Changed normals check to print statement and not exception\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    #how to find the normals of facet groups:\n",
    "    facet_group_1_normal = new_mesh.face_normals[facet_1[0]] #main_mesh_normals\n",
    "    facet_group_2_normal = new_mesh.face_normals[facet_2[0]] #child_mesh_normals\n",
    "\n",
    "\n",
    "    #get the correct version of the normals: (might need to flip them if going in opposite direction)\n",
    "    if np.dot(facet_group_1_normal,facet_group_2_normal) > 0.8:\n",
    "        raise Exception(\"same direction normals\")\n",
    "    elif np.dot(facet_group_1_normal,facet_group_2_normal) < -0.8:\n",
    "        print(\"opposite direction normals\")\n",
    "    else:\n",
    "        print(\"Not correct normals\")\n",
    "        #raise Exception(\"Not correct normals\")\n",
    "\n",
    "    # make each row correspond to a single face \n",
    "    edges = new_mesh.edges_sorted.reshape((-1, 6))\n",
    "    # get the edges for each facet\n",
    "    edges_facet = [edges[i].reshape((-1, 2)) for i in [facet_1,facet_2]]\n",
    "    edges_boundary = np.array([i[trimesh.grouping.group_rows(i, require_count=1)]\n",
    "                               for i in edges_facet])\n",
    "\n",
    "    #the list of boundary edges and unique points in the boundary edges\n",
    "    edge_0 = edges_boundary[0]\n",
    "    edge_1 = edges_boundary[1]\n",
    "\n",
    "    #gets the unique number of points\n",
    "    edge_0_points = np.unique(np.hstack(edge_0))\n",
    "    edge_1_points = np.unique(np.hstack(edge_1))\n",
    "    print(\"Found boundary edges\")\n",
    "    \"\"\"\n",
    "    get the dot product of all the points\n",
    "    \"\"\"\n",
    "\n",
    "    #get any 2 points on the triangle and make that the reference edge\n",
    "    edge_0_anchor_points = new_mesh.vertices[[edge_0_points[0],edge_0_points[1]]]\n",
    "\n",
    "    #gets the starting index for the 1st facet (so that the start of the stitching is close)\n",
    "    max_index = 0\n",
    "    max_magnitude = ClosestPointOnLine(edge_0_anchor_points[0],edge_0_anchor_points[1],new_mesh.vertices[max_index])\n",
    "\n",
    "    for i in range(1,len(edge_0_points)):\n",
    "        current_magnitude = ClosestPointOnLine(edge_0_anchor_points[0],edge_0_anchor_points[1],new_mesh.vertices[edge_0_points[i]])\n",
    "\n",
    "        if current_magnitude > max_magnitude:\n",
    "            max_index = i\n",
    "            max_magnitude = current_magnitude\n",
    "\n",
    "    edge_0_starting_point = edge_0_points[max_index]\n",
    "\n",
    "    #gets the starting index for the 2nd facet (so that the start of the stitching is close)\n",
    "    max_index = 0\n",
    "    max_magnitude = ClosestPointOnLine(edge_0_anchor_points[0],edge_0_anchor_points[1],new_mesh.vertices[max_index])\n",
    "\n",
    "    for i in range(1,len(edge_1_points)):\n",
    "        current_magnitude = ClosestPointOnLine(edge_0_anchor_points[0],edge_0_anchor_points[1],new_mesh.vertices[edge_1_points[i]])\n",
    "        if current_magnitude > max_magnitude:\n",
    "            max_index = i\n",
    "            max_magnitude = current_magnitude\n",
    "\n",
    "    edge_1_starting_point = edge_1_points[max_index]\n",
    "\n",
    "    print(f\"starting edge 1st facet = {edge_0_starting_point}, starting edge 2nd facet= {edge_1_starting_point}, \")\n",
    "    #print(new_mesh.vertices[edge_0_starting_point],new_mesh.vertices[edge_1_starting_point])\n",
    "\n",
    "    \"\"\"\n",
    "    Need to order the points for restitching\n",
    "\n",
    "    Pseudocode: \n",
    "    1) Get starting piont\n",
    "    2) Find the two edges corresponding to that point\n",
    "    3) Need to decide which direction to start....\n",
    "    - go in direction that make the cross of the (1st and last) point in the same direction of the \n",
    "    normal of the first facet\n",
    "    4) loop through and record the orders of the vertices as you traverse along the edges \n",
    "    until you arrive back at the start\n",
    "    5) Error if:\n",
    "        a. You arrive back at the start and haven't processed all the edges\n",
    "        b. Processsed all the edges but haven't arrived back at start\n",
    "\n",
    "    6) Repeat steps 1 through 5 for 2nd facet group\n",
    "    \"\"\"\n",
    "    start_point_list = [edge_0_starting_point,edge_1_starting_point]\n",
    "    edge_list = [edge_0,edge_1]\n",
    "    edge_order_list = []\n",
    "\n",
    "\n",
    "\n",
    "    #loop that organizes the unique boundary points into the correct order\n",
    "    for i,start_point in enumerate(start_point_list):\n",
    "        print(f\"Starting Organizing vertices for side {i}\")\n",
    "        #print(f\"start_point = {start_point}\")\n",
    "        edge_order = [start_point]\n",
    "        processed_edges = []\n",
    "\n",
    "        #find the matching edges to the starting point\n",
    "        starting_edges_indices = np.where(np.logical_or(edge_list[i][:,0] == start_point,edge_list[i][:,1] == start_point) == True)[0]\n",
    "\n",
    "        starting_edges = edge_list[i][starting_edges_indices]\n",
    "        #print(f\"starting edges = {starting_edges}\") #the list of the two possible edges\n",
    "\n",
    "        if starting_edges.size < 4:\n",
    "            raise Exception(\"Not enough edges for 1st facet start point\")\n",
    "\n",
    "        if starting_edges.size > 4:\n",
    "            raise Exception(\"Too many edges for 1st facet start point\") \n",
    "\n",
    "        #np.where(starting_edges[1,:] != start_point)[0][0]\n",
    "        #gets the vectors that will be used for the cross product\n",
    "        #print(\"np.where(starting_edges[0,:] != start_point)[0][0] = \" + str(np.where(starting_edges[0,:] != start_point)[0][0]))\n",
    "        #print(\"np.where(starting_edges[1,:] != start_point)[0][0] = \" + str(np.where(starting_edges[1,:] != start_point)[0][0]))\n",
    "\n",
    "        \"\"\"*************** where pick the starting edge starts ************\n",
    "        The way it works: \n",
    "        1) Gets the two possible starting edges\n",
    "        2) Generates the vectors for the edges where origin is the starting point\n",
    "        3) Gets the cross porduct of both vectors\n",
    "        4) Chooses the cross product that is in the direction of the face normals\n",
    "\n",
    "        Why that doesn't work:\n",
    "        1) they are opposite normals\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        Possible other solution:\n",
    "        1) Get the starting points on the child edge\n",
    "        2) Pick the first edge as the default edge\n",
    "\n",
    "        \"\"\"\n",
    "        processed_edges.append(starting_edges_indices[0])\n",
    "        current_vertex = starting_edges[0][np.where(starting_edges[0,:] != start_point)[0][0]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #         #gets the possible starting vectors from the two possible edges\n",
    "    #         possible_starting_vector_1 = new_mesh.vertices[starting_edges[0,:][np.where(starting_edges[0,:] != start_point)[0][0]]] - new_mesh.vertices[start_point]\n",
    "    #         #just start with a random edge\n",
    "    #         possible_starting_vector_2 = new_mesh.vertices[starting_edges[1,:][np.where(starting_edges[1,:] != start_point)[0][0]]] - new_mesh.vertices[start_point]\n",
    "\n",
    "\n",
    "    #         #find the cross product of the starting vectors\n",
    "    #         starting_edges_cross = np.cross(possible_starting_vector_1,possible_starting_vector_2)\n",
    "\n",
    "    #         #make sure that the order of the vectors goes so that the cross product is in line with the starting normal\n",
    "    #         #this ensures the the circular direction of the stitching will be the same\n",
    "    #         if np.dot(starting_edges_cross,facet_group_1_normal) > 0:\n",
    "    #             print(\"Edge 1 picked for direction\")\n",
    "    #             processed_edges.append(starting_edges_indices[0])\n",
    "    #             current_vertex = starting_edges[0][np.where(starting_edges[0,:] != start_point)[0][0]]\n",
    "    #         else:\n",
    "    #             print(\"Edge 2 picked for direction\")\n",
    "    #             processed_edges.append(starting_edges_indices[1])\n",
    "    #             #print(\"np.where(starting_edges[1,:] != start_point) = \" + str(np.where(starting_edges[1,:] != start_point)))\n",
    "    #             current_vertex = starting_edges[1][np.where(starting_edges[1,:] != start_point)[0][0]]\n",
    "\n",
    "        #print(f\"current_vertex = {current_vertex}\" )\n",
    "        #print(\"edge_list = \" + str(edge_list))\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"*************** where pick the starting edge ends ************\"\"\"\n",
    "        #now iterate through number of \n",
    "        for z in range(1,edge_list[i][:,0].size):\n",
    "            #print(\"edge_order_temp = \" + str(edge_order))\n",
    "            if current_vertex == start_point:\n",
    "                print(\"Start vertex reached before processed all of edges\")\n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "                These should be ok because the extra loops are created from holes inside and this process should always get the outside loop\n",
    "\n",
    "\n",
    "                \"\"\"\n",
    "                break\n",
    "\n",
    "            #get the next edge\n",
    "            counter = 0\n",
    "            next_vertex = -1\n",
    "            for j,edg in enumerate(edge_list[i]):\n",
    "                #print(\"edg = \" + str(edg))\n",
    "                #print(\"processed_edges = \" + str(processed_edges))\n",
    "                if current_vertex in edg and j not in processed_edges:\n",
    "                    current_edge_index = j\n",
    "                    if edg[0] != current_vertex:\n",
    "                        next_vertex = edg[0]\n",
    "                    else:\n",
    "                        next_vertex = edg[1]\n",
    "\n",
    "\n",
    "                    counter += 1\n",
    "                    if counter >= 2:\n",
    "                        #raise Exception(f\"More than 2 edges possibilities for {current_vertex}\")\n",
    "                        #Don't want to make it an exception anymore put just print out warning\n",
    "                        print(\"More than 2 edges possibilities for {current_vertex}\") # BAC change\n",
    "\n",
    "            #make sure the next vertex was found\n",
    "            if next_vertex <= -1:\n",
    "                raise Exception(f\"No next vertex was found for {current_vertex} \")\n",
    "\n",
    "            #if found next vertex then add the old vertex and edge index\n",
    "            #to the processed edges lists and the order of vertices\n",
    "            processed_edges.append(current_edge_index)\n",
    "            edge_order.append(current_vertex)\n",
    "\n",
    "            current_vertex = next_vertex\n",
    "\n",
    "\n",
    "        edge_order_list.append(edge_order)\n",
    "        print(f\"edge_{i}_order done, len = {len(edge_order)} \")#\"= {edge_order}\")\n",
    "\n",
    "    #     #print the edge orders\n",
    "    #     for e in edge_order_list:\n",
    "    #         print(type(e))\n",
    "    lengths_of_boundaries = [len(x) for x in edge_order_list]\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\" ************ PROCESS OF ORDERING THE EDGE PATHS SO THAT *********\n",
    "    main mesh loop goes in counter clockwise in reference to the gap\n",
    "    child goes clockwise in reference to gap\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    1) Pick the starting point as your P point\n",
    "    2) For each point in ordered list calculate point - P and store that vector\n",
    "    3) Do the cross product of list[0:n-2] x list[1:n-1]\n",
    "    4) Take the sum of these lists of cross products\n",
    "    5) Do the dot product to compare the direction with the normal vector \n",
    "    Result: \n",
    "    - if positive --> conuter-clockwise according to normal\n",
    "    - if negative --> clockwise according to normal\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    starter_point = np.array([0,0,0])\n",
    "\n",
    "    #     list_of_points = [1,2,3,4,0]\n",
    "\n",
    "    #     list_of_points = [list_of_points[len(list_of_points) - x -1] for x in range(0,len(list_of_points))]\n",
    "    #     print(list_of_points)\n",
    "\n",
    "    #print(\"facet_group_2_normal = \" + str(facet_group_2_normal))\n",
    "\n",
    "    for ed,e_loop in enumerate(edge_order_list):\n",
    "\n",
    "        #get the vertices according to the points\n",
    "        vertices_list = new_mesh.vertices[e_loop]\n",
    "\n",
    "        #get the cross product of the offsetted list\n",
    "        #vertices_list[0:len(vertices_list)-1,:]\n",
    "        \"\"\" Wrong earlier previous way\n",
    "\n",
    "        cross_products = np.cross(vertices_list[0:len(vertices_list)-1,:],vertices_list[1:len(vertices_list)])\n",
    "        \"\"\"\n",
    "\n",
    "        cross_products = np.cross(vertices_list[0:len(vertices_list),:],\n",
    "                             np.vstack([vertices_list[1:len(vertices_list),:],vertices_list[0,:]]))\n",
    "\n",
    "        sum_cross_products = np.sum(cross_products,axis=0)\n",
    "\n",
    "        #print(\"cross_products = \" + str(cross_products))\n",
    "        #print(\"sum_cross_products = \" + str(sum_cross_products))\n",
    "\n",
    "        #print(\"Before edge list = \" + str(edge_order_list[ed]))\n",
    "        if ed == 0:\n",
    "            #get the dot product\n",
    "            normals_dot = np.dot(sum_cross_products,facet_group_1_normal)\n",
    "            #print(' normals_dot = ' + str(normals_dot))\n",
    "            if normals_dot > 0:\n",
    "                print(\"Main originally was counter-clockwise --> keeping\")\n",
    "\n",
    "\n",
    "            else:\n",
    "                print(\"Main originally was clockwise --> flipping\")\n",
    "                edge_order_list[ed] = [e_loop[len(e_loop) - x -1] for x in range(0,len(e_loop))]\n",
    "\n",
    "\n",
    "        else: \n",
    "            # for the children want the cross product to be counter clockwise\n",
    "            normals_dot = np.dot(sum_cross_products,facet_group_2_normal)\n",
    "            #print(' normals_dot = ' + str(normals_dot))\n",
    "            if normals_dot > 0:\n",
    "                print(\"Child originally was counter-clockwise --> flipping\")\n",
    "                edge_order_list[ed] = [e_loop[len(e_loop) - x -1] for x in range(0,len(e_loop))]\n",
    "            else:\n",
    "                print(\"Child originally was clockwise --> keeping\")\n",
    "\n",
    "\n",
    "        #print(\"After edge list = \" + str(edge_order_list[ed]))\n",
    "    \"\"\"  SHOWS THAT DOING THE CROSS PRODUCT THAT WAY WORKS\n",
    "    #do the cross products manually\n",
    "    for jj in range(0,len(vertices_list)-1):\n",
    "        print(np.cross(vertices_list[jj],vertices_list[jj+1]))\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #getting which one is the bigger one\n",
    "    bigger = lengths_of_boundaries.index(max(lengths_of_boundaries))\n",
    "    smaller = 1-bigger\n",
    "\n",
    "    if bigger == 0:\n",
    "        starter_face = \"child\" #if the bigger one was the main, then child is the smaller one you start from\n",
    "    else:\n",
    "        starter_face = \"main\" #if the bigger one was the child, then main is the smaller one you start from\n",
    "\n",
    "\n",
    "    print(\"smaller_face = \" + str(starter_face))    \n",
    "\n",
    "    \"\"\" The rules that have to be following in order for normals to be correctly aligned\n",
    "    1) if the smaller is the child (will be traveling in clockwise direction\n",
    "    --> need to stitch points as:\n",
    "    Regular: other_2, other_1,current_point\n",
    "    Neighbor: current,other_1,current-1\n",
    "\n",
    "\n",
    "    1) if the smaller is the main mesh (\n",
    "    --> need to stitch points as:\n",
    "    Regular: current_point,other_1,other_2\n",
    "    Neighbor: current,current-1,other\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    #print(f\"index of bigger facets = {bigger}\\nindex of smaller facets = {smaller}\",)\n",
    "\n",
    "    #calculates the number of vertices will be stitched to each vertices on smaller side\n",
    "    dividend = int(lengths_of_boundaries[bigger]/lengths_of_boundaries[smaller])\n",
    "    remainder = lengths_of_boundaries[bigger] - int(lengths_of_boundaries[bigger]/lengths_of_boundaries[smaller])*lengths_of_boundaries[smaller]\n",
    "\n",
    "    print(f\"dividend = {dividend}, remainder = {remainder}\")\n",
    "\n",
    "    #loop that adds the new faces\n",
    "    print(\"About to add faces\")\n",
    "    start_time = time.time()\n",
    "    new_faces = []\n",
    "    current_bigger = 0\n",
    "    total_counter= 0\n",
    "    end_number = 1000\n",
    "    for i,current_smaller in enumerate(edge_order_list[smaller]):\n",
    "        #print(\"current_smaller =\" + str(current_smaller))\n",
    "        #print(\"current_bigger=\" + str(edge_order_list[bigger][current_bigger]))\n",
    "\n",
    "        #connecting to the neighbor on the shorter side\n",
    "        \"\"\"\n",
    "        if i == 0:\n",
    "\n",
    "            new_faces.append([current_smaller,edge_order_list[smaller][-1],edge_order_list[bigger][current_bigger]])\n",
    "        else:\n",
    "            new_faces.append([current_smaller,edge_order_list[smaller][i-1],edge_order_list[bigger][current_bigger]])\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        if starter_face == \"main\":\n",
    "            new_faces.append([current_smaller,edge_order_list[bigger][current_bigger],edge_order_list[smaller][i-1]])\n",
    "        else:\n",
    "            new_faces.append([current_smaller,edge_order_list[smaller][i-1],edge_order_list[bigger][current_bigger]])\n",
    "\n",
    "        total_counter += 1\n",
    "        if total_counter > end_number:\n",
    "            break\n",
    "        for j in range(0,dividend + int(i<remainder)):\n",
    "            if current_bigger > len(edge_order_list[bigger]):\n",
    "                raise Exception(\"Somehow rapped around too much\")\n",
    "\n",
    "            if current_bigger >= len(edge_order_list[bigger])-1:\n",
    "                next_bigger = 0\n",
    "            else:\n",
    "                next_bigger = current_bigger+1\n",
    "\n",
    "            if starter_face == \"main\":\n",
    "                new_faces.append([edge_order_list[bigger][next_bigger],\n",
    "                                  edge_order_list[bigger][current_bigger],\n",
    "                                  current_smaller,\n",
    "                                ])\n",
    "            else:\n",
    "                new_faces.append([\n",
    "                                current_smaller,\n",
    "                                  edge_order_list[bigger][current_bigger],\n",
    "                                  edge_order_list[bigger][next_bigger],\n",
    "\n",
    "                                ])\n",
    "\n",
    "            current_bigger += 1\n",
    "\n",
    "            total_counter += 1\n",
    "            if total_counter > end_number:\n",
    "                break\n",
    "        if total_counter > end_number:\n",
    "                break\n",
    "\n",
    "\n",
    "    #print(\"new_faces = \" + str(new_faces))\n",
    "    print(f\"Finished adding faces: {time.time() - start_time}\")\n",
    "\n",
    "\n",
    "    print(\"Starting creating stitch mesh\")\n",
    "    start_time = time.time()\n",
    "    stitch_mesh = trimesh.Trimesh()\n",
    "\n",
    "    stitch_mesh.vertices = new_mesh.vertices\n",
    "    stitch_mesh.faces = np.vstack([new_mesh.faces, new_faces])\n",
    "    print(f\"Finished creating stitch mesh: {time.time() - start_time}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if delete_facets == True:\n",
    "        #now take away the original facet faces:\n",
    "        total_faces = np.linspace(0,len(stitch_mesh.faces)-1,len(stitch_mesh.faces)).astype(\"int\")\n",
    "        facet_faces = np.hstack([facet_1 ,facet_2])\n",
    "        faces_to_keep = set(total_faces).difference(set(facet_faces))\n",
    "        faces_to_keep\n",
    "\n",
    "        stitch_mesh = stitch_mesh.submesh([list(faces_to_keep)])[0]\n",
    "\n",
    "    if fix_normals == True:\n",
    "        trimesh.repair.fix_inversion(stitch_mesh)\n",
    "        trimesh.repair.fix_winding(stitch_mesh)\n",
    "        trimesh.repair.fix_normals(stitch_mesh)\n",
    "\n",
    "    #print(\"Finished stitching\")\n",
    "\n",
    "    if return_added_mesh == True:\n",
    "        added_mesh = trimesh.Trimesh()\n",
    "        added_mesh.vertices = new_mesh.vertices\n",
    "        added_mesh.faces = new_faces\n",
    "        trimesh.repair.fix_inversion(added_mesh)\n",
    "        trimesh.repair.fix_winding(added_mesh)\n",
    "        trimesh.repair.fix_normals(added_mesh)\n",
    "\n",
    "        return stitch_mesh,added_mesh\n",
    "\n",
    "    else:\n",
    "        return stitch_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes a copy of the main mesh and the main mesh facets so can just run this cell again if errors:\n",
    "main_mesh_saved = main_mesh.copy()\n",
    "main_mesh_facets_centers_saved = main_mesh_facets_centers.copy()\n",
    "main_mesh_facets_saved = main_mesh_facets.copy()\n",
    "\n",
    "#save off the child information as well\n",
    "from copy import deepcopy\n",
    "\n",
    "child_meshes_saved = deepcopy(child_meshes)\n",
    "child_meshes_facets_saved = deepcopy(child_meshes_facets) #has both the centers and the facet lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restitch_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Pseudocode for loop at the end that will keep everything going:\n",
    "1) When process a child, will add that index to a list\n",
    "2) Have no_new_children_processed counter set at end of loop \n",
    "    if no children were added to main mesh\n",
    "    --> this will prompt the expansion of the initial parameters\n",
    "3) If this gets too high\n",
    "\n",
    "\n",
    "\n",
    "Things that still need to add:\n",
    "1) Better way of making sure that the normals are good\n",
    "- Can sample one of the neighboring points and flip normals if the dot product is negative\n",
    "\n",
    "\n",
    "Change list: \n",
    "1) Reduced the stitch distance\n",
    "2) Added the copy features that allows this cell to be rerun without rerunning whole notebook\n",
    "3) added the new tie_breaker for childs that want to connect to same parent is just the one with closest facet\n",
    "    Uses the added feature of child_meshes_stitch_distances that is saved along the way\n",
    "4) Iterates through the repeated faces instead of just doing so once which was incorrect before\n",
    "5) Fixed bug that was adding to current_main_mesh but then was using main mesh also in the loop\n",
    "6) Made changes to the stitching mechanism that not error if find a vertices with more than 2 edges\n",
    "--> because did observe some facets with cut out faces along the boundary\n",
    "7) Changed the consider_same_direction normal as False \n",
    "8) Changed the max index error that was used for finding the starting point in stitch meshes\n",
    "\n",
    "\"\"\"\n",
    "total_stitch_processing_time = time.time()\n",
    "#load our main mesh stuff from the copies\n",
    "#makes a copy of the main mesh and the main mesh facets so can just run this cell again if errors:\n",
    "main_mesh = main_mesh_saved.copy()\n",
    "main_mesh_facets_centers = main_mesh_facets_centers_saved.copy()\n",
    "main_mesh_facets = main_mesh_facets_saved.copy()\n",
    "\n",
    "#load the child info from the saved copies\n",
    "child_meshes_facets_saved = deepcopy(child_meshes_facets_saved)\n",
    "child_meshes  = deepcopy(child_meshes_saved)\n",
    "\n",
    "\n",
    "#sets \n",
    "initial_parameters = dict(bounding_box_threshold=4000,\n",
    "                         stitch_distance_threshold=800,\n",
    "                         size_ratio_threshold=0.15,\n",
    "                         normal_closeness= 0.95)\n",
    "\n",
    "bounding_box_threshold = initial_parameters[\"bounding_box_threshold\"]\n",
    "stitch_distance_threshold = initial_parameters[\"stitch_distance_threshold\"]\n",
    "size_ratio_threshold = initial_parameters[\"size_ratio_threshold\"]\n",
    "normal_closeness=initial_parameters[\"normal_closeness\"]\n",
    "\n",
    "no_new_children_multiplier = 0\n",
    "bbox_expansion_percentage = 0.10\n",
    "stitch_expansion_percentage = 0.20\n",
    "size_ratio_expansion_percentage = 0.10\n",
    "\n",
    "no_new_children_limit = 4\n",
    "\n",
    "consider_same_direction_normals = False\n",
    "children_processed = []\n",
    "\n",
    "#lists to store the faces that need to be removed later from main mesh\n",
    "child_faces_to_remove = []\n",
    "main_faces_to_remove = []\n",
    "\n",
    "while len(children_processed) < len(child_meshes):\n",
    "    stitch_loop_time = time.time()\n",
    "    if no_new_children_multiplier >= no_new_children_limit:\n",
    "        print(\"The number of times expanding the thresholds has exceed the limit /n Just returning main mesh\")\n",
    "        print(f\"total_stitch_processing_time = {time.time() - total_stitch_processing_time}\")\n",
    "        raise Exception(\"Finished the mesh stitiching\")\n",
    "    \n",
    "    #update the thresholds\n",
    "    bounding_box_threshold = initial_parameters[\"bounding_box_threshold\"]*(1 + bbox_expansion_percentage*no_new_children_multiplier)\n",
    "    stitch_distance_threshold = initial_parameters[\"stitch_distance_threshold\"]*(1 + stitch_expansion_percentage*no_new_children_multiplier)\n",
    "    #reduces the \n",
    "    size_ratio_threshold = initial_parameters[\"size_ratio_threshold\"]*(1 - size_ratio_expansion_percentage*no_new_children_multiplier)\n",
    "    \n",
    "    #print thresholds\n",
    "#     print(f\"bounding_box_threshold = {bounding_box_threshold}\")\n",
    "#     print(f\"stitch_distance_threshold = {stitch_distance_threshold}\" )\n",
    "#     print(f\"size_ratio_threshold = {size_ratio_threshold}\")\n",
    "\n",
    "    #get the main mesh facets normals\n",
    "    main_mesh_normals = [main_mesh.face_normals[fac[0]] for fac in main_mesh_facets]\n",
    "    hit_indexes_list= []\n",
    "    \n",
    "    \n",
    "    #dictionary to save the stitch points\n",
    "    child_meshes_stitch_facets = dict()\n",
    "    child_meshes_stitch_face_ratios = dict()\n",
    "    child_meshes_stitch_distances = dict()\n",
    "    for i,child in enumerate(child_meshes):\n",
    "        \n",
    "        if i in children_processed:\n",
    "            #print(f\"Child {i} already processed\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Starting Child {i}\")\n",
    "\n",
    "        #initialize the stitch index\n",
    "        #child_meshes_stitch_facets[i] = [-1,-1]\n",
    "\n",
    "        #two highest points for the bounding box\n",
    "        min_bb = np.array(main_mesh.bounding_box.vertices).min(0)\n",
    "        max_bb = np.array(main_mesh.bounding_box.vertices).max(0)\n",
    "\n",
    "        min_bb_zone = min_bb - bounding_box_threshold\n",
    "        max_bb_zone = max_bb + bounding_box_threshold\n",
    "\n",
    "\n",
    "\n",
    "        #then send mesh to function that decides if with\n",
    "        pass_bbox_filter = apply_bbox_filter(child,min_bb_zone,max_bb_zone)\n",
    "\n",
    "        if not pass_bbox_filter:\n",
    "            print(\"skipped by bounding box filter\")\n",
    "            continue\n",
    "\n",
    "        #### used for validation to make sure that bounding box was correctly filtering\n",
    "    #     #add the following to main mesh just to visualize\n",
    "    #     final_mesh = final_mesh + child\n",
    "    #     print(\"just added\")\n",
    "\n",
    "        #\n",
    "        \"\"\"\n",
    "\n",
    "        Do pairwise calculation of distances between centers of facets on child piece and main piece\n",
    "            Filter the pairs for stitch distance threshold\n",
    "            Filter the pairs for matching or opposite normals\n",
    "            Filter for those that are reasonable in size matching (within 50% of each other)\n",
    "\n",
    "        If there are still ties after this point then pitch the best matching size\n",
    "\n",
    "        If None remaining then keep going (might loosen up the parameters later), BUT WITH GLOBAL CHECK SO DOESN’T KEEP ITERATING\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    " \n",
    "        \"\"\" OLD WAY OF COMPUTING PAIRWISE ***************************************************************\n",
    "        \n",
    "        child_facets,child_facets_centers = child_meshes_facets[i]\n",
    "\n",
    "        facet_distances = np.zeros((len(child_facets_centers),len(main_mesh_facets_centers)))\n",
    "        facet_normals = np.zeros((len(child_facets_centers),len(main_mesh_facets_centers)))\n",
    "\n",
    "        start_time = time.time()\n",
    "        #do the pairwise comparison\n",
    "        for cc,child_center in enumerate(child_facets_centers):\n",
    "\n",
    "            #get the normal of the child\n",
    "            child_normal = child.face_normals[child_facets[cc][0]]\n",
    "            for mm, main_center in enumerate(main_mesh_facets_centers):\n",
    "                #get the euclidean distance\n",
    "    #             facet_distances[cc,mm] = math.sqrt((child_center[0] - main_center[0])**2 + \n",
    "    #                                                  (child_center[1] - main_center[1])**2 + \n",
    "    #                                                  (child_center[2] - main_center[2])**2 )\n",
    "\n",
    "\n",
    "\n",
    "                facet_distances[cc,mm] = np.linalg.norm(np.array(child_center) - np.array(main_center))\n",
    "\n",
    "                main_normal = main_mesh_normals[mm]\n",
    "    #             print(\"main_normal = \" + str(main_normal))\n",
    "    #             print(\"child_normal = \" + str(child_normal))\n",
    "                #get whether the normals are line up (or possibly opposite)\n",
    "                normals_dot = np.dot(child_normal,main_normal)\n",
    "                #print(normals_dot)\n",
    "                if consider_same_direction_normals == True:\n",
    "                    facet_normals[cc,mm] =  normals_dot < -0.95  or normals_dot > 0.95\n",
    "                else:\n",
    "                    facet_normals[cc,mm] =  normals_dot < -0.95 # or normals_dot > 0.95\n",
    "\n",
    "\n",
    "        \n",
    "        print(f\"Total pairwise : {time.time() - start_time}\")\n",
    "\n",
    "    #     if i == 1:\n",
    "    #         4,12\n",
    "    #         print(\"4,12 facet distance = \" + str(facet_distances[4,12]))\n",
    "\n",
    "        #apply the filters\n",
    "        #stitch_distance_booleans = facet_distances < stitch_distance_threshold\n",
    "\n",
    "        \n",
    "        #how to debug certain faces that have been filtered\n",
    "#         main_facet_bebug = 124\n",
    "#         piece_facet_debug = 11\n",
    "        \n",
    "#         if i == 2 and (0 in children_processed):\n",
    "#             print(\"**********\" + str(facet_normals[piece_facet_debug,main_facet_bebug]) + \"**********\")\n",
    "#             print(\"**********\" + str((facet_distances < stitch_distance_threshold)[piece_facet_debug,main_facet_bebug]) + \"**********\")\n",
    "        \n",
    "        \n",
    "        #get the indexes that make it through the first two filters\n",
    "        hit_indexes = np.where(np.logical_and(facet_distances < stitch_distance_threshold,facet_normals)== True) \n",
    "\n",
    "        possible_stitch_pairs = np.vstack(hit_indexes).T\n",
    "        \n",
    "        #print(\"possible_stitch_pairs = \" + str(possible_stitch_pairs))\n",
    "        \n",
    "        face_0_unique_facets = np.unique(hit_indexes[0])\n",
    "        face_1_unique_facets = np.unique(hit_indexes[1])\n",
    "        \n",
    "        if len(hit_indexes[0]) <= 0:\n",
    "            print(f\"Child {i} There was no possible stitch found after stitch distance and face normal filters\")\n",
    "            continue\n",
    "\n",
    "        if len(hit_indexes[0]) > 0:\n",
    "            face_0_facet_sizes = dict([(u,find_polygon_area(child,child_facets[u])) for u in face_0_unique_facets])\n",
    "            face_1_facet_sizes = dict([(u,find_polygon_area(main_mesh,main_mesh_facets[u])) for u in face_1_unique_facets])\n",
    "\n",
    "            \n",
    "\n",
    "         *************************************************************** \"\"\"\n",
    "        \n",
    "        \"\"\"  NEW WAY OF COMPUTING THE PAIRWISE CALCULATIONS  *************************************************************** \"\"\"\n",
    "        \n",
    "        child_facets,child_facets_centers = child_meshes_facets[i]\n",
    "        pairs_start_time = time.time()\n",
    "\n",
    "        \n",
    "        if len(child_facets_centers) == 0:\n",
    "            print(\"child_facets_centers for child {i} was 0, so skipping\")\n",
    "            continue\n",
    "        \n",
    "        start_time = time.time()\n",
    "        a_New = np.array(child_facets_centers).astype(\"float\")\n",
    "        b_New = np.array(main_mesh_facets_centers).astype(\"float\")\n",
    "\n",
    "        print(len(a_New),len(b_New))\n",
    "#         print(\"starting distance matrix\")\n",
    "        start_time = time.time()\n",
    "        from scipy.spatial import distance_matrix\n",
    "        a_b_distance = distance_matrix(a_New, b_New)\n",
    "        \n",
    "        #print(f\"Time = {time.time() - start_time}\")\n",
    "\n",
    "        #now get the indexes that are within stitch distance\n",
    "\n",
    "#         print(\"min(a_b_distance) = \" + str(np.amin(a_b_distance.shape)))\n",
    "        indexes_not = np.where(a_b_distance < stitch_distance_threshold)\n",
    "        print(f\"Done distance matrix: {time.time() - start_time}\")\n",
    "        \n",
    "        \n",
    "#         print(\"(indexes_not) = \" + str((indexes_not)))\n",
    "#         print(\"starting normals\")\n",
    "        start_time = time.time()\n",
    "\n",
    "#         #old way to do it\n",
    "#         child_normals = child.face_normals[indexes_not[0]]\n",
    "#         main_normals = main_mesh.face_normals[indexes_not[1]]\n",
    "\n",
    "        if not indexes_not[0].any():\n",
    "            print(f\"Child {i} There were no points close enough\")\n",
    "            continue\n",
    "\n",
    "        #old way to do it\n",
    "#         print(indexes_not[0])\n",
    "#         print(child_facets[indexes_not[0]])\n",
    " \n",
    "        \n",
    "        child_normals = child.face_normals[[p[0] for p in child_facets[indexes_not[0]]]]\n",
    "        main_normals = main_mesh.face_normals[[p[0] for p in main_mesh_facets[indexes_not[1]]]]\n",
    "                                           \n",
    "                                           \n",
    "                                           \n",
    "#         print(child_facets[indexes_not[0]][0])\n",
    "#         print('child_normals = ' + str(child_normals))\n",
    "#         print(main_mesh_facets[indexes_not[1]][0])\n",
    "#         print('main_normals = ' + str(main_normals))\n",
    "        #start_time = time.time()\n",
    "        #dot_products = np.dot(child_normals,main_normals.T)\n",
    "        \n",
    "        total_normal_dots = np.sum(child_normals*main_normals,axis=1)\n",
    "#         print(\"total_normal_dots = \" + str(total_normal_dots))\n",
    "        total_normal_dots_facet_mask = total_normal_dots < -normal_closeness\n",
    "        \n",
    "#         print(f\"Done Normals generation: {time.time() - start_time}\")\n",
    "#         print(\"starting pair generation\")\n",
    "        \n",
    "        \n",
    "        start_time = time.time()\n",
    "        final_pairs = (np.array(indexes_not).T)[total_normal_dots_facet_mask]\n",
    "        #print(final_pairs)\n",
    "        \n",
    "        \n",
    "        #get the sizes of all the unique ones\n",
    "        face_0_unique_facets = np.unique(final_pairs[:,0])\n",
    "        face_1_unique_facets = np.unique(final_pairs[:,1])\n",
    "        #print(\"final_pairs = \" + str(final_pairs))\n",
    "#         print(\"face_0_unique_facets = \" + str(face_0_unique_facets))\n",
    "#         print(\"face_1_unique_facets = \" + str(face_1_unique_facets))\n",
    "        \n",
    "        \n",
    "        if len(final_pairs) <= 0:\n",
    "            print(f\"Child {i} There was no possible stitch found after stitch distance and face normal filters\")\n",
    "            continue\n",
    "\n",
    "        if len(final_pairs[0]) > 0:\n",
    "            face_0_facet_sizes = dict([(u,find_polygon_area(child,child_facets[u])) for u in face_0_unique_facets])\n",
    "            face_1_facet_sizes = dict([(u,find_polygon_area(main_mesh,main_mesh_facets[u])) for u in face_1_unique_facets])\n",
    "\n",
    "        \n",
    "        possible_stitch_pairs = final_pairs\n",
    "        print(f\"Done Generating final pairs: {time.time() - pairs_start_time}\")\n",
    "        \n",
    "        \n",
    "        \"\"\"  NEW WAY OF COMPUTING THE PAIRWISE  *************************************************************** \"\"\"\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #     print(\"possible_stitch_pairs = \" + str(possible_stitch_pairs))\n",
    "    #     print(\"len(hit_indexes) = \" + str(len(hit_indexes)))\n",
    "    #     print(\"hit_indexes[0].any() = \" + str(hit_indexes[0].any()))\n",
    "    #     print(\"hit_indexes = \" + str(hit_indexes))\n",
    "    #     print(\"hit_indexes[0] = \" + str(hit_indexes[0]))\n",
    "    #     print(\"len(hit_indexes[0]) = \" + str(len(hit_indexes[0])))\n",
    "\n",
    "        #find the sizes of all of them\n",
    "        face_pair_sizes = np.zeros(len(possible_stitch_pairs[:,0]))\n",
    "        face_size_ratios = np.zeros(len(possible_stitch_pairs[:,0]))\n",
    "\n",
    "        #print(\"possible_stitch_pairs = \" + str(possible_stitch_pairs))\n",
    "        for numba,pair in enumerate(possible_stitch_pairs):\n",
    "            #print(\"pair = \" + str(pair))\n",
    "            sizes = [face_0_facet_sizes[pair[0]],face_1_facet_sizes[pair[1]]]\n",
    "            min_area = min(sizes)\n",
    "            max_area = max(sizes)\n",
    "\n",
    "            ratio = min_area/max_area\n",
    "\n",
    "            #print(f\"ratio = {ratio}\")\n",
    "            #print(f\"Total size  = {min_area + max_area}\")\n",
    "            if ratio >= size_ratio_threshold:\n",
    "                face_pair_sizes[numba] = min_area + max_area\n",
    "                face_size_ratios[numba] = ratio\n",
    "            \n",
    "                #print(f\"face_pair_sizes[numba] = {face_pair_sizes[numba]}, face_size_ratios[numba] = {face_size_ratios[numba]}\")\n",
    "\n",
    "\n",
    "        #check that made it past stitch ratio threshold\n",
    "\n",
    "        #best possible stitch pair is just the maximum sized matching ones\n",
    "        best_index = np.where(face_pair_sizes == max(face_pair_sizes))\n",
    "        best_stitch_pair = possible_stitch_pairs[best_index][0]\n",
    "        best_stitch_pair_size = face_pair_sizes[best_index][0]\n",
    "        best_stitch_pair_size_ratio = face_size_ratios[best_index][0]\n",
    "        \n",
    "        #get the distance of the best_stitch_pair\n",
    "        best_stitch_pair_distance = a_b_distance[possible_stitch_pairs[best_index][0][0],\n",
    "                                                   possible_stitch_pairs[best_index][0][1]]\n",
    "        \n",
    "        print(\"best_stitch_pair = \" + str(best_stitch_pair))\n",
    "        print(\"best_stitch_pair_size = \" + str(best_stitch_pair_size))\n",
    "        print(\"best_stitch_pair_distance = \" + str(best_stitch_pair_distance))\n",
    "        print(\"best_stitch_pair_size_ratio = \" + str(best_stitch_pair_size_ratio))\n",
    "\n",
    "        child_meshes_stitch_facets[i] = [best_stitch_pair[0],best_stitch_pair[1]]\n",
    "        child_meshes_stitch_face_ratios[i] = best_stitch_pair_size_ratio\n",
    "        child_meshes_stitch_distances[i] = best_stitch_pair_distance\n",
    "        \n",
    "#         if i == 1:\n",
    "#             print(\"Just processed piece 1\")\n",
    "#             raise Exception(\"stoping\")\n",
    "\n",
    "    \n",
    "#     if 1 in child_meshes_stitch_facets.keys():\n",
    "#         print(\"Just processed piece 1\")\n",
    "#         raise Exception(\"stoping\")\n",
    "    \n",
    "    \n",
    "    #if there were no possible stitch points found\n",
    "    if len(child_meshes_stitch_facets.keys()) == 0:\n",
    "        #increment the no children flag multiplier\n",
    "        \n",
    "        no_new_children_multiplier += 1\n",
    "        print(f\"no stitch points found IN ALL CHILDREN --> relaxing the parameters time {no_new_children_multiplier}\")\n",
    "        continue\n",
    "        \n",
    "    # makes sure that no two child branches try to connect to the same main branch\n",
    "    from collections import Counter\n",
    "    mesh_stitch_counter = Counter(np.array([val for val in child_meshes_stitch_facets.values()])[:,1])\n",
    "\n",
    "    repeat_main_facets = [key for key,val in mesh_stitch_counter.items() if (key != -1 and val > 1)] #gets the main mesh facet with multiples\n",
    "    print(\"repeat_main_facets = \" + str(repeat_main_facets))\n",
    "\n",
    "\n",
    "    #how to fix that some faces are trying to branch to same main facet\n",
    "    #make it iterate through all of the repeats\n",
    "    if len(repeat_main_facets)>0:\n",
    "        for repeat_main in repeat_main_facets:\n",
    "            child_mesh_double_indexes = [key for key,val in child_meshes_stitch_facets.items() if val[1] == repeat_main]\n",
    "            print(\"child_mesh_double_indexes = \" + str(child_mesh_double_indexes))\n",
    "\n",
    "\n",
    "            #decide which one to keep and then ditch all the rest --> pick the CLOSEST ONE, and not the best matching area:\n",
    "\n",
    "            ###### picks the closest area\n",
    "            min_distance = 10000000000\n",
    "            min_child = -1\n",
    "\n",
    "\n",
    "            for child_index in child_mesh_double_indexes:\n",
    "                current_distance = child_meshes_stitch_distances[child_index]\n",
    "\n",
    "                if current_distance < min_distance:\n",
    "                    min_child = child_index\n",
    "                    min_distance = current_distance\n",
    "\n",
    "            print(f\"min_child = {min_child}, max_ratio = {min_distance}\")\n",
    "\n",
    "    #         ###### picks the maximum area\n",
    "    #         max_ratio = -1\n",
    "    #         max_child = -1\n",
    "\n",
    "\n",
    "    #         for child_index in child_mesh_double_indexes:\n",
    "    #             current_ratio = child_meshes_stitch_face_ratios[child_index]\n",
    "\n",
    "    #             if current_ratio > max_ratio:\n",
    "    #                 max_child = child_index\n",
    "    #                 max_ratio = current_ratio\n",
    "\n",
    "    #         print(f\"max_child = {max_child}, max_ratio = {max_ratio}\")\n",
    "\n",
    "\n",
    "\n",
    "            #remove the others from the stitch facets\n",
    "            for double_index in child_mesh_double_indexes:\n",
    "                if double_index != min_child:\n",
    "                    del child_meshes_stitch_facets[double_index]\n",
    "    \n",
    "    \"\"\"\n",
    "    Pseudocode for stitching:\n",
    "    1) For each pair in the child_meshes_stitch_facets:\n",
    "    a. Get the child mesh for that pair\n",
    "    b. Get the list of faces for the child facet (from the facet number)\n",
    "    c. Get the list of faces for the main facet (from the main number)\n",
    "\n",
    "    d. Get the original number of faces and vertices in the main mesh\n",
    "    d2. Use the orignal number of faces and add to list of faces for child facet to offset them correctly\n",
    "        - Save this number list in a dictionary (to use for later and creating the submesh)\n",
    "    e. Add the two meshes together to get big mesh\n",
    "    f. Send the two meshes and the two facet lists to the restitching function to get a main mesh that is stitched up\n",
    "     - but send it to function that doesnt delete the original facet faces \n",
    "         (because this would remove meshes from original and screw up facet number)\n",
    "    g. reassign the main_mesh to this newly stitched up mesh\n",
    "    h. recompute the facets for the main mesh\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    current_main_mesh = main_mesh.copy()\n",
    "    \n",
    "    main_mesh_facet_index_to_delete = []\n",
    "\n",
    "    \n",
    "    #if there were no possible stitch points found\n",
    "    if len(child_meshes_stitch_facets.keys()) == 0:\n",
    "        #increment the no children flag multiplier\n",
    "        \n",
    "        no_new_children_multiplier += 1\n",
    "        print(f\"no stitch points found IN ALL CHILDREN --> relaxing the parameters time {no_new_children_multiplier}\")\n",
    "        continue\n",
    "    else: #if there were stitch points found\n",
    "        print(\"child_meshes_stitch_facets = \" + str(child_meshes_stitch_facets))\n",
    "        for child_key,pair in child_meshes_stitch_facets.items():\n",
    "            \"\"\"\n",
    "            child_key has the child that is currently being processed\n",
    "            \n",
    "            pair has the facet ids that are to be stitched together\n",
    "            \n",
    "            \"\"\"\n",
    "            \n",
    "            child_used_facet_index = pair[0]\n",
    "            main_used_faceet_index = pair[1]\n",
    "            \n",
    "            stitch_time = time.time()\n",
    "            print(f\"---Stitching child {child_key} with pair: {pair}---\")\n",
    "            current_child_mesh = child_meshes[child_key]\n",
    "            current_child_facet_faces = child_meshes_facets[child_key][0][pair[0]]\n",
    "\n",
    "\n",
    "            current_main_mesh_facet_faces = main_mesh_facets[pair[1]]\n",
    "\n",
    "            #Get the original number of faces and vertices in the main mesh\n",
    "            original_mesh_faces_len = len(current_main_mesh.faces)\n",
    "            current_child_facet_faces_adjusted = current_child_facet_faces + original_mesh_faces_len\n",
    "\n",
    "            #Save the faces number for deletion later\n",
    "            child_faces_to_remove += current_child_facet_faces_adjusted.tolist()\n",
    "            main_faces_to_remove += current_main_mesh_facet_faces.tolist()\n",
    "\n",
    "            combined_mesh = current_main_mesh + current_child_mesh\n",
    "\n",
    "            #how to stitch up the mesh\n",
    "            start_time = time.time()\n",
    "            current_main_mesh = stitch_mesh_piece_vp4(new_mesh=combined_mesh,\n",
    "                                                           facet_1=current_main_mesh_facet_faces,\n",
    "                                                           facet_2=current_child_facet_faces_adjusted,\n",
    "                                                          delete_facets=False,\n",
    "                                                          return_added_mesh=False,\n",
    "                                                           fix_normals = False)\n",
    "            \n",
    "            print(f\"returned from stitch mesh: {time.time() - start_time}\")\n",
    "            \n",
    "            \n",
    "            #Don't need to do any deletion now \n",
    "            \n",
    "            #add the child to processed child\n",
    "            children_processed.append(child_key)\n",
    "            print(f\"Finished stitching child {child_key} : {time.time() - stitch_time}\")\n",
    "            \n",
    "            \"\"\"\n",
    "            Add all of the child facets that weren't the ones used to the main mesh facets (with adjusted facet numbers)\n",
    "            \"\"\"\n",
    "            original_mesh_faces_len #the original number of faces in the main mesh (including all those stitched before)\n",
    "            \n",
    "            #remove certian rows from array of the child facets and cetners\n",
    "            current_child_facet_faces_with_deletion = np.delete(child_meshes_facets[child_key][0],(child_used_facet_index),axis=0)\n",
    "            current_child_facet_centers_with_deletion = np.delete(child_meshes_facets[child_key][1],(child_used_facet_index),axis=0)\n",
    "\n",
    "            #have to adjust the faces of the child_facets list to account for the faces off set\n",
    "            current_child_facet_faces_with_deletion = current_child_facet_faces_with_deletion + original_mesh_faces_len\n",
    "\n",
    "            #append this list to the main mesh list\n",
    "            main_mesh_facets = np.concatenate([main_mesh_facets,current_child_facet_faces_with_deletion])\n",
    "            main_mesh_facets_centers = np.concatenate([main_mesh_facets_centers,current_child_facet_centers_with_deletion])\n",
    "\n",
    "            #save off the facets to delete for the main mesh at the end of the loop\n",
    "            main_mesh_facet_index_to_delete.append(pair[1])\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        #reset the no_new_children_multiplier because there were successful stitching\n",
    "        no_new_children_multiplier = 0\n",
    "        \"\"\"recompute the main mesh facets  ###Not going to recompute anymore\n",
    "        #main_mesh_facets,main_mesh_facets_centers = filter_final_facets(main_mesh)\n",
    "        \n",
    "        Now we just remove the main mesh facets that are used and reassign\n",
    "        \"\"\"\n",
    "        main_mesh = current_main_mesh\n",
    "    \n",
    "    \n",
    "        #at the end of the big loop have to delete the facets used from main mesh\n",
    "        #remove certian rows from array\n",
    "        \n",
    "        #creating the new facets\n",
    "        main_mesh_facets = np.delete(main_mesh_facets,(main_mesh_facet_index_to_delete),axis=0)\n",
    "        main_mesh_facets_centers = np.delete(main_mesh_facets_centers,(main_mesh_facet_index_to_delete),axis=0)\n",
    "\n",
    "        \n",
    "        print(f\"***************Finished big stitching iteration: {time.time() - stitch_loop_time}***************\")\n",
    "        \n",
    "#         if 0 in children_processed and 1 in children_processed:\n",
    "#             print(\"Exiting before does piece 2\")\n",
    "#             break\n",
    "\n",
    "        if len(np.unique(children_processed)) == len(child_meshes):\n",
    "            print(\"All children have been processed\")\n",
    "            break\n",
    "    \n",
    "\n",
    "#children  that weren't attached:\n",
    "non_attached = [10,14,15,19,20,21,22,25,28,29,30,33,42,44,45,46,47,48,50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now to extract the full mesh after it's done so don't screw up all the facets numbers:\n",
    "\n",
    "\n",
    "#remove all of the processed facets from the main mesh\n",
    "#now take away the original facet faces:\n",
    "total_faces = np.linspace(0,len(main_mesh.faces)-1,len(main_mesh.faces)).astype(\"int\")\n",
    "\n",
    "\n",
    "#these are the faces that need to be removed\n",
    "facet_faces = np.hstack([child_faces_to_remove ,main_faces_to_remove])\n",
    "faces_to_keep = set(total_faces).difference(set(facet_faces))\n",
    "\n",
    "\n",
    "main_mesh = main_mesh.submesh([list(faces_to_keep)])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from print_trimesh import print_trimesh\n",
    "\n",
    "print_trimesh(main_mesh,\"./test_meshes/\" + str(neuron_id) +\"entire_neuron_facets_optimized_v11.off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total time for restitching = {time.time() - restitch_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
