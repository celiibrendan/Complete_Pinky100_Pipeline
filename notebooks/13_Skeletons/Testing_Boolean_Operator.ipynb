{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import time\n",
    "import pymeshfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### would have to install pymesh and might take a little too much #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@10.28.0.34:3306\n"
     ]
    }
   ],
   "source": [
    "#setting the address and the username\n",
    "dj.config['database.host'] = '10.28.0.34'\n",
    "dj.config['database.user'] = 'celiib'\n",
    "dj.config['database.password'] = 'newceliipass'\n",
    "dj.config['safemode']=True\n",
    "dj.config[\"display.limit\"] = 20\n",
    "\n",
    "schema = dj.schema('microns_ta3p100')\n",
    "ta3p100 = dj.create_virtual_module('ta3p100', 'microns_ta3p100')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(2, 648518346341393609, Decimal('0.35'), 466615, 931294, array([[203098.765625  , 201025.015625  ,  11656.66015625],\n",
       "       [203106.015625  , 201024.625     ,  11581.84375   ],\n",
       "       [203141.9375    , 200947.84375   ,  11581.54101562],\n",
       "       ...,\n",
       "       [462651.5625    , 246667.09375   ,  63784.89453125],\n",
       "       [462678.15625   , 246518.0625    ,  63816.5234375 ],\n",
       "       [462718.6875    , 246634.125     ,  63846.13671875]]), array([[197667, 197827, 197212],\n",
       "       [199865, 199228, 200170],\n",
       "       [198980, 199087, 198398],\n",
       "       ...,\n",
       "       [407010, 407536, 406918],\n",
       "       [408254, 408111, 408374],\n",
       "       [408111, 408269, 408374]], dtype=uint32))],\n",
       "      dtype=[('segmentation', '<i8'), ('segment_id', '<i8'), ('decimation_ratio', 'O'), ('n_vertices', '<i8'), ('n_triangles', '<i8'), ('vertices', 'O'), ('triangles', 'O')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_id = 648518346341393609\n",
    "dict_key = dict(segmentation=2,segment_id=segment_id)\n",
    "mesh = (ta3p100.CleansedMesh & dict_key).fetch()\n",
    "mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[199865, 199228, 200170],\n",
       "       [198980, 199087, 198398],\n",
       "       [198980, 198398, 198770],\n",
       "       [198980, 198770, 198708],\n",
       "       [197831, 197022, 197606]], dtype=uint32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_triangles = mesh[\"triangles\"][0]\n",
    "original_triangles[[1,2,3,4,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(2, 648518346341393609, Decimal('0.35'), 'computer_Auto', 'bcelii', datetime.datetime(2019, 2, 1, 12, 39, 11), array([10, 10, 10, ..., 10, 10, 10], dtype=uint8), array([10, 10, 10, ...,  3,  3,  3], dtype=uint8))],\n",
       "      dtype=[('segmentation', '<i8'), ('segment_id', '<i8'), ('decimation_ratio', 'O'), ('author_original', 'O'), ('author_proofreader', 'O'), ('date_time', 'O'), ('vertices', 'O'), ('triangles', 'O')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the labels\n",
    "mesh_labels = (ta3p100.CoarseLabelFinal & dict_key).fetch()\n",
    "\n",
    "mesh_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <b>Vertex labels for ta3p100.ProofreadLabel did not correctly match the triangle labels, so these are regenerated from the correct triangle labels.</b>\n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">segmentation</p>\n",
       "                                <span class=\"djtooltiptext\">segmentation id</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">segment_id</p>\n",
       "                                <span class=\"djtooltiptext\">segment id unique within each Segmentation</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">decimation_ratio</p>\n",
       "                                <span class=\"djtooltiptext\"></span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">author_original</p>\n",
       "                                <span class=\"djtooltiptext\">name of last editor</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">author_proofreader</p>\n",
       "                                <span class=\"djtooltiptext\">name of last editor</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">date_time</p>\n",
       "                                <span class=\"djtooltiptext\">the last time it was edited</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">vertices</p>\n",
       "                                <span class=\"djtooltiptext\">Corrected vertex labels</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">triangles</p>\n",
       "                                <span class=\"djtooltiptext\">Same triangle labels as ta3p100.ProofreadLabel</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr> <td>2</td>\n",
       "<td>648518346341393609</td>\n",
       "<td>0.35</td>\n",
       "<td>computer_Auto</td>\n",
       "<td>bcelii</td>\n",
       "<td>2019-02-01 12:39:11</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>=BLOB=</td> </tr> </tbody>\n",
       "            </table>\n",
       "            \n",
       "            <p>1 tuples</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*segmentation  *segment_id    *decimation_ra *author_origin *author_proofr *date_time     vertices   triangles \n",
       "+------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +--------+ +--------+\n",
       "2              64851834634139 0.35           computer_Auto  bcelii         2019-02-01 12: =BLOB=     =BLOB=    \n",
       " (1 tuples)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_key = dict(segmentation=2,segment_id=segment_id)\n",
    "ta3p100.CoarseLabelFinal() & dict_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "651958\n"
     ]
    }
   ],
   "source": [
    "#look for errors\n",
    "not_errors = [k for k in mesh_labels[\"triangles\"][0] if k != 10]\n",
    "print(len(not_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(original_triangles[not_errors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see if has any error labels\n",
    "traingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta3p100.CoarseLabelFinal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_neighborhood(self, triangles, num_vertices):\n",
    "    neighborhood = dict()\n",
    "    for i in range(num_vertices):\n",
    "        neighborhood[i] = set()\n",
    "    for node1, node2, node3 in triangles:\n",
    "        neighborhood[node1].update([node2, node3])\n",
    "        neighborhood[node2].update([node1, node3])\n",
    "        neighborhood[node3].update([node1, node2])\n",
    "    return neighborhood\n",
    "\n",
    "def set_search_first(self, starting_node, neighborhood):\n",
    "    \"\"\"\n",
    "    Modified Depth-First-Search utilizing sets to reduce duplicate checks:\n",
    "\n",
    "    Neighborhood must be a dict with the keys being the vertex indices!\n",
    "    \"\"\"    \n",
    "    visited_nodes = set()\n",
    "    temp_stack = set()\n",
    "    temp_stack.add(starting_node)\n",
    "    while len(temp_stack) > 0:\n",
    "        starting_node = temp_stack.pop()\n",
    "        if starting_node not in visited_nodes:\n",
    "            visited_nodes.add(starting_node)\n",
    "            temp_stack.update(neighborhood[starting_node])\n",
    "    return list(visited_nodes)\n",
    "\n",
    "def get_connected_portions(self, neighborhood):\n",
    "    neighborhood_copy = neighborhood.copy()\n",
    "    portions = []\n",
    "    while len(neighborhood_copy) > 0:\n",
    "        starting_node = next(iter(neighborhood_copy))\n",
    "        portion = self.set_search_first(starting_node, neighborhood_copy)\n",
    "        for node in portion:\n",
    "            neighborhood_copy.pop(node)\n",
    "        portions.append(portion)\n",
    "    return portions\n",
    "\n",
    "def get_largest_portion_index(self, portions):\n",
    "    portion_lengths = [len(portion) for portion in portions]\n",
    "    return portion_lengths.index(max(portion_lengths))\n",
    "\n",
    "def get_largest_portion(self, portions):\n",
    "    return portions[self.get_largest_portion_index(portions)]\n",
    "\n",
    "def remove_floating_artifacts(self, mesh):    \n",
    "    mesh_copy = mesh.copy()\n",
    "\n",
    "    \"\"\"\n",
    "    # Generating the neighborhoods gets quite expensive for full resolution meshes, but the searches are extremely quick.\n",
    "    neighborhood = self.generate_neighborhood(mesh_copy['triangles'], len(mesh_copy['vertices']))\n",
    "    portions = self.get_connected_portions(neighborhood)\n",
    "\n",
    "    main_mesh_body_index = self.get_largest_portion_index(portions)\n",
    "    triangle_removal_nodes = portions[main_mesh_body_index:] + portions[:main_mesh_body_index + 1]\n",
    "\n",
    "    new_triangles = []\n",
    "    main_body_portion = set(self.get_largest_portion(portions))\n",
    "    for i, triangle in enumerate(mesh_copy['triangles']):\n",
    "        node1 = triangle[0]\n",
    "        if node1 in main_body_portion:\n",
    "            new_triangles.append(triangle)\n",
    "    mesh_copy['triangles'] = np.array(new_triangles)\"\"\"\n",
    "    \n",
    "    #get the triangle indices:\n",
    "    \n",
    "    #get the labels\n",
    "    mesh_labels = (ta3p100.CoarseLabelFinal & dict_key).fetch()\n",
    "    \n",
    "    #look for errors\n",
    "    not_errors = [k for k in mesh_labels[\"triangles\"][0] if k != 10]\n",
    "    \n",
    "    original_triangles = mesh[triangles][0]\n",
    "    \n",
    "    print(type(not_errors))\n",
    "    print(len(not_errors))\n",
    "    print(not_errors)\n",
    "    print(type(original_triangles))\n",
    "    print(len(original_triangles))\n",
    "    print(original_triangles)\n",
    "    \n",
    "    mesh_copy['triangles'] = np.array(original_triangles[not_errors])\n",
    "    \n",
    "\n",
    "    return mesh_copy\n",
    "\n",
    "\n",
    "def remove_isolated_vertices(self, mesh):\n",
    "    mesh_copy = mesh.copy()\n",
    "\n",
    "    neighborhood = self.generate_neighborhood(mesh_copy['triangles'], len(mesh_copy['vertices']))\n",
    "    isolated_nodes = [portion.pop() for portion in self.get_connected_portions(neighborhood) if len(portion) == 1]\n",
    "\n",
    "    vertices = mesh_copy['vertices']\n",
    "    triangles = mesh_copy['triangles']\n",
    "    vertex_list = list(vertices)\n",
    "\n",
    "    if len(isolated_nodes) > 0:\n",
    "        num_isolated_nodes_passed = 0\n",
    "        isolated_nodes_set = set(isolated_nodes)\n",
    "        count_to_decrement = np.zeros(len(vertices))\n",
    "        for i in range(len(vertices)):\n",
    "            if i in isolated_nodes_set:\n",
    "                num_isolated_nodes_passed += 1\n",
    "            else:\n",
    "                count_to_decrement[i] = num_isolated_nodes_passed\n",
    "\n",
    "        for i, triangle in enumerate(triangles):\n",
    "            start = time.time()\n",
    "            node1, node2, node3 = triangle\n",
    "            triangles[i][0] -= count_to_decrement[node1]\n",
    "            triangles[i][1] -= count_to_decrement[node2]\n",
    "            triangles[i][2] -= count_to_decrement[node3]\n",
    "        for i, isolated_node in enumerate(isolated_nodes):\n",
    "            vertex_list.pop(isolated_node - i)\n",
    "\n",
    "    mesh_copy['vertices'] = np.array(vertex_list)\n",
    "\n",
    "    return mesh_copy\n",
    "\n",
    "\n",
    "def remove_error_segments(self, key):\n",
    "    full_start = time.time()\n",
    "\n",
    "    print(key['segment_id'], key['decimation_ratio'], \":\")\n",
    "    start = time.time()\n",
    "\n",
    "    mesh = (ta3p100.DecimationOrphan & key).fetch1()\n",
    "    print(key['segment_id'], \"mesh fetched.\", time.time() - start)\n",
    "    start = time.time()\n",
    "\n",
    "    neighborhood = self.generate_neighborhood(mesh['triangles'], len(mesh['vertices']))\n",
    "    print(key['segment_id'] , \"neighborhood generated.\", time.time() - start)\n",
    "    start = time.time()\n",
    "\n",
    "    mesh = self.remove_floating_artifacts(mesh)\n",
    "    print(key['segment_id'], \"floating artifacts removed.\", time.time() - start)\n",
    "    start = time.time()\n",
    "\n",
    "    mesh = self.remove_isolated_vertices(mesh)\n",
    "    print(key['segment_id'], \"isolated nodes removed.\", time.time() - start)\n",
    "    start = time.time()\n",
    "\n",
    "    key['n_vertices'] = len(mesh['vertices'])\n",
    "    key['n_triangles'] = len(mesh['triangles'])\n",
    "    key['vertices'] = mesh['vertices']\n",
    "    key['triangles'] = mesh['triangles']\n",
    "\n",
    "    self.insert1(key, skip_duplicates=True)\n",
    "    print(key['segment_id'], \"key successfully inserted.\", time.time() - start)\n",
    "    start = time.time()\n",
    "\n",
    "    print(\"This took \", time.time() - full_start, \"seconds.\")\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_neighborhood(triangles, num_vertices):\n",
    "    neighborhood = dict()\n",
    "    for i in range(num_vertices):\n",
    "        neighborhood[i] = set()\n",
    "    for node1, node2, node3 in triangles:\n",
    "        neighborhood[node1].update([node2, node3])\n",
    "        neighborhood[node2].update([node1, node3])\n",
    "        neighborhood[node3].update([node1, node2])\n",
    "    return neighborhood\n",
    "\n",
    "def set_search_first(starting_node, neighborhood):\n",
    "    \"\"\"\n",
    "    Modified Depth-First-Search utilizing sets to reduce duplicate checks:\n",
    "\n",
    "    Neighborhood must be a dict with the keys being the vertex indices!\n",
    "    \"\"\"    \n",
    "    visited_nodes = set()\n",
    "    temp_stack = set()\n",
    "    temp_stack.add(starting_node)\n",
    "    while len(temp_stack) > 0:\n",
    "        starting_node = temp_stack.pop()\n",
    "        if starting_node not in visited_nodes:\n",
    "            visited_nodes.add(starting_node)\n",
    "            temp_stack.update(neighborhood[starting_node])\n",
    "    return list(visited_nodes)\n",
    "\n",
    "def get_connected_portions(neighborhood):\n",
    "    neighborhood_copy = neighborhood.copy()\n",
    "    portions = []\n",
    "    while len(neighborhood_copy) > 0:\n",
    "        starting_node = next(iter(neighborhood_copy))\n",
    "        portion = set_search_first(starting_node, neighborhood_copy)\n",
    "        for node in portion:\n",
    "            neighborhood_copy.pop(node)\n",
    "        portions.append(portion)\n",
    "    return portions\n",
    "\n",
    "def get_largest_portion_index(portions):\n",
    "    portion_lengths = [len(portion) for portion in portions]\n",
    "    return portion_lengths.index(max(portion_lengths))\n",
    "\n",
    "def get_largest_portion(portions):\n",
    "    return portions[get_largest_portion_index(portions)]\n",
    "\n",
    "def remove_floating_artifacts(mesh):    \n",
    "    mesh_copy = mesh.copy()\n",
    "\n",
    "    \"\"\"\n",
    "    # Generating the neighborhoods gets quite expensive for full resolution meshes, but the searches are extremely quick.\n",
    "    neighborhood = self.generate_neighborhood(mesh_copy['triangles'], len(mesh_copy['vertices']))\n",
    "    portions = self.get_connected_portions(neighborhood)\n",
    "\n",
    "    main_mesh_body_index = self.get_largest_portion_index(portions)\n",
    "    triangle_removal_nodes = portions[main_mesh_body_index:] + portions[:main_mesh_body_index + 1]\n",
    "\n",
    "    new_triangles = []\n",
    "    main_body_portion = set(self.get_largest_portion(portions))\n",
    "    for i, triangle in enumerate(mesh_copy['triangles']):\n",
    "        node1 = triangle[0]\n",
    "        if node1 in main_body_portion:\n",
    "            new_triangles.append(triangle)\n",
    "    mesh_copy['triangles'] = np.array(new_triangles)\"\"\"\n",
    "    \n",
    "    #get the triangle indices:\n",
    "    \n",
    "    #get the labels\n",
    "    mesh_labels = (ta3p100.CoarseLabelFinal & dict_key).fetch1()\n",
    "    \n",
    "    #look for errors\n",
    "    not_errors = [i for i,k in enumerate(mesh_labels[\"triangles\"]) if k != 10]\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(type(not_errors))\n",
    "    print(len(not_errors))\n",
    "    print(\"not_errors = \"+ str(not_errors[:100]))\n",
    "    original_triangles = mesh[\"triangles\"]\n",
    "    print(type(original_triangles))\n",
    "    print(len(original_triangles))\n",
    "    #print(original_triangles)\n",
    "    print(\"not_errors = \" + str(original_triangles[not_errors]))\n",
    "    \n",
    "    mesh_copy['triangles'] = np.array(original_triangles[not_errors])\n",
    "    \n",
    "    print(\"mesh_copy[Triangles]=\" + str(mesh_copy['triangles'][:100]))\n",
    "    print(\"mesh_copy[Triangles]=\" + str(len(mesh_copy['triangles'])))\n",
    "    \n",
    "    return mesh_copy\n",
    "\n",
    "\n",
    "def remove_isolated_vertices(mesh):\n",
    "    mesh_copy = mesh.copy()\n",
    "\n",
    "    neighborhood = generate_neighborhood(mesh_copy['triangles'], len(mesh_copy['vertices']))\n",
    "    isolated_nodes = [portion.pop() for portion in get_connected_portions(neighborhood) if len(portion) == 1]\n",
    "\n",
    "    vertices = mesh_copy['vertices']\n",
    "    triangles = mesh_copy['triangles']\n",
    "    vertex_list = list(vertices)\n",
    "\n",
    "    if len(isolated_nodes) > 0:\n",
    "        num_isolated_nodes_passed = 0\n",
    "        isolated_nodes_set = set(isolated_nodes)\n",
    "        count_to_decrement = np.zeros(len(vertices))\n",
    "        for i in range(len(vertices)):\n",
    "            if i in isolated_nodes_set:\n",
    "                num_isolated_nodes_passed += 1\n",
    "            else:\n",
    "                count_to_decrement[i] = num_isolated_nodes_passed\n",
    "\n",
    "        for i, triangle in enumerate(triangles):\n",
    "            start = time.time()\n",
    "            node1, node2, node3 = triangle\n",
    "            triangles[i][0] -= count_to_decrement[node1]\n",
    "            triangles[i][1] -= count_to_decrement[node2]\n",
    "            triangles[i][2] -= count_to_decrement[node3]\n",
    "        for i, isolated_node in enumerate(isolated_nodes):\n",
    "            vertex_list.pop(isolated_node - i)\n",
    "\n",
    "    mesh_copy['vertices'] = np.array(vertex_list)\n",
    "\n",
    "    return mesh_copy\n",
    "\n",
    "\n",
    "def remove_error_segments(key):\n",
    "    full_start = time.time()\n",
    "\n",
    "    print(key['segment_id'], key['decimation_ratio'], \":\")\n",
    "    start = time.time()\n",
    "\n",
    "    mesh = (ta3p100.CleansedMesh & key).fetch1()\n",
    "    print(key['segment_id'], \"mesh fetched.\", time.time() - start)\n",
    "    start = time.time()\n",
    "\n",
    "    original_triangles = mesh[\"triangles\"]\n",
    "    print(type(original_triangles))\n",
    "    print(len(original_triangles))\n",
    "    \n",
    "    neighborhood = generate_neighborhood(mesh['triangles'], len(mesh['vertices']))\n",
    "    print(key['segment_id'] , \"neighborhood generated.\", time.time() - start)\n",
    "    start = time.time()\n",
    "\n",
    "    original_triangles = mesh[\"triangles\"]\n",
    "    print(type(original_triangles))\n",
    "    print(len(original_triangles))\n",
    "    \n",
    "    mesh = remove_floating_artifacts(mesh)\n",
    "    print(key['segment_id'], \"floating artifacts removed.\", time.time() - start)\n",
    "    start = time.time()\n",
    "\n",
    "    mesh = remove_isolated_vertices(mesh)\n",
    "    print(key['segment_id'], \"isolated nodes removed.\", time.time() - start)\n",
    "    start = time.time()\n",
    "\n",
    "    key['n_vertices'] = len(mesh['vertices'])\n",
    "    key['n_triangles'] = len(mesh['triangles'])\n",
    "    key['vertices'] = mesh['vertices']\n",
    "    key['triangles'] = mesh['triangles']\n",
    "\n",
    "    #self.insert1(key, skip_duplicates=True)\n",
    "    print(key['segment_id'], \"key successfully inserted.\", time.time() - start)\n",
    "    start = time.time()\n",
    "\n",
    "    print(\"This took \", time.time() - full_start, \"seconds.\")\n",
    "    print()\n",
    "    return key\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_id = 648518346341393609\n",
    "dict_key = dict(segmentation=2,segment_id=segment_id,decimation_ratio=0.35)\n",
    "new_key = remove_error_segments(dict_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_Whole_Neuron_Off_file(new_key[\"segment_id\"],new_key[\"vertices\"],new_key[\"triangles\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the output file\n",
    "##write the OFF file for the neuron\n",
    "import pathlib\n",
    "def write_Whole_Neuron_Off_file(neuron_ID,vertices=[], triangles=[]):\n",
    "    #primary_key = dict(segmentation=1, segment_id=segment_id, decimation_ratio=0.35)\n",
    "    #vertices, triangles = (mesh_Table_35 & primary_key).fetch1('vertices', 'triangles')\n",
    "    \n",
    "    num_vertices = (len(vertices))\n",
    "    num_faces = len(triangles)\n",
    "    \n",
    "    #get the current file location\n",
    "    file_loc = pathlib.Path.cwd() / \"temp\"\n",
    "    filename = \"neuron_\" + str(neuron_ID)\n",
    "    path_and_filename = file_loc / filename\n",
    "    \n",
    "    #print(file_loc)\n",
    "    #print(path_and_filename)\n",
    "    \n",
    "    #open the file and start writing to it    \n",
    "    f = open(str(path_and_filename) + \".off\", \"w\")\n",
    "    f.write(\"OFF\\n\")\n",
    "    f.write(str(num_vertices) + \" \" + str(num_faces) + \" 0\\n\" )\n",
    "    \n",
    "    \n",
    "    #iterate through and write all of the vertices in the file\n",
    "    for verts in vertices:\n",
    "        f.write(str(verts[0]) + \" \" + str(verts[1]) + \" \" + str(verts[2])+\"\\n\")\n",
    "    \n",
    "    #print(\"Done writing verts\")\n",
    "        \n",
    "    for faces in triangles:\n",
    "        f.write(\"3 \" + str(faces[0]) + \" \" + str(faces[1]) + \" \" + str(faces[2])+\"\\n\")\n",
    "    \n",
    "    print(\"Done writing OFF file\")\n",
    "    #f.write(\"end\")\n",
    "    \n",
    "    return str(path_and_filename),str(filename),str(file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find a suitable neurite for our neuron\n",
    "synapse_dict = dict(segmentation=2,postsyn=dict_key[\"segment_id\"])\n",
    "ta3p100.Synapse() & synapse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta3p100.CoarseLabelFinal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(ta3p100.Synapse() & synapse_dict).aggr\n",
    "new_seg = 648518346341393609\n",
    "synapse_dict = dict(segmentation=2,postsyn=new_seg)\n",
    "\n",
    "synapse_tables = dj.U('segmentation','presyn').aggr((ta3p100.Synapse() & synapse_dict), \n",
    "                    num_synapses='sum(postsyn = ' + str(new_seg)+ ')')\n",
    "synapse_tables & \"num_synapses>4\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_seg = 648518346349472574 #none\n",
    "new_seg = 648518346349471562 #has like 5\n",
    "synapse_dict = dict(segmentation=2,postsyn=new_seg)\n",
    "\n",
    "synapse_tables = dj.U('segmentation','presyn').aggr((ta3p100.Synapse() & synapse_dict), \n",
    "                    num_synapses='sum(postsyn = ' + str(new_seg)+ ')')\n",
    "presyn, num_synapses =(synapse_tables & \"num_synapses>4\").fetch(\"presyn\",\"num_synapses\")\n",
    "print(presyn)\n",
    "\n",
    "#find the maximum\n",
    "np.argmax(num_synapses)\n",
    "#max(num_synapses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the highest synapsing one:\n",
    "\n",
    "#get the synapses from CoarseLabel\n",
    "coarse_ids = ta3p100.CoarseLabelFinal.fetch(\"segment_id\")\n",
    "\n",
    "for id in coarse_ids:\n",
    "    #get the table that corresponds to that id\n",
    "    #(ta3p100.Synapse() & synapse_dict).aggr\n",
    "    new_seg = id\n",
    "    synapse_dict = dict(segmentation=2,postsyn=new_seg)\n",
    "\n",
    "    synapse_tables = dj.U('segmentation','presyn').aggr((ta3p100.Synapse() & synapse_dict), \n",
    "                        num_synapses='sum(postsyn = ' + str(new_seg)+ ')')\n",
    "    (synapse_tables & \"num_synapses>10\").fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta3p100.Neurite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta3p100.PairVoxelDist() & \"segment_a=648518346349473597\" & 'nearest_dist < 50' & ta3p100.CoarseLabelFinal.proj(segment_id=\"segment_b\") & ta3p100.Neurite.proj(segment_id=\"segment_b\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#possible ones:\n",
    "\"\"\"\n",
    "presyn           postsyn           num\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the mesh of the neurite\n",
    "axon_mesh = (ta3p100.Mesh & \"segment_id=648518346349507130\" & \"segmentation=2\").fetch1()\n",
    "print(axon_mesh[\"n_vertices\"])\n",
    "\n",
    "\n",
    "\n",
    "#get the off file\n",
    "write_Whole_Neuron_Off_file(\"axon\" + str(axon_mesh[\"segment_id\"]),axon_mesh[\"vertices\"],axon_mesh[\"triangles\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(ta3p100.Synapse() & synapse_dict).aggr\n",
    "segment_id=648518346349471910\n",
    "synapse_dict = dict(segmentation=2,postsyn=dict_key[\"segment_id\"])\n",
    "\n",
    "\n",
    "synapse_tables = dj.U('segmentation','presyn').aggr((ta3p100.Synapse() & synapse_dict), \n",
    "                    num_synapses='sum(postsyn = ' + str(segment_id)')')\n",
    "synapse_tables & \"num_synapses>4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the skeleton for 1) axon 648518346349507130 and 2) target 648518346341393609.\n",
    "import pymeshfix\n",
    "dir(pymeshfix.MeshFix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get 648518346341393609\n",
    "\n",
    "meshfix = pymeshfix.MeshFix(new_key[\"vertices\"],new_key[\"triangles\"])\n",
    "meshfix.repair(verbose=False,joincomp=True,remove_smallest_components=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meshfix.write(\"temp/648518346341393609_fixed.off\")\n",
    "#dir(meshfix.write)\n",
    "write_Whole_Neuron_Off_file(\"target_\" + str(648518346341393609),meshfix.v,meshfix.f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the axon\n",
    "\n",
    "seg_id = \"648518346349507130\"\n",
    "axon_data = (ta3p100.Mesh & \"segment_id=\" + str(seg_id) & \"segmentation=2\").fetch1()\n",
    "print(len(axon_data[\"triangles\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meshfix_axon = pymeshfix.MeshFix(axon_data[\"vertices\"],axon_data[\"triangles\"])\n",
    "meshfix_axon.repair(verbose=False,joincomp=True,remove_smallest_components=False)\n",
    "\n",
    "write_Whole_Neuron_Off_file(\"axon_\" + str(seg_id),meshfix_axon.v,meshfix_axon.f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the skeletons for each of the targets\n",
    "\n",
    "import calcification_Module as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.calcification(\"temp/neuron_axon_648518346349507130\")\n",
    "cm.calcification(\"temp/neuron_target_648518346341393609\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meshparty import trimesh_io\n",
    "mesh = trimesh_io.Mesh(vertices=axon_data[\"vertices\"], faces=axon_data[\"triangles\"])\n",
    "voxels = mesh.voxelized(1500)\n",
    "voxel_mesh = voxels.as_boxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_mesh.export(\"temp/neuron_axon_vox_648518346349507130.off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymeshfix\n",
    "meshfix_axon = pymeshfix.MeshFix(voxel_mesh.vertices,voxel_mesh.faces)\n",
    "meshfix_axon.repair(verbose=False,joincomp=True,remove_smallest_components=False)\n",
    "\n",
    "write_Whole_Neuron_Off_file(\"axon_vox_pym_\" + str(seg_id),meshfix_axon.v,meshfix_axon.f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.calcification(\"temp/neur_ax_vox_meshlabserver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
