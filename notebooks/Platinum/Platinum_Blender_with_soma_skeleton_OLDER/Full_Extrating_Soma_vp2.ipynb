{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Testing out the full soma extraction\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cgal_Segmentation_Module as csm\n",
    "from whole_neuron_classifier_datajoint_adapted import extract_branches_whole_neuron\n",
    "import time\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import datajoint as dj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@10.28.0.34:3306\n"
     ]
    }
   ],
   "source": [
    "m65 = dj.create_virtual_module('m65', 'microns_minnie65_01')\n",
    "schema = dj.schema(\"microns_minnie65_01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_id = 107816118160698192\n",
    "version = 0\n",
    "key = dict(segment_id=segment_id, version = version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Entire Mesh Processed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all the meshes into one mesh\n",
    "def add_mesh_piece(main_mesh_vertices,main_mesh_faces,sub_mesh_vertices,sub_mesh_faces):\n",
    "    \"\"\"\n",
    "    Purpose: Takes in a large mesh piece and an array of other meshes and \n",
    "    returns a large mesh with all meshes appended\n",
    "    \n",
    "    Parameters:\n",
    "    main_mesh_vertices (np.array) : np array store the vertices as rows and the elements as the coordinates\n",
    "    main_mesh_faces (np.array) : np array store the faces as rows and the elements as the referenced vertices\n",
    "    sub_mesh_vertices(list of np.arrays) : list of np arrays with the vertices arrays for all subsegments to be added\n",
    "    sub_mesh_faces(list of np.arrays) : list of np arrays with the faces arrays for all subsegments to be added\n",
    "    \n",
    "    Returns:\n",
    "    mesh_vertices (np.array) : np array store the vertices as rows and the elements as the coordinates for NEW CONCATENATED MESH\n",
    "    mesh_faces (np.array) : np array store the faces as rows and the elements as the referenced vertices for NEW CONCATENATED MESH\n",
    "    \n",
    "    \n",
    "    Pseudocode: \n",
    "    - Checks: \n",
    "    a. Make sure there sub_mesh arrays are greater than 0 and of the same length\n",
    "\n",
    "    1) Count the number of vertices and faces in the main mesh\n",
    "    2) Iterate through the submesh vertices and faces. In loop:\n",
    "    a. Count the number of vertices in the submesh and concate the vertices arrays to the main mesh array\n",
    "    b. Add the vertices_count and add that to every number in the faces array\n",
    "    c. Concatenate the submesh faces onto the larger mesh face\n",
    "    d. Save this new vertices and faces as the main_mesh verts and faces\n",
    "    e. Print out how many new vertices and faces added\n",
    "    3) Print out number of segments added, total faces/vertices for new mesh\n",
    "    4) Return the main mesh vertices and faces\n",
    "    \n",
    "    \"\"\"\n",
    "    #a. Make sure there sub_mesh arrays are greater than 0 and of the same length\n",
    "    if len(sub_mesh_vertices) <= 0:\n",
    "        print(\"There were no vertices in submesh to add, returning main mesh\")\n",
    "        return main_mesh_vertices, main_mesh_faces\n",
    "    if len(sub_mesh_faces) <= 0:\n",
    "        print(\"There were no face in submesh to add, returning main mesh\")\n",
    "        return main_mesh_vertices, main_mesh_faces\n",
    "    if len(sub_mesh_faces) != len(sub_mesh_vertices):\n",
    "        raise Exception(\"The sub_mesh_faces and sub_mesh_vertices length did not match\")\n",
    "        \n",
    "    \n",
    "    #1) Count the number of vertices and faces in the main mesh\n",
    "    n_main_vertices = len(main_mesh_vertices)\n",
    "    n_main_faces = len(main_mesh_faces)\n",
    "    \n",
    "    \n",
    "    #2) Iterate through the submesh vertices and faces. In loop:\n",
    "    for i,(sub_verts, sub_faces) in enumerate(zip(sub_mesh_vertices,sub_mesh_faces)):\n",
    "        #a. Count the number of vertices in the submesh and concate the vertices arrays to the main mesh array\n",
    "        n_sub_verts = len(sub_verts)\n",
    "        n_sub_faces = len(sub_faces)\n",
    "        \n",
    "        main_mesh_vertices = np.vstack([main_mesh_vertices,sub_verts])\n",
    "\n",
    "        \n",
    "        #b. Add the vertices_count of main to every number in the faces array\n",
    "        sub_faces = sub_faces + n_main_vertices\n",
    "        \n",
    "        #c. Concatenate the submesh faces onto the larger mesh face\n",
    "        main_mesh_faces = np.vstack([main_mesh_faces,sub_faces])\n",
    "        \n",
    "        #d. Save this new vertices and faces as the main_mesh verts and faces (DONE)\n",
    "        \n",
    "        #e. Print out how many new vertices and faces added\n",
    "        #print(f\"Added subsegment {i} with {n_sub_verts} vertices and {n_sub_faces} faces\")\n",
    "        \n",
    "        n_main_vertices = len(main_mesh_vertices)\n",
    "        n_main_faces = len(main_mesh_faces)\n",
    "    \n",
    "    #3) Print out number of segments added, total faces/vertices for new mesh  \n",
    "    print(f\"Added {len(sub_mesh_vertices)} subsegements \\n  --> final mesh: {len(main_mesh_vertices)} vertices and {len(main_mesh_faces)} faces\")\n",
    "        \n",
    "    return main_mesh_vertices,main_mesh_faces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = (m65.FromNeuromancer & key).fetch1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Main Neuron ---\n",
      "107816118160698192\n",
      "937779\n",
      "[[1219061.75     459752.59375  865277.5    ]\n",
      " [1218984.5      459845.03125  865190.25   ]\n",
      " [1219070.       459819.375    865243.25   ]\n",
      " ...\n",
      " [1360432.       734720.       787360.     ]\n",
      " [1360528.       734784.       787360.     ]\n",
      " [1360640.       734832.       787360.     ]]\n",
      "[[     0      2      1]\n",
      " [     0      1      3]\n",
      " [     0      3      4]\n",
      " ...\n",
      " [937729 937765 937778]\n",
      " [937729 937778 937758]\n",
      " [937712 937711 937767]]\n"
     ]
    }
   ],
   "source": [
    "print(\"---Main Neuron ---\")\n",
    "print(n[\"segment_id\"])\n",
    "print(n[\"n_vertices\"])\n",
    "print(n[\"vertices\"])\n",
    "print(n[\"faces\"])\n",
    "\n",
    "#get all of the segments and their data\n",
    "lookup_key = dict(segment_id=n[\"segment_id\"],version = n[\"version\"])\n",
    "subsegments = (m65.FromNeuromancer.Subsegment & lookup_key).fetch(as_dict=True)\n",
    "\n",
    "subsegment_dicts = dict([(k[\"subsegment_id\"],dict(vertices=k[\"vertices\"],faces=k[\"faces\"])) for k in subsegments])\n",
    "\n",
    "subsegment_ordered_list = np.sort(np.array(list(subsegment_dicts.keys())))\n",
    "subsegments_vertices = [subsegment_dicts[k][\"vertices\"] for k in subsegment_ordered_list]\n",
    "subsegments_faces = [subsegment_dicts[k][\"faces\"] for k in subsegment_ordered_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 46 subsegements \n",
      "  --> final mesh: 1252162 vertices and 2390205 faces\n"
     ]
    }
   ],
   "source": [
    "# creating the entire mesh from the main mesh and all of its sub meshes: \n",
    "new_mesh_vertices, new_mesh_faces = add_mesh_piece(main_mesh_vertices=n[\"vertices\"],\n",
    "                   main_mesh_faces=n[\"faces\"],\n",
    "                   sub_mesh_vertices = subsegments_vertices,\n",
    "                   sub_mesh_faces=subsegments_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Meshlab and CGAL algorithms to extract the mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'_orig'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"_orig_inal.off\"\n",
    "indices = [i for i, a in enumerate(s) if a == \"_\"]\n",
    "print(indices)\n",
    "s[:-(len(s)-indices[-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "import trimesh\n",
    "original_main = trimesh.Trimesh(vertices=n[\"vertices\"],faces=n[\"faces\"])\n",
    "output_mesh_name = \"temp/\" + str(n[\"segment_id\"]) + \"_original.off\"\n",
    "original_main.export(\"./\" + output_mesh_name)\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_meshlab_script(mlx_script,input_mesh_file,output_mesh_file):\n",
    "    script_command = (\" -i \" + str(input_mesh_file) + \" -o \" + \n",
    "                                    str(output_mesh_file) + \" -s \" + str(mlx_script))\n",
    "    #return script_command\n",
    "    command_to_run = 'xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@ ' + script_command\n",
    "    #command_to_run = 'meshlabserver ' + script_command\n",
    "    \n",
    "    print(command_to_run)\n",
    "    subprocess_result = subprocess.run(command_to_run,shell=True)\n",
    "    \n",
    "    return subprocess_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, contextlib\n",
    "import pathlib\n",
    "import subprocess\n",
    "def meshlab_fix_manifold_path_specific_mls(input_path_and_filename,\n",
    "                                           output_path_and_filename=\"\",\n",
    "                                           segment_id=-1,meshlab_script=\"\"):\n",
    "    #fix the path if it comes with the extension\n",
    "    if input_path_and_filename[-4:] == \".off\":\n",
    "        path_and_filename = input_path_and_filename[:-4]\n",
    "        input_mesh = input_path_and_filename\n",
    "    else:\n",
    "        raise Exception(\"Not passed off file\")\n",
    "    \n",
    "    \n",
    "    if output_path_and_filename == \"\":\n",
    "        output_mesh = path_and_filename+\"_mls.off\"\n",
    "    else:\n",
    "        output_mesh = output_path_and_filename\n",
    "    \n",
    "    if meshlab_script == \"\":\n",
    "        meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"remeshing_remove_non_man_edges.mls\"\n",
    "    \n",
    "    #print(\"meshlab_script = \" + str(meshlab_script))\n",
    "    #print(\"starting meshlabserver fixing non-manifolds\")\n",
    "    subprocess_result_1 = run_meshlab_script(meshlab_script,\n",
    "                      input_mesh,\n",
    "                      output_mesh)\n",
    "    #print(\"Poisson subprocess_result= \"+ str(subprocess_result_1))\n",
    "    \n",
    "    if str(subprocess_result_1)[-13:] != \"returncode=0)\":\n",
    "        raise Exception('neuron' + str(segment_id) + \n",
    "                         ' did not fix the manifold edges')\n",
    "    \n",
    "    return output_mesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum_Blender/poisson_working_meshlab.mls\n",
      "/notebooks/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum_Blender/temp/107816118160698192_original.off\n",
      "/notebooks/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum_Blender/temp/107816118160698192_mls.off\n",
      "Running the mls function\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum_Blender/temp/107816118160698192_original.off -o /notebooks/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum_Blender/temp/107816118160698192_mls.off -s /notebooks/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum_Blender/poisson_working_meshlab.mls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/notebooks/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum_Blender/temp/107816118160698192_mls.off'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "# run the meshlab server script\n",
    "script_name = \"poisson_working_meshlab.mls\"\n",
    "meshlab_script_path_and_name = str(pathlib.Path.cwd()) + \"/\" + script_name\n",
    "input_path =str(pathlib.Path.cwd()) + \"/\" +  output_mesh_name\n",
    "\n",
    "indices = [i for i, a in enumerate(input_path) if a == \"_\"]\n",
    "stripped_ending = input_path[:-(len(input_path)-indices[-1])]\n",
    "\n",
    "output_path = stripped_ending + \"_mls.off\"\n",
    "print(meshlab_script_path_and_name)\n",
    "print(input_path)\n",
    "print(output_path)\n",
    "print(\"Running the mls function\")\n",
    "meshlab_fix_manifold_path_specific_mls(input_path_and_filename=input_path,\n",
    "                                           output_path_and_filename=output_path,\n",
    "                                           segment_id=n[\"segment_id\"],\n",
    "                                           meshlab_script=meshlab_script_path_and_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The CGAL segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the mesh\n",
    "new_mesh = trimesh.load_mesh(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done exporting\n"
     ]
    }
   ],
   "source": [
    "mesh_splits = new_mesh.split(only_watertight=True)\n",
    "\n",
    "len(\"Total mesh splits = \" + str(mesh_splits))\n",
    "#get the largest mesh\n",
    "mesh_lengths = np.array([len(split.faces) for split in mesh_splits])\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.set()\n",
    "# sns.distplot(mesh_lengths)\n",
    "\n",
    "largest_index = np.where(mesh_lengths == np.max(mesh_lengths))\n",
    "largest_mesh = mesh_splits[largest_index][0]\n",
    "\n",
    "\n",
    "indices = [i for i, a in enumerate(output_path) if a == \"_\"]\n",
    "stripped_ending = output_path[:-(len(output_path)-indices[-1])]\n",
    "largest_mesh_path = stripped_ending + \"_largest_piece.off\"\n",
    "\n",
    "largest_mesh.export(largest_mesh_path)\n",
    "print(\"done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00041937828063964844\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2\n",
      "1\n",
      "Finished CGAL segmentation algorithm: 119.0459213256836\n",
      "2) Finished: Generating CGAL segmentation for neuron: 125.82241702079773\n",
      "3) Staring: Generating Graph Structure and Identifying Soma\n",
      "soma_index = 1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.17187952995300293\n",
      "5) Staring: Finding Apical Index\n",
      "Soma Index = 1\n",
      "Soma Connections = [0, 28, 15, 12, 7, 6]\n",
      "soma_80_percent = 681368.76\n",
      "Debugging the axon filter\n",
      "[(0, 679210.8), (28, 690449.6), (15, 684768.2), (12, 706800.5), (7, 685836.4), (6, 692856.0)]\n",
      "possible_Axons_filter_1 = [0]\n",
      "possible_Axons_filter_2 = []\n",
      "possible_Apical = None\n",
      "5) Finished: Finding Apical Index: 0.03493165969848633\n",
      "6) Staring: Classifying Entire Neuron\n",
      "MET AXON THRESHOLD CRITERIA but not low enough on soma for neighbor = 0\n",
      "12 = axon\n",
      "28 = axon\n",
      "6 = error\n",
      "MET AXON THRESHOLD CRITERIA but not low enough on soma for neighbor = 7\n",
      "MET AXON THRESHOLD CRITERIA but not low enough on soma for neighbor = 15\n",
      "Total Labels found = {'axon', 'unsure', 'soma', 'error'}\n",
      "6) Finished: Classifying Entire Neuron: 0.5301761627197266\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.37079668045043945\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 2.522211790084839\n"
     ]
    }
   ],
   "source": [
    "segment_id = n[\"segment_id\"]\n",
    "faces = np.array(largest_mesh.faces)\n",
    "verts = np.array(largest_mesh.vertices)\n",
    "#run the whole algorithm on the neuron to test\n",
    "verts_labels, faces_labels = extract_branches_whole_neuron(import_Off_Flag=False,segment_id=segment_id,vertices=verts,\n",
    "                     triangles=faces,pymeshfix_Flag=False,\n",
    "                     import_CGAL_Flag=False,\n",
    "                     return_Only_Labels=True,\n",
    "                     clusters=3,\n",
    "                     smoothness=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({6.0: 104613, 18.0: 40991, 5.0: 29555, 53.0: 19384, 22.0: 17449, 35.0: 15550, 28.0: 13250, 48.0: 12918, 49.0: 12676, 51.0: 12511, 38.0: 10064, 33.0: 9670, 36.0: 7854, 50.0: 7632, 25.0: 5831, 10.0: 5653, 34.0: 3588, 59.0: 3392, 57.0: 3047, 27.0: 2641, 52.0: 2522, 54.0: 2045, 60.0: 1036, 55.0: 692, 56.0: 690, 37.0: 323, 58.0: 140, 31.0: 126, 32.0: 125})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(faces_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrackedArray([1297160.16772195,  684347.53524855,  864123.49286675])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soma_faces = np.where(faces_labels == 5.0)[0]\n",
    "soma_mesh = largest_mesh.submesh([soma_faces],append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the center of the soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_center = soma_mesh.vertices.mean(axis=0).astype(\"float\")\n",
    "soma_center = soma_center/np.array([4,4,40])\n",
    "print(\"Poor man's center from just averagin vertices = \" + str(soma_center))\n",
    "print(\"Trimesh center of mass = \" + str(soma_mesh.center_mass))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
