{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPurpose: To create the skeletons for the neurons\\n-- adapted from the Neurite Skeleton that was run successfully on the Neurites\\n\\nLabels will have to pull from: \\nUndecimatedNeuronLabels\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose: To create the skeletons for the neurons\n",
    "-- adapted from the Neurite Skeleton that was run successfully on the Neurites\n",
    "\n",
    "Labels will have to pull from: \n",
    "UndecimatedNeuronLabels\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWill generate the skeletons for all of the\\nExhitatory Neurons and Orphan Neurons\\n\\nProcess: \\n1) Check which table the neuron is in\\n2) Filter away any error labels \\n3) Run pymeshfix on neuron\\n4) Run skeletonization\\n5) Write to datajoint as array\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Will generate the skeletons for all of the\n",
    "Exhitatory Neurons and Orphan Neurons\n",
    "\n",
    "Process: \n",
    "1) Check which table the neuron is in\n",
    "2) Filter away any error labels \n",
    "3) Run pymeshfix on neuron\n",
    "4) Run skeletonization\n",
    "5) Write to datajoint as array\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import time\n",
    "import pymeshfix\n",
    "import os\n",
    "import datetime\n",
    "import calcification_Module as cm\n",
    "from meshparty import trimesh_io\n",
    "import trimesh\n",
    "\n",
    "#for supressing the output\n",
    "import os, contextlib\n",
    "import pathlib\n",
    "import subprocess\n",
    "\n",
    "#for error counting\n",
    "from collections import Counter\n",
    "\n",
    "#for reading in the new raw_skeleton files\n",
    "import csv\n",
    "\n",
    "from Skeleton_Stitcher import stitch_skeleton_with_degree_check, find_skeleton_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@10.28.0.34:3306\n"
     ]
    }
   ],
   "source": [
    "#setting the address and the username\n",
    "dj.config['database.host'] = '10.28.0.34'\n",
    "dj.config['database.user'] = 'celiib'\n",
    "dj.config['database.password'] = 'newceliipass'\n",
    "dj.config['safemode']=True\n",
    "dj.config[\"display.limit\"] = 100\n",
    "\n",
    "schema = dj.schema('microns_pinky')\n",
    "pinky = dj.create_virtual_module('pinky', 'microns_pinky')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #different types of errors\n",
    "\n",
    "# #IndexError\n",
    "# print((schema.jobs & \"key_hash = '3808fc0c6b3bcd5ec7d82f4eb8ed9955'\").fetch1(\"key\",\"error_message\"))\n",
    "# #string is not a file\n",
    "# print((schema.jobs & \"key_hash = '08aa5df56afaa2fe130b05582cf9cd62'\").fetch1(\"key\",\"error_message\"))\n",
    "\n",
    "# print((schema.jobs & \"key_hash = '10c18713710c7047bb2fe919c0423b4d'\").fetch1(\"key\",\"error_message\"))\n",
    "\n",
    "# print((schema.jobs & \"key_hash = '188fa44ea025fb0d461d0330a1804295'\").fetch1(\"key\",\"error_message\"))\n",
    "\n",
    "# #then one where it is reserved but hasnt finished\n",
    "# print((schema.jobs & \"key_hash = '188fa44ea025fb0d461d0330a1804295'\").fetch1(\"key\",\"error_message\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (schema.jobs & \"table_name='__neuron_skeleton_stitched'\" \n",
    "#  & \"key_hash='5c5b8a7912e4bcedbd2eb1235797d037'\").delete()#.fetch(\"key\")#.delete()\n",
    "\n",
    "# #key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output for the skeleton edges to be stored by datajoint\n",
    "\"\"\" OLD WAY THAT DATAJOINT WAS GETTING MAD AT \n",
    "def read_skeleton(file_path):\n",
    "    with open(file_path) as f:\n",
    "        bones = list()\n",
    "        for line in f.readlines():\n",
    "            bones.append(np.array(line.split()[1:], float).reshape(-1, 3))\n",
    "    return np.array(bones)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" NEW FLAT LIST WAY\"\"\"\n",
    "#practice reading in dummy skeleton file\n",
    "def read_skeleton_flat(file_path):\n",
    "    with open(file_path) as f:\n",
    "        bones = list()\n",
    "        for line in f.readlines():\n",
    "            for r in (np.array(line.split()[1:], float).reshape(-1, 3)):\n",
    "                bones.append(r)\n",
    "            bones.append([np.nan,np.nan,np.nan])\n",
    "    return np.array(bones).astype(float)\n",
    "\n",
    "\n",
    "\"\"\" New read function: for adjusted 2 vert skeleton output\"\"\"\n",
    "def read_raw_skeleton(file_path):\n",
    "    edges = list()\n",
    "    with open(file_path) as f:\n",
    "        reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONE)\n",
    "        for i,row in enumerate(reader):\n",
    "            v1 = (float(row[1]),float(row[2]),float(row[3]))\n",
    "            v2 = (float(row[4]),float(row[5]),float(row[6]))\n",
    "            edges.append((v1,v2))\n",
    "    return np.array(edges).astype(float)\n",
    "\n",
    "def read_skeleton_revised(file_path):\n",
    "    with open(file_path) as f:\n",
    "        bones = np.array([])\n",
    "        for line in f.readlines():\n",
    "            #print(line)\n",
    "            line = (np.array(line.split()[1:], float).reshape(-1, 3))\n",
    "            #print(line[:-1])\n",
    "            #print(line[1:])\n",
    "\n",
    "            #print(bones.size)\n",
    "            if bones.size <= 0:\n",
    "                bones = np.stack((line[:-1],line[1:]),axis=1)\n",
    "            else:\n",
    "                bones = np.vstack((bones,(np.stack((line[:-1],line[1:]),axis=1))))\n",
    "            #print(bones)\n",
    "\n",
    "\n",
    "    return np.array(bones).astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure there is a temp file in the directory, if not then make one\n",
    "#if temp folder doesn't exist then create it\n",
    "if (os.path.isdir(os.getcwd() + \"/pymesh_NEURONS\")) == False:\n",
    "    os.mkdir(\"pymesh_NEURONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the output file\n",
    "##write the OFF file for the neuron\n",
    "import pathlib\n",
    "def write_Whole_Neuron_Off_file(neuron_ID,\n",
    "                                vertices=[], \n",
    "                                triangles=[],\n",
    "                                folder=\"pymesh_NEURONS\"):\n",
    "    #primary_key = dict(segmentation=1, segment_id=segment_id, decimation_ratio=0.35)\n",
    "    #vertices, triangles = (mesh_Table_35 & primary_key).fetch1('vertices', 'triangles')\n",
    "    \n",
    "    num_vertices = (len(vertices))\n",
    "    num_faces = len(triangles)\n",
    "    \n",
    "    #get the current file location\n",
    "    file_loc = pathlib.Path.cwd() / folder\n",
    "    filename = \"neuron_\" + str(neuron_ID)\n",
    "    path_and_filename = file_loc / filename\n",
    "    \n",
    "    #print(file_loc)\n",
    "    #print(path_and_filename)\n",
    "    \n",
    "    #open the file and start writing to it    \n",
    "    f = open(str(path_and_filename) + \".off\", \"w\")\n",
    "    f.write(\"OFF\\n\")\n",
    "    f.write(str(num_vertices) + \" \" + str(num_faces) + \" 0\\n\" )\n",
    "    \n",
    "    \n",
    "    #iterate through and write all of the vertices in the file\n",
    "    for verts in vertices:\n",
    "        f.write(str(verts[0]) + \" \" + str(verts[1]) + \" \" + str(verts[2])+\"\\n\")\n",
    "    \n",
    "    #print(\"Done writing verts\")\n",
    "        \n",
    "    for faces in triangles:\n",
    "        f.write(\"3 \" + str(faces[0]) + \" \" + str(faces[1]) + \" \" + str(faces[2])+\"\\n\")\n",
    "    \n",
    "    print(\"Done writing OFF file\")\n",
    "    #f.write(\"end\")\n",
    "    \n",
    "    return str(path_and_filename),str(filename),str(file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meshlab_fix_manifold(key,folder=\"pymesh_NEURONS\"):\n",
    "    \n",
    "    file_loc = pathlib.Path.cwd() / folder\n",
    "    filename = \"neuron_\" + str(key[\"segment_id\"])\n",
    "    path_and_filename = str(file_loc / filename)\n",
    "    \n",
    "    \n",
    "    input_mesh = path_and_filename + \".off\"\n",
    "    output_mesh = path_and_filename+\"_mls.off\"\n",
    "    \n",
    "    \n",
    "    meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"remeshing_remove_non_man_edges.mls\"\n",
    "    \n",
    "    print(\"starting meshlabserver fixing non-manifolds\")\n",
    "    subprocess_result_1 = run_meshlab_script(meshlab_script,\n",
    "                      input_mesh,\n",
    "                      output_mesh)\n",
    "    #print(\"Poisson subprocess_result= \"+ str(subprocess_result_1))\n",
    "    \n",
    "    if str(subprocess_result_1)[-13:] != \"returncode=0)\":\n",
    "        raise Exception('neuron' + str(key[\"segment_id\"]) + \n",
    "                         ' did not fix the manifold edges')\n",
    "    \n",
    "    return output_mesh\n",
    "\n",
    "def meshlab_fix_manifold_path(path_and_filename,segment_id=-1):\n",
    "    #fix the path if it comes with the extension\n",
    "    if path_and_filename[-4:] == \".off\":\n",
    "        path_and_filename = path_and_filename[-4:]\n",
    "    \n",
    "    input_mesh = path_and_filename + \".off\"\n",
    "    output_mesh = path_and_filename+\"_mls.off\"\n",
    "    \n",
    "    #print(\"input_mesh = \" + str(input_mesh))\n",
    "    #print(\"output_mesh = \" + str(output_mesh))\n",
    "    \n",
    "    meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"remeshing_remove_non_man_edges.mls\"\n",
    "    \n",
    "    print(\"starting meshlabserver fixing non-manifolds\")\n",
    "    subprocess_result_1 = run_meshlab_script(meshlab_script,\n",
    "                      input_mesh,\n",
    "                      output_mesh)\n",
    "    #print(\"Poisson subprocess_result= \"+ str(subprocess_result_1))\n",
    "    \n",
    "    if str(subprocess_result_1)[-13:] != \"returncode=0)\":\n",
    "        raise Exception('neuron' + str(segment_id) + \n",
    "                         ' did not fix the manifold edges')\n",
    "    \n",
    "    return output_mesh\n",
    "\n",
    "def meshlab_fix_manifold_path_specific_mls(path_and_filename,segment_id=-1,meshlab_script=\"\"):\n",
    "    #fix the path if it comes with the extension\n",
    "    if path_and_filename[-4:] == \".off\":\n",
    "        path_and_filename = path_and_filename[:-4]\n",
    "    \n",
    "    input_mesh = path_and_filename + \".off\"\n",
    "    output_mesh = path_and_filename+\"_mls.off\"\n",
    "    \n",
    "    #print(\"input_mesh = \" + str(input_mesh))\n",
    "    #print(\"output_mesh = \" + str(output_mesh))\n",
    "    if meshlab_script == \"\":\n",
    "        meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"remeshing_remove_non_man_edges.mls\"\n",
    "    \n",
    "    print(\"meshlab_script = \" + str(meshlab_script))\n",
    "    #print(\"starting meshlabserver fixing non-manifolds\")\n",
    "    subprocess_result_1 = run_meshlab_script(meshlab_script,\n",
    "                      input_mesh,\n",
    "                      output_mesh)\n",
    "    #print(\"Poisson subprocess_result= \"+ str(subprocess_result_1))\n",
    "    \n",
    "    if str(subprocess_result_1)[-13:] != \"returncode=0)\":\n",
    "        raise Exception('neuron' + str(segment_id) + \n",
    "                         ' did not fix the manifold edges')\n",
    "    \n",
    "    return output_mesh\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_meshlab_script(mlx_script,input_mesh_file,output_mesh_file):\n",
    "    script_command = (\" -i \" + str(input_mesh_file) + \" -o \" + \n",
    "                                    str(output_mesh_file) + \" -s \" + str(mlx_script))\n",
    "    #return script_command\n",
    "    print('xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@ ' + script_command)\n",
    "    subprocess_result = subprocess.run('xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@ ' + \n",
    "                   script_command,shell=True)\n",
    "    \n",
    "    return subprocess_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the skeleton stitching function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# key = dict(segmentation=3,segment_id=648518346341395072)\n",
    "\n",
    "# split_significance_threshold = 100\n",
    "\n",
    "# global_time = time.time()\n",
    "# #get the mesh with the error segments filtered away\n",
    "# start_time = time.time()\n",
    "# print(str(key['segment_id']) +  \":\")\n",
    "# my_dict = (pinky.Mesh & pinky.Neurite.proj() & pinky.CurrentSegmentation\n",
    "#                    & key).fetch1()\n",
    "# print(f\"Step 1: Retrieving Mesh and removing error segments: {time.time() - start_time}\")\n",
    "# new_key = dict(segmentation=key[\"segmentation\"],\n",
    "#                segment_id=key[\"segment_id\"])\n",
    "\n",
    "\n",
    "# # Don't need these attributes      \n",
    "# #vertices=key[\"vertices\"],\n",
    "# #                       triangles=new_key[\"triangles\"],n_vertices=key[\"n_vertices\"],\n",
    "# #                       n_triangles=key[\"n_triangles\"])\n",
    "\n",
    "\n",
    "# start_time = time.time()\n",
    "# #pass the vertices and faces to pymeshfix to become watertight\n",
    "\n",
    "# mesh = trimesh_io.Mesh(vertices=my_dict[\"vertices\"], faces=my_dict[\"triangles\"])\n",
    "\n",
    "# \"\"\" OLDER WAY OF JUST GETTING THE LARGEST MESH PIECE\n",
    "# count, labels = trimesh_io.trimesh.graph.csgraph.connected_components(\n",
    "#                                                     mesh.edges_sparse,\n",
    "#                                                     directed=False,\n",
    "#                                                     return_labels=True)\n",
    "\n",
    "\n",
    "# label_counter = Counter(labels)\n",
    "\n",
    "\n",
    "# new_key[\"n_bodies\"] = count\n",
    "# values = np.array(labels)\n",
    "\n",
    "\n",
    "# list_counter = Counter(labels)\n",
    "# max_counter = max(list_counter.values())\n",
    "\n",
    "# max_label = -1\n",
    "# for label_key,label_number in list_counter.items():\n",
    "#     if label_number==max_counter:\n",
    "#         max_label = label_key\n",
    "# print(\"max label = \" + str(max_label))\n",
    "\n",
    "# searchval = max_label\n",
    "\n",
    "# ii = np.where(values == searchval)[0]\n",
    "# new_key[\"largest_mesh_perc\"] = len(ii)/len(labels)\n",
    "\n",
    "# print(\"n_bodies = \" + str(new_key[\"n_bodies\"]))\n",
    "# print(\"largest mesh perc = \" + str(new_key[\"largest_mesh_perc\"]))\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# total_splits = mesh.split(only_watertight=False)\n",
    "# print(f\"There were {len(total_splits)} after split and significance threshold\")\n",
    "# mesh_pieces = [k for k in total_splits if len(k.faces) > split_significance_threshold]\n",
    "# print(f\"There were {len(mesh_pieces)} after split and significance threshold\")\n",
    "# for g,mh in enumerate(mesh_pieces):\n",
    "#     print(f\"Mesh piece {g} with number of faces {len(mh.faces)}\")\n",
    "    \n",
    "# print(f\"Step 2a: Getting the number of splits: {time.time() - start_time}\")\n",
    "\n",
    "# #get the largest mesh piece\n",
    "# largest_mesh_index = -1\n",
    "# largest_mesh_size = 0\n",
    "\n",
    "# for t,msh in enumerate(mesh_pieces):\n",
    "#     if len(msh.faces) > largest_mesh_size:\n",
    "#         largest_mesh_index = t\n",
    "#         largest_mesh_size = len(msh.faces) \n",
    "\n",
    "# #largest mesh piece\n",
    "# largest_mesh_perc = largest_mesh_size/len(mesh.faces)\n",
    "# new_key[\"largest_mesh_perc\"] = largest_mesh_perc\n",
    "# print(\"largest mesh perc = \" + str(largest_mesh_perc))\n",
    "\n",
    "# largest_mesh_skeleton_distance = -1\n",
    "\n",
    "# paths_used = []\n",
    "# total_edges = np.array([])\n",
    "# for h,m in enumerate(mesh_pieces): \n",
    "    \n",
    "#     print(f\"Working on split {h} with face total = {len(m.faces)}\")\n",
    "\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     #pass the vertices and faces to pymeshfix to become watertight\n",
    "#     meshfix = pymeshfix.MeshFix(m.vertices,m.faces)\n",
    "#     meshfix.repair(verbose=False,joincomp=True,remove_smallest_components=False)\n",
    "#     print(f\"Step 2b: Pymesh shrinkwrapping: {time.time() - start_time}\")\n",
    "\n",
    "#     #print(\"Step 2: Writing Off File\")\n",
    "#     start_time = time.time()\n",
    "#     #write the new mesh to off file\n",
    "#     path_and_filename,filename,file_loc = write_Whole_Neuron_Off_file(str(new_key[\"segment_id\"]) + \"_piece_\" + str(h),meshfix.v,meshfix.f)\n",
    "#     print(f\"Step 3: Writing shrinkwrap off file: {time.time() - start_time}\")\n",
    "#     #add the path to be deleted later\n",
    "#     paths_used.append(path_and_filename)\n",
    "\n",
    "\n",
    "#     #Run the meshlabserver scripts\n",
    "#     start_time = time.time()\n",
    "#     output_mesh = meshlab_fix_manifold_path(path_and_filename,key[\"segment_id\"])\n",
    "#     print(f\"Step 4: Meshlab fixing non-manifolds: {time.time() - start_time}\")\n",
    "\n",
    "#     print(output_mesh[:-4])\n",
    "\n",
    "#     #send to be skeletonized\n",
    "#     start_time = time.time()\n",
    "#     return_value = cm.calcification(output_mesh[:-4])\n",
    "#     if return_value > 0:\n",
    "#         raise Exception('skeletonization for neuron ' + str(new_key[\"segment_id\"]) + \n",
    "#                         ' did not finish... exited with error code: ' + str(return_value))\n",
    "#     #print(f\"Step 5: Generating Skeleton: {time.time() - start_time}\")\n",
    "\n",
    "\n",
    "\n",
    "#     #read in the skeleton files into an array\n",
    "#     bone_array = read_skeleton_revised(output_mesh[:-4]+\"_skeleton.cgal\")\n",
    "\n",
    "#     #print(bone_array)\n",
    "#     if len(bone_array) <= 0:\n",
    "#         raise Exception('No skeleton generated for ' + str(new_key[\"segment_id\"]))\n",
    "#     print(f\"Step 5: Generating and reading Skeleton: {time.time() - start_time}\")\n",
    "\n",
    "#     #get the largest mesh skeleton distance\n",
    "#     if h == largest_mesh_index:\n",
    "#         largest_mesh_skeleton_distance = find_skeleton_distance(bone_array)\n",
    "\n",
    "#     #add the skeleton edges to the total edges\n",
    "#     if not total_edges.any():\n",
    "#         total_edges = bone_array\n",
    "#     else:\n",
    "#         total_edges = np.vstack([total_edges,bone_array])\n",
    "\n",
    "    \n",
    "\n",
    "# total_edges_stitched = stitch_skeleton_with_degree_check(total_edges)\n",
    "\n",
    "# #get the total skeleton distance for the stitched skeleton\n",
    "# total_skeleton_distance = find_skeleton_distance(total_edges_stitched)\n",
    "\n",
    "# largest_mesh_distance_perc = largest_mesh_skeleton_distance/total_skeleton_distance\n",
    "\n",
    "\n",
    "# start_time = time.time()\n",
    "# new_key[\"n_edges\"] = len(total_edges_stitched)\n",
    "# new_key[\"edges\"] = bone_array\n",
    "# new_key[\"n_bodies\"] = len(total_splits)\n",
    "# new_key[\"n_bodies_stitched\"] = len(mesh_pieces)\n",
    "# new_key[\"largest_mesh_perc\"] = largest_mesh_perc\n",
    "# new_key[\"largest_mesh_distance_perc\"] = largest_mesh_distance_perc\n",
    "\n",
    "# #self.insert1(new_key,skip_duplicates=True)\n",
    "# print(f\"Step 6: Inserting dictionary: {time.time() - start_time}\")\n",
    "# #raise Exception(\"done with one neuron\")\n",
    "# for path_and_filename in paths_used:\n",
    "#     os.system(\"rm \"+str(path_and_filename)+\"*\")\n",
    "\n",
    "# print(f\"Total time: {time.time() - global_time}\")\n",
    "# print(\"\\n\\n\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Undecimated Mesh Coarse and Overlayed Labels\n",
      "-> pinky.Mesh\n",
      "---\n",
      "coarse_vertices_labels : longblob                     # vertex labels for the base compartments\n",
      "coarse_triangles_labels : longblob                     # traingle labels for the base compartments\n",
      "overlay_vertices_labels : longblob                     # vertex labels for the spine compartments overlayed over the base compartments\n",
      "overlay_triangles_labels : longblob                     # triangles labels for the spine compartments overlayed over the base compartments\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Undecimated Mesh Coarse and Overlayed Labels\\n-> pinky.Mesh\\n---\\ncoarse_vertices_labels : longblob                     # vertex labels for the base compartments\\ncoarse_triangles_labels : longblob                     # traingle labels for the base compartments\\noverlay_vertices_labels : longblob                     # vertex labels for the spine compartments overlayed over the base compartments\\noverlay_triangles_labels : longblob                     # triangles labels for the spine compartments overlayed over the base compartments\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinky.UndecimatedNeuronLabels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 7 1 2]\n",
      "[ 5  5  2  3 10]\n"
     ]
    }
   ],
   "source": [
    "coarse_test = np.array([4,5,5,5,5,6,7,1,2,10])\n",
    "spine_test = np.array([12,13,5,5,14,15,2,3,10,2])\n",
    "\n",
    "non_errors = coarse_test != 10\n",
    "non_spines = spine_test<12\n",
    "\n",
    "total_mesh_mask = np.logical_and(non_errors,non_spines)\n",
    "total_mesh_mask\n",
    "\n",
    "#get the indices \n",
    "total_indices = np.linspace(0,len(coarse_test)-1,len(coarse_test)).astype(\"int\")\n",
    "face_indexes = total_indices[total_mesh_mask]\n",
    "\n",
    "print(coarse_test[face_indexes])\n",
    "print(spine_test[face_indexes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function submesh in module trimesh.base:\n",
      "\n",
      "submesh(self, faces_sequence, **kwargs)\n",
      "    Return a subset of the mesh.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    faces_sequence : sequence (m,) int\n",
      "      Face indices of mesh\n",
      "    only_watertight : bool\n",
      "      Only return submeshes which are watertight\n",
      "    append : bool\n",
      "      Return a single mesh which has the faces appended.\n",
      "      if this flag is set, only_watertight is ignored\n",
      "    \n",
      "    Returns\n",
      "    ---------\n",
      "    if append : trimesh.Trimesh object\n",
      "    else :      list of trimesh.Trimesh objects\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(trimesh.Trimesh.submesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mesh_minus_errors_and_spines(key):\n",
    "    \"\"\"\n",
    "    Will retrieve the mesh from the database\n",
    "    Retrieve the labels and then subtract the spines and error segments\n",
    "    from the mesh to get a suitable submesh\n",
    "    \"\"\"\n",
    "    \n",
    "    #get the mesh\n",
    "    verts,faces = (pinky.Mesh & key).fetch1(\"vertices\",\"triangles\")\n",
    "    \n",
    "    coarse_triangles_labels,overlay_triangles_labels = (pinky.UndecimatedNeuronLabels &\n",
    "                                                           key).fetch1(\"coarse_triangles_labels\",\"overlay_triangles_labels\")\n",
    "    \n",
    "    #get the mask that will filter out errors and \n",
    "    non_errors = coarse_triangles_labels != 10\n",
    "    non_spines = overlay_triangles_labels<12\n",
    "    \n",
    "    total_mesh_mask = np.logical_and(non_errors,non_spines)\n",
    "    \n",
    "    total_indices = np.linspace(0,len(coarse_triangles_labels)-1,len(coarse_triangles_labels)).astype(\"int\")\n",
    "    face_indexes = total_indices[total_mesh_mask]\n",
    "    \n",
    "    #check to see if the face_indexes is empty\n",
    "    if not face_indexes.any():\n",
    "        #create an empty mesh\n",
    "        current_mesh = trimesh.Trimesh(np.array([]),np.array([]),process=False)\n",
    "        return current_mesh,np.array([])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #get a trimesh object of this mesh and return the submesh\n",
    "    current_mesh = trimesh.Trimesh(verts,faces,process=False)\n",
    "    new_mesh = current_mesh.submesh([face_indexes],only_watertight=False,append=True)\n",
    "    return new_mesh,face_indexes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different types of errors\n",
    "\n",
    "#IndexError\n",
    "#######print((schema.jobs & \"key_hash = '3808fc0c6b3bcd5ec7d82f4eb8ed9955'\").fetch1(\"key\",\"error_message\"))\n",
    "#string is not a file\n",
    "#print((schema.jobs & \"key_hash = '08aa5df56afaa2fe130b05582cf9cd62'\").fetch1(\"key\",\"error_message\"))\n",
    "\n",
    "#print((schema.jobs & \"key_hash = '09c57a9a9ce51ad14acc9a89abce05a0'\").fetch1(\"key\",\"error_message\"))\n",
    "\n",
    "#print((schema.jobs & \"key_hash = '11d28c04739ffed6715289f434fd8d5b'\").fetch1(\"key\",\"error_message\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#schema.jobs & \"timestamp>'2019-07-14 10:00:00'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the schema so can run it again\n",
    "#(schema.jobs & \"key_hash = '11d28c04739ffed6715289f434fd8d5b'\").delete()#.fetch1(\"key\",\"error_message\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(schema.jobs & \"table_name='__neuron_skeleton_stitched'\").delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pymeshfix import _meshfix\n",
    "import pymeshfix\n",
    "\n",
    "def clean_from_arrays_celii(v, f, verbose=False, joincomp=False,\n",
    "                      remove_smallest_components=True,clean=True):\n",
    "    \"\"\"\n",
    "    Performs default cleaning procedure on vertex and face arrays\n",
    "    Returns cleaned vertex and face arrays\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    v : numpy.ndarray\n",
    "        Numpy n x 3 array of vertices\n",
    "    f : numpy.ndarray\n",
    "        Numpy n x 3 array of faces.\n",
    "    verbose : bool, optional\n",
    "        Prints progress to stdout.  Default True.\n",
    "    joincomp : bool, optional\n",
    "        Attempts to join nearby open components.  Default False\n",
    "    remove_smallest_components : bool, optional\n",
    "        Remove all but the largest isolated component from the mesh\n",
    "        before beginning the repair process.  Default True.\n",
    "    Examples\n",
    "    --------\n",
    "    >>>\n",
    "    >>> CleanFromFile('inmesh.ply', 'outmesh.ply')\n",
    "    \"\"\"\n",
    "    # Create mesh object and load from file\n",
    "    tin = _meshfix.PyTMesh(verbose)\n",
    "    tin.load_array(v, f)\n",
    "\n",
    "    # repari and return vertex and face arrays\n",
    "    repair_celii(tin, verbose, joincomp, remove_smallest_components,clean)\n",
    "    return tin.return_arrays()\n",
    "\n",
    "#what the repair function does: \n",
    "def repair_celii(tin, verbose=False, joincomp=True, remove_smallest_components=True,clean=True):\n",
    "    \"\"\"\n",
    "    Performs mesh repair using default cleaning procedure using a tin object.\n",
    "    Internal function.  Use CleanFromFile or CleanFromVF.\n",
    "    \"\"\"\n",
    "\n",
    "    # Keep only the largest component (i.e. with most triangles)\n",
    "    if remove_smallest_components:\n",
    "        sc = tin.remove_smallest_components()\n",
    "        if sc and verbose:\n",
    "            print('Removed %d small components' % sc)\n",
    "\n",
    "    # join closest components\n",
    "    if joincomp:\n",
    "        tin.join_closest_components()\n",
    "    \n",
    "    if tin.boundaries():\n",
    "        if verbose:\n",
    "            print('Patching holes...')\n",
    "        holespatched = tin.fill_small_boundaries()\n",
    "        if verbose:\n",
    "            print('Patched %d holes' % holespatched)\n",
    "    \n",
    "    \n",
    "        \n",
    "    tin.boundaries()\n",
    "    if clean == True:\n",
    "        # Perform mesh cleaning\n",
    "        if verbose:\n",
    "            print('Fixing degeneracies and intersections')\n",
    "        result = tin.clean()\n",
    "    else:\n",
    "        print(\"Skipping the degenerative cleaning\")\n",
    "        result = False\n",
    "\n",
    "    # Check boundaries again\n",
    "    if tin.boundaries():\n",
    "        if verbose:\n",
    "            print('Patching holes...')\n",
    "        holespatched = tin.fill_small_boundaries()\n",
    "        if verbose:\n",
    "            print('Patched %d holes' % holespatched)\n",
    "    \n",
    "        if verbose:\n",
    "            print('Performing final check...')\n",
    "        if clean == True:\n",
    "            if verbose:\n",
    "                print('Fixing degeneracies and intersections')\n",
    "            result = tin.clean()\n",
    "        else:\n",
    "            print(\"Skipping the degenerative cleaning\")\n",
    "            result = False\n",
    "\n",
    "    if result:\n",
    "        warnings.warn('MeshFix could not fix everything')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class NeuronSkeletonStitched(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> pinky.Mesh\n",
    "    ---\n",
    "    n_edges   :int unsigned #number of edges stored\n",
    "    edges     :longblob #array storing edges on each row\n",
    "    n_bodies    :int unsigned #the amount of segments the neurite was originally split into\n",
    "    n_bodies_stitched  :int unsigned #the amount of segments whose skeletons were stitched back together (aka above the significance threshold)\n",
    "    largest_mesh_perc : float #number of faces of largest submesh / number of faces of entire skeletal mesh\n",
    "    largest_mesh_distance_perc : float #skeleton length of largest submesh / skeleton length of entire stitched mesh\n",
    "    n_faces_in_filtered : int unsigned #number of faces in the mesh after spines and errors filtered away\n",
    "    faces_in_filtered : longblob #array storing face indices used for submesh once errors and spines removed\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    key_source = ((dj.U(\"segmentation\",\"segment_id\") & pinky.CoarseLabelFinal.proj()) \n",
    "     + (dj.U(\"segmentation\",\"segment_id\") & pinky.CoarseLabelOrphan.proj())) & \"segment_id=648518346349473838\"\n",
    "    \n",
    "    def make(self, key):\n",
    "        print(\"----------Working on \" + str(key['segment_id']) +  \":----------\")\n",
    "        \n",
    "        split_significance_threshold = 200\n",
    "\n",
    "        global_time = time.time()\n",
    "        \n",
    "        #get the mesh with the error segments filtered away\n",
    "        start_time = time.time()\n",
    "        \n",
    "        \n",
    "        mesh,face_indexes = get_mesh_minus_errors_and_spines(key)\n",
    "        \n",
    "        new_key = dict(segmentation=key[\"segmentation\"],\n",
    "                           segment_id=key[\"segment_id\"])\n",
    "        \n",
    "        \"\"\"\n",
    "        Handle the poosibility that there is no mesh\n",
    "        \"\"\"\n",
    "        if len(mesh.faces) < 50:\n",
    "            print(f\"There were only {len(mesh.faces)} faces in mesh so not doing skeletonization\")\n",
    "            new_key[\"n_edges\"] = 0\n",
    "            new_key[\"edges\"] = np.array([]).astype(float)\n",
    "            new_key[\"n_bodies\"] = 0\n",
    "            new_key[\"n_bodies_stitched\"] = 0\n",
    "            new_key[\"largest_mesh_perc\"] = 0\n",
    "            new_key[\"largest_mesh_distance_perc\"] = 0\n",
    "            new_key[\"n_faces_in_filtered\"] = len(face_indexes)\n",
    "            new_key[\"faces_in_filtered\"] = face_indexes\n",
    "            \n",
    "            self.insert1(new_key,skip_duplicates=True)\n",
    "        else:\n",
    "\n",
    "\n",
    "            print(f\"Step 1: Retrieving Mesh and removing error segments: {time.time() - start_time}\")\n",
    "            \n",
    "\n",
    "\n",
    "            # Don't need these attributes      \n",
    "            #vertices=key[\"vertices\"],\n",
    "            #                       triangles=new_key[\"triangles\"],n_vertices=key[\"n_vertices\"],\n",
    "            #                       n_triangles=key[\"n_triangles\"])\n",
    "\n",
    "\n",
    "            start_time = time.time()\n",
    "            \n",
    "            \"\"\" OLDER WAY OF JUST GETTING THE LARGEST MESH PIECE\n",
    "            count, labels = trimesh_io.trimesh.graph.csgraph.connected_components(\n",
    "                                                                mesh.edges_sparse,\n",
    "                                                                directed=False,\n",
    "                                                                return_labels=True)\n",
    "\n",
    "\n",
    "            label_counter = Counter(labels)\n",
    "\n",
    "\n",
    "            new_key[\"n_bodies\"] = count\n",
    "            values = np.array(labels)\n",
    "\n",
    "\n",
    "            list_counter = Counter(labels)\n",
    "            max_counter = max(list_counter.values())\n",
    "\n",
    "            max_label = -1\n",
    "            for label_key,label_number in list_counter.items():\n",
    "                if label_number==max_counter:\n",
    "                    max_label = label_key\n",
    "            print(\"max label = \" + str(max_label))\n",
    "\n",
    "            searchval = max_label\n",
    "\n",
    "            ii = np.where(values == searchval)[0]\n",
    "            new_key[\"largest_mesh_perc\"] = len(ii)/len(labels)\n",
    "\n",
    "            print(\"n_bodies = \" + str(new_key[\"n_bodies\"]))\n",
    "            print(\"largest mesh perc = \" + str(new_key[\"largest_mesh_perc\"]))\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "            total_splits = mesh.split(only_watertight=False)\n",
    "            print(f\"There were {len(total_splits)} after split and significance threshold\")\n",
    "            mesh_pieces = [k for k in total_splits if len(k.faces) > split_significance_threshold]\n",
    "            print(f\"There were {len(mesh_pieces)} after split and significance threshold\")\n",
    "            for g,mh in enumerate(mesh_pieces):\n",
    "                print(f\"Mesh piece {g} with number of faces {len(mh.faces)}\")\n",
    "\n",
    "            print(f\"Step 2a: Getting the number of splits: {time.time() - start_time}\")\n",
    "\n",
    "            #get the largest mesh piece\n",
    "            largest_mesh_index = -1\n",
    "            largest_mesh_size = 0\n",
    "\n",
    "            for t,msh in enumerate(mesh_pieces):\n",
    "                if len(msh.faces) > largest_mesh_size:\n",
    "                    largest_mesh_index = t\n",
    "                    largest_mesh_size = len(msh.faces) \n",
    "\n",
    "            #largest mesh piece\n",
    "            largest_mesh_perc = largest_mesh_size/len(mesh.faces)\n",
    "            new_key[\"largest_mesh_perc\"] = largest_mesh_perc\n",
    "            print(\"largest mesh perc = \" + str(largest_mesh_perc))\n",
    "\n",
    "            largest_mesh_skeleton_distance = -1\n",
    "\n",
    "            paths_used = []\n",
    "            total_edges = np.array([])\n",
    "            for h,m in enumerate(mesh_pieces): \n",
    "                print(f\"Working on split {h} with face total = {len(m.faces)}\")\n",
    "\n",
    "\n",
    "    #             start_time = time.time()\n",
    "    #             #pass the vertices and faces to pymeshfix to become watertight\n",
    "    #             meshfix = pymeshfix.MeshFix(m.vertices,m.faces)\n",
    "    #             meshfix.repair(verbose=False,joincomp=True,remove_smallest_components=False)\n",
    "    #             print(f\"Step 2b: Pymesh shrinkwrapping: {time.time() - start_time}\")\n",
    "\n",
    "    #             #print(\"Step 2: Writing Off File\")\n",
    "    #             start_time = time.time()\n",
    "    #             #write the new mesh to off file\n",
    "    #             path_and_filename,filename,file_loc = write_Whole_Neuron_Off_file(str(new_key[\"segment_id\"]) + \"_piece_\" + str(h),meshfix.v,meshfix.f)\n",
    "    #             print(f\"Step 3: Writing shrinkwrap off file: {time.time() - start_time}\")\n",
    "                #add the path to be deleted later\n",
    "        \n",
    "                #send the data through the hole patching function from pymesh:\n",
    "                cleaned_verts, cleaned_triangles= clean_from_arrays_celii(m.vertices,m.faces,verbose=True,joincomp=True,remove_smallest_components=False,clean=False)\n",
    "                #cleaned_mesh = make_trimesh_object(m.vertices,m.faces)\n",
    "            \n",
    "            \n",
    "        \n",
    "                path_and_filename,filename,file_loc = write_Whole_Neuron_Off_file(str(new_key[\"segment_id\"]) + \"_piece_\" + str(h),cleaned_verts, cleaned_triangles)\n",
    "\n",
    "                paths_used.append(path_and_filename)\n",
    "\n",
    "\n",
    "                #Run the meshlabserver scripts\n",
    "                start_time = time.time()\n",
    "\n",
    "                #output_mesh = meshlab_fix_manifold_path(path_and_filename,key[\"segment_id\"])\n",
    "                meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"pymesh_fix_substitute_2.mls\"\n",
    "                output_mesh = meshlab_fix_manifold_path_specific_mls(path_and_filename,key[\"segment_id\"],meshlab_script)\n",
    "                \n",
    "                \n",
    "                meshlab_script_2 = str(pathlib.Path.cwd()) + \"/\" + \"remove_intersecting_faces.mls\"\n",
    "                output_mesh = meshlab_fix_manifold_path_specific_mls(output_mesh,key[\"segment_id\"],meshlab_script_2)\n",
    "                \n",
    "                print(\"About to run pymeshfix\")\n",
    "                start_time_py = time.time()\n",
    "                loaded_mesh = trimesh.load_mesh(output_mesh,process=False)\n",
    "                meshfix = pymeshfix.MeshFix(loaded_mesh.vertices,loaded_mesh.faces)\n",
    "                meshfix.repair(verbose=False,joincomp=True,remove_smallest_components=False)\n",
    "                print(f\"Total time for pymeshfix = {time.time() - start_time_py}\")\n",
    "                \n",
    "                path_and_filename,filename,file_loc = write_Whole_Neuron_Off_file(str(new_key[\"segment_id\"]) + \"_piece_\" + str(h),meshfix.v, meshfix.f)\n",
    "                \n",
    "                \n",
    "                print(f\"Step 4: Meshlab fixing non-manifolds: {time.time() - start_time}\")\n",
    "\n",
    "                print(path_and_filename)\n",
    "\n",
    "                #send to be skeletonized\n",
    "                start_time = time.time()\n",
    "\n",
    "                mls_mesh = trimesh.load_mesh(path_and_filename + \".off\")\n",
    "\n",
    "                if len(mls_mesh.faces) < 20:\n",
    "                    print(\"Number of faces are less than 20 so not generating skeleton\")\n",
    "                    continue\n",
    "\n",
    "                return_value = cm.calcification(path_and_filename)\n",
    "                if return_value > 0:\n",
    "                    raise Exception('skeletonization for neuron ' + str(new_key[\"segment_id\"]) + \n",
    "                                    ' did not finish... exited with error code: ' + str(return_value))\n",
    "\n",
    "                    print(\"Trying skeletonization with pymesh\")\n",
    "\n",
    "                    #try to run the same skeletonization but now with skeletonization\n",
    "\n",
    "                    #             start_time = time.time()\n",
    "                    #pass the vertices and faces to pymeshfix to become watertight\n",
    "\n",
    "\n",
    "                    meshfix = pymeshfix.MeshFix(mls_mesh.vertices,mls_mesh.faces)\n",
    "                    meshfix.repair(verbose=False,joincomp=True,remove_smallest_components=False)\n",
    "                    print(f\"Step 2b: Pymesh shrinkwrapping: {time.time() - start_time}\")\n",
    "\n",
    "                    if len(meshfix.f) < 20:\n",
    "                        print(\"Number of faces are less than 20 so not generating skeleton\")\n",
    "                        continue\n",
    "\n",
    "                    #print(\"Step 2: Writing Off File\")\n",
    "                    start_time = time.time()\n",
    "                    #write the new mesh to off file\n",
    "                    path_and_filename,filename,file_loc = write_Whole_Neuron_Off_file(str(new_key[\"segment_id\"]) + \"_piece_\" + str(h),meshfix.v,meshfix.f)\n",
    "                    print(f\"Step 3: Writing shrinkwrap off file: {time.time() - start_time}\")\n",
    "                    #add the path to be deleted later\n",
    "                    paths_used.append(path_and_filename)\n",
    "\n",
    "                    #Run the meshlabserver scripts\n",
    "                    start_time = time.time()\n",
    "\n",
    "                    #output_mesh = meshlab_fix_manifold_path(path_and_filename,key[\"segment_id\"])\n",
    "                    meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"pymesh_fix_substitute_2.mls\"\n",
    "                    output_mesh = meshlab_fix_manifold_path_specific_mls(path_and_filename,key[\"segment_id\"],meshlab_script)\n",
    "                    \n",
    "\n",
    "                    print(f\"Step 4: Meshlab fixing non-manifolds: {time.time() - start_time}\")\n",
    "\n",
    "                    #print(output_mesh[:-4])\n",
    "\n",
    "                    #send to be skeletonized\n",
    "                    start_time = time.time()\n",
    "\n",
    "                    mls_mesh = trimesh.load_mesh(output_mesh)\n",
    "\n",
    "                    if len(mls_mesh.faces) < 20:\n",
    "                        print(\"Number of faces are less than 20 so not generating skeleton\")\n",
    "                        continue\n",
    "\n",
    "                    return_value = cm.calcification(output_mesh[:-4])\n",
    "\n",
    "                    if return_value > 0:\n",
    "                        raise Exception('skeletonization for neuron ' + str(new_key[\"segment_id\"]) + \n",
    "                                    ' did not finish EVEN AFTER TRYING PYMESH... exited with error code: ' + str(return_value))\n",
    "\n",
    "\n",
    "\n",
    "                print(f\"Step 5: Generating Skeleton: {time.time() - start_time}\")\n",
    "\n",
    "\n",
    "\n",
    "                #read in the skeleton files into an array\n",
    "                bone_array = read_skeleton_revised(path_and_filename+\"_skeleton.cgal\")\n",
    "\n",
    "                #print(bone_array)\n",
    "                if len(bone_array) <= 0:\n",
    "                    raise Exception('No skeleton generated for ' + str(new_key[\"segment_id\"]))\n",
    "                print(f\"Step 5: Generating and reading Skeleton: {time.time() - start_time}\")\n",
    "\n",
    "                #get the largest mesh skeleton distance\n",
    "                if h == largest_mesh_index:\n",
    "                    largest_mesh_skeleton_distance = find_skeleton_distance(bone_array)\n",
    "\n",
    "                #add the skeleton edges to the total edges\n",
    "                if not total_edges.any():\n",
    "                    total_edges = bone_array\n",
    "                else:\n",
    "                    total_edges = np.vstack([total_edges,bone_array])\n",
    "\n",
    "\n",
    "            total_edges_stitched = stitch_skeleton_with_degree_check(total_edges)\n",
    "\n",
    "            #get the total skeleton distance for the stitched skeleton\n",
    "            total_skeleton_distance = find_skeleton_distance(total_edges_stitched)\n",
    "\n",
    "            largest_mesh_distance_perc = largest_mesh_skeleton_distance/total_skeleton_distance\n",
    "\n",
    "\n",
    "            start_time = time.time()\n",
    "            new_key[\"n_edges\"] = len(total_edges_stitched)\n",
    "            new_key[\"edges\"] = total_edges_stitched\n",
    "            new_key[\"n_bodies\"] = len(total_splits)\n",
    "            new_key[\"n_bodies_stitched\"] = len(mesh_pieces)\n",
    "            new_key[\"largest_mesh_perc\"] = largest_mesh_perc\n",
    "            new_key[\"largest_mesh_distance_perc\"] = largest_mesh_distance_perc\n",
    "            new_key[\"n_faces_in_filtered\"] = len(face_indexes)\n",
    "            new_key[\"faces_in_filtered\"] = face_indexes\n",
    "            \n",
    "            #print(\"new_key=\" + str(new_key))\n",
    "\n",
    "            self.insert1(new_key,skip_duplicates=True)\n",
    "            print(f\"Step 6: Inserting dictionary: {time.time() - start_time}\")\n",
    "            #raise Exception(\"done with one neuron\")\n",
    "            for path_and_filename in paths_used:\n",
    "                os.system(\"rm \"+str(path_and_filename)+\"*\")\n",
    "\n",
    "            print(f\"Total time: {time.time() - global_time}\")\n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "        \n",
    "\n",
    "                         \n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(schema.jobs & \"table_name='__neuron_skeleton_stitched'\" & \"status='error'\").delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NeuronSkeletonStitched & \"segment_id=neuron648518346349487734\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neuron to test\n",
    "#648518346349473838"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Working on 648518346349473838:----------\n",
      "Step 1: Retrieving Mesh and removing error segments: 2.0414159297943115\n",
      "There were 907 after split and significance threshold\n",
      "There were 9 after split and significance threshold\n",
      "Mesh piece 0 with number of faces 1124983\n",
      "Mesh piece 1 with number of faces 672\n",
      "Mesh piece 2 with number of faces 14642\n",
      "Mesh piece 3 with number of faces 9930\n",
      "Mesh piece 4 with number of faces 11538\n",
      "Mesh piece 5 with number of faces 680\n",
      "Mesh piece 6 with number of faces 240\n",
      "Mesh piece 7 with number of faces 618\n",
      "Mesh piece 8 with number of faces 297\n",
      "Step 2a: Getting the number of splits: 1.6297035217285156\n",
      "largest mesh perc = 0.9641725217820577\n",
      "Working on split 0 with face total = 1124983\n",
      "Patching holes...\n",
      "Patched 2257 holes\n",
      "Skipping the degenerative cleaning\n",
      "Done writing OFF file\n",
      "meshlab_script = /notebooks/Pass_2_Sk_Neurons_Final/pymesh_fix_substitute_2.mls\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_0.off -o /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_0_mls.off -s /notebooks/Pass_2_Sk_Neurons_Final/pymesh_fix_substitute_2.mls\n",
      "meshlab_script = /notebooks/Pass_2_Sk_Neurons_Final/remove_intersecting_faces.mls\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_0_mls.off -o /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_0_mls_mls.off -s /notebooks/Pass_2_Sk_Neurons_Final/remove_intersecting_faces.mls\n",
      "About to run pymeshfix\n",
      "Total time for pymeshfix = 281.07249665260315\n",
      "Done writing OFF file\n",
      "Step 4: Meshlab fixing non-manifolds: 452.2543683052063\n",
      "/notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_0\n",
      "Step 5: Generating Skeleton: 49.94156241416931\n",
      "Step 5: Generating and reading Skeleton: 50.03069829940796\n",
      "Working on split 1 with face total = 672\n",
      "Patching holes...\n",
      "Patched 2 holes\n",
      "Skipping the degenerative cleaning\n",
      "Done writing OFF file\n",
      "meshlab_script = /notebooks/Pass_2_Sk_Neurons_Final/pymesh_fix_substitute_2.mls\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_1.off -o /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_1_mls.off -s /notebooks/Pass_2_Sk_Neurons_Final/pymesh_fix_substitute_2.mls\n",
      "meshlab_script = /notebooks/Pass_2_Sk_Neurons_Final/remove_intersecting_faces.mls\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_1_mls.off -o /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_1_mls_mls.off -s /notebooks/Pass_2_Sk_Neurons_Final/remove_intersecting_faces.mls\n",
      "About to run pymeshfix\n",
      "Total time for pymeshfix = 0.021889448165893555\n",
      "Done writing OFF file\n",
      "Step 4: Meshlab fixing non-manifolds: 1.6013879776000977\n",
      "/notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_1\n",
      "Step 5: Generating Skeleton: 0.05852508544921875\n",
      "Step 5: Generating and reading Skeleton: 0.059309959411621094\n",
      "Working on split 2 with face total = 14642\n",
      "Patching holes...\n",
      "Patched 64 holes\n",
      "Skipping the degenerative cleaning\n",
      "Done writing OFF file\n",
      "meshlab_script = /notebooks/Pass_2_Sk_Neurons_Final/pymesh_fix_substitute_2.mls\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_2.off -o /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_2_mls.off -s /notebooks/Pass_2_Sk_Neurons_Final/pymesh_fix_substitute_2.mls\n",
      "meshlab_script = /notebooks/Pass_2_Sk_Neurons_Final/remove_intersecting_faces.mls\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_2_mls.off -o /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_2_mls_mls.off -s /notebooks/Pass_2_Sk_Neurons_Final/remove_intersecting_faces.mls\n",
      "About to run pymeshfix\n",
      "Total time for pymeshfix = 0.38190770149230957\n",
      "Done writing OFF file\n",
      "Step 4: Meshlab fixing non-manifolds: 2.8841910362243652\n",
      "/notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_2\n",
      "Step 5: Generating Skeleton: 0.41762590408325195\n",
      "Step 5: Generating and reading Skeleton: 0.4196054935455322\n",
      "Working on split 3 with face total = 9930\n",
      "Patching holes...\n",
      "Patched 32 holes\n",
      "Skipping the degenerative cleaning\n",
      "Done writing OFF file\n",
      "meshlab_script = /notebooks/Pass_2_Sk_Neurons_Final/pymesh_fix_substitute_2.mls\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_3.off -o /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_3_mls.off -s /notebooks/Pass_2_Sk_Neurons_Final/pymesh_fix_substitute_2.mls\n",
      "meshlab_script = /notebooks/Pass_2_Sk_Neurons_Final/remove_intersecting_faces.mls\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_3_mls.off -o /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_3_mls_mls.off -s /notebooks/Pass_2_Sk_Neurons_Final/remove_intersecting_faces.mls\n",
      "About to run pymeshfix\n",
      "Total time for pymeshfix = 0.2973651885986328\n",
      "Done writing OFF file\n",
      "Step 4: Meshlab fixing non-manifolds: 2.5291500091552734\n",
      "/notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_3\n",
      "Step 5: Generating Skeleton: 0.2832794189453125\n",
      "Step 5: Generating and reading Skeleton: 0.28557491302490234\n",
      "Working on split 4 with face total = 11538\n",
      "Patching holes...\n",
      "Patched 18 holes\n",
      "Skipping the degenerative cleaning\n",
      "Done writing OFF file\n",
      "meshlab_script = /notebooks/Pass_2_Sk_Neurons_Final/pymesh_fix_substitute_2.mls\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_4.off -o /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_4_mls.off -s /notebooks/Pass_2_Sk_Neurons_Final/pymesh_fix_substitute_2.mls\n",
      "meshlab_script = /notebooks/Pass_2_Sk_Neurons_Final/remove_intersecting_faces.mls\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_4_mls.off -o /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_4_mls_mls.off -s /notebooks/Pass_2_Sk_Neurons_Final/remove_intersecting_faces.mls\n",
      "About to run pymeshfix\n",
      "Total time for pymeshfix = 0.2255232334136963\n",
      "Done writing OFF file\n",
      "Step 4: Meshlab fixing non-manifolds: 2.4529621601104736\n",
      "/notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_4\n",
      "Step 5: Generating Skeleton: 0.378312349319458\n",
      "Step 5: Generating and reading Skeleton: 0.382068395614624\n",
      "Working on split 5 with face total = 680\n",
      "Patching holes...\n",
      "Patched 1 holes\n",
      "Skipping the degenerative cleaning\n",
      "Done writing OFF file\n",
      "meshlab_script = /notebooks/Pass_2_Sk_Neurons_Final/pymesh_fix_substitute_2.mls\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_5.off -o /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_5_mls.off -s /notebooks/Pass_2_Sk_Neurons_Final/pymesh_fix_substitute_2.mls\n",
      "meshlab_script = /notebooks/Pass_2_Sk_Neurons_Final/remove_intersecting_faces.mls\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_5_mls.off -o /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_5_mls_mls.off -s /notebooks/Pass_2_Sk_Neurons_Final/remove_intersecting_faces.mls\n",
      "About to run pymeshfix\n",
      "Total time for pymeshfix = 0.019008874893188477\n",
      "Done writing OFF file\n",
      "Step 4: Meshlab fixing non-manifolds: 1.6169276237487793\n",
      "/notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_5\n",
      "Step 5: Generating Skeleton: 0.044857025146484375\n",
      "Step 5: Generating and reading Skeleton: 0.04573178291320801\n",
      "Working on split 6 with face total = 240\n",
      "Patching holes...\n",
      "Patched 1 holes\n",
      "Skipping the degenerative cleaning\n",
      "Done writing OFF file\n",
      "meshlab_script = /notebooks/Pass_2_Sk_Neurons_Final/pymesh_fix_substitute_2.mls\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_6.off -o /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_6_mls.off -s /notebooks/Pass_2_Sk_Neurons_Final/pymesh_fix_substitute_2.mls\n",
      "meshlab_script = /notebooks/Pass_2_Sk_Neurons_Final/remove_intersecting_faces.mls\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_6_mls.off -o /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_6_mls_mls.off -s /notebooks/Pass_2_Sk_Neurons_Final/remove_intersecting_faces.mls\n",
      "About to run pymeshfix\n",
      "Total time for pymeshfix = 0.010261058807373047\n",
      "Done writing OFF file\n",
      "Step 4: Meshlab fixing non-manifolds: 1.5607709884643555\n",
      "/notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_6\n",
      "Step 5: Generating Skeleton: 0.016897201538085938\n",
      "Step 5: Generating and reading Skeleton: 0.017530202865600586\n",
      "Working on split 7 with face total = 618\n",
      "Patching holes...\n",
      "Patched 2 holes\n",
      "Skipping the degenerative cleaning\n",
      "Done writing OFF file\n",
      "meshlab_script = /notebooks/Pass_2_Sk_Neurons_Final/pymesh_fix_substitute_2.mls\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_7.off -o /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_7_mls.off -s /notebooks/Pass_2_Sk_Neurons_Final/pymesh_fix_substitute_2.mls\n",
      "meshlab_script = /notebooks/Pass_2_Sk_Neurons_Final/remove_intersecting_faces.mls\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_7_mls.off -o /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_7_mls_mls.off -s /notebooks/Pass_2_Sk_Neurons_Final/remove_intersecting_faces.mls\n",
      "About to run pymeshfix\n",
      "Total time for pymeshfix = 0.01772308349609375\n",
      "Done writing OFF file\n",
      "Step 4: Meshlab fixing non-manifolds: 1.6285557746887207\n",
      "/notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_7\n",
      "Step 5: Generating Skeleton: 0.04896187782287598\n",
      "Step 5: Generating and reading Skeleton: 0.04982352256774902\n",
      "Working on split 8 with face total = 297\n",
      "Patching holes...\n",
      "Patched 1 holes\n",
      "Skipping the degenerative cleaning\n",
      "Done writing OFF file\n",
      "meshlab_script = /notebooks/Pass_2_Sk_Neurons_Final/pymesh_fix_substitute_2.mls\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_8.off -o /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_8_mls.off -s /notebooks/Pass_2_Sk_Neurons_Final/pymesh_fix_substitute_2.mls\n",
      "meshlab_script = /notebooks/Pass_2_Sk_Neurons_Final/remove_intersecting_faces.mls\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_8_mls.off -o /notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_8_mls_mls.off -s /notebooks/Pass_2_Sk_Neurons_Final/remove_intersecting_faces.mls\n",
      "About to run pymeshfix\n",
      "Total time for pymeshfix = 0.011971473693847656\n",
      "Done writing OFF file\n",
      "Step 4: Meshlab fixing non-manifolds: 1.5505948066711426\n",
      "/notebooks/Pass_2_Sk_Neurons_Final/pymesh_NEURONS/neuron_648518346349473838_piece_8\n",
      "Step 5: Generating Skeleton: 0.018514633178710938\n",
      "Step 5: Generating and reading Skeleton: 0.019165515899658203\n",
      "len_subgraphs AT BEGINNING = 9\n",
      "min_dist = 833.363930104972\n",
      "min_dist_subgraph_index = 5\n",
      "min_dist_edge_index = [1574, 1579]\n",
      "min_dist_edge = [array([433815. , 267689. ,  77883.2]), array([433966., 267529.,  78687.])]\n",
      "len_subgraphs AT END= 8\n",
      "min_dist = 1172.357982870418\n",
      "min_dist_subgraph_index = 4\n",
      "min_dist_edge_index = [1034, 1048]\n",
      "min_dist_edge = [array([418253. , 259788. ,  74893.6]), array([418785. , 259114. ,  75691.8])]\n",
      "len_subgraphs AT END= 7\n",
      "min_dist = 1367.76590102254\n",
      "min_dist_subgraph_index = 6\n",
      "min_dist_edge_index = [2194, 2249]\n",
      "min_dist_edge = [array([464625. , 294983. ,  62897.8]), array([465095. , 296266. ,  62836.2])]\n",
      "len_subgraphs AT END= 6\n",
      "min_dist = 1400.320709694748\n",
      "min_dist_subgraph_index = 5\n",
      "min_dist_edge_index = [2170, 2138]\n",
      "min_dist_edge = [array([461520. , 255968. ,  61791.6]), array([461267. , 254663. ,  62231.9])]\n",
      "len_subgraphs AT END= 5\n",
      "min_dist = 2070.8285201821996\n",
      "min_dist_subgraph_index = 4\n",
      "min_dist_edge_index = [1795, 1801]\n",
      "min_dist_edge = [array([446241. , 292882. ,  51937.6]), array([446797., 294820.,  51465.])]\n",
      "len_subgraphs AT END= 4\n",
      "min_dist = 2339.450756053651\n",
      "min_dist_subgraph_index = 3\n",
      "min_dist_edge_index = [1458, 1448]\n",
      "min_dist_edge = [array([429832., 197739.,  21718.]), array([429215. , 195658. ,  20845.2])]\n",
      "len_subgraphs AT END= 3\n",
      "min_dist = 5145.673619653699\n",
      "min_dist_subgraph_index = 1\n",
      "min_dist_edge_index = [561, 543]\n",
      "min_dist_edge = [array([371331. , 270185. ,  62498.7]), array([366629. , 268112. ,  62230.7])]\n",
      "len_subgraphs AT END= 2\n",
      "min_dist = 1267.6856905400477\n",
      "min_dist_subgraph_index = 1\n",
      "min_dist_edge_index = [146, 196]\n",
      "min_dist_edge = [array([340369., 257456.,  63052.]), array([340935. , 256705. ,  62201.9])]\n",
      "len_subgraphs AT END= 1\n",
      "Step 6: Inserting dictionary: 0.7527749538421631\n",
      "Total time: 542.9906961917877\n",
      "\n",
      "\n",
      "\n",
      "543.0837943553925\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "NeuronSkeletonStitched.populate(reserve_jobs=True)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pymeshfix import _meshfix\n",
    "# # Keep only the largest component (i.e. with most triangles)\n",
    "# def get_largest_piece(v,f,verbose=True):\n",
    "    \n",
    "\n",
    "#     # Create mesh object and load from file\n",
    "#     tin = _meshfix.PyTMesh(verbose)\n",
    "#     tin.load_array(v, f)\n",
    "\n",
    "#     sc = tin.remove_smallest_components()\n",
    "#     if sc and verbose:\n",
    "#         print('Removed %d small components' % sc)\n",
    "        \n",
    "#     return tin.return_arrays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Checking on how to make mesh work:\n",
    "# \"\"\"\n",
    "# Pseudocode:\n",
    "# 1) Import the cleaned mesh\n",
    "# 2) Get the largest mesh from it\n",
    "# 3) Write the largest mesh\n",
    "# 4) Run that through calcification\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "# cleansed_mesh = trimesh.load_mesh(\"./pymesh_NEURONS/neuron_648518346349473838_piece_0_mls_mls.off\",process=False)\n",
    "\n",
    "# v,f = get_largest_piece(cleansed_mesh.vertices,cleansed_mesh.faces,verbose=True)\n",
    "# write_Whole_Neuron_Off_file(\"test\",v,f)\n",
    "# print(\"ok\")\n",
    "                           \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #output_mesh = meshlab_fix_manifold_path(path_and_filename,key[\"segment_id\"])\n",
    "# path_and_filename = \"./pymesh_NEURONS/neuron_648518346349473838_piece_0_mls_mls.off\"\n",
    "# meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"remove_intersecting_faces.mls\"\n",
    "# output_mesh = meshlab_fix_manifold_path_specific_mls(path_and_filename,\"test\",meshlab_script)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_mesh = trimesh.load_mesh(\"./pymesh_NEURONS/neuron_648518346349473838_piece_0_mls_mls_mls.off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_mesh.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #output_mesh = meshlab_fix_manifold_path(path_and_filename,key[\"segment_id\"])\n",
    "# path_and_filename = \"./pymesh_NEURONS/neuron_648518346349473838_piece_0_mls_mls.off\"\n",
    "# meshlab_script = str(pathlib.Path.cwd()) + \"/\" + \"remove_intersecting_faces.mls\"\n",
    "# output_mesh = meshlab_fix_manifold_path_specific_mls(path_and_filename,\"test\",meshlab_script)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
